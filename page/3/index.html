

<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>第 3 页 | 帅羊羊的博客</title>
  
  <meta name="google-site-verification" content="hLu-CnRbqpthWxa76MJ-vpnGr7yMChNtTW6KA0pRMQo" />  
  
  <meta name="author" content="Shuai yy">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="帅羊羊的博客"/>

  
    <meta property="og:image" content=""/>
  
  <link href="/favicon.ico" rel="icon" type="image/x-ico">
  <link rel="alternate" href="http://zipperary.com/atom.xml" title="帅羊羊的博客" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <script src="//libs.baidu.com/jquery/1.8.0/jquery.min.js"></script>
  
  
</head>



<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">帅羊羊的博客</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/"><i class="fa fa-home"></i>首页</a></li>
	  
    
      <li><a href="/archives"><i class="fa fa-archive"></i>归档</a></li>
	  
    
      <li><a href="/resume"><i class="fa fa-user"></i>关于</a></li>
	  
    
	<li> <a href="/atom.xml"><i class="fa fa-rss"></i>RSS</a> </li>
<li> <a title="把这个链接拖到你的Chrome收藏夹工具栏中" href='javascript:(function() {
	function c() {
		var e = document.createElement("link");
		e.setAttribute("type", "text/css");
		e.setAttribute("rel", "stylesheet");
		e.setAttribute("href", f);
		e.setAttribute("class", l);
		document.body.appendChild(e)
	}
 
	function h() {
		var e = document.getElementsByClassName(l);
		for (var t = 0; t < e.length; t++) {
			document.body.removeChild(e[t])
		}
	}
 
	function p() {
		var e = document.createElement("div");
		e.setAttribute("class", a);
		document.body.appendChild(e);
		setTimeout(function() {
			document.body.removeChild(e)
		}, 100)
	}
 
	function d(e) {
		return {
			height : e.offsetHeight,
			width : e.offsetWidth
		}
	}
 
	function v(i) {
		var s = d(i);
		return s.height > e && s.height < n && s.width > t && s.width < r
	}
 
	function m(e) {
		var t = e;
		var n = 0;
		while (!!t) {
			n += t.offsetTop;
			t = t.offsetParent
		}
		return n
	}
 
	function g() {
		var e = document.documentElement;
		if (!!window.innerWidth) {
			return window.innerHeight
		} else if (e && !isNaN(e.clientHeight)) {
			return e.clientHeight
		}
		return 0
	}
 
	function y() {
		if (window.pageYOffset) {
			return window.pageYOffset
		}
		return Math.max(document.documentElement.scrollTop, document.body.scrollTop)
	}
 
	function E(e) {
		var t = m(e);
		return t >= w && t <= b + w
	}
 
	function S() {
		var e = document.createElement("audio");
		e.setAttribute("class", l);
		e.src = i;
		e.loop = false;
		e.addEventListener("canplay", function() {
			setTimeout(function() {
				x(k)
			}, 500);
			setTimeout(function() {
				N();
				p();
				for (var e = 0; e < O.length; e++) {
					T(O[e])
				}
			}, 15500)
		}, true);
		e.addEventListener("ended", function() {
			N();
			h()
		}, true);
		e.innerHTML = " <p>If you are reading this, it is because your browser does not support the audio element. We recommend that you get a new browser.</p> <p>";
		document.body.appendChild(e);
		e.play()
	}
 
	function x(e) {
		e.className += " " + s + " " + o
	}
 
	function T(e) {
		e.className += " " + s + " " + u[Math.floor(Math.random() * u.length)]
	}
 
	function N() {
		var e = document.getElementsByClassName(s);
		var t = new RegExp("\\b" + s + "\\b");
		for (var n = 0; n < e.length; ) {
			e[n].className = e[n].className.replace(t, "")
		}
	}
 
	var e = 30;
	var t = 30;
	var n = 350;
	var r = 350;
	var i = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake.mp3";
	var s = "mw-harlem_shake_me";
	var o = "im_first";
	var u = ["im_drunk", "im_baked", "im_trippin", "im_blown"];
	var a = "mw-strobe_light";
	var f = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css";
	var l = "mw_added_css";
	var b = g();
	var w = y();
	var C = document.getElementsByTagName("*");
	var k = null;
	for (var L = 0; L < C.length; L++) {
		var A = C[L];
		if (v(A)) {
			if (E(A)) {
				k = A;
				break
			}
		}
	}
	if (A === null) {
		console.warn("Could not find a node of the right size. Please try a different page.");
		return
	}
	c();
	S();
	var O = [];
	for (var L = 0; L < C.length; L++) {
		var A = C[L];
		if (v(A)) {
			O.push(A)
		}
	}
})()    '>High一下</a> </li>

  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-09-17T08:45:30.910Z"><a href="/2017/09/17/科研/2014-11-09-What-is-NP-Hard/">2017-09-17</a></time>
      
      
  
    <h1 class="title"><a href="/2017/09/17/科研/2014-11-09-What-is-NP-Hard/">什么是 P, NP, NP-complete, NP-hard</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        
    </div>

      
        <p>###相关概念<br>NP-hard（non-deterministic polynomial-time hard）</p>
<ol>
<li>P：能在多项式时间内解决</li>
<li>NP：不能在多项式时间内解决或不确定能不能在多项式时间内解决，但一旦你找到一个解，只需要多项式时间去验证这个解是正确的</li>
<li>NP-hard：如果一个问题是NP-hard，意味着可以将任意NP问题化约到这个问题。如果可以解这个问题，那么可以轻松地解任意NP问题。</li>
<li>NPC：NP完全问题，所有NP问题在多项式时间内都能化约（Reducibility）到某一NP问题，这一NP问题就是NPC问题，即解决了此NPC问题，所有NP问题也都解决了。</li>
</ol>
<p>###资料原文<br>These refer to how long it takes a program to run.  Problems in class P can be solved with algorithms that run in <strong>polynomial time</strong>.</p>
<p>Say you have an algorithm that finds the smallest integer in an array.  One way to do this is by iterating over all the integers of the array and keeping track of the smallest number you’ve seen up to that point.  Every time you look at an element, you compare it to the current minimum, and if it’s smaller, you update the minimum.</p>
<p>How long does this take?  Let’s say there are n elements in the array.  For every element the algorithm has to perform a constant number of operations.  Therefore we can say that the algorithm runs in O(n) time, or that the runtime is a linear function of how many elements are in the array.  So this algorithm runs in <strong>linear time</strong>.</p>
<p>You can also have algorithms that run in <strong>quadratic time</strong> (O(n^2)), <strong>exponential time</strong> (O(2^n)), or even <strong>logarithmic time</strong> (O(log n)).  Binary search (on a balanced tree) runs in logarithmic time because the height of the binary search tree is a logarithmic function of the number of elements in the tree.</p>
<p>If the running time is some polynomial function of the size of the input, for instance if the algorithm runs in linear time or quadratic time or cubic time, then we say the algorithm runs in <strong>polynomial time</strong> and the problem it solves is in class <strong>P</strong>.</p>
<p>###<strong>NP</strong><br>Now there are a lot of programs that don’t (necessarily) run in polynomial time on a regular computer, but do run in polynomial time on a nondeterministic Turing machine.  These programs solve problems in <strong>NP</strong>, which stands for <strong>nondeterministic polynomial time</strong>.  A nondeterministic Turing machine can do everything a regular computer can and more. This means all problems in P are also in NP.</p>
<p>An equivalent way to define NP is by pointing to the problems that can be verified in polynomial time.  This means there is not necessarily a polynomial-time way to find a solution, but once you have a solution it only takes polynomial time to verify that it is correct.</p>
<p>Some people think P = NP, which means any problem that can be verified in polynomial time can also be solved in polynomial time and vice versa.  If they could prove this, it would revolutionize computer science because people would be able to construct faster algorithms for a lot of important problems.</p>
<p>###<strong>NP-hard</strong><br>What does NP-hard mean?  A lot of times you can solve a problem by reducing it to a different problem.  I can reduce Problem B to Problem A if, given a solution to Problem A, I can easily construct a solution to Problem B.  (In this case, “easily” means “in polynomial time.”)</p>
<p>If a problem is <strong>NP-hard</strong>, this means I can reduce any problem in NP to that problem.  This means if I can solve that problem, I can easily solve any problem in NP.  If we could solve an NP-hard problem in polynomial time, this would prove P = NP.</p>
<p>###<strong>NP-complete</strong><br>A problem is <strong>NP-complete</strong> if the problem is both</p>
<ul>
<li>NP-hard, and</li>
<li>in NP.</li>
</ul>
<p>###参考资料<br>【1】<a href="http://www.quora.com/What-are-P-NP-NP-complete-and-NP-hard" target="_blank" rel="external">What are P, NP, NP-complete, and NP-hard?</a></p>

      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-09-17T08:45:30.910Z"><a href="/2017/09/17/科研/2015-03-23-Newton-QuasiNewton-Method/">2017-09-17</a></time>
      
      
  
    <h1 class="title"><a href="/2017/09/17/科研/2015-03-23-Newton-QuasiNewton-Method/">牛顿法与拟牛顿法（DFP BFGS LBFGS VLBFGS）</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        
    </div>

      
        <p>最近做LBFGS的并行，顺便把牛顿法、拟牛顿法顺理一下。</p>
<p>拟牛顿法是求解非线性优化问题最有效的方法之一。考虑无约束的极小化问题<a href="http://www.codecogs.com/eqnedit.php?latex=\min\limits_x&space;f(x)" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\min\limits_x&space;f(x)" title="\min\limits_x f(x)"></a>，假设<a href="http://www.codecogs.com/eqnedit.php?latex=f(x)" target="_blank"><img src="http://latex.codecogs.com/gif.latex?f(x)" title="f(x)"></a>为凸函数，且二阶连续可导。</p>
<p>###原始牛顿法<br>基本思想：在现有极小点估计值的附近对f(x)进行二阶泰勒展开，进而找到下一个极小点的估计值</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=x_{k&plus;1}=x_{k}-(H_k)^{-1}g_{k},&space;k=0,1,\cdots" target="_blank"><img src="http://latex.codecogs.com/gif.latex?x_{k&plus;1}=x_{k}-(H_k)^{-1}g_{k},&space;k=0,1,\cdots" title="x_{k+1}=x_{k}-(H_k)^{-1}g_{k}, k=0,1,\cdots"></a></p>
<p>牛顿法具有二次收敛性，但当目标函数非二次型时，牛顿法不能保证函数稳定地下降（缺点）。</p>
<p>###阻尼牛顿法<br>每次迭代前需要沿迭代方向<a href="http://www.codecogs.com/eqnedit.php?latex=d_k=-(H_k)^{-1}g_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?d_k=-(H_k)^{-1}g_k" title="d_k=-(H_k)^{-1}g_k"></a>做线搜索，寻求最优的步长因子<a href="http://www.codecogs.com/eqnedit.php?latex=\lambda_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\lambda_k" title="\lambda_k"></a>，即</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=\lambda_k&space;=&space;\arg\min\limits_{\lambda}&space;f(x_k&plus;\lambda&space;d_k)" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\lambda_k&space;=&space;\arg\min\limits_{\lambda}&space;f(x_k&plus;\lambda&space;d_k)" title="\lambda_k = \arg\min\limits_{\lambda} f(x_k+\lambda d_k)"></a></p>
<p>###拟牛顿法<br>基本思想：不使用二阶偏导数而构造出可以近似Hession或Hession的逆的正定对称阵，在“拟牛顿”的条件下优化目标函数。</p>
<p>先推导拟牛顿条件：在<a href="http://www.codecogs.com/eqnedit.php?latex=x_{k&plus;1}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?x_{k&plus;1}" title="x_{k+1}"></a>附近对<a href="http://www.codecogs.com/eqnedit.php?latex=f(x)" target="_blank"><img src="http://latex.codecogs.com/gif.latex?f(x)" title="f(x)"></a>做泰勒展开，取二阶近似项</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=f(x)=f(x_{k&plus;1})&plus;\nabla&space;f(x_{k&plus;1})(x-x_{k&plus;1})&plus;\frac{1}{2}(x-x_{k&plus;1})^T\nabla^2&space;f(x_{k&plus;1})(x-x_{k&plus;1})" target="_blank"><img src="http://latex.codecogs.com/gif.latex?f(x)=f(x_{k&plus;1})&plus;\nabla&space;f(x_{k&plus;1})(x-x_{k&plus;1})&plus;\frac{1}{2}(x-x_{k&plus;1})^T\nabla^2&space;f(x_{k&plus;1})(x-x_{k&plus;1})" title="f(x)=f(x_{k+1})+\nabla f(x_{k+1})(x-x_{k+1})+\frac{1}{2}(x-x_{k+1})^T\nabla^2 f(x_{k+1})(x-x_{k+1})"></a><br>推出</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=\nabla&space;f(x)\approx&space;\nabla&space;f(x_{k&plus;1})&plus;H_{k&plus;1}(x-x_{k&plus;1})" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\nabla&space;f(x)\approx&space;\nabla&space;f(x_{k&plus;1})&plus;H_{k&plus;1}(x-x_{k&plus;1})" title="\nabla f(x)\approx \nabla f(x_{k+1})+H_{k+1}(x-x_{k+1})"></a><br>取<a href="http://www.codecogs.com/eqnedit.php?latex=x=x_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?x=x_k" title="x=x_k"></a>，推出</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=g_{k&plus;1}-g_{k}\approx&space;H_{k&plus;1}(x_{k&plus;1}-x_k)" target="_blank"><img src="http://latex.codecogs.com/gif.latex?g_{k&plus;1}-g_{k}\approx&space;H_{k&plus;1}(x_{k&plus;1}-x_k)" title="g_{k+1}-g_{k}\approx H_{k+1}(x_{k+1}-x_k)"></a></p>
<p>引入记号 <a href="http://www.codecogs.com/eqnedit.php?latex=s_k=x_{k&plus;1}-x_{k},&space;y_k=g_{k&plus;1}-g_{k}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?s_k=x_{k&plus;1}-x_{k},&space;y_k=g_{k&plus;1}-g_{k}" title="s_k=x_{k+1}-x_{k}, y_k=g_{k+1}-g_{k}"></a>， 推出</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=y_k=H_{k&plus;1}s_k&space;,&space;s_k=H^{-1}_{k&plus;1}y_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?y_k=H_{k&plus;1}s_k&space;,&space;s_k=H^{-1}_{k&plus;1}y_k" title="y_k=H_{k+1}s_k , s_k=H^{-1}_{k+1}y_k"></a>(<code>拟牛顿条件</code>)</p>
<p>它迭代过程中的hession矩阵做约束，因此，对hession对近似的<a href="http://www.codecogs.com/eqnedit.php?latex=B_{k&plus;1}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?B_{k&plus;1}" title="B_{k+1}"></a>，以及对hession的逆做近似的<a href="http://www.codecogs.com/eqnedit.php?latex=D_{k&plus;1}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?D_{k&plus;1}" title="D_{k+1}"></a>，可以将</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=y_{k}=B_{k&plus;1}s_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?y_{k}=B_{k&plus;1}s_k" title="y_{k}=B_{k+1}s_k"></a> 或 <a href="http://www.codecogs.com/eqnedit.php?latex=s_{k}=D_{k&plus;1}y_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?s_{k}=D_{k&plus;1}y_k" title="s_{k}=D_{k+1}y_k"></a> 作为指导。</p>
<p>####DFP算法（Davidon–Fletcher–Powell formula）</p>
<p>核心：通过迭代的方法，对hession的逆做近似。迭代格式为</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=D_{k&plus;1}=D_k&plus;\Delta&space;D_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?D_{k&plus;1}=D_k&plus;\Delta&space;D_k" title="D_{k+1}=D_k+\Delta D_k"></a>（通常<a href="http://www.codecogs.com/eqnedit.php?latex=D_0=I" target="_blank"><img src="http://latex.codecogs.com/gif.latex?D_0=I" title="D_0=I"></a>）</p>
<p>猜想<a href="http://www.codecogs.com/eqnedit.php?latex=\Delta&space;D_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\Delta&space;D_k" title="\Delta D_k"></a>待定为<a href="http://www.codecogs.com/eqnedit.php?latex=\Delta&space;D_k=\alpha&space;\mathbf{u}&space;\mathbf{u}^{\mathrm{T}}&plus;\beta\mathbf{v}\mathbf{v}^{\mathrm{T}}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\Delta&space;D_k=\alpha&space;\mathbf{u}&space;\mathbf{u}^{\mathrm{T}}&plus;\beta\mathbf{v}\mathbf{v}^{\mathrm{T}}" title="\Delta D_k=\alpha \mathbf{u} \mathbf{u}^{\mathrm{T}}+\beta\mathbf{v}\mathbf{v}^{\mathrm{T}}"></a>（具有对称性）</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=\Rightarrow&space;s_k=D_ky_k&plus;\alpha\mathbf{u}\mathbf{u}^{\mathrm{T}}y_k&plus;\beta\mathbf{v}\mathbf{v}^{\mathrm{T}}y_k=D_ky_k&plus;(\alpha\mathbf{u}^{\mathrm{T}}y_k)\mathbf{u}&plus;(\beta\mathbf{v}^{\mathrm{T}}y_k)\mathbf{v}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\Rightarrow&space;s_k=D_ky_k&plus;\alpha\mathbf{u}\mathbf{u}^{\mathrm{T}}y_k&plus;\beta\mathbf{v}\mathbf{v}^{\mathrm{T}}y_k=D_ky_k&plus;(\alpha\mathbf{u}^{\mathrm{T}}y_k)\mathbf{u}&plus;(\beta\mathbf{v}^{\mathrm{T}}y_k)\mathbf{v}" title="\Rightarrow s_k=D_ky_k+\alpha\mathbf{u}\mathbf{u}^{\mathrm{T}}y_k+\beta\mathbf{v}\mathbf{v}^{\mathrm{T}}y_k=D_ky_k+(\alpha\mathbf{u}^{\mathrm{T}}y_k)\mathbf{u}+(\beta\mathbf{v}^{\mathrm{T}}y_k)\mathbf{v}"></a></p>
<p>括号中是数值，将其分别简单赋值为1，-1，即</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=\alpha=\frac{1}{\mathbf{u}^{\mathrm{T}}y_k},\beta=-\frac{1}{\mathbf{v}^{\mathrm{T}}y_k}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\alpha=\frac{1}{\mathbf{u}^{\mathrm{T}}y_k},\beta=-\frac{1}{\mathbf{v}^{\mathrm{T}}y_k}" title="\alpha=\frac{1}{\mathbf{u}^{\mathrm{T}}y_k},\beta=-\frac{1}{\mathbf{v}^{\mathrm{T}}y_k}"></a></p>
<p>其中向量u,v仍有待确定，由上面</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=\Rightarrow&space;\mathbf{u}-\mathbf{v}=s_k-D_ky_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\Rightarrow&space;\mathbf{u}-\mathbf{v}=s_k-D_ky_k" title="\Rightarrow \mathbf{u}-\mathbf{v}=s_k-D_ky_k"></a>（要此式成立，不妨直接取<a href="http://www.codecogs.com/eqnedit.php?latex=\mathbf{u}=s_k,\mathbf{v}=D_ky_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\mathbf{u}=s_k,\mathbf{v}=D_ky_k" title="\mathbf{u}=s_k,\mathbf{v}=D_ky_k"></a>）</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=\Rightarrow&space;\alpha=\frac{1}{s^{\mathrm{T}}_ky_k},\beta=-\frac{1}{y^{\mathrm{T}}_kD_ky_k}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\Rightarrow&space;\alpha=\frac{1}{s^{\mathrm{T}}_ky_k},\beta=-\frac{1}{y^{\mathrm{T}}_kD_ky_k}" title="\Rightarrow \alpha=\frac{1}{s^{\mathrm{T}}_ky_k},\beta=-\frac{1}{y^{\mathrm{T}}_kD_ky_k}"></a></p>
<p>至此，校正矩阵<a href="http://www.codecogs.com/eqnedit.php?latex=\Delta&space;D_k" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\Delta&space;D_k" title="\Delta D_k"></a>就已经构造出来了</p>
<p><a href="http://www.codecogs.com/eqnedit.php?latex=\Rightarrow&space;\Delta&space;D_k=\frac{s_ks_k^{\mathrm{T}}}{s_k^{\mathrm{T}}y_k}-\frac{D_ky_ky_k^{\mathrm{T}}D_k}{y_k^{\mathrm{T}}D_ky_k}" target="_blank"><img src="http://latex.codecogs.com/gif.latex?\Rightarrow&space;\Delta&space;D_k=\frac{s_ks_k^{\mathrm{T}}}{s_k^{\mathrm{T}}y_k}-\frac{D_ky_ky_k^{\mathrm{T}}D_k}{y_k^{\mathrm{T}}D_ky_k}" title="\Rightarrow \Delta D_k=\frac{s_ks_k^{\mathrm{T}}}{s_k^{\mathrm{T}}y_k}-\frac{D_ky_ky_k^{\mathrm{T}}D_k}{y_k^{\mathrm{T}}D_ky_k}"></a></p>
<p>####BFGS算法（Broyden–Fletcher–Goldfarb–Shanno algorithm）<br>核心公式的推导过程与DFP完全类似，只是互换了其中s{k}和y{k}的位置。BFGS直接逼近Hession矩阵B_k。(公式敲起来太累了，请自行推导)</p>
<p>####LBFGS算法(limited-memory BFGS)<br>不再存储完整的D_k，而是存储计算过程中的向量序列{s}，{y}。当需要矩阵D_k时，利用向量序列的计算来代替。并且，向量序列也不是全部存储，而是固定存最新的m个。</p>
<p>若要实现并行，需要同时在x与梯度（影响y的计算）那儿求一致平均。</p>
<p>###资料</p>
<p>【1】<a href="http://en.wikipedia.org/wiki/Davidon%E2%80%93Fletcher%E2%80%93Powell_formula" target="_blank" rel="external">DFP算法</a></p>
<p>【2】<a href="http://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm" target="_blank" rel="external">BFGS算法</a></p>
<p>【3】<a href="http://en.wikipedia.org/wiki/Limited-memory_BFGS" target="_blank" rel="external">LBFGS算法</a></p>
<p>【4】<a href="http://papers.nips.cc/paper/5333-large-scale-l-bfgs-using-mapreduce.pdf" target="_blank" rel="external">Large-scale L-BFGS using MapReduce</a></p>

      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-09-17T08:45:30.910Z"><a href="/2017/09/17/科研/2015-02-04-Group-Meeting/">2017-09-17</a></time>
      
      
  
    <h1 class="title"><a href="/2017/09/17/科研/2015-02-04-Group-Meeting/">大数据机器学习初探---南大李武军</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        
    </div>

      
        <p>每周的组会大概会持续2小时。如果是主讲，就需要花更多的时间去准备报告内容。之前，组会开完我就不管了，缺乏总结思考。而这样子的话实质上意义就不大了，没有内化为自己的知识，也没有什么critical thinking。从现在开始，记录每一次组会的思考。</p>
<p>常言道：亡羊补牢，为时未晚。T.T</p>
<p>###Outline</p>
<ul>
<li>Learning to Hash</li>
<li>Distributed Learning</li>
<li>Stochastic Learning</li>
</ul>
<p>有一个形象的比喻是这样说的，大数据是金矿，云计算是采矿技术，大数据机器学习是冶金技术。</p>
<p>大数据机器学习面临的挑战，一是存储，而是计算速度，三是网络。</p>
<p>哈希学习，在内存、硬盘、cpu、通信上有优势；<br>分布式学习在内存、硬盘、cpu上有优势，但会增加通信成本；随机学习在内存、硬盘、cpu方面有优势。</p>
<p>###Learning to Hash<br>主讲人：大师兄</p>
<p>最近邻搜索在大数据背景下，会出现维数灾难，存储成本也高，查询速度也慢。解决方法之一是保相似性哈希，可以降低维数并减少存储成本。通常用海明距离（hamming distance）来表征哈希值之间的差异。哈希方案也具有较快的查询速度，通常具有常数或者次线性的搜索时间复杂度；即使是穷举搜索也可以被接受，因为海明距离计算起来是很快的。</p>
<p>哈希函数学习的两个阶段：</p>
<ol>
<li>Projection Stage（dimension reduction）</li>
<li>Quantization Stage</li>
</ol>
<p>贡献：</p>
<ul>
<li>Isotropic Hash</li>
</ul>
<p>思想：学习一个正交阵（幻灯片21页），其目的是让大于某一阈值的feature的重要程度是一样的。</p>
<ul>
<li>Supervised Hashing with Latent Factor Models</li>
<li>Supervised Multimodal Hashing with SCM</li>
<li>Multiple-Bit Quantization</li>
</ul>
<p>###Distributed Learning<br>主讲人：我</p>
<p>主要内容：</p>
<ol>
<li>文章：Coupled Group Lasso for Web-Scale CTR Prediction</li>
<li>文章：Distributed Power-Law Graph Computing</li>
</ol>
<p>####文章1<br>为了解决在线广告的CTR（click through rate）预测，即当某广告展示给某用户时，它被该用户点击的概率，通常的方法是LR（logistic regression），即逻辑回归。但LR的一个短板是，因其是线性的，所以无法将用户与广告之间某些微妙的非线性关系纳入。注意LR中，正则项若为2范数平方，称为标准逻辑回归；正则项若为1范数，问题通常被叫做Lasso。所以需要一种新的方法。</p>
<p>这里的贡献是：</p>
<ol>
<li>CGL的似然定义中，可以纳入用户与广告之间的某些非线性关系的考量。</li>
<li>正则项改为参数的2-1范数，目的是是用户特征向量参数W、广告特征向量参数V中更多的行为0，行为0说明该行对应的feature没作用，即达到删除冗余feature的作用。</li>
</ol>
<p>分布式实现。这个算法具有较好的扩展性，一个master，若干slave，类似于并行计算，从而实现分布式。</p>
<p>####文章2<br>GP（graph partitioning）图分割的方法有两种：边分割；点分割。点分割在分布式计算中的通信成本会比图分割小，原因在于在不同的machine上，点分割只需保留点的copy，而边分割需要同时保留点与边的copy。</p>
<p>切割degree大的点，即邻居多的点可以降低通信成本。</p>
<p>###Stochastic Learning<br>主讲人：浩锋</p>
<p>思想：在需要用到所有节点上的信息时，通信代价往往很大，这时可以随机的选取某一个节点上的信息（比如梯度）作为替代品。</p>
<p>###资料<br>【1】<a href="http://cs.nju.edu.cn/lwj/slides/BigLearning.pdf" target="_blank" rel="external">幻灯片</a></p>
<p>【2】<a href="http://jmlr.csail.mit.edu/proceedings/papers/v32/yan14.pdf" target="_blank" rel="external">Coupled Group Lasso for<br>Web-Scale CTR Prediction in Display Advertising</a></p>
<p>【3】<a href="http://papers.nips.cc/paper/5396-distributed-power-law-graph-computing-theoretical-and-empirical-analysis.pdf" target="_blank" rel="external">Distributed Power-law Graph Computing:<br>Theoretical and Empirical Analysis</a></p>

      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-09-17T08:45:30.894Z"><a href="/2017/09/17/科研/2014-07-27-norms-of-vector-and-matrix/">2017-09-17</a></time>
      
      
  
    <h1 class="title"><a href="/2017/09/17/科研/2014-07-27-norms-of-vector-and-matrix/">各类范数</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        
    </div>

      
        <p>###向量范数<br><img src="/public/img/posts/vector_norms.JPG" alt="vector_norms"></p>
<p>###矩阵范数<br><img src="/public/img/posts/matrix_norms.JPG" alt="matrix_norms"></p>
<p>###矩阵乘积的迹<br><img src="/public/img/posts/trace.JPG" alt="trace"></p>
<p>###特殊范数</p>
<ul>
<li>矩阵W的L2-1范数：<br><img src="/public/img/posts/2_1norm.png" alt="2_1norm"></li>
</ul>
<p>###TV范数<br>||L(x)||_1。 其中L是差分算子，x是某种数字信号，在一维情况下，如下所示：</p>
<p>||L(x)||_1 = |x2-x1| + |x3-x2| + |x4-x3| + ……</p>
<p>加TV范数的目的是为了使求得的去噪信号仍然具有分段连续的性质。因为差值的1范数说明差值稀疏，从而说明求得的信号分段连续。</p>

      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-09-17T08:45:30.894Z"><a href="/2017/09/17/科研/2014-07-25-matrix-completion/">2017-09-17</a></time>
      
      
  
    <h1 class="title"><a href="/2017/09/17/科研/2014-07-25-matrix-completion/">低秩矩阵补全</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        
    </div>

      
        <p>###问题描述:</p>
<div>如果有这样一个矩阵<img src="http://latex.codecogs.com/gif.latex?\mathbf{W}" title="\mathbf{W}"></div>

<ul>
<li>矩阵中有部分元素缺失</li><li>矩阵的秩<img src="http://latex.codecogs.com/gif.latex?rank(\mathbf{W})" title="rank(\mathbf{W})">相较于矩阵维数来说很小，并作为先验已知</li>



</ul>
<p>我们希望恢复那些缺失的元素，这个问题就是低秩矩阵补全问题。      </p>
<p>###思考过程:</p>
<ul>
<li>需要恢复一个低秩矩阵</li><li>直接想法是极小化矩阵的秩<img src="http://latex.codecogs.com/gif.latex?\min&space;rank(\mathbf{W})" title="\min rank(\mathbf{W})"></li><br><li>但是<img src="http://latex.codecogs.com/gif.latex?\min&space;rank(\mathbf{W})" title="\min rank(\mathbf{W})">的优化问题非凸，不好求解</li><br><li>核范数<img src="http://latex.codecogs.com/gif.latex?\left&space;\|&space;\mathbf{W}\right&space;\|_{*}" title="\left \| \mathbf{W}\right \|_{*}">是秩的凸近似，所以想到<img src="http://latex.codecogs.com/gif.latex?\min&space;\left&space;\|&space;\mathbf{W}\right&space;\|_{*}" title="\min \left \| \mathbf{W}\right \|_{*}"></li>


</ul>
<p>###极小化核范数的集中式算法:</p>
<div>求解<img src="http://latex.codecogs.com/gif.latex?\min&space;\left&space;\|&space;\mathbf{W}\right&space;\|_{*}" title="\min \left \| \mathbf{W}\right \|_{*}">的集中式算法有很多，比如：</div>

<ul>
<li>singular value thresholding algorithm</li>
<li>fixed-point shrinkage algorithm</li>
<li>proximal gradient algorithm</li>
<li>ADMM</li>
</ul>
<p>但如果矩阵规模和秩增大，以上算法的计算代价也增大，因为它们都需要求解奇异值分解(SVD)。SVD中求伪逆的步骤运算量大，很耗费资源。因此需要想更好的方法，避免极小化核范数。</p>
<p>###极小化分解矩阵之积的集中式方法:</p>
<p><div>将问题写为<img src="http://latex.codecogs.com/gif.latex?\min&space;\left&space;\|&space;\mathbf{Z}-\mathbf{X}\mathbf{Y}\right&space;\|_{F}" title="\min \left \| \mathbf{Z}-\mathbf{X}\mathbf{Y}\right \|_{F}">，其中<img src="http://latex.codecogs.com/gif.latex?\mathbf{Z}" title="\mathbf{Z}">是对<img src="http://latex.codecogs.com/gif.latex?\mathbf{W}" title="\mathbf{W}">的估计，在元素没有缺失的位置上<img src="http://latex.codecogs.com/gif.latex?\mathbf{Z}" title="\mathbf{Z}">和<img src="http://latex.codecogs.com/gif.latex?\mathbf{W}" title="\mathbf{W}">的元素相同，<img src="http://latex.codecogs.com/gif.latex?\mathbf{X}" title="\mathbf{X}">,<img src="http://latex.codecogs.com/gif.latex?\mathbf{Y}" title="\mathbf{Y}">是对<img src="http://latex.codecogs.com/gif.latex?\mathbf{W}" title="\mathbf{W}">的乘法分解。介绍两种求解该问题的方法：</div></p>
<ul>
<li>nonlinear Gauss-Seidel method</li>
<li>nonlinear SOR(Successive Over-Relaxation)-like scheme:LMaFit</li>
</ul>
<p>其中SOR方法是GS方法的拓展，区别仅在于SOR方法中对于<strong>X</strong>的更新加了权重，并对权值进行更新。</p>
<p>###去中心式算法:</p>
<p><div>当矩阵规模大到一定程度时，集中式算法在计算能力上要求过高，普通计算机也许无法计算。这时，我们需要在由许多普通计算机作为节点组成的网络中运算，这需要实现去中心式计算。去中心式计算式很容易实现的，将<img src="http://latex.codecogs.com/gif.latex?\mathbf{W}" title="\mathbf{W}">,<img src="http://latex.codecogs.com/gif.latex?\mathbf{Z}" title="\mathbf{Z}">,<img src="http://latex.codecogs.com/gif.latex?\mathbf{Y}" title="\mathbf{Y}">分别切块放在每个节点上，将<img src="http://latex.codecogs.com/gif.latex?\mathbf{X}" title="\mathbf{X}">作为公共信息在网络各个邻居节点间交换，优化问题形式不变，但需要加上<img src="http://latex.codecogs.com/gif.latex?\mathbf{X}_{(i)}=\mathbf{X}_{(j)}" title="\mathbf{X}_{(i)}=\mathbf{X}_{(j)}">的约束。而这样一个约束就引出了另一个子问题：一致平均(average consensus)问题。</div></p>
<p>关于一致平均问题的介绍请看：</p>
<ul>
<li><a href="http://painterlin.com/2014/08/22/Average-Consensus.html" target="_blank" rel="external">《对于一致平均问题的理解》</a></li>
<li><a href="http://painterlin.com/2014/08/31/Papers-about-average-consensus.html" target="_blank" rel="external">《动态一致平均问题的4篇论文》</a></li>
</ul>

      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-05-02T16:00:00.000Z"><a href="/2017/05/03/技术/Python-pip-requirement/">2017-05-03</a></time>
      
      
  
    <h1 class="title"><a href="/2017/05/03/技术/Python-pip-requirement/">pip requirements</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#requirements-txt的作用"><span class="toc-text">requirements.txt的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#查找python项目依赖并生成requirements-txt"><span class="toc-text">查找python项目依赖并生成requirements.txt</span></a></li></ol>
    </div>

      
        <h3 id="requirements-txt的作用"><a href="#requirements-txt的作用" class="headerlink" title="requirements.txt的作用"></a>requirements.txt的作用</h3><p>在很多Python项目中都包含一个requirements.txt文件，里面写的是一些包的名称和版本信息。</p>
<p>描述运行这个项目所需要的环境，包括一些库。</p>
<p>可以使用<code>pip install -r requirements.txt</code>安装这些库。</p>
<h3 id="查找python项目依赖并生成requirements-txt"><a href="#查找python项目依赖并生成requirements-txt" class="headerlink" title="查找python项目依赖并生成requirements.txt"></a>查找python项目依赖并生成requirements.txt</h3><ul>
<li><p>将整个python环境的依赖包list出来，</p>
<p><code>pip freeze &gt; requirements.txt</code></p>
</li>
<li><p>list某个项目用到的依赖包,使用工具pipreqs ，但有的时候结果会有偏差(源码分析的不准确)</p>
<p><code>pip install pipreqs</code></p>
<p><code>pipreqs ./</code></p>
</li>
</ul>

      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-04-12T16:00:00.000Z"><a href="/2017/04/13/技术/dolphin-exam/">2017-04-13</a></time>
      
      
  
    <h1 class="title"><a href="/2017/04/13/技术/dolphin-exam/">海豚笔试</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、Java部分"><span class="toc-text">1、Java部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、Python部分"><span class="toc-text">2、Python部分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3、机器学习"><span class="toc-text">3、机器学习</span></a></li></ol>
    </div>

      
        <blockquote>
<p>今天参加了一个实习生招聘的笔试，准备的不充分，错的惨不忍睹。整理一下遇到的题目。</p>
</blockquote>
<h3 id="1、Java部分"><a href="#1、Java部分" class="headerlink" title="1、Java部分"></a>1、Java部分</h3><p>试题有java和c++两种，以前上课学的C和Java早还给老师了，python的BIF用多了，发现连个排序算法都写不好了。</p>
<ul>
<li>考察java的类继承和静态方法</li>
</ul>
<ol>
<li><p>通过类名来调用子类中的静态变量和静态方法，当父类与子类相同时是，子类会隐藏父类中与其相同的静态变量和静态方法，如果子类中没有与其父类相同的静态变量和静态方法，子类从其父类调用过来的静态变量和静态方法就会表现出来。</p>
</li>
<li><p>通过子类创建对象来用对象名调用子类中的静态变量和静态方法，除非是父类没有的静态变量和静态方法，会显示其子类的静态变量和静态方法。否则，最后显示一定是从父类哪里引用来的静态变量和静态方法。</p>
</li>
</ol>
<p><img src="http://i1.piimg.com/567571/b0d17cd4aadfd6f3.png" alt=""></p>
<p><img src="http://i2.muimg.com/567571/0209cc264f8d4a42.png" alt=""></p>
<p><img src="http://i4.buimg.com/567571/3a8a5454ac34308f.png" alt=""></p>
<p><img src="http://i2.muimg.com/567571/abfaaa03127d63dc.png" alt=""></p>
<ul>
<li><p>考察Java String变量的比较及值比较</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//"=="操作符:用于基本数据类型的比较,判断引用是否指向同一内存块</span></div><div class="line"><span class="comment">//如果String缓冲池内不存在与其指定值相同的String对象，那么此时虚拟机将为此创建新的String对象，并存放在String缓冲池内。</span></div><div class="line"><span class="keyword">import</span> java.io.*;</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">test</span>  </span></div><div class="line"><span class="class"></span>&#123;</div><div class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span> <span class="params">(String[] args)</span> <span class="keyword">throws</span> java.lang.Exception</span></div><div class="line"><span class="function">	</span>&#123;</div><div class="line">		String s1 = <span class="string">"helloworld"</span>;</div><div class="line">		String s2 = <span class="string">"hello"</span> + <span class="string">"world"</span>;</div><div class="line">	    String s0 = <span class="string">"helloworld"</span>;</div><div class="line">	    String s3 = <span class="keyword">new</span> String(<span class="string">"helloworld"</span>);</div><div class="line">		System.out.println(s1==s0);  <span class="comment">// true</span></div><div class="line">		System.out.println(s2==s0);  <span class="comment">// true</span></div><div class="line">		System.out.println(s1==s2);  <span class="comment">// true</span></div><div class="line">		System.out.println(s1.equals(s0)); <span class="comment">// true</span></div><div class="line">		System.out.println(s1.equals(s3)); <span class="comment">// true</span></div><div class="line">		System.out.println(s1==s3);  <span class="comment">//false</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">//如果String缓冲池内存在与其指定值相同的String对象，那么此时虚拟机将不为此创建新的String对象，而直接返回已存在的String对象的引用。</span></div></pre></td></tr></table></figure>
<p>​</p>
</li>
<li><p>简单的算法，一个32位整数的数组，返回有序排列的2个相邻元素之差的最大值。整数是32位的，时间复杂度o(n)有加分。<a href="https://oj.leetcode.com/problems/maximum-gap/" target="_blank" rel="external">LeetCode</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 写了个最蠢的方法，冒泡排序，然后遍历数组，求最大的差值。时间复杂度在排序，o(n^2);</span></div><div class="line"><span class="comment">// 数据结构书里只记得o(n*logn)的排序算法，快速排序，插入排序，堆排序，选择排序o(n^2);</span></div><div class="line"><span class="comment">// 在整数取值范围有限的情况下，计数排序、基数排序和桶排序可以实现空间复杂度O(k),时间复杂度O(n)的排序</span></div><div class="line"><span class="comment">/* 思路：使用桶排序的原理，但桶的取值设为n-1，而不是整数的取值范围。桶内数据无序，桶间，用后一个桶的min 减去 前一个桶的max即可。</span></div><div class="line"><span class="comment">*/</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxGap</span></span></div><div class="line"><span class="class"></span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maximumGap</span><span class="params">(<span class="keyword">int</span>[] num)</span></span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">int</span> maxGap = <span class="number">0</span>;</div><div class="line"></div><div class="line">        <span class="comment">// edge case</span></div><div class="line">        <span class="keyword">if</span> (num.length &lt; <span class="number">2</span>)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">return</span> maxGap;</div><div class="line">        &#125;</div><div class="line">      </div><div class="line">        <span class="comment">// get maximum and minimum</span></div><div class="line">        <span class="keyword">int</span> min = num[<span class="number">0</span>];</div><div class="line">        <span class="keyword">int</span> max = num[<span class="number">0</span>];</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num.length; i++)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">if</span> (num[i] &lt; min)</div><div class="line">                min = num[i];</div><div class="line">            <span class="keyword">if</span> (num[i] &gt; max)</div><div class="line">                max = num[i];</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// divide into identical gaps</span></div><div class="line">        Gap[] gaps = <span class="keyword">new</span> Gap[num.length - <span class="number">1</span>];</div><div class="line">        <span class="keyword">boolean</span>[] Engaged = <span class="keyword">new</span> <span class="keyword">boolean</span>[num.length - <span class="number">1</span>];</div><div class="line">        <span class="keyword">double</span> gap = (<span class="keyword">double</span>) (max - min) / (<span class="keyword">double</span>) (num.length - <span class="number">1</span>);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; gaps.length; i++)</div><div class="line">            Engaged[Math.min((<span class="keyword">int</span>) Math.floor((<span class="keyword">double</span>) (num[i] - min) / gap), gaps.length - <span class="number">1</span>)] = <span class="keyword">true</span>;</div><div class="line"></div><div class="line">        <span class="comment">// assign maximum and minimum for each gap</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; gaps.length; i++)</div><div class="line">            gaps[i] = <span class="keyword">new</span> Gap();</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num.length; i++)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">int</span> index = (<span class="keyword">int</span>) Math.floor((<span class="keyword">double</span>) (num[i] - min) / gap);</div><div class="line">            index = Math.min(index, gaps.length - <span class="number">1</span>);</div><div class="line"></div><div class="line">            <span class="comment">// lower bound</span></div><div class="line">            <span class="keyword">if</span> (gaps[index].low == -<span class="number">1</span>)</div><div class="line">                gaps[index].low = num[i];</div><div class="line">            <span class="keyword">else</span></div><div class="line">                gaps[index].low = Math.min(gaps[index].low, num[i]);</div><div class="line"></div><div class="line">            <span class="comment">// upper bound</span></div><div class="line">            <span class="keyword">if</span> (gaps[index].high == -<span class="number">1</span>)</div><div class="line">                gaps[index].high = num[i];</div><div class="line">            <span class="keyword">else</span></div><div class="line">                gaps[index].high = Math.max(gaps[index].high, num[i]);</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment">// find maximum gap</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; gaps.length; i++)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">if</span> (Engaged[i])</div><div class="line">            &#123;</div><div class="line">                <span class="comment">// check its inner gap</span></div><div class="line">                maxGap = Math.max(gaps[i].high - gaps[i].low, maxGap);</div><div class="line"></div><div class="line">                <span class="comment">// lower all the way</span></div><div class="line">                <span class="keyword">int</span> j = i;</div><div class="line">                <span class="keyword">while</span> (--j &gt;= <span class="number">0</span>)</div><div class="line">                &#123;</div><div class="line">                    <span class="keyword">if</span> (Engaged[j])</div><div class="line">                        <span class="keyword">break</span>;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">if</span> (j &gt;= <span class="number">0</span>)</div><div class="line">                    maxGap = Math.max(gaps[i].low - gaps[j].high, maxGap);</div><div class="line"></div><div class="line">                <span class="comment">// upper all the way</span></div><div class="line">                j = i;</div><div class="line">                <span class="keyword">while</span> (++j &lt; num.length - <span class="number">2</span>)</div><div class="line">                &#123;</div><div class="line">                    <span class="keyword">if</span> (Engaged[j])</div><div class="line">                        <span class="keyword">break</span>;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">if</span> (j &lt; gaps.length)</div><div class="line">                    maxGap = Math.max(gaps[j].low - gaps[i].high, maxGap);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">return</span> maxGap;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Gap</span></span></div><div class="line"><span class="class">    </span>&#123;</div><div class="line">        <span class="keyword">int</span> low;</div><div class="line">        <span class="keyword">int</span> high;</div><div class="line">        <span class="keyword">boolean</span> hasItem;</div><div class="line"></div><div class="line">        Gap()</div><div class="line">        &#123;</div><div class="line">            low = -<span class="number">1</span>;</div><div class="line">            high = -<span class="number">1</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        Gap(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</div><div class="line">        &#123;</div><div class="line">            low = x;</div><div class="line">            high = y;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span></div><div class="line"><span class="function">    </span>&#123;</div><div class="line">        <span class="keyword">int</span>[] num = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>&#125;;</div><div class="line">        System.out.println((<span class="keyword">new</span> MaxGap()).maximumGap(num));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
<h3 id="2、Python部分"><a href="#2、Python部分" class="headerlink" title="2、Python部分"></a>2、Python部分</h3><ul>
<li><p>下列不能创建字典的语句是 <code>dict1 = {[1,2,3]: &#39;use&#39;}</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">a = &#123;[<span class="number">1</span>,<span class="number">2</span> ,<span class="number">3</span>]: <span class="string">"user"</span>&#125;</div><div class="line">Traceback (most recent call last):</div><div class="line">  Python Shell, prompt <span class="number">6</span>, line <span class="number">1</span></div><div class="line">TypeError: unhashable type: <span class="string">'list'</span></div><div class="line"></div><div class="line">a = &#123;<span class="number">4</span>:<span class="number">5</span>&#125;        </div><div class="line">a = &#123;&#125;</div><div class="line">a = &#123;(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>): <span class="string">'use'</span>&#125;</div><div class="line"><span class="keyword">print</span> a</div><div class="line">&#123;(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>): <span class="string">'use'</span>&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>Numpy数组的切片操作</p>
</li>
</ul>
<h3 id="3、机器学习"><a href="#3、机器学习" class="headerlink" title="3、机器学习"></a>3、机器学习</h3><ul>
<li><p>研究发现，买尿布的顾客中80%的也会同时购买啤酒，这属于数据挖掘的哪种问题？关联规则。</p>
</li>
<li><p>为了防止过拟合可以采取的<a href="http://blog.csdn.net/heyongluoyao8/article/details/49429629" target="_blank" rel="external">方法</a>，正则化，early stopping，数据集扩增，Dropout(神经网络)。</p>
</li>
<li><p>分类和回归的区别，应用场景，常见的算法</p>
<p>分类和回归的区别在于输出变量的类型。</p>
<p>定量输出称为回归，或者说是连续变量预测；预测明天的气温是多少度，这是一个回归任务；<br>定性输出称为分类，或者说是离散变量预测。预测明天是阴、晴还是雨，就是一个分类任务。</p>
<p>常见算法？好像很多算法思想都既能用于回归，也能用于分类。分类和回归应该有内在联系，</p>
<p><strong>标记一下，以后深入学习后补充</strong></p>
<p><img src="http://i4.buimg.com/567571/25582df73feeb3a8.jpg" alt=""></p>
</li>
<li><p>逻辑回归中的常用激励函数</p>
<p>记得神经网络里有sigmod函数做激励函数，逻辑回归？</p>
<p>logistic回归<strong>此处留疑，后面再补充</strong></p>
</li>
<li><p>描述你熟悉的神经网络和它们的特征</p>
<p>重要的人工神经网络算法包括：感知器神经网络（Perceptron Neural Network）, 反向传递（Back Propagation）， Hopfield网络，自组织映射（Self-Organizing Map, SOM）。学习矢量量化（Learning Vector Quantization， LVQ） </p>
<p><strong>都不熟悉，先去看书了:cry:</strong></p>
<p>​</p>
</li>
</ul>

      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="book">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-10T16:00:00.000Z"><a href="/2017/03/11/阅读/Book-List-2017-Q1/">2017-03-11</a></time>
      
      
  
    <h1 class="title"><a href="/2017/03/11/阅读/Book-List-2017-Q1/">2017年Q1阅读书单</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        
    </div>

      
        
      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-01T16:00:00.000Z"><a href="/2017/03/02/技术/scrapy-redis分布式爬虫入门/">2017-03-02</a></time>
      
      
  
    <h1 class="title"><a href="/2017/03/02/技术/scrapy-redis分布式爬虫入门/">scrapy-redis 分布式爬虫</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#scrapy-redis-分布式爬虫"><span class="toc-text">scrapy-redis 分布式爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#简介"><span class="toc-text">简介</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#安装和配置"><span class="toc-text">安装和配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#作用和特点"><span class="toc-text">作用和特点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#初步使用"><span class="toc-text">初步使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#settings参数"><span class="toc-text">settings参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#scrapy-redis使用方法"><span class="toc-text">scrapy-redis使用方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分布式爬取"><span class="toc-text">分布式爬取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#直接运行多个爬虫"><span class="toc-text">直接运行多个爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#利用docker部署爬虫"><span class="toc-text">利用docker部署爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#导出redis中的items"><span class="toc-text">导出redis中的items</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>

      
        <h1 id="scrapy-redis-分布式爬虫"><a href="#scrapy-redis-分布式爬虫" class="headerlink" title="scrapy-redis 分布式爬虫"></a>scrapy-redis 分布式爬虫</h1><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><h4 id="安装和配置"><a href="#安装和配置" class="headerlink" title="安装和配置"></a>安装和配置</h4><ul>
<li>安装redis数据库 </li>
<li><code>pip install scrapy redis-py scrapy-redis</code></li>
</ul>
<h4 id="作用和特点"><a href="#作用和特点" class="headerlink" title="作用和特点"></a>作用和特点</h4><blockquote>
<p>scrapy-redis是为Scrapy提供redis支持以实现分布式爬虫的组件</p>
</blockquote>
<ul>
<li>多个爬虫共享一个redis队列（分配request）</li>
<li>分布式的post处理。将爬到的items也放入redis队列，因而可以实现items的分布式处理。</li>
</ul>
<p>scrapy-redis仅仅为scrapy提供了部分基于redis的组件，可以查看源码。</p>
<ul>
<li>pipeline</li>
<li>scheluder</li>
<li>redis队列替换原有的scrapy队列</li>
<li>过滤器 Duplication</li>
</ul>
<h3 id="初步使用"><a href="#初步使用" class="headerlink" title="初步使用"></a>初步使用</h3><h4 id="settings参数"><a href="#settings参数" class="headerlink" title="settings参数"></a><strong>settings参数</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Enables scheduling storing requests queue in redis.</span></div><div class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></div><div class="line"></div><div class="line"><span class="comment"># Ensure all spiders share same duplicates filter through redis.</span></div><div class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></div><div class="line"></div><div class="line"><span class="comment"># Don't cleanup redis queues, allows to pause/resume crawls.</span></div><div class="line">SCHEDULER_PERSIST = <span class="keyword">True</span></div><div class="line"></div><div class="line"><span class="comment"># Schedule requests using a priority queue. (default)</span></div><div class="line">SCHEDULER_QUEUE_CLASS = <span class="string">'scrapy_redis.queue.PriorityQueue'</span></div><div class="line"><span class="comment"># Alternative queues.</span></div><div class="line"><span class="comment">#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.FifoQueue'</span></div><div class="line"><span class="comment">#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.LifoQueue'</span></div><div class="line"></div><div class="line"><span class="comment"># Max idle time to prevent the spider from being closed when distributed crawling.</span></div><div class="line"><span class="comment"># This only works if queue class is SpiderQueue or SpiderStack,</span></div><div class="line"><span class="comment"># and may also block the same time when your spider start at the first time (because the queue is empty).</span></div><div class="line"><span class="comment">#SCHEDULER_IDLE_BEFORE_CLOSE = 10</span></div><div class="line"></div><div class="line"><span class="comment"># Store scraped item in redis for post-processing.</span></div><div class="line">ITEM_PIPELINES = &#123;</div><div class="line">    <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">300</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Specify the host and port to use when connecting to Redis (optional).</span></div><div class="line"><span class="comment">#REDIS_HOST = 'localhost'</span></div><div class="line"><span class="comment">#REDIS_PORT = 6379</span></div><div class="line"></div><div class="line"><span class="comment"># Specify the full Redis URL for connecting (optional).</span></div><div class="line"><span class="comment"># If set, this takes precedence over the REDIS_HOST and REDIS_PORT settings.</span></div><div class="line">REDIS_URL = <span class="string">'redis://user:pass@hostname:9001'</span></div><div class="line"></div><div class="line"><span class="comment"># Use other encoding than utf-8 for redis.默认utf-8</span></div><div class="line">REDIS_ENCODING = <span class="string">'latin1'</span></div></pre></td></tr></table></figure>
<h4 id="scrapy-redis使用方法"><a href="#scrapy-redis使用方法" class="headerlink" title="scrapy-redis使用方法"></a>scrapy-redis使用方法</h4><ul>
<li><p>首先用scrapy实现一个爬虫，然后在替换其中的组件为scrapy-redis</p>
<p>setting里修改：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># setting.py</span></div><div class="line">BOT_NAME = <span class="string">'moko1'</span></div><div class="line"></div><div class="line">SPIDER_MODULES = [<span class="string">'moko1.spiders'</span>]</div><div class="line">NEWSPIDER_MODULE = <span class="string">'moko1.spiders'</span></div><div class="line"></div><div class="line"><span class="comment"># 使用scrapy-redis的去重和调度器组件</span></div><div class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></div><div class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></div><div class="line">SCHEDULER_PERSIST = <span class="keyword">True</span></div><div class="line"></div><div class="line">ITEM_PIPELINES = &#123;</div><div class="line"><span class="comment"># 会将items放入redis队列中</span></div><div class="line"><span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">400</span>,</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>spiders里修改：</p>
<p><strong>spider类</strong>从scrapy_redis.spiders导入，有RedisSpider和RedisCrawlSpider，对应scrapy原来的Spider和CrawlSpider。</p>
<p><strong>start_urls</strong>改为从redis中某个key获取，因此redis_key = ‘moko_spider:start_urls’，然后向该key push数据。</p>
<p>直接给出start_urls也是可行的，但是不太符合redis队列及分布式的逻辑，而且不能手动动态添加。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> scrapy</div><div class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</div><div class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> Rule</div><div class="line"><span class="keyword">from</span> ..items <span class="keyword">import</span>  Moko1Item</div><div class="line"><span class="keyword">from</span> scrapy_redis.spiders <span class="keyword">import</span> RedisCrawlSpider</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MokoSpiderSpider</span><span class="params">(RedisCrawlSpider)</span>:</span> <span class="comment"># 修改此处</span></div><div class="line">    name = <span class="string">'moko_spider'</span></div><div class="line">    allowed_domains = [<span class="string">'moko.cc'</span>]</div><div class="line">    start_urls = [<span class="string">'http://www.moko.cc/moko/post/1.html'</span>]  <span class="comment"># 修改此处</span></div><div class="line">    <span class="comment"># redis_key = 'moko_spider:start_urls'</span></div><div class="line">  </div><div class="line">    rules = (</div><div class="line">        Rule(LinkExtractor(allow=<span class="string">r'http://www\.moko\.cc/post/\d+\.html'</span>), callback=<span class="string">'parse_item'</span>, follow=<span class="keyword">True</span>),</div><div class="line">    )</div><div class="line">  </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></div><div class="line">        item = Moko1Item()</div><div class="line">        item[<span class="string">'name'</span>] = response.css(<span class="string">"#workNickName::text"</span>).extract()[<span class="number">0</span>]</div><div class="line">        <span class="keyword">return</span> item</div></pre></td></tr></table></figure>
</li>
<li><p>确保redis数据库运行，清空数据库<code>flushdb</code>, “moko_spider:dupefilter”保存了我上次执行时已经爬取过的url信息。再次执行会被过滤掉，scrapy的去重机制。</p>
</li>
<li><p>然后启动scrapy爬虫，然后向redis_key = ‘moko_spider:start_urls’中push数据，在redis-cli客户端中执行<code>lpush moko_spider:start_urls https://moko.cc/1.html</code></p>
</li>
<li><p>如果启用了scrapy_redis.pipelines.RedisPipeline，items会存储在moko_spider:items中。可以将items不断的pop出来，并进行其他处理，如存储等。(感觉这种活应该交给一个pipeline干)</p>
</li>
</ul>
<h3 id="分布式爬取"><a href="#分布式爬取" class="headerlink" title="分布式爬取"></a>分布式爬取</h3><h4 id="直接运行多个爬虫"><a href="#直接运行多个爬虫" class="headerlink" title="直接运行多个爬虫"></a>直接运行多个爬虫</h4><blockquote>
<p>上面的单个爬虫默认从localhost的Redis数据库中存取request和爬到的items，</p>
<p>而实现分布式爬虫只需要为爬虫指定Redis数据库的网络位置，所有的爬虫都去redis队列里存取。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># settings.py</span></div><div class="line">REDIS_URL = <span class="string">'redis://user:mima@localhost:6379'</span> </div><div class="line"><span class="comment"># 或者不带密码的</span></div><div class="line">REDIS_HOST = <span class="string">'localhost'</span></div><div class="line">REDIS_PORT = <span class="number">6379</span></div></pre></td></tr></table></figure>
<ul>
<li><p>配置redis允许远程访问</p>
<p>修改配置文件/etc/redis.conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># bind 127.0.0.1</div><div class="line">requirepass mima  # 设置密码</div></pre></td></tr></table></figure>
<p>​</p>
</li>
<li><p>关于<strong>主从模式</strong></p>
<p>分布式架构一般分为主从模式和P2P模式。有的人认为scrapy-redis中安装有redis数据库的节点就是master，错的！</p>
<p>scrapy-redis中的每只爬虫都是平级的，没有主从之分。每只爬虫都是主动请求任务，执行任务，爬到的数据也可以提交给redis。redis的request队列为空时，爬虫处于饥饿状态。</p>
<p>scrapy-redis仅仅是把scrapy原来得本地队列放入redis数据库中，从通信和数据传输的角度来看，redis像是一个master，而实际上redis对爬虫没做任何控制和操作，只是被动的为它们提供数据。</p>
</li>
</ul>
<h4 id="利用docker部署爬虫"><a href="#利用docker部署爬虫" class="headerlink" title="利用docker部署爬虫"></a>利用docker部署爬虫</h4><ul>
<li><p>创建一个docker镜像并配置scrapy环境，这样下次就能恢复环境直接使用了</p>
<ul>
<li>首先在daocloud申请一台胶囊主机，然后ssh登录上去，配置scrapy环境</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 使用ubuntu的docker镜像</span></div><div class="line">docker run -it  daocloud.io/ubuntu:14.04 /bin/bash</div><div class="line">apt-get update </div><div class="line">apt-get install lrzsz</div><div class="line">apt-get install python2.7 python-pip python-dev</div><div class="line">apt-get install libxml2-dev libxslt-dev  python-lxml # 安装lxml</div><div class="line">apt-get install build-essential libssl-dev  libffi-dev</div><div class="line">pip install  six --upgrade</div><div class="line">python -m pip install pyparsing appdirs</div><div class="line">pip install  cryptography</div><div class="line">pip install pymongo redis twisted scrapy scrapy-redis</div><div class="line">exit # 退出docker，记住id，docker id root@ea0d832b19bb</div></pre></td></tr></table></figure>
<ul>
<li>打包上传镜像</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> 打包镜像，docker容器的id ea0d832b19bb</span></div><div class="line">~$ docker commit -m "ubuntu with scrapy_redis" -a "author——info" ea0d832b19bb scrapy-redis</div><div class="line">sha256:53a605ccc92ab29bba70f9f026c002a9c4afa43fb9b14a9819d5859f51b0d586</div><div class="line">~$ docker images # 查看镜像</div><div class="line"><span class="meta">#</span><span class="bash"> 为镜像打上tag</span></div><div class="line">docker tag scrapy-redis syy2358/scrapy-redis:latest</div><div class="line"><span class="meta">#</span><span class="bash"> 上传至dockerhub托管</span></div><div class="line">docker login # 先注册并登录dockerhub，创建一个托管仓库scrapy-redis</div><div class="line">docker push syy2358/scrapy-redis:lastest # 将镜像上传至dockerhub</div><div class="line"><span class="meta">#</span><span class="bash"> 胶囊主机只有2小时，hub上传速度又慢，只好打包镜像文件下载到我的电脑上。</span></div><div class="line">docker save ea0d832b19bb &gt; /home/ubuntu/scrapy-redis.tar</div><div class="line"><span class="meta">#</span><span class="bash"> 可以在有docker的电脑上恢复该容器，</span></div><div class="line">docker load &lt; scrapy-redis.tar</div><div class="line"><span class="meta">#</span><span class="bash"> 或者直接拉dockerhub/daocloud上的镜像用就行了</span></div><div class="line">docker pull syy2358/scrapy-redis</div><div class="line">docker run -it xx.xx</div><div class="line"><span class="meta">#</span><span class="bash"> 导出 <span class="built_in">export</span> 和save的区别- 导入 import</span></div><div class="line"><span class="meta">#</span><span class="bash"> save保存了容器的运行状态，支持回滚，但是数据较大。</span></div></pre></td></tr></table></figure>
<ul>
<li><p>​<strong>自己配置环境各种报错，主要是下载链接超时，用daocloud就很顺利  </strong></p>
<blockquote>
<p>首先自己编译docker镜像容易遇到各种错误，而且dockerhub的镜像push、pull的速度巨慢，估计是被墙了，所以决定改用daocloud在线编译发布镜像，编译和pull的速度都很快。</p>
</blockquote>
<p>镜像制作过程：</p>
<ol>
<li>在自己 GitHub 创建新的 repository 。</li>
<li>将爬虫的代码，包含<code>Dockerfile</code> push 到自己刚创建的 repository。</li>
<li>到 <code>https://dashboard.daocloud.io/build-flows/new</code> ，项目名称 <code>scrapy</code>，选择自己刚在 GitHub 创建的 repository同步代码，开始创建，选择<code>分支：master</code>，手动执行。如果失败，可以先看下流程定义里的构建阶段，修改任务，选择云端Dockerfile。</li>
<li>到 <code>https://dashboard.daocloud.io/packages</code> 选择 <code>scrapy</code>，设置 -&gt; 镜像访问控制 -&gt; 公开,设置tag为latest。</li>
<li><code>https://dashboard.daocloud.io/packages/</code>选择scrapy后，版本 -&gt; latest 。然后可以部署到已经接入的docker或者云测试环境(右上角打开控制台，能进入web版的终端，在里面执行scrapy crawl spider即可)。</li>
<li>或者在自己的docker环境下，使用<code>docker run -it daocloud.io/blue_whale/scrapy</code>,然后就能看到爬虫在运行了</li>
</ol>
</li>
<li><p>镜像地址</p>
<p><code>daocloud.io/blue_whale/scrapy</code> : daocloud上的，速度很快</p>
<p><code>syy2358/scrapy-redis</code>: dockerhub上的，巨慢</p>
<p>​</p>
</li>
</ul>
</li>
<li><p>运行爬虫</p>
<ol>
<li><p>上传源码，并从Dockerfile build镜像，然后运行爬虫</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 项目结构</span></div><div class="line">.</div><div class="line">├── docker-compose.yml</div><div class="line">├── Dockerfile</div><div class="line">├── moko1</div><div class="line">│   ├── __init__.py</div><div class="line">│   ├── items.py</div><div class="line">│   ├── pipelines.py</div><div class="line">│   ├── settings.py</div><div class="line">│   └── spiders</div><div class="line">│       ├── __init__.py</div><div class="line">│       ├── moko_spider.py</div><div class="line">├── requirements.txt</div><div class="line">└── scrapy.cfg</div><div class="line"></div><div class="line">---------------------------</div><div class="line"></div><div class="line"><span class="comment"># docker-compose.yml</span></div><div class="line">version: '2'</div><div class="line">services:</div><div class="line">  spider:</div><div class="line">    build: .</div><div class="line">    volumes:</div><div class="line">     - .:/code</div><div class="line"></div><div class="line">------------------------</div><div class="line"></div><div class="line"><span class="comment"># Dockerfile</span></div><div class="line">FROM syy2358/scrapy-redis</div><div class="line">ENV PATH /usr/local/bin:$PATH</div><div class="line">ADD . /code</div><div class="line">WORKDIR /code</div><div class="line">RUN pip install -r requirements.txt</div><div class="line"><span class="comment"># COPY spiders.py /usr/local/lib/python3.5/site-packages/scrapy_redis</span></div><div class="line">CMD scrapy crawl moko_spider</div></pre></td></tr></table></figure>
<p>我的redis服务器是在腾讯云上的，没有使用docker。</p>
<p>如果redis在docker中运行的话，需要在<code>docker-compose.yml</code>中定义redis的container，将spider和redis link起来，同时redis需要映射端口6379，这样不同的container之间才能相互通信。</p>
<p>使用docker-compose创建container</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">pip install docker-compose</div><div class="line"> rz -E  # 上传爬虫源码</div><div class="line"> docker-compose up #从 docker-compose.yml 中创建 `container`</div><div class="line"> docker-compose scale spider=4 #将 spider 这一个服务扩展到4个container</div><div class="line"><span class="meta"> #</span><span class="bash"> 会有4个scrapy爬虫运行，处于饥饿状态，因为刚开始start_urls为空，直到我们pushurl去feed爬虫，爬虫才会开始抓取工作。</span></div></pre></td></tr></table></figure>
<p>​</p>
</li>
</ol>
</li>
</ul>
<ol>
<li><p>方法二，使用已经build好的docker镜像(爬虫代码也已经copy进去了)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">docker run -it daocloud.io/blue_whale/scrapy</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 或者</span></span></div><div class="line">docker run -it syy2358/scrapy-redis</div><div class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Ctrl+P+Q 将当前container放入后台，回到docker界面</span></span></div><div class="line">docker ps -a ## 查看正在运行的container</div><div class="line">docker attach  id  # 连接入正在执行的container</div></pre></td></tr></table></figure>
</li>
</ol>
<ul>
<li><p>退出attach的docker container</p>
<p>用1执行爬虫时真惨，attach上container退不出去，scrapy不停地输出log内容，按啥键都不好使，只好退出ssh重连T.T，重连后发现原来的container仍在运行中。</p>
<p>正常attach上一个container，可以Ctrl+P+Q退出再后台执行，或exit终止运行并退出container。</p>
<p>使用<a href="http://lib.csdn.net/base/docker" target="_blank" rel="external">Docker</a> attach命名进入docker容器后：</p>
<p>【场景一】如果要正常退出不关闭容器，请按Ctrl+P+Q进行退出容器。</p>
<p>【场景二】如果使用exit退出，那么在退出容器后会关闭容器，如下图所示。</p>
</li>
<li><p>总结</p>
<p>只需要配置一次scrapy的docker运行环境，上传代码，然后将container打包成镜像，就可以在任何有docker的地方pull下镜像运行。</p>
<p>docker挺有意思的，项目部署非常方便，不过我这个新手对docker只是一知半解。</p>
</li>
</ul>
<h4 id="导出redis中的items"><a href="#导出redis中的items" class="headerlink" title="导出redis中的items"></a>导出redis中的items</h4><ul>
<li><p>linux下使用redis-dump <code>redis-dump -u 127.0.0.1:6379 &gt; db_full.json</code></p>
</li>
<li><p>将数据导入mongodb中</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/env python</span></div><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> json</div><div class="line"><span class="keyword">import</span> redis</div><div class="line"><span class="keyword">import</span> pymongo</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></div><div class="line">    r = redis.Redis(host=<span class="string">'192.168.1.112'</span>,port=<span class="number">6379</span>,db=<span class="number">0</span>)</div><div class="line">    client = pymongo.MongoClient(host=<span class="string">'localhost'</span>, port=<span class="number">27017</span>)</div><div class="line">    db = client[<span class="string">'dmoz'</span>]</div><div class="line">    sheet = db[<span class="string">'sheet'</span>]</div><div class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</div><div class="line">        <span class="comment"># 将队列里的数据逐条pop出来，并插入mongodb中</span></div><div class="line">        <span class="comment"># process queue as FIFO, change `blpop` to `brpop` to process as LIFO</span></div><div class="line">        source, data = r.blpop([<span class="string">"dmoz:items"</span>])</div><div class="line">        item = json.loads(data)</div><div class="line">        sheet.insert(item)</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            <span class="keyword">print</span> <span class="string">u"Processing: %(name)s &lt;%(link)s&gt;"</span> % item</div><div class="line">        <span class="keyword">except</span> KeyError:</div><div class="line">            <span class="keyword">print</span> <span class="string">u"Error procesing: %r"</span> % item</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    main()</div></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>

      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-28T16:00:00.000Z"><a href="/2017/03/01/技术/scapy-redis源码阅读/">2017-03-01</a></time>
      
      
  
    <h1 class="title"><a href="/2017/03/01/技术/scapy-redis源码阅读/">Scrapy_redis源码阅读</a></h1>
  

    </header>
    <div class="entry">
         
        
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#scapy-redis-源码阅读"><span class="toc-text">scapy-redis 源码阅读</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#connection-py"><span class="toc-text">connection.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dupefilter-py"><span class="toc-text">dupefilter.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#picklecompat-py"><span class="toc-text">picklecompat.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pipelines-py"><span class="toc-text">pipelines.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Queue-py"><span class="toc-text">Queue.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#scheduler-py"><span class="toc-text">scheduler.py</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spiders-py"><span class="toc-text">spiders.py</span></a></li></ol></li></ol>
    </div>

      
        <h2 id="scapy-redis-源码阅读"><a href="#scapy-redis-源码阅读" class="headerlink" title="scapy-redis 源码阅读"></a>scapy-redis 源码阅读</h2><h3 id="connection-py"><a href="#connection-py" class="headerlink" title="connection.py"></a>connection.py</h3><blockquote>
<p>创建redis连接实例</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> six</div><div class="line"><span class="keyword">from</span> scrapy.utils.misc <span class="keyword">import</span> load_object  <span class="comment">#  加载对象</span></div><div class="line"><span class="keyword">from</span> . <span class="keyword">import</span> defaults</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Shortcut maps 'setting name' -&gt; 'parmater name'.</span></div><div class="line">SETTINGS_PARAMS_MAP = &#123;</div><div class="line">    <span class="string">'REDIS_URL'</span>: <span class="string">'url'</span>,</div><div class="line">    <span class="string">'REDIS_HOST'</span>: <span class="string">'host'</span>,</div><div class="line">    <span class="string">'REDIS_PORT'</span>: <span class="string">'port'</span>,</div><div class="line">    <span class="string">'REDIS_ENCODING'</span>: <span class="string">'encoding'</span>,</div><div class="line">&#125;</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_redis_from_settings</span><span class="params">(settings)</span>:</span></div><div class="line">    <span class="string">"""Returns a redis client instance from given Scrapy settings object.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    This function uses ``get_client`` to instantiate the client and uses</span></div><div class="line"><span class="string">    ``defaults.REDIS_PARAMS`` global as defaults values for the parameters. You</span></div><div class="line"><span class="string">    can override them using the ``REDIS_PARAMS`` setting.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    settings : Settings</span></div><div class="line"><span class="string">        A scrapy settings object. See the supported settings below.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns</span></div><div class="line"><span class="string">    -------</span></div><div class="line"><span class="string">    server</span></div><div class="line"><span class="string">        Redis client instance.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Other Parameters</span></div><div class="line"><span class="string">    ----------------</span></div><div class="line"><span class="string">    REDIS_URL : str, optional</span></div><div class="line"><span class="string">        Server connection URL.</span></div><div class="line"><span class="string">    REDIS_HOST : str, optional</span></div><div class="line"><span class="string">        Server host.</span></div><div class="line"><span class="string">    REDIS_PORT : str, optional</span></div><div class="line"><span class="string">        Server port.</span></div><div class="line"><span class="string">    REDIS_ENCODING : str, optional</span></div><div class="line"><span class="string">        Data encoding.</span></div><div class="line"><span class="string">    REDIS_PARAMS : dict, optional</span></div><div class="line"><span class="string">        Additional client parameters.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="comment">#  获取Redis的设置参数</span></div><div class="line">    params = defaults.REDIS_PARAMS.copy()</div><div class="line">    params.update(settings.getdict(<span class="string">'REDIS_PARAMS'</span>))</div><div class="line">    <span class="keyword">for</span> source, dest <span class="keyword">in</span> SETTINGS_PARAMS_MAP.items():</div><div class="line">        val = settings.get(source)</div><div class="line">        <span class="keyword">if</span> val:</div><div class="line">            params[dest] = val</div><div class="line"></div><div class="line">    <span class="comment"># ``redis_cls``是redis类的路径</span></div><div class="line">    <span class="keyword">if</span> isinstance(params.get(<span class="string">'redis_cls'</span>), six.string_types):</div><div class="line">        params[<span class="string">'redis_cls'</span>] = load_object(params[<span class="string">'redis_cls'</span>])  <span class="comment"># 通过'redis_cls'得到redis对象，如果if为False，get_redis函数中会加载默认的redis类StrictRedis</span></div><div class="line"></div><div class="line">    <span class="keyword">return</span> get_redis(**params)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Backwards compatible alias.</span></div><div class="line">from_settings = get_redis_from_settings</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_redis</span><span class="params">(**kwargs)</span>:</span></div><div class="line">    <span class="string">"""Returns a redis client instance.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Parameters</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    redis_cls : class, optional</span></div><div class="line"><span class="string">        Defaults to ``redis.StrictRedis``.</span></div><div class="line"><span class="string">    url : str, optional</span></div><div class="line"><span class="string">        If given, ``redis_cls.from_url`` is used to instantiate the class.</span></div><div class="line"><span class="string">    **kwargs</span></div><div class="line"><span class="string">        Extra parameters to be passed to the ``redis_cls`` class.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns</span></div><div class="line"><span class="string">    -------</span></div><div class="line"><span class="string">    server</span></div><div class="line"><span class="string">        Redis client instance.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line">    redis_cls = kwargs.pop(<span class="string">'redis_cls'</span>, defaults.REDIS_CLS)  <span class="comment"># defaults.REDIS_CLS 默认值redis.StrictRedis</span></div><div class="line">    url = kwargs.pop(<span class="string">'url'</span>, <span class="keyword">None</span>)</div><div class="line">    <span class="keyword">if</span> url:</div><div class="line">        <span class="keyword">return</span> redis_cls.from_url(url, **kwargs) <span class="comment"># url不为None，则通过url创建一个Redis连接客户端实例</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">return</span> redis_cls(**kwargs)</div></pre></td></tr></table></figure>
<h3 id="dupefilter-py"><a href="#dupefilter-py" class="headerlink" title="dupefilter.py"></a>dupefilter.py</h3><blockquote>
<p>实现去重机制</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line"><span class="keyword">from</span> scrapy.dupefilters <span class="keyword">import</span> BaseDupeFilter</div><div class="line"><span class="keyword">from</span> scrapy.utils.request <span class="keyword">import</span> request_fingerprint  <span class="comment"># 计算url的指纹</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> . <span class="keyword">import</span> defaults</div><div class="line"><span class="keyword">from</span> .connection <span class="keyword">import</span> get_redis_from_settings</div><div class="line"></div><div class="line"></div><div class="line">logger = logging.getLogger(__name__)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># <span class="doctag">TODO:</span> Rename class to RedisDupeFilter.</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RFPDupeFilter</span><span class="params">(BaseDupeFilter)</span>:</span></div><div class="line">    <span class="string">"""Redis-based request duplicates filter.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    This class can also be used with default Scrapy's scheduler.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    logger = logger</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, server, key, debug=False)</span>:</span></div><div class="line">        <span class="string">"""Initialize the duplicates filter.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Parameters</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        server : redis.StrictRedis</span></div><div class="line"><span class="string">            The redis server instance.</span></div><div class="line"><span class="string">        key : str</span></div><div class="line"><span class="string">            Redis key Where to store fingerprints.</span></div><div class="line"><span class="string">        debug : bool, optional</span></div><div class="line"><span class="string">            Whether to log filtered requests.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        """</span></div><div class="line">        self.server = server</div><div class="line">        self.key = key</div><div class="line">        self.debug = debug</div><div class="line">        self.logdupes = <span class="keyword">True</span></div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_settings</span><span class="params">(cls, settings)</span>:</span></div><div class="line">        <span class="string">"""Returns an instance from given settings.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        This uses by default the key ``dupefilter:&lt;timestamp&gt;``. When using the</span></div><div class="line"><span class="string">        ``scrapy_redis.scheduler.Scheduler`` class, this method is not used as</span></div><div class="line"><span class="string">        it needs to pass the spider name in the key.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Parameters</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        settings : scrapy.settings.Settings</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Returns</span></div><div class="line"><span class="string">        -------</span></div><div class="line"><span class="string">        RFPDupeFilter</span></div><div class="line"><span class="string">            A RFPDupeFilter instance.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        """</span></div><div class="line">        server = get_redis_from_settings(settings)</div><div class="line">        <span class="comment"># <span class="doctag">XXX:</span> This creates one-time key. needed to support to use this</span></div><div class="line">        <span class="comment"># class as standalone dupefilter with scrapy's default scheduler</span></div><div class="line">        <span class="comment"># if scrapy passes spider on open() method this wouldn't be needed</span></div><div class="line">        <span class="comment"># <span class="doctag">TODO:</span> Use SCRAPY_JOB env as default and fallback to timestamp.</span></div><div class="line">        key = defaults.DUPEFILTER_KEY % &#123;<span class="string">'timestamp'</span>: int(time.time())&#125;</div><div class="line">        debug = settings.getbool(<span class="string">'DUPEFILTER_DEBUG'</span>)</div><div class="line">        <span class="keyword">return</span> cls(server, key=key, debug=debug)</div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></div><div class="line">        <span class="string">"""Returns instance from crawler.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Parameters</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        crawler : scrapy.crawler.Crawler</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Returns</span></div><div class="line"><span class="string">        -------</span></div><div class="line"><span class="string">        RFPDupeFilter</span></div><div class="line"><span class="string">            Instance of RFPDupeFilter.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="keyword">return</span> cls.from_settings(crawler.settings)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request_seen</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line"><span class="string">        去重判断</span></div><div class="line"><span class="string">        如果request已经请求过了，则返回false</span></div><div class="line"><span class="string">        """</span></div><div class="line">        fp = self.request_fingerprint(request)</div><div class="line">        <span class="comment"># This returns the number of values added, zero if already exists.</span></div><div class="line">        <span class="comment"># redis客户端的sadd操作，即向集合里添加元素</span></div><div class="line">        added = self.server.sadd(self.key, fp)</div><div class="line">        <span class="keyword">return</span> added == <span class="number">0</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request_fingerprint</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="keyword">return</span> request_fingerprint(request)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self, reason=<span class="string">''</span>)</span>:</span></div><div class="line">        <span class="string">"""Delete data on close. Called by Scrapy's scheduler.</span></div><div class="line"><span class="string">        退出时清除URL指纹数据</span></div><div class="line"><span class="string">        Parameters</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        reason : str, optional</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        """</span></div><div class="line">        self.clear()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Clears fingerprints data."""</span></div><div class="line">        self.server.delete(self.key)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">log</span><span class="params">(self, request, spider)</span>:</span></div><div class="line">        <span class="string">"""Logs given request.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Parameters</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        request : scrapy.http.Request</span></div><div class="line"><span class="string">        spider : scrapy.spiders.Spider</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="keyword">if</span> self.debug:</div><div class="line">            msg = <span class="string">"Filtered duplicate request: %(request)s"</span></div><div class="line">            self.logger.debug(msg, &#123;<span class="string">'request'</span>: request&#125;, extra=&#123;<span class="string">'spider'</span>: spider&#125;)</div><div class="line">        <span class="keyword">elif</span> self.logdupes:</div><div class="line">            msg = (<span class="string">"Filtered duplicate request %(request)s"</span></div><div class="line">                   <span class="string">" - no more duplicates will be shown"</span></div><div class="line">                   <span class="string">" (see DUPEFILTER_DEBUG to show all duplicates)"</span>)</div><div class="line">            self.logger.debug(msg, &#123;<span class="string">'request'</span>: request&#125;, extra=&#123;<span class="string">'spider'</span>: spider&#125;)</div><div class="line">            self.logdupes = <span class="keyword">False</span></div></pre></td></tr></table></figure>
<h3 id="picklecompat-py"><a href="#picklecompat-py" class="headerlink" title="picklecompat.py"></a>picklecompat.py</h3><blockquote>
<p>实现序列化， 参考<a href="http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/00138683221577998e407bb309542d9b6a68d9276bc3dbe000" target="_blank" rel="external">廖雪峰-序列化</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="string">"""A pickle wrapper module with protocol=-1 by default.</span></div><div class="line"><span class="string">redis数据格式有整数和字符串，其他的Python复杂的数据类型需要序列化成字符串后存入redis</span></div><div class="line"><span class="string">把变量从内存中变成可存储或传输的过程称之为序列化，</span></div><div class="line"><span class="string">"""</span></div><div class="line"><span class="keyword">try</span>:</div><div class="line">    <span class="keyword">import</span> cPickle <span class="keyword">as</span> pickle  <span class="comment"># PY2</span></div><div class="line"><span class="keyword">except</span> ImportError:</div><div class="line">    <span class="keyword">import</span> pickle</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loads</span><span class="params">(s)</span>:</span></div><div class="line">    <span class="keyword">return</span> pickle.loads(s)</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">dumps</span><span class="params">(obj)</span>:</span></div><div class="line">    <span class="keyword">return</span> pickle.dumps(obj, protocol=<span class="number">-1</span>)</div></pre></td></tr></table></figure>
<h3 id="pipelines-py"><a href="#pipelines-py" class="headerlink" title="pipelines.py"></a>pipelines.py</h3><p>&gt;</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scrapy.utils.misc <span class="keyword">import</span> load_object</div><div class="line"><span class="keyword">from</span> scrapy.utils.serialize <span class="keyword">import</span> ScrapyJSONEncoder</div><div class="line"><span class="keyword">from</span> twisted.internet.threads <span class="keyword">import</span> deferToThread</div><div class="line"><span class="keyword">from</span> . <span class="keyword">import</span> connection, defaults</div><div class="line"></div><div class="line"></div><div class="line">default_serialize = ScrapyJSONEncoder().encode</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisPipeline</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="string">"""Pushes serialized item into a redis list/queue</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Settings</span></div><div class="line"><span class="string">    --------</span></div><div class="line"><span class="string">    REDIS_ITEMS_KEY : str</span></div><div class="line"><span class="string">        Redis key where to store items.</span></div><div class="line"><span class="string">    REDIS_ITEMS_SERIALIZER : str</span></div><div class="line"><span class="string">        Object path to serializer function.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, server,</span></span></div><div class="line"><span class="function"><span class="params">                 key=defaults.PIPELINE_KEY,</span></span></div><div class="line"><span class="function"><span class="params">                 serialize_func=default_serialize)</span>:</span></div><div class="line">        <span class="string">"""Initialize pipeline.</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        server : StrictRedis,Redis client instance.</span></div><div class="line"><span class="string">        key : str,Redis key where to store items.</span></div><div class="line"><span class="string">        serialize_func : callable,Items serializer function.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        self.server = server</div><div class="line">        self.key = key  <span class="comment"># defaults.PIPELINE_KEY = '%(spider)s:items',不同的爬虫用不同的key</span></div><div class="line">        self.serialize = serialize_func</div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_settings</span><span class="params">(cls, settings)</span>:</span></div><div class="line">        params = &#123;</div><div class="line">            <span class="string">'server'</span>: connection.from_settings(settings),</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> settings.get(<span class="string">'REDIS_ITEMS_KEY'</span>):</div><div class="line">            params[<span class="string">'key'</span>] = settings[<span class="string">'REDIS_ITEMS_KEY'</span>]</div><div class="line">        <span class="keyword">if</span> settings.get(<span class="string">'REDIS_ITEMS_SERIALIZER'</span>):</div><div class="line">            params[<span class="string">'serialize_func'</span>] = load_object(</div><div class="line">                settings[<span class="string">'REDIS_ITEMS_SERIALIZER'</span>]</div><div class="line">            )</div><div class="line"></div><div class="line">        <span class="keyword">return</span> cls(**params)</div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></div><div class="line">        <span class="keyword">return</span> cls.from_settings(crawler.settings)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">        <span class="keyword">return</span> deferToThread(self._process_item, item, spider)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_process_item</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">        key = self.item_key(item, spider)</div><div class="line">        data = self.serialize(item)</div><div class="line">        self.server.rpush(key, data)</div><div class="line">        <span class="keyword">return</span> item</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_key</span><span class="params">(self, item, spider)</span>:</span></div><div class="line">        <span class="string">"""Returns redis key based on given spider.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Override this function to use a different key depending on the item</span></div><div class="line"><span class="string">        and/or spider.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="keyword">return</span> self.key % &#123;<span class="string">'spider'</span>: spider.name&#125;</div></pre></td></tr></table></figure>
<h3 id="Queue-py"><a href="#Queue-py" class="headerlink" title="Queue.py"></a>Queue.py</h3><blockquote>
<p>实现消息队列</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scrapy.utils.reqser <span class="keyword">import</span> request_to_dict, request_from_dict</div><div class="line"><span class="keyword">from</span> . <span class="keyword">import</span> picklecompat</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="string">"""Per-spider base queue class"""</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, server, spider, key, serializer=None)</span>:</span></div><div class="line">        <span class="string">"""Initialize per-spider redis queue.</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        server : StrictRedis,Redis client instance.</span></div><div class="line"><span class="string">        spider : Spider,Scrapy spider instance.</span></div><div class="line"><span class="string">        key: str, Redis key where to put and get messages.</span></div><div class="line"><span class="string">        serializer : object, Serializer object with ``loads`` and ``dumps`` methods.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="keyword">if</span> serializer <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="comment"># Backward compatibility.</span></div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> deprecate pickle.</span></div><div class="line">            serializer = picklecompat</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(serializer, <span class="string">'loads'</span>):</div><div class="line">            <span class="keyword">raise</span> TypeError(<span class="string">"serializer does not implement 'loads' function: %r"</span></div><div class="line">                            % serializer)</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> hasattr(serializer, <span class="string">'dumps'</span>):</div><div class="line">            <span class="keyword">raise</span> TypeError(<span class="string">"serializer '%s' does not implement 'dumps' function: %r"</span></div><div class="line">                            % serializer)</div><div class="line"></div><div class="line">        self.server = server</div><div class="line">        self.spider = spider</div><div class="line">        self.key = key % &#123;<span class="string">'spider'</span>: spider.name&#125;</div><div class="line">        self.serializer = serializer</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_encode_request</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="string">"""Encode a request object"""</span></div><div class="line">        obj = request_to_dict(request, self.spider)</div><div class="line">        <span class="keyword">return</span> self.serializer.dumps(obj)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_decode_request</span><span class="params">(self, encoded_request)</span>:</span></div><div class="line">        <span class="string">"""Decode an request previously encoded"""</span></div><div class="line">        obj = self.serializer.loads(encoded_request)</div><div class="line">        <span class="keyword">return</span> request_from_dict(obj, self.spider)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Return the length of the queue"""</span></div><div class="line">        <span class="keyword">raise</span> NotImplementedError</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="string">"""Push a request"""</span></div><div class="line">        <span class="keyword">raise</span> NotImplementedError</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self, timeout=<span class="number">0</span>)</span>:</span></div><div class="line">        <span class="string">"""Pop a request"""</span></div><div class="line">        <span class="keyword">raise</span> NotImplementedError</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Clear queue/stack"""</span></div><div class="line">        self.server.delete(self.key)</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">FifoQueue</span><span class="params">(Base)</span>:</span></div><div class="line">    <span class="string">"""Per-spider FIFO queue"""</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Return the length of the queue"""</span></div><div class="line">        <span class="keyword">return</span> self.server.llen(self.key)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="string">"""Push a request"""</span></div><div class="line">        self.server.lpush(self.key, self._encode_request(request))</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self, timeout=<span class="number">0</span>)</span>:</span></div><div class="line">        <span class="string">"""Pop a request"""</span></div><div class="line">        <span class="keyword">if</span> timeout &gt; <span class="number">0</span>:</div><div class="line">            data = self.server.brpop(self.key, timeout)</div><div class="line">            <span class="keyword">if</span> isinstance(data, tuple):</div><div class="line">                data = data[<span class="number">1</span>]</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            data = self.server.rpop(self.key)</div><div class="line">        <span class="keyword">if</span> data:</div><div class="line">            <span class="keyword">return</span> self._decode_request(data)</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">PriorityQueue</span><span class="params">(Base)</span>:</span></div><div class="line">    <span class="string">"""Per-spider priority queue abstraction using redis' sorted set"""</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Return the length of the queue"""</span></div><div class="line">        <span class="keyword">return</span> self.server.zcard(self.key)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="string">"""Push a request"""</span></div><div class="line">        data = self._encode_request(request)</div><div class="line">        score = -request.priority</div><div class="line">        <span class="comment"># We don't use zadd method as the order of arguments change depending on</span></div><div class="line">        <span class="comment"># whether the class is Redis or StrictRedis, and the option of using</span></div><div class="line">        <span class="comment"># kwargs only accepts strings, not bytes.</span></div><div class="line">        self.server.execute_command(<span class="string">'ZADD'</span>, self.key, score, data)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self, timeout=<span class="number">0</span>)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line"><span class="string">        Pop a request</span></div><div class="line"><span class="string">        timeout not support in this queue class</span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="comment"># use atomic range/remove using multi/exec</span></div><div class="line">        pipe = self.server.pipeline()</div><div class="line">        pipe.multi()</div><div class="line">        pipe.zrange(self.key, <span class="number">0</span>, <span class="number">0</span>).zremrangebyrank(self.key, <span class="number">0</span>, <span class="number">0</span>)</div><div class="line">        results, count = pipe.execute()</div><div class="line">        <span class="keyword">if</span> results:</div><div class="line">            <span class="keyword">return</span> self._decode_request(results[<span class="number">0</span>])</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LifoQueue</span><span class="params">(Base)</span>:</span></div><div class="line">    <span class="string">"""Per-spider LIFO queue."""</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Return the length of the stack"""</span></div><div class="line">        <span class="keyword">return</span> self.server.llen(self.key)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">push</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="string">"""Push a request"""</span></div><div class="line">        self.server.lpush(self.key, self._encode_request(request))</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pop</span><span class="params">(self, timeout=<span class="number">0</span>)</span>:</span></div><div class="line">        <span class="string">"""Pop a request"""</span></div><div class="line">        <span class="keyword">if</span> timeout &gt; <span class="number">0</span>:</div><div class="line">            data = self.server.blpop(self.key, timeout)</div><div class="line">            <span class="keyword">if</span> isinstance(data, tuple):</div><div class="line">                data = data[<span class="number">1</span>]</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            data = self.server.lpop(self.key)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> data:</div><div class="line">            <span class="keyword">return</span> self._decode_request(data)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># <span class="doctag">TODO:</span> Deprecate the use of these names.</span></div><div class="line">SpiderQueue = FifoQueue  <span class="comment"># 先进先出</span></div><div class="line">SpiderStack = LifoQueue  <span class="comment"># 后进先出</span></div><div class="line">SpiderPriorityQueue = PriorityQueue  <span class="comment"># 优先级队列</span></div></pre></td></tr></table></figure>
<h3 id="scheduler-py"><a href="#scheduler-py" class="headerlink" title="scheduler.py"></a>scheduler.py</h3><blockquote>
<p>调度，对request查重，为spider分配request任务。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> importlib</div><div class="line"><span class="keyword">import</span> six</div><div class="line"><span class="keyword">from</span> scrapy.utils.misc <span class="keyword">import</span> load_object</div><div class="line"><span class="keyword">from</span> . <span class="keyword">import</span> connection, defaults</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># <span class="doctag">TODO:</span> add SCRAPY_JOB support.</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scheduler</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="string">"""Redis-based scheduler</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Settings</span></div><div class="line"><span class="string">    --------</span></div><div class="line"><span class="string">    SCHEDULER_PERSIST : bool (default: False)</span></div><div class="line"><span class="string">        Whether to persist or clear redis queue.</span></div><div class="line"><span class="string">    SCHEDULER_FLUSH_ON_START : bool (default: False)</span></div><div class="line"><span class="string">        Whether to flush redis queue on start.</span></div><div class="line"><span class="string">    SCHEDULER_IDLE_BEFORE_CLOSE : int (default: 0)</span></div><div class="line"><span class="string">        How many seconds to wait before closing if no message is received.</span></div><div class="line"><span class="string">    SCHEDULER_QUEUE_KEY : str</span></div><div class="line"><span class="string">        Scheduler redis key.</span></div><div class="line"><span class="string">    SCHEDULER_QUEUE_CLASS : str</span></div><div class="line"><span class="string">        Scheduler queue class.</span></div><div class="line"><span class="string">    SCHEDULER_DUPEFILTER_KEY : str</span></div><div class="line"><span class="string">        Scheduler dupefilter redis key.</span></div><div class="line"><span class="string">    SCHEDULER_DUPEFILTER_CLASS : str</span></div><div class="line"><span class="string">        Scheduler dupefilter class.</span></div><div class="line"><span class="string">    SCHEDULER_SERIALIZER : str</span></div><div class="line"><span class="string">        Scheduler serializer.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, server,</span></span></div><div class="line"><span class="function"><span class="params">                 persist=False,</span></span></div><div class="line"><span class="function"><span class="params">                 flush_on_start=False,</span></span></div><div class="line"><span class="function"><span class="params">                 queue_key=defaults.SCHEDULER_QUEUE_KEY,</span></span></div><div class="line"><span class="function"><span class="params">                 queue_cls=defaults.SCHEDULER_QUEUE_CLASS,</span></span></div><div class="line"><span class="function"><span class="params">                 dupefilter_key=defaults.SCHEDULER_DUPEFILTER_KEY,</span></span></div><div class="line"><span class="function"><span class="params">                 dupefilter_cls=defaults.SCHEDULER_DUPEFILTER_CLASS,</span></span></div><div class="line"><span class="function"><span class="params">                 idle_before_close=<span class="number">0</span>,</span></span></div><div class="line"><span class="function"><span class="params">                 serializer=None)</span>:</span></div><div class="line">        <span class="string">"""Initialize scheduler.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Parameters</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        server : Redis</span></div><div class="line"><span class="string">            The redis server instance.</span></div><div class="line"><span class="string">        persist : bool</span></div><div class="line"><span class="string">            Whether to flush requests when closing. Default is False.</span></div><div class="line"><span class="string">        flush_on_start : bool</span></div><div class="line"><span class="string">            Whether to flush requests on start. Default is False.</span></div><div class="line"><span class="string">        queue_key : str</span></div><div class="line"><span class="string">            Requests queue key.</span></div><div class="line"><span class="string">        queue_cls : str</span></div><div class="line"><span class="string">            Importable path to the queue class.</span></div><div class="line"><span class="string">        dupefilter_key : str</span></div><div class="line"><span class="string">            Duplicates filter key.</span></div><div class="line"><span class="string">        dupefilter_cls : str</span></div><div class="line"><span class="string">            Importable path to the dupefilter class.</span></div><div class="line"><span class="string">        idle_before_close : int</span></div><div class="line"><span class="string">            Timeout before giving up.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="keyword">if</span> idle_before_close &lt; <span class="number">0</span>:</div><div class="line">            <span class="keyword">raise</span> TypeError(<span class="string">"idle_before_close cannot be negative"</span>)</div><div class="line"></div><div class="line">        self.server = server</div><div class="line">        self.persist = persist</div><div class="line">        self.flush_on_start = flush_on_start</div><div class="line">        self.queue_key = queue_key</div><div class="line">        self.queue_cls = queue_cls</div><div class="line">        self.dupefilter_cls = dupefilter_cls</div><div class="line">        self.dupefilter_key = dupefilter_key</div><div class="line">        self.idle_before_close = idle_before_close</div><div class="line">        self.serializer = serializer</div><div class="line">        self.stats = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> len(self.queue)</div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_settings</span><span class="params">(cls, settings)</span>:</span></div><div class="line">        kwargs = &#123;</div><div class="line">            <span class="string">'persist'</span>: settings.getbool(<span class="string">'SCHEDULER_PERSIST'</span>),</div><div class="line">            <span class="string">'flush_on_start'</span>: settings.getbool(<span class="string">'SCHEDULER_FLUSH_ON_START'</span>),</div><div class="line">            <span class="string">'idle_before_close'</span>: settings.getint(<span class="string">'SCHEDULER_IDLE_BEFORE_CLOSE'</span>),</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="comment"># If these values are missing, it means we want to use the defaults.</span></div><div class="line">        optional = &#123;</div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> Use custom prefixes for this settings to note that are</span></div><div class="line">            <span class="comment"># specific to scrapy-redis.</span></div><div class="line">            <span class="string">'queue_key'</span>: <span class="string">'SCHEDULER_QUEUE_KEY'</span>,</div><div class="line">            <span class="string">'queue_cls'</span>: <span class="string">'SCHEDULER_QUEUE_CLASS'</span>,</div><div class="line">            <span class="string">'dupefilter_key'</span>: <span class="string">'SCHEDULER_DUPEFILTER_KEY'</span>,</div><div class="line">            <span class="comment"># We use the default setting name to keep compatibility.</span></div><div class="line">            <span class="string">'dupefilter_cls'</span>: <span class="string">'DUPEFILTER_CLASS'</span>,</div><div class="line">            <span class="string">'serializer'</span>: <span class="string">'SCHEDULER_SERIALIZER'</span>,</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span> name, setting_name <span class="keyword">in</span> optional.items():</div><div class="line">            val = settings.get(setting_name)</div><div class="line">            <span class="keyword">if</span> val:</div><div class="line">                kwargs[name] = val</div><div class="line"></div><div class="line">        <span class="comment"># Support serializer as a path to a module.</span></div><div class="line">        <span class="keyword">if</span> isinstance(kwargs.get(<span class="string">'serializer'</span>), six.string_types):</div><div class="line">            kwargs[<span class="string">'serializer'</span>] = importlib.import_module(kwargs[<span class="string">'serializer'</span>])</div><div class="line"></div><div class="line">        server = connection.from_settings(settings)</div><div class="line">        <span class="comment"># Ensure the connection is working.</span></div><div class="line">        server.ping()</div><div class="line"></div><div class="line">        <span class="keyword">return</span> cls(server=server, **kwargs)</div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></div><div class="line">        instance = cls.from_settings(crawler.settings)</div><div class="line">        <span class="comment"># <span class="doctag">FIXME:</span> for now, stats are only supported from this constructor</span></div><div class="line">        instance.stats = crawler.stats</div><div class="line">        <span class="keyword">return</span> instance</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(self, spider)</span>:</span></div><div class="line">        self.spider = spider</div><div class="line"></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            <span class="comment"># 根据对象名字创建一个对象</span></div><div class="line">            self.queue = load_object(self.queue_cls)(</div><div class="line">                server=self.server,</div><div class="line">                spider=spider,</div><div class="line">                key=self.queue_key % &#123;<span class="string">'spider'</span>: spider.name&#125;,</div><div class="line">                serializer=self.serializer,</div><div class="line">            )</div><div class="line">        <span class="keyword">except</span> TypeError <span class="keyword">as</span> e:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"Failed to instantiate queue class '%s': %s"</span>,</div><div class="line">                             self.queue_cls, e)</div><div class="line"></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            self.df = load_object(self.dupefilter_cls)(</div><div class="line">                server=self.server,</div><div class="line">                key=self.dupefilter_key % &#123;<span class="string">'spider'</span>: spider.name&#125;,</div><div class="line">                debug=spider.settings.getbool(<span class="string">'DUPEFILTER_DEBUG'</span>),</div><div class="line">            )</div><div class="line">        <span class="keyword">except</span> TypeError <span class="keyword">as</span> e:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"Failed to instantiate dupefilter class '%s': %s"</span>,</div><div class="line">                             self.dupefilter_cls, e)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.flush_on_start:</div><div class="line">            self.flush()</div><div class="line">        <span class="comment"># notice if there are requests already in the queue to resume the crawl</span></div><div class="line">        <span class="keyword">if</span> len(self.queue):</div><div class="line">            spider.log(<span class="string">"Resuming crawl (%d requests scheduled)"</span> % len(self.queue))</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self, reason)</span>:</span></div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.persist:</div><div class="line">            self.flush()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">flush</span><span class="params">(self)</span>:</span></div><div class="line">        self.df.clear()</div><div class="line">        self.queue.clear()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">enqueue_request</span><span class="params">(self, request)</span>:</span></div><div class="line">        <span class="comment"># 如果需要检测去重，且检测到有重复，返回False</span></div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> request.dont_filter <span class="keyword">and</span> self.df.request_seen(request):</div><div class="line">            self.df.log(request, self.spider)</div><div class="line">            <span class="keyword">return</span> <span class="keyword">False</span></div><div class="line">        <span class="keyword">if</span> self.stats:</div><div class="line">            self.stats.inc_value(<span class="string">'scheduler/enqueued/redis'</span>, spider=self.spider)</div><div class="line">        <span class="comment"># 将request入队，返回True</span></div><div class="line">        self.queue.push(request)</div><div class="line">        <span class="keyword">return</span> <span class="keyword">True</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">next_request</span><span class="params">(self)</span>:</span></div><div class="line">        block_pop_timeout = self.idle_before_close</div><div class="line">        <span class="comment"># 分发request</span></div><div class="line">        request = self.queue.pop(block_pop_timeout)</div><div class="line">        <span class="keyword">if</span> request <span class="keyword">and</span> self.stats:</div><div class="line">            self.stats.inc_value(<span class="string">'scheduler/dequeued/redis'</span>, spider=self.spider)</div><div class="line">        <span class="keyword">return</span> request</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">has_pending_requests</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> len(self) &gt; <span class="number">0</span></div></pre></td></tr></table></figure>
<h3 id="spiders-py"><a href="#spiders-py" class="headerlink" title="spiders.py"></a>spiders.py</h3><blockquote>
<p>爬虫类，</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</div><div class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DontCloseSpider</div><div class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> Spider, CrawlSpider</div><div class="line"><span class="keyword">from</span> . <span class="keyword">import</span> connection, defaults</div><div class="line"><span class="keyword">from</span> .utils <span class="keyword">import</span> bytes_to_str</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Mixin 混合类型，利用多重继承来简洁的实现组合模式</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisMixin</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="string">"""Mixin class to implement reading urls from a redis queue."""</span></div><div class="line">    redis_key = <span class="keyword">None</span></div><div class="line">    redis_batch_size = <span class="keyword">None</span></div><div class="line">    redis_encoding = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="comment"># Redis client placeholder.</span></div><div class="line">    server = <span class="keyword">None</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Returns a batch of start requests from redis."""</span></div><div class="line">        <span class="keyword">return</span> self.next_requests()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup_redis</span><span class="params">(self, crawler=None)</span>:</span></div><div class="line">        <span class="string">"""Setup redis connection and idle signal.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        This should be called after the spider has set its crawler object.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        <span class="keyword">if</span> self.server <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">return</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> crawler <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="comment"># We allow optional crawler argument to keep backwards</span></div><div class="line">            <span class="comment"># compatibility.</span></div><div class="line">            <span class="comment"># <span class="doctag">XXX:</span> Raise a deprecation warning.</span></div><div class="line">            crawler = getattr(self, <span class="string">'crawler'</span>, <span class="keyword">None</span>)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> crawler <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"crawler is required"</span>)</div><div class="line"></div><div class="line">        settings = crawler.settings</div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.redis_key <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            self.redis_key = settings.get(</div><div class="line">                <span class="string">'REDIS_START_URLS_KEY'</span>, defaults.START_URLS_KEY,</div><div class="line">            )</div><div class="line"></div><div class="line">        self.redis_key = self.redis_key % &#123;<span class="string">'name'</span>: self.name&#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.redis_key.strip():</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"redis_key must not be empty"</span>)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.redis_batch_size <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            <span class="comment"># <span class="doctag">TODO:</span> Deprecate this setting (REDIS_START_URLS_BATCH_SIZE).</span></div><div class="line">            self.redis_batch_size = settings.getint(</div><div class="line">                <span class="string">'REDIS_START_URLS_BATCH_SIZE'</span>,</div><div class="line">                settings.getint(<span class="string">'CONCURRENT_REQUESTS'</span>),</div><div class="line">            )</div><div class="line"></div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            self.redis_batch_size = int(self.redis_batch_size)</div><div class="line">        <span class="keyword">except</span> (TypeError, ValueError):</div><div class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"redis_batch_size must be an integer"</span>)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.redis_encoding <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            self.redis_encoding = settings.get(<span class="string">'REDIS_ENCODING'</span>, defaults.REDIS_ENCODING)</div><div class="line"></div><div class="line">        self.logger.info(<span class="string">"Reading start URLs from redis key '%(redis_key)s' "</span></div><div class="line">                         <span class="string">"(batch size: %(redis_batch_size)s, encoding: %(redis_encoding)s"</span>,</div><div class="line">                         self.__dict__)</div><div class="line"></div><div class="line">        self.server = connection.from_settings(crawler.settings)</div><div class="line">        <span class="comment"># The idle signal is called when the spider has no requests left,</span></div><div class="line">        <span class="comment"># that's when we will schedule new requests from redis queue</span></div><div class="line">        crawler.signals.connect(self.spider_idle, signal=signals.spider_idle)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">next_requests</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Returns a request to be scheduled or none."""</span></div><div class="line">        use_set = self.settings.getbool(<span class="string">'REDIS_START_URLS_AS_SET'</span>, defaults.START_URLS_AS_SET)</div><div class="line">        fetch_one = self.server.spop <span class="keyword">if</span> use_set <span class="keyword">else</span> self.server.lpop</div><div class="line">        <span class="comment"># <span class="doctag">XXX:</span> Do we need to use a timeout here?</span></div><div class="line">        found = <span class="number">0</span></div><div class="line">        <span class="comment"># <span class="doctag">TODO:</span> Use redis pipeline execution.</span></div><div class="line">        <span class="keyword">while</span> found &lt; self.redis_batch_size:</div><div class="line">            data = fetch_one(self.redis_key) <span class="comment"># 取出一条数据</span></div><div class="line">            <span class="keyword">if</span> <span class="keyword">not</span> data:</div><div class="line">                <span class="comment"># Queue empty.</span></div><div class="line">                <span class="keyword">break</span></div><div class="line">            req = self.make_request_from_data(data)</div><div class="line">            <span class="keyword">if</span> req:</div><div class="line">                <span class="keyword">yield</span> req</div><div class="line">                found += <span class="number">1</span></div><div class="line">            <span class="keyword">else</span>:</div><div class="line">                self.logger.debug(<span class="string">"Request not made from data: %r"</span>, data)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> found:</div><div class="line">            self.logger.debug(<span class="string">"Read %s requests from '%s'"</span>, found, self.redis_key)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_request_from_data</span><span class="params">(self, data)</span>:</span></div><div class="line">        <span class="string">"""Returns a Request instance from data coming from Redis.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        By default, ``data`` is an encoded URL. You can override this method to</span></div><div class="line"><span class="string">        provide your own message decoding.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Parameters</span></div><div class="line"><span class="string">        ----------</span></div><div class="line"><span class="string">        data : bytes</span></div><div class="line"><span class="string">            Message from redis.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        """</span></div><div class="line">        url = bytes_to_str(data, self.redis_encoding)</div><div class="line">        <span class="keyword">return</span> self.make_requests_from_url(url)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">schedule_next_requests</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Schedules a request if available"""</span></div><div class="line">        <span class="comment"># <span class="doctag">TODO:</span> While there is capacity, schedule a batch of redis requests.</span></div><div class="line">        <span class="keyword">for</span> req <span class="keyword">in</span> self.next_requests():</div><div class="line">            self.crawler.engine.crawl(req, spider=self)</div><div class="line">    </div><div class="line">    <span class="comment">#  当爬虫空闲时</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_idle</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Schedules a request if available, otherwise waits."""</span></div><div class="line">        <span class="comment"># <span class="doctag">XXX:</span> Handle a sentinel to close the spider.</span></div><div class="line">        self.schedule_next_requests()</div><div class="line">        <span class="keyword">raise</span> DontCloseSpider</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisSpider</span><span class="params">(RedisMixin, Spider)</span>:</span></div><div class="line">    <span class="string">"""Spider that reads urls from redis queue when idle.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Attributes</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    redis_key : str (default: REDIS_START_URLS_KEY)</span></div><div class="line"><span class="string">        Redis key where to fetch start URLs from..</span></div><div class="line"><span class="string">    redis_batch_size : int (default: CONCURRENT_REQUESTS)</span></div><div class="line"><span class="string">        Number of messages to fetch from redis on each attempt.</span></div><div class="line"><span class="string">    redis_encoding : str (default: REDIS_ENCODING)</span></div><div class="line"><span class="string">        Encoding to use when decoding messages from redis queue.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Settings</span></div><div class="line"><span class="string">    --------</span></div><div class="line"><span class="string">    REDIS_START_URLS_KEY : str (default: "&lt;spider.name&gt;:start_urls")</span></div><div class="line"><span class="string">        Default Redis key where to fetch start URLs from..</span></div><div class="line"><span class="string">    REDIS_START_URLS_BATCH_SIZE : int (deprecated by CONCURRENT_REQUESTS)</span></div><div class="line"><span class="string">        Default number of messages to fetch from redis on each attempt.</span></div><div class="line"><span class="string">    REDIS_START_URLS_AS_SET : bool (default: False)</span></div><div class="line"><span class="string">        Use SET operations to retrieve messages from the redis queue. If False,</span></div><div class="line"><span class="string">        the messages are retrieve using the LPOP command.</span></div><div class="line"><span class="string">    REDIS_ENCODING : str (default: "utf-8")</span></div><div class="line"><span class="string">        Default encoding to use when decoding messages from redis queue.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(self, crawler, *args, **kwargs)</span>:</span></div><div class="line">        obj = super(RedisSpider, self).from_crawler(crawler, *args, **kwargs)</div><div class="line">        obj.setup_redis(crawler)</div><div class="line">        <span class="keyword">return</span> obj</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RedisCrawlSpider</span><span class="params">(RedisMixin, CrawlSpider)</span>:</span></div><div class="line">    <span class="string">"""Spider that reads urls from redis queue when idle.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Attributes</span></div><div class="line"><span class="string">    ----------</span></div><div class="line"><span class="string">    redis_key : str (default: REDIS_START_URLS_KEY)</span></div><div class="line"><span class="string">        Redis key where to fetch start URLs from..</span></div><div class="line"><span class="string">    redis_batch_size : int (default: CONCURRENT_REQUESTS)</span></div><div class="line"><span class="string">        Number of messages to fetch from redis on each attempt.</span></div><div class="line"><span class="string">    redis_encoding : str (default: REDIS_ENCODING)</span></div><div class="line"><span class="string">        Encoding to use when decoding messages from redis queue.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Settings</span></div><div class="line"><span class="string">    --------</span></div><div class="line"><span class="string">    REDIS_START_URLS_KEY : str (default: "&lt;spider.name&gt;:start_urls")</span></div><div class="line"><span class="string">        Default Redis key where to fetch start URLs from..</span></div><div class="line"><span class="string">    REDIS_START_URLS_BATCH_SIZE : int (deprecated by CONCURRENT_REQUESTS)</span></div><div class="line"><span class="string">        Default number of messages to fetch from redis on each attempt.</span></div><div class="line"><span class="string">    REDIS_START_URLS_AS_SET : bool (default: True)</span></div><div class="line"><span class="string">        Use SET operations to retrieve messages from the redis queue.</span></div><div class="line"><span class="string">    REDIS_ENCODING : str (default: "utf-8")</span></div><div class="line"><span class="string">        Default encoding to use when decoding messages from redis queue.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(self, crawler, *args, **kwargs)</span>:</span></div><div class="line">        obj = super(RedisCrawlSpider, self).from_crawler(crawler, *args, **kwargs)</div><div class="line">        obj.setup_redis(crawler)</div><div class="line">        <span class="keyword">return</span> obj</div></pre></td></tr></table></figure>

      
    </div>
    <footer>
      
        
		<!--  livere评论支持 -->
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
    <a href="/page/2/" class="alignleft prev">上一页</a>
  
  
    <a href="/page/4/" class="alignright next">下一页</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  
<div>
<a href="javascript:;" class="popup-trigger">      
      <i class="menu-item-icon fa fa-search fa-fw"></i>        
   搜索
</a>
</div>


<div class="site-search">
<div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>
</div>

<script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }
     
  var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        success: function( xmlResponse ) {
            // get the contents from search data
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var str='<ul class=\"search-result-list\">';
                var str1=str                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>';
                if (this.value.trim().length <= 0) {
                    return;
                }
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
					else { isMatch=false; } //更新此处
					
					//更新此处
					
                    // show search results
                    if (isMatch) {
                        str += "<li><a href='"+ data_url +"' class='search-result-title' target='_blank'>"+ "> " + data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out characters
                            var start = first_occur - 20;
                            var end = first_occur + 30;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 10;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substr(start, end); 
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<em class=\"search-keyword\">"+keyword+"</em>");
                            })
							//console.log(match_content)
                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                    }
                })
                //修改
				if (str1==str){
					str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>';
					}
				
				$resultContent.innerHTML = str;
            })
        }
    })
}
    // search function;
 </script>
<script>

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
	  proceedsearch();
	  //添加的
	  document.getElementById("local-search-result").innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>';
     
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>
  
<script type="text/javascript">      
     var search_path = "search.xml";
     if (search_path.length == 0) {
     	search_path = "search.xml";
     }
     var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
</script>





  
<div class="widget tag">
  <h3 class="title" id="categories">分类</h3>
     <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a><span class="category-list-count">43</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/技术/django/">django</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/git/">git</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/latex/">latex</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/linux/">linux</a><span class="category-list-count">10</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/markdown/">markdown</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/mongodb/">mongodb</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/numpy/">numpy</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/pandas/">pandas</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/python/">python</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/python-爬虫/">python 爬虫</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/redis/">redis</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/scrapy/">scrapy</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/其他/">其他</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/生活/">生活</a><span class="category-list-count">11</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/生活/游戏/">游戏</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/生活/读书/">读书</a><span class="category-list-count">3</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/科研/">科研</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/资源/">资源</a><span class="category-list-count">3</span></li></ul> 
</div>
 

  <div class="widget tag">
<h3 class="title">简介</h3>
<ul class="entry">
<li>博主：帅羊羊</li>
<li>现状：武大CS在读研究生</li>
<li>Theme: <a href="https://github.com/zippera/lightum">Lightum</a>
<!-- <li>想交友的朋友请<a href="http://zipperary.com/about">联系我</a>！</li> -->
<li>QQ 号：2Ol896963</li>
<li>博客: 记录个人生活学习的点滴</li>
<!-- <font color="red">Hexo 交流群：287306637</font> -->
</ul>
</div>



  <iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=2&ptype=1&speed=0&skin=1&isTitle=1&noborder=1&isWeibo=1&isFans=0&uid=2946363961&verifier=371067b2&dpc=1"></iframe>

  <div class="widget tag">
<h3 class="title">打赏</h3>
<ul class="entry">
<li>支付宝扫一扫，捐助支持，谢谢！</li>
<li><a href="http://o8i01ajlj.bkt.clouddn.com/blog/171004/LikDAfKDg0.png" title="" class="fancybox" rel="gallery3"><img width="100%" src="http://o8i01ajlj.bkt.clouddn.com/blog/171004/LikDAfKDg0.png"></a></li>
</ul>
</div>

  <div class="widget tag">
  <h3 class="title">日历云</h3>
  <div id="calendar"></div>
</div>

  
  <div class="widget tag">
    <h3 class="title">归档</h3>
	<ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">2017年09月</a><span class="archive-list-count">25</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">2017年05月</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">2017年04月</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">2017年03月</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">2017年02月</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">2016年12月</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">2016年11月</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">2016年10月</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">2016年09月</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">2016年08月</a><span class="archive-list-count">6</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">2016年07月</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">2016年05月</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">2016年01月</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">2015年01月</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">2014年12月</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/09/">2014年09月</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/08/">2014年08月</a><span class="archive-list-count">1</span></li></ul>
  </div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><section>
Theme of <a href="https://github.com/zippera/lightum">Lightum</a>, Improved from <a href="https://github.com/hexojs/hexo-theme-light">Light</a>, by <a href="/">zippera</a> 
</section>
<div class="clearfix"></div>
</footer>
  <script src="//libs.baidu.com/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('zh-CN',{single:true, root:'calendar/'});
    
    });
  </script>

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>


<a href="https://github.com/shuaiyy" target="_blank"><img style="position: absolute; top: 0; left: 0; border: 0;" src="/imgs/forkme_left_green_007200.png" alt="Fork me on GitHub"></a>
