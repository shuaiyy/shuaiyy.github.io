<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spring boot 入门]]></title>
    <url>%2F2018%2F03%2F04%2F%E6%8A%80%E6%9C%AF%2FSpring%20Boot%20%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring Boot 入门spring boot是可以基于maven项目快速搭建SSM/H（或者其他Spring相关的项目）的开发框架。可以简化SSM框架的一系列配置，从而快速开发。 快速搭建Web项目 创建项目 在IDEA中，菜单 -&gt; New -&gt; Project -&gt; Spring Initializer 然后点 Next。 输入项目名称，然后next。 选择web模块，然后next，指定项目路径，ok。 项目结构如下： 其中绿色的是手动创建的，红色的文件是springboot创建的。 配置切换 spring boot仍然需要一定的配置，可以为不同环境设置单独的配置。 配置端口和servlet的根URL 。 配置JSP支持，需引入maven依赖。 1234567891011121314151617# 主配置，application.properties# jsp文件重定向spring.mvc.view.prefix=/WEB-INF/jsp/spring.mvc.view.suffix=.jsp# 指定使用生产环境的配置文件spring.profiles.active=pro# 专用配置文件，由主配置中指定 # application-dev.properties 或者 application-pro.propertiesserver.port=8080server.servlet.path=/testspring.datasource.url=jdbc:mysql://127.0.0.1:3306/test?characterEncoding=UTF-8spring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.jpa.properties.hibernate.hbm2ddl.auto=update 基于yml格式的配置 yml格式用“冒号 空格” 区分键值， 如果分级，则使用4个空格。 12345678spring: mvc: view: prefix: /WEB-INF/jsp/ suffix: .jspserver: port: 8888 context-path: /test ​ maven依赖 由于IDEA的bug，无法使用provided scope，因此需要删除jar包依赖配置中的provided，以及项目结构文件iml中的provided。 不需要直接引入spring-core之类的jar包，spring-boot的依赖已经引用并管理了一系列相关的jar包。 由于从parent继承，一些jar包的版本也无需指定。从maven依赖关系图可以看出，spring-boot-starter-web下有spring-webmvc。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.shuaiyy&lt;/groupId&gt; &lt;artifactId&gt;sboot_idea&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!--&lt;packaging&gt;jar&lt;/packaging&gt;--&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;sboot_idea&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;!-- 官方为相关jar包提供了版本控制 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;mysql.version&gt;5.1.6&lt;/mysql.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- servlet依赖. --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- tomcat的支持.--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt; &lt;/dependency&gt; &lt;!-- jpa--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql驱动包--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 分页插件支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;4.1.6&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; ​ MVC contoller 123456789@Controllerpublic class HelloWorldController &#123; @RequestMapping("/hello") public String hello(Model model)&#123; System.out.println("hello"); model.addAttribute("now", DateFormat.getDateTimeInstance().format(new Date())); return "hello"; &#125;&#125; ​ 启动 SpringbootApplication, 其被@SpringBootApplication 所注解，表示这个是一个Springboot 应用，用于启动项目。 spring boot内置了Tomcat服务器，因此可以由spring-boot应用直接启动，也可以由Tomcat启动web应用。 浏览器访问http://127.0.0.1:8080/hello 打包部署 jar方式： 执行 mvn install ,然后运行jar包 java -jar target/springboot-0.0.1-SNAPSHOT.jar --spring.profiles.active=pro 。 war方式： spring boot app要添加一个注解@ServletComponentScan，并继承类SpringBootServletInitializer，重写configure方法。 1234567891011121314// war方式打包@SpringBootApplication@ServletComponentScanpublic class SbootIdeaApplication extends SpringBootServletInitializer&#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(SbootIdeaApplication.class); &#125; public static void main(String[] args) &#123; SpringApplication.run(SbootIdeaApplication.class, args); &#125;&#125; pom中修改packaging方式为war方式。 1&lt;packaging&gt;war&lt;/packaging&gt; 然后运行mvn clean package, 构建war包。 热部署 每次rebuild项目后自动部署，不用重启Application类。idea也可以设置成自动build。 只需增加一个依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt;&lt;/dependency&gt; 持久层支持JPAJPA(Java Persistence API)是Sun官方提出的Java持久化规范，用来方便大家操作数据库。真正干活的可能是Hibernate,TopLink等等实现了JPA规范的不同厂商,默认是Hibernate。 在配置文件中增加参数： 1234567spring.mvc.view.prefix=/WEB-INF/jsp/spring.mvc.view.suffix=.jspspring.datasource.url=jdbc:mysql://127.0.0.1:3306/test?characterEncoding=UTF-8spring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.jpa.properties.hibernate.hbm2ddl.auto=update 增加mysql和jpa的依赖包 123456789101112&lt;!-- mysql--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt;&lt;/dependency&gt; &lt;!-- jpa--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt; 创建一个dao接口，即可使用对应的jpa方法。 123456789public interface CategoryDAO extends JpaRepository&lt;Category,Integer&gt;&#123;&#125;// 使用@Autowired CategoryDAO categoryDAO;// findList&lt;Category&gt; cs=categoryDAO.findAll();// add or updatecategoryDAO.save(c);// deletecategoryDAO.delete(c) 实现分页，返回的是Page对象。 1234567891011@RequestMapping("/list")public String listByJPA(Model model, @RequestParam(value = "start",defaultValue = "0") int start, @RequestParam(value = "size",defaultValue = "5") int size) throws Exception &#123; // 分页， 降序， size必须大于0 start = start &lt; 0 ? 0:start; Sort sort = new Sort(Sort.Direction.DESC, "id"); Pageable pageable = new PageRequest(start, size, sort); Page&lt;Category&gt; page = categoryDAO.findAll(pageable); model.addAttribute("page", page); return "list_category_page";&#125; page对象的使用： Mybatis 增加相关依赖 123456789101112131415161718&lt;!-- mybatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mysql --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 分页插件 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;4.1.6&lt;/version&gt;&lt;/dependency&gt; 创建Mapper接口，并实现相应的CRUD方法。 1234567891011@Mapperpublic interface CategoryMapper &#123; @Select("select * from category_ ") List&lt;Category&gt; findAll(); &#125;// 使用@Autowired CategoryMapper categoryMapper;List&lt;Category&gt; cs=categoryMapper.findAll(); 实现分页 需要实现一个PageHelper的拦截器Bean，可以使用spring Configuration类实现相关bean的定义。 123456789101112131415package cn.shuaiyy.springboot.config;@Configurationpublic class PageHelperConfig &#123; @Bean public PageHelper pageHelper() &#123; PageHelper pageHelper = new PageHelper(); Properties p = new Properties(); p.setProperty("offsetAsPageNum", "true"); p.setProperty("rowBoundsWithCount", "true"); p.setProperty("reasonable", "true"); pageHelper.setProperties(p); return pageHelper; &#125;&#125; mapper接口无需改动，在查询前设置分页信息,并返回pageInfo对象: 1234567891011@RequestMapping("/mybatis/list")public String listCategoryByMybatis(Model model, @RequestParam(value = "start", defaultValue = "0") int start, @RequestParam(value="size", defaultValue = "3") int size) throws Exception &#123; // ModelAndView mav = new ModelAndView(); start = start&gt;0 ? start:0; PageHelper.startPage(start,size, "id desc"); List&lt;Category&gt; categories = categoryMapper.findAll(); PageInfo&lt;Category&gt; pageInfo = new PageInfo&lt;&gt;(categories); model.addAttribute("page", pageInfo); return "list_category_by_pagehelper";&#125; pageInfo对象的使用： 文件上传 post 上传二进制文件，注意name参数用于后端获取数据对象 1234&lt;form action="upload" method="post" enctype="multipart/form-data"&gt; 选择图片:&lt;input type="file" name="file" accept="image/*" /&gt; &lt;br&gt; &lt;input type="submit" value="上传"&gt;&lt;/form&gt; 上传,使用MultipartFile对象接收二进制数据，确定存储位置和文件名后，使用transferTo保存。 123456789101112131415161718192021@RequestMapping(value = "/upload", method = RequestMethod.POST) public String upload(HttpServletRequest req, @RequestParam("file") MultipartFile file,Model m) &#123; try &#123; String fileName = System.currentTimeMillis()+file.getOriginalFilename(); String destFileName=req.getServletContext().getRealPath("")+"uploaded"+File.separator+fileName; File destFile = new File(destFileName); destFile.getParentFile().mkdirs(); file.transferTo(destFile); m.addAttribute("fileName",fileName); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); return "上传失败," + e.getMessage(); &#125; catch (IOException e) &#123; e.printStackTrace(); return "上传失败," + e.getMessage(); &#125; return "showImg"; &#125; &#125; 上传文件的大小设置 12spring.servlet.multipart.max-file-size=100Mbspring.servlet.multipart.max-request-size=100Mb ​ 实现RESTFUL 后端的HTTP方法 使用PUT delete POST GET，当进行增删改时，返回视图会出错405，method不允许，应该直接返回字符串或者redirect。 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Controllerpublic class CategoryRestful &#123; @Autowired CategoryDAO categoryDAO; @GetMapping(value = "/category/&#123;id&#125;") public String get(Model model, @PathVariable("id") int id)&#123; List&lt;Category&gt; categories = new LinkedList&lt;&gt;(); categories.add(categoryDAO.getOne(id)); model.addAttribute("categories", categories); return "list_category"; &#125; @GetMapping(value = "/category") public String getAll(Model model)&#123; List&lt;Category&gt; categories = categoryDAO.findAll(); model.addAttribute("categories", categories); return "list_category"; &#125; @DeleteMapping(value = "/category/&#123;id&#125;") public String delete(@PathVariable("id") int id)&#123; Category category = new Category(); category.setId(id); categoryDAO.delete(category); return "redirect:/category"; &#125; @PostMapping(value = "/category/&#123;id&#125;") public String update(Model model, @PathVariable("id") int id, Category category)&#123; category.setId(id); categoryDAO.save(category); List&lt;Category&gt; categories = categoryDAO.findAll(); model.addAttribute("categories", categories); return "redirect:/category"; &#125; @PutMapping(value = "/category") public String add(Category category)&#123; categoryDAO.save(category); return "redirect:/category"; &#125;&#125; 前端发起请求时，使用form表单提交，并在hidden input使用_method PUT来标识相应的方法，spring mvc会自动将post方法转为对应的方法。 ​ JSON提交、获取数据 实体类增加注解@JsonIgnoreProperties({ &quot;handler&quot;,&quot;hibernateLazyInitializer&quot; }) 12345678910@Entity@Table(name = "category_")@JsonIgnoreProperties(&#123; "handler","hibernateLazyInitializer" &#125;) public class Category &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = "id") private int id;&#125; 控制器类，必须使用RestController，即返回的是字符串，而不是视图。提交数据使用PUT，获取数据使用GET,直接return对象，会自动转换成相应的json字符串对象。 123456789101112131415161718192021222324@RestControllerpublic class CategoryController &#123; @Autowired CategoryDAO categoryDAO; @GetMapping("/category") public List&lt;Category&gt; listCategory(@RequestParam(value = "start", defaultValue = "0") int start,@RequestParam(value = "size", defaultValue = "5") int size) throws Exception &#123; start = start&lt;0?0:start; Sort sort = new Sort(Sort.Direction.DESC, "id"); Pageable pageable = new PageRequest(start, size, sort); Page&lt;Category&gt; page =categoryDAO.findAll(pageable); return page.getContent(); &#125; @GetMapping("/category/&#123;id&#125;") public Category getCategory(@PathVariable("id") int id) throws Exception &#123; Category c= categoryDAO.getOne(id); System.out.println(c); return c; &#125; @PutMapping("/category") public void addCategory(@RequestBody Category category) throws Exception &#123; System.out.println("springboot接受到浏览器以JSON格式提交的数据："+category); &#125;&#125; ​ 前端提交数据时，使用PUT方法，raw格式数据，并设置json的context header。]]></content>
      <categories>
        <category>技术</category>
        <category>Java</category>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6.8服务器使用]]></title>
    <url>%2F2018%2F03%2F02%2F%E6%8A%80%E6%9C%AF%2FCentOS%206.8%2F</url>
    <content type="text"><![CDATA[CentOS 6.8开启SSH默认是开机启动并自动运行的，无需设置。 查看是否安装sshrpm -qa | grep ssh 安装命令 yum install openssh-server 查看服务状态service sshd status 文件传输 安装lrzsz 安装并开启ftp服务 1234567891011121314151617181920212223242539 yum -y install vsftpd# 为ftp创建一个Linux用户，其主目录用于文件传输，禁止其登陆系统， 46 useradd ftpuser -d /ftpfile -s /sbin/nologin# 修改主目录的所有权47 chown ftpuser.ftpuser /ftpfile# 修改用户密码48 passwd ftpuser50 vim /etc/vsftpd/chroot_list51 vim /etc/selinux/config 52 vim /etc/vsftpd/vsftpd.conf 53 service vsftpd restart# 配置防火墙54 iptables -I INPUT -p tcp --dport 61001:62000 -j ACCEPT55 iptables -I OUTPUT -p tcp --sport 61001:62000 -j ACCEPT56 iptables -I INPUT -p tcp --dport 20 -j ACCEPT57 iptables -I OUTPUT -p tcp --sport 20 -j ACCEPT58 iptables -I INPUT -p tcp --dport 21 -j ACCEPT59 iptables -I OUTPUT -p tcp --sport 21 -j ACCEPT60 iptables-save61 service iptables save # 永久保存62 vim /ftpfile/index.html63 setsebool -P ftp_home_dir 164 vim /etc/selinux/config # 关闭selinux65 reboot79 service vsftpd restart ​ ​ 增加用户sudoer权限root用户下执行 visudo，并添加用户ypur_user ALL=(ALL) ALL 更改阿里云源sudo wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo yum makecache 配置Java开发环境JDK 官网下载jdk的rpm包，卸载自带的openjdk rpm -qa | grep jdk yum remove XXX 安装jdk，并配置环境变量 12345675 chmod 777 jdk-8u171-linux-x64.rpm 7 rpm -ivh jdk-8u171-linux-x64.rpm 9 java -version10 vim /etc/profileexport JAVA_HOME=/usr/java/jdk1.8.0_171-amd64export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/jre/lib/dt.jar:$JAVA_HOME/jre/lib/tools.jar11 source /etc/profile ​ Tomcat 下载、解压 配置环境变量 修改配置文件，设置URI编码为utf-8字符集， vim /developer/apache-tomcat-8.5.30/conf/server.xml 执行startup.sh启动， shutdown.sh停止。 开放防火墙端口8080访问权限 iptables -I INPUT -p tcp --dport 8080 -j ACCEPT service iptables save 访问url : ip:8080 Maven maven3.5，下载、解压、配置环境变量 Nginx 安装依赖 yum install -y gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel 下载解压,编译，安装 123456789 cd nginx-1.4.0 91 ./configure 92 make 95 make install 96 whereis nginx 97 cd /usr/local/nginx/sbin/ 99 ./nginx 100 ps aux | grep nginx101 curl http://localhost nginx的常用命令 cd /usr/local/nginx/sbin 启动：./nginx 停止：./nginx -s stop 重启：./nginx -s reopen 设置图片文件服务反向代理 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768 114 vim /usr/local/nginx/conf/nginx.conf#增加一行，表示扫描该目录下的配置文件,以域名命名配置文件，方便管理 include vhost/*.conf 115 ls /usr/local/nginx/conf/ 116 mkdir /usr/local/nginx/conf/vhost 117 cd /usr/local/nginx/conf/vhost 118 vim /usr/local/nginx/conf/vhost/img.happymall.com.conf #目录转发，将此二级域名指向指定的文件存储位置，端口和域名是可以修改的server &#123; listen 80; autoindex off; #开启后可以通过索引 遍历访问 server_name img.happymmall.com; access_log /usr/local/nginx/logs/access.log combined; index index.html index.htm index.jsp index.php; #error_page 404 /404.html; if ( $query_string ~* ".*[\;'\&lt;\&gt;].*" )&#123; return 404; &#125; location ~ /(mmall_fe|mmall_admin_fe)/dist/view/* &#123; deny all; &#125; location / &#123; root /ftpfile/img/; add_header Access-Control-Allow-Origin *; &#125;&#125;118 vim /usr/local/nginx/conf/vhost/happymall.com.conf#端口转发，将happymmall.com的请求，转发至http://127.0.0.1:8080的Tomcat服务。server &#123;listen 80;autoindex on;server_name happymmall.com www.happymmall.com;access_log /usr/local/nginx/logs/access.log combined;index index.html index.htm index.jsp index.php;if ( $query_string ~* ".*[\;'\&lt;\&gt;].*" )&#123; return 404; &#125;location = / &#123; root /product/front/mmall_fe/dist/view; index index.html;&#125;location ~ .*\.html$ &#123; root /product/front/mmall_fe/dist/view; index index.html;&#125;location / &#123; proxy_pass http://127.0.0.1:8080/; &#125;location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|flv|ico)$ &#123; proxy_pass http://127.0.0.1:8080; expires 30d; &#125;location ~ .*\.(js|css)?$ &#123; proxy_pass http://127.0.0.1:8080; expires 7d; &#125;&#125; 119 service vsftpd status 120 /usr/local/nginx/sbin/nginx -s reload 由于没有真实的域名，修改C:\Windows\System32\drivers\etc\hosts文件，将Nginx的ip与其代理的域名关联起来，就可以本地访问，看到转发效果了。 Mysql 安装 yum -y install mysql-server 默认配置文件 /etc/my.cnf 在mysqld节点下增加 default-character-set=utf8 character-set-server=utf8 设置开机启动，配置防火墙 1234567127 vim /etc/my.cnf 128 chkconfig mysqld on129 chkconfig --list mysqld 130 iptables -A INPUT -p tcp -m tcp --dport 3306 -j ACCEPT131 iptables-save132 service iptables saveservice mysqld satrt 设置数据库用户和密码 123456789101112131415mysql -u root #默认没密码&gt;set password for root@localhost=password('123456');&gt;select user,host from mysql.user; # 查看用户#删除匿名用户，即用户名为空的用户delete from mysql.user where user='';#添加新用户insert into mysql.user(Host,User,Password) values('localhost', 'test', password('123456'));#刷新flush privileges;#创建新的数据库，数据库名用的不是单引号，是~键所在的那个。如果不是保留字也可以不用点。CREATE DATABASE `tpcms` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci# 授权（增删改查） db.table 对 user@ip 使用user密码验证GRANT ALL PRIVILEGES ON *.* TO root@"%" IDENTIFIED BY '用户root的密码';# 查看权限select * from mysql.user \G GIT 安装和配置 123456789101112131415161718192021162 yum remove git163 yum install -y curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc xmlto perl-devel perl-CPAN autoconf*164 wget https://github.com/git/git/archive/v2.17.0.tar.gz165 pwd166 tar -zxvf v2.17.0.tar.gz 168 cd git-2.17.0/169 make configure170 ./configure --prefix=/usr/local/git --with-iconv=/usr/local/libiconv171 make all doc172 make install install-doc install-html#环境变量176 echo "export PATH=$PATH:/usr/local/git/bin" &gt;&gt; /etc/bashrc177 source /etc/bashrc 180 vim /etc/profile181 source /etc/profile182 git --versiongit config --global core.autocrlf false # 不去管win/linux换行符的问题git config --global gui.encoding utf-8git config --global core.quotepath off # 避免git status的中文乱码问题git config --global 生成SSH key pair 123456ssh-keygen -t rsa -C "syy@163.com"187 ssh-add ~/.ssh/id_rsa #添加秘钥188 eval `ssh-agent` #上一步出错时执行189 ssh-add ~/.ssh/id_rsa #添加秘钥190 cat ~/.ssh/id_rsa.pub #将公钥添加到githubo 或码云里git clone git@gitee.com:shuayy/helloworld.git ​]]></content>
      <categories>
        <category>技术</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring入门]]></title>
    <url>%2F2018%2F02%2F25%2F%E6%8A%80%E6%9C%AF%2FSpring%E5%85%A5%E9%97%A8-Hello%20World%2F</url>
    <content type="text"><![CDATA[Spring Hello World Spring 是一个IOC(DI) 和AOP 容器框架 IOC/DI两个概念（其实是不同的角度） 控制反转：对象实例由spring通过配置创建，而不是程序员主动new构造。 依赖注入：拿到的对象实例可以直接使用，其定义在配置文件的属性值在实例化时已被注入。 创建一个pojo类，POJO（Plain Ordinary Java Object）简单的Java对象，实际就是普通JavaBeans。 1234567891011121314151617public class Category &#123; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; private int id; private String name;&#125; 创建spring的配置文件，在bean中配置要生成的对象实例及其属性。 applicationContext.xml 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:context="http://www.springframework.org/schema/context"&gt;&lt;!-- 定义bean对象及其属性 --&gt; &lt;bean name="c" class="com.how2java.pojo.Category"&gt; &lt;property name="name" value="category_1" /&gt; &lt;property name="id" value="1000" /&gt; &lt;/bean&gt;&lt;/beans&gt; Spring通过配置文件创建实例 123456789101112131415161718import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import Category;public class TestSpring &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext( new String[] &#123; "applicationContext.xml" &#125;); Category c = (Category) context.getBean("c"); System.out.println(c.getName()); c.setName("hello"); System.out.println(c.getName()); System.out.println(c.getId()); c.setId(100); System.out.println(c.getId()); &#125;&#125; 注入对象 假设一个Product类的属性里有Category类，在实例化Product类时，可以注入一个已有的Category实例。 1234567891011public class Product &#123; private Category category; public Category getCategory() &#123; return category; &#125; public void setCategory(Category category) &#123; this.category = category; &#125;&#125; 配置applicationContext.xml,使用rel指定对象实例。 1234567&lt;bean name="c" class="com.how2java.pojo.Category"&gt; &lt;property name="name" value="category 1" /&gt; &lt;/bean&gt; &lt;bean name="p" class="com.how2java.pojo.Product"&gt; &lt;property name="name" value="product1" /&gt; &lt;property name="category" ref="c" /&gt; &lt;/bean&gt; ​ 通过注解方式实现IOC/DI 在applicationContext中声明使用注解方式进行装配 1234567891011&lt;beans&gt; &lt;context:annotation-config/&gt; &lt;bean name="c" class="com.how2java.pojo.Category"&gt; &lt;property name="name" value="category_1" /&gt; &lt;property name="id" value="1000" /&gt; &lt;/bean&gt; &lt;bean name="p1" class="com.how2java.pojo.Product"&gt; &lt;!--&lt;property name="category" ref="c"/&gt;--&gt; &lt;property name="name" value="product_1"/&gt; &lt;/bean&gt;&lt;/beans&gt; @Autowired 自动装配依赖对象 首先了解beans里的default-autowire参数，声明了该参数，则会使用指定的方式自动配置，不用显示的在bean中指定依赖。 &lt;beans xmlns=&quot;...&quot; default-autowire=&quot;byName&quot;&gt; 默认值为no，即不自动装配。四种方式： byName,找到与属性名一样的bean，然后装配给该属性 byType， 找到与属性类型一样的bean，然后装配给该属性。如果 找到多个，抛出异常，没找到不会异常(设置dependency-check=“object” 可以让spring抛出异常) constructor，与byType类似，使用的是构造器方法参数的类型，如果找不到类型一致的bean，则会异常 autodect，通过bean的自省来决定，如果是默认的构造器则用byType，否则使用constructor。 自动装配依赖对象 @Autowired 可以用来注解构造方法、属性、setter方法，使用的是byType方式装配 123456789101112131415161718public class Product &#123;// @Autowired private Category category; @Autowired(required=false) // 默认是不允许对象为null的，可以使用required参数修改 public Product(Category category) &#123; this.category = category; &#125; public Category getCategory() &#123; return category; &#125;// @Autowired public void setCategory(Category category) &#123; this.category = category; &#125;&#125; @Resource(name=&quot;xxx&quot;) 使用@Resource注解也可以实现为bean自动注入对象 12345public class Product &#123;// @Autowired @Resource(name="c") private Category category;&#125; @Component 将pojo类注解为Spring bean，在配置文件中声明bean class的位置，bean的初始化不再由配置文件注入，而是由类自身实现。 123&lt;beans&gt; &lt;context:component-scan base-package="com.test.pojo"/&gt;&lt;/beans&gt; 1234567891011@Component("c")public class Category &#123; private String name="category_1";&#125;@Component("p")public class Product &#123; @Autowired private Category category; private String name="category_1";&#125; ​ AOP AOP 即 Aspect Oriented Program 面向切面编程 . 首先在面向切面编程的思想里面，把功能分为核心业务功能，和周边功能。 核心业务，比如登陆，数据操作等；周边功能如性能统计，日志，事务管理等等 传统的面向对象编程OOP如果实现周边功能，需要在每个类中实现该功能接口，耦合高。 在面向切面编程AOP的思想里面，核心业务功能和周边功能分别独立进行开发， 然后把周边功能和核心业务功能 “编织” 在一起，这就叫AOP。 简单的示例: 在执行核心功能前后执行log打印 核心业务，在切点上执行 123456789101112package com.test.service;public class ProductService &#123; public void doSomething()&#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("do someting!"); &#125;&#125; ​ 辅助业务， 在切面上执行 1package com.test.aspect; import org.aspectj.lang.ProceedingJoinPoint; public class LogAspect { public Object log(ProceedingJoinPoint joinPoint) throws Throwable { System.out.println(&quot;start at&quot; + System.currentTimeMillis()); // 辅助功能 Object obj = joinPoint.proceed(); // 执行核心功能 System.out.println(&quot;end at&quot; + System.currentTimeMillis()); // 辅助功能 return obj; } } 123456789101112131415+ 声明切点、切面的bean对象，并配置AOP关系 ```xml &lt;!-- 定义切点、切面 --&gt; &lt;bean name=&quot;product_service&quot; class=&quot;com.how2java.service.ProductService&quot;/&gt; &lt;bean name=&quot;logAspect&quot; class=&quot;com.how2java.aspect.LogAspect&quot;/&gt; &lt;!-- 配置切点和切面 --&gt; &lt;aop:config&gt; &lt;aop:pointcut id=&quot;logPointCut&quot; expression=&quot;execution(* com.test.service.ProductService.*(..)) &quot;/&gt; &lt;aop:aspect id=&quot;logger&quot; ref=&quot;logAspect&quot;&gt; &lt;aop:around pointcut-ref=&quot;logPointCut&quot; method=&quot;log&quot;/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; ​ 通过注解实现AOP @Component 表示这是一个bean,由Spring进行管理，业务类和切面类都是由spring管理的bean类。 @Aspect 注解表示这是一个切面，用在切面类上 @Around(value = &quot;execution(* com.test.service.ProductService.*(..))&quot;) 用在切面方法上，表示对哪些业务类的哪些方法进行切面操作。 业务类 1234567891011@Component("productService")public class ProductService &#123; public void doSomething()&#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("do someting!"); &#125;&#125; 切面类 1234567891011121314@Component("logAspect")@Aspectpublic class LogAspect &#123; @Around(value = "execution(* com.how2java.service.ProductService.*(..))") public Object log(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.out.println("start at" + System.currentTimeMillis()); Object obj = joinPoint.proceed(); // 执行核心功能 System.out.println("end at" + System.currentTimeMillis()); return obj; &#125;&#125; applicationContext.xml配置 123&lt;context:component-scan base-package="com.how2java.aspect"/&gt;&lt;context:component-scan base-package="com.how2java.service"/&gt;&lt;aop:aspectj-autoproxy/&gt; ​ 通过注解执行Spring测试类 @RunWith(SpringJUnit4ClassRunner.class) 声明这是一个Spring的测试类 @ContextConfiguration(&quot;classpath:applicationContext.xml&quot;) 加载Spring的配置文件 @Autowired 给属性自动装配相关对象 @Test 声明方法为测试类Test方法, 需要junit和hamcrest-all jar包 1234567891011121314151617@ContextConfiguration("classpath:applicationContext.xml")@RunWith(SpringJUnit4ClassRunner.class)public class TestSpring &#123; @Autowired Category c; @Autowired Product p1; @Autowired ProductService ps; @Test public void test() &#123; System.out.println(c.getName()); System.out.println(p1.getName()); ps.doSomething(); &#125;&#125; 不使用注解的话和测试类的话 需要main方法执行，手动加载配置，获取beans并执行 12345678910111213141516171819202122public class TestSpring &#123; public static void main(String[] args) &#123; ApplicationContext context = new ClassPathXmlApplicationContext( new String[] &#123; "applicationContext.xml" &#125;); Category c = (Category) context.getBean("c"); System.out.println(c.getName()); c.setName("hello"); System.out.println(c.getName()); System.out.println(c.getId()); c.setId(100); System.out.println(c.getId()); Product p1 = (Product) context.getBean("p1"); System.out.println(p1.getName() + p1.getCategory().getName() + p1.getCategory().getId()); ProductService ps = (ProductService) context.getBean("productService"); ps.doSomething(); &#125;&#125; ​ Spring配置Bean 配置形式：基于xml、基于注解 Bean 的配置方式：通过全类名（反射）、通过工厂方法（静态工厂方法&amp;实例工厂方法）、FactoryBean IOC 容器BeanFactory &amp; ApplicationContext ApplicationContext是Beanfactory的子接口，IOC容器负责实例化Bean。ApplicationContext 在初始化上下文时就实例化了所有的单例Bean。 ClassPathXmlApplicationContext：从类路径下加载配置文件FileSystemXmlApplicationContext: 从文件系统中加载配置文件 依赖注入的方式：属性注入（通过setter方法）；构造器注入. 属性可以使用ref引用其他bean，也可以创建内部bean。 ​ 注入属性值的字面值，即可以用字符串表示的值，基本类型，封装类都可以。 &lt;null/&gt;表示注入null值。 12345678910&lt;!-- 可以根据 index 和 type 进行更加精确的定位. (了解) --&gt; &lt;bean id="car" class="com.atguigu.spring.helloworld.Car"&gt; &lt;constructor-arg value="KUGA" index="1"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value="ChangAnFord" index="0"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value="250000" type="float"&gt;&lt;/constructor-arg&gt; &lt;!-- 若字面值中包含特殊字符, 则可以使用 CDATA 来进行赋值. (了解) --&gt; &lt;constructor-arg&gt; &lt;value&gt;&lt;![CDATA[&lt;ATARZA&gt;]]&gt;&lt;/value&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; 集合属性值： util.map 子标签 entry key value list props定义util.Properties，子标签为prop 12345678910111213141516171819&lt;!-- 装配集合属性 --&gt; &lt;bean id="user" class="com.atguigu.spring.helloworld.User"&gt; &lt;property name="userName" value="Jack"&gt;&lt;/property&gt; &lt;property name="cars"&gt; &lt;!-- 使用 list 元素来装配集合属性 --&gt; &lt;list&gt; &lt;ref bean="car"/&gt; &lt;ref bean="car2"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 引用外部声明的 list --&gt; &lt;property name="newCars" ref="cars"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 声明集合类型的 bean --&gt; &lt;util:list id="cars"&gt; &lt;ref bean="car"/&gt; &lt;ref bean="car2"/&gt; &lt;/util:list&gt; ​ 自动装配：byName, byType bean 之间的关系：继承；依赖 子Bean 从父Bean 中继承或覆盖配置, 包括Bean 的属性配置。 父Bean 可以作为配置模板, 也可以作为Bean 实例. 若只想把父Bean 作为模板, 可以设置父bean的abstract 属性为true, 这样Spring 将不会实例化这个 Bean。 depends-on，依赖关系，依赖的bean会在本bean之前实例化 bean 的作用域：singleton；prototype；WEB 环境作用域； scope属性设置作用域，默认是单例的，即singleton，容器加载后即创建单实例的Bean。 prototype是每次返回一个新的实例。 使用外部属性文件 使用PropertyPlaceholderConfigurer载入外部properties配置文件，然后使用${varName}引用 12&lt;!-- 导入外部的资源文件 --&gt; &lt;context:property-placeholder location="classpath:db.properties"/&gt; ​ spEL，使用#{...}作为定界符。 表示字面量、引用对象及其属性或方法`#{5} #{“string1”} #{false} #{obj} #{obj.id} #{obj.toString()} 算数运算，三元运算，正则表达式，调用静态类使用 #{ T(java.lang.Math).PI} IOC 容器中Bean 的生命周期 scope属性可以设置是单例还是prototype，生命周期也会不同。 Bean的配置中可以声明init-method和destroy-method属性，为Bean指定初始化和销毁方法。 在初始化方法执行的前后仍可以使用自定的Bean后置处理器，执行before和after的相关逻辑代码。 123456789&lt;!-- 初始化和销毁方法--&gt;&lt;bean id="boy" class="com.helloworld.User" init-method="init" destroy-method="destroy"&gt; &lt;property name="userName" value="bob"&gt;&lt;/property&gt; &lt;property name="wifeName" value="#&#123;girl.userName&#125;"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 前置处理器，自己实现的类，AOP --&gt;&lt;!-- 配置 bean 后置处理器: 不需要配置 id 属性, IOC 容器会识别到他是一个 bean 后置处理器, 并调用其方法， 注意：所有的bean都会被处理--&gt; &lt;bean class="com.helloworld.MyBeanPostProcessor"&gt;&lt;/bean&gt; java类： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class User&#123; public void init()&#123; System.out.println("init method..."); &#125; public void destroy()&#123; System.out.println("destroy method..."); &#125;&#125;// Bean 后置处理器import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.BeanPostProcessor;public class MyBeanPostProcessor implements BeanPostProcessor &#123; //该方法在 init 方法之后被调用 @Override public Object postProcessAfterInitialization(Object arg0, String arg1) throws BeansException &#123; if(arg1.equals("boy"))&#123; System.out.println("postProcessAfterInitialization..." + arg0 + "," + arg1); User user = (User) arg0; user.setUserName("李大齐"); &#125; return arg0; &#125; //该方法在 init 方法之前被调用 //可以工作返回的对象来决定最终返回给 getBean 方法的对象是哪一个, 属性值是什么 /** * @param arg0: 实际要返回的对象 * @param arg1: bean 的 id 值 */ @Override public Object postProcessBeforeInitialization(Object arg0, String arg1) throws BeansException &#123; if(arg1.equals("boy")) System.out.println("postProcessBeforeInitialization..." + arg0 + "," + arg1); return arg0; &#125;&#125; 组件 组件扫描，component-scan，可以扫描并实例化具有特定注解的组件 配置中&lt;context:component-scan&gt;, base-package 属性指定一个需要扫描的基类包，Spring 容器将会扫描这个基类包里及其子包中的所有类. 当需要扫描多个包时, 可以使用逗号分隔. 还可以指定包含或过滤的特定类，或者匹配模式 @Autowired 和@Resource 、@Inject注解的属性也会被自动装配。 特定组件： 默认命名为类名的首字母小写，或者通过注解的value指定。 自动装配 ​ AOP如日志、验证等需要面向切面编程的场景。做到核心业务与辅助业务相分离。 相关概念： 切面(Aspect): 横切关注点(跨越应用程序多个模块的功能)被模块化的特殊对象 通知(Advice): 切面必须要完成的工作 目标(Target): 被通知的对象 代理(Proxy): 向目标对象应用通知之后创建的对象 连接点（Joinpoint）：程序执行的某个特定位置：如类某个方法调用前、调用后、方法抛出异常后等。连接点由两个信息确定：执行点和相对执行点的方位。 切点（pointcut）：每个类都拥有多个连接点, AOP通过切点定位到特定的连接点。 切点通过 org.springframework.aop.Pointcut 接口进行描述，它使用类和方法作为连接点的查询条件。 声明配置切面 AspectJ是Java 社区里最完整最流行的AOP 框架，开启支持需要导入相关的jar包，并配置&lt;aop:aspectj-autoproxy&gt; 通过注解配置AOP 配置文件中自动扫描切面组件 &lt;context:component-scan base-package=&quot;com.helloworld.spring.aop&quot;&gt;&lt;/context:component-scan&gt; 加入使 AspjectJ 注解起作用的配置:&lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;为匹配的类自动生成动态代理对象. 编写切面类，需要@Component 和 @Aspect 声明类为spring bean，且为切面。在切面类的方法上声明为通知方法，如@Before(&quot;切点表达式&quot;)声明前置通知。 可在通知方法中添加 JoinPoint 类型的参数, 以访问到切点方法（被通知的方法）的签名和方法的参数. ​ 切面只是一个带有@Aspect 注解的Java 类. 通知Advice是标注有某种注解的简单的Java 方法. – @Before: 前置通知, 在方法执行之前执行– @After: 后置通知, 在方法执行（正常返回或异常）之后执行– @AfterRunning: 返回通知, 在方法返回结果之后执行– @AfterThrowing: 异常通知, 在方法抛出异常之后– @Around: 环绕通知, 围绕着方法执行 @DeclareParents(value=”目标类对象”， defaultImpl=YourImpl.class)：引入通知，为目标类对象动态的增加接口实现，实现多重继承。而不用修改目标类的代码。 新接口实现由yourImpl负责实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Aspect@Order(0) // 执行优先级，越小越先被执行@Compomentpublic class LoggingAspect &#123; @Before("execution(public int com.helloworld.Calculator.*(int, int))") public void beforeMethod(JoinPoint joinPoint)&#123; String methodName = joinPoint.getSignature().getName(); Object [] args = joinPoint.getArgs(); &#125; // 无论是正常返回还是出现异常，后置通知都会执行 @After("execution(* com.helloworld.spring.aop.*.*(..))") //表达式支持通配符 public void afterMethod(JoinPoint joinPoint)&#123; String methodName = joinPoint.getSignature().getName(); System.out.println("The method " + methodName + " ends"); &#125; // 正常返回后执行通知, 使用returning属性获取返回值，并在通知方法的参数中接收，参数名要一致 @AfterReturing(pointcut="execution(* com.helloworld.spring.aop.*.*(..))", returning="result") public void afterReturning(JoinPoint joinPoint, Object result)&#123; String methodName = joinPoint.getSignature().getName(); System.out.println("The method " + methodName + " ends with " + result); &#125; // 异常通知，通知方法传入的异常可以指定具体的类型以捕获感兴趣的通知 @AfterThrowing(pointcut="execution(* com.helloworld.spring.aop.*.*(..))", throwing="e") public void afterThrowing(JoinPoint joinPoint, Exception e)&#123; String methodName = joinPoint.getSignature().getName(); System.out.println("The method " + methodName + " occurs excetion:" + e); &#125; // 环绕通知，功能最为强大的, 能够全面地控制连接点. 甚至可以控制是否执行连接点 // 必须显示调用ProceedingJoinPoint对象的proceed方法执行被代理的目标方法，并将结果返回。 @Around("execution(public int com.atguigu.spring.aop.ArithmeticCalculator.*(..))") public Object aroundMethod(ProceedingJoinPoint pjd)&#123; Object result = null; String methodName = pjd.getSignature().getName(); try &#123; //前置通知 System.out.println("The method " + methodName + " begins with " + Arrays.asList(pjd.getArgs())); //执行目标方法 result = pjd.proceed(); //返回通知 System.out.println("The method " + methodName + " ends with " + result); &#125; catch (Throwable e) &#123; //异常通知 System.out.println("The method " + methodName + " occurs exception:" + e); throw new RuntimeException(e); &#125; //后置通知 System.out.println("The method " + methodName + " ends"); return result; // 必须返回目标方法的结果 &#125;&#125; ​ 切入点表达式支持通配符，多个表达式可以通过操作符&amp;&amp;, ||, !结合起来. 切入点表达式重用，用@Pointcut(“切入点表达式”)声明一个切入点的空方法，通知注解的pointcut属性传入该方法的调用。 连接点对象JoinPoint，可以让Advice的方法访问连接点的细节.@Around环绕通知使用的是ProceedingJoinPoint。 通过XML配置AOP xml是由spring支持的，而注解则是AspctJ实现的，且AspectJ被很多AOP框架支持，应优先考虑用注解。 123456789101112131415161718192021222324252627&lt;!-- 配置切面的 bean. --&gt; &lt;bean id="loggingAspect" class="com.helloworld.aspect.LoggingAspect"&gt;&lt;/bean&gt; &lt;bean id="vlidationAspect" class="com.helloworld.aspect.VlidationAspect"&gt;&lt;/bean&gt; &lt;!-- 配置 AOP --&gt; &lt;aop:config&gt; &lt;!-- 配置切点表达式 --&gt; &lt;aop:pointcut expression="execution(* com.helloworld.UserService.*(..))" id="pointcut"/&gt; &lt;!-- 配置切面及通知 --&gt; &lt;aop:aspect ref="loggingAspect" order="2"&gt; &lt;aop:before method="beforeMethod" pointcut-ref="pointcut"/&gt; &lt;aop:after method="afterMethod" pointcut-ref="pointcut"/&gt; &lt;aop:after-throwing method="afterThrowing" pointcut-ref="pointcut" throwing="e"/&gt; &lt;aop:after-returning method="afterReturning" pointcut-ref="pointcut" returning="result"/&gt; &lt;!-- &lt;aop:around method="aroundMethod" pointcut-ref="pointcut"/&gt; --&gt; &lt;/aop:aspect&gt; &lt;!-- 同一切点执行多个切面通知时，可以指定执行顺序 --&gt; &lt;aop:aspect ref="vlidationAspect" order="1"&gt; &lt;aop:before method="validateArgs" pointcut-ref="pointcut"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; ​ JdbcTemplatespring对原始的jdbc api提供了封装。 注入方式，在DAO中注入jdbcTemplate对象。 支持批量更新、插入、删除，查询；sql语句可以使用具名参数，如map集合进行参数绑定 123456789101112131415161718// 查询一个String sql = "SELECT id, last_name lastName, email, dept_id as \"department.id\" FROM employees WHERE id = ?";RowMapper&lt;Employee&gt; rowMapper = new BeanPropertyRowMapper&lt;&gt;(Employee.class);Employee employee = jdbcTemplate.queryForObject(sql, rowMapper, 1);// 查询多个String sql = "SELECT id, last_name lastName, email FROM employees WHERE id &gt; ?";RowMapper&lt;Employee&gt; rowMapper = new BeanPropertyRowMapper&lt;&gt;(Employee.class);List&lt;Employee&gt; employees = jdbcTemplate.query(sql, rowMapper,5);List&lt;Object[]&gt; batchObjs = new ArrayList&lt;&gt;();batchObjs.add(new Object[]&#123;"AA", "aa@atguigu.com", 1&#125;);batchObjs.add(new Object[]&#123;"BB", "bb@atguigu.com", 2&#125;);batchObjs.add(new Object[]&#123;"CC", "cc@atguigu.com", 3&#125;);batchObjs.add(new Object[]&#123;"DD", "dd@atguigu.com", 3&#125;);batchObjs.add(new Object[]&#123;"EE", "ee@atguigu.com", 2&#125;);// 批量更新String sql = "INSERT INTO employees(last_name, email, dept_id) VALUES(?,?,?)";jdbcTemplate.batchUpdate(sql, batchObjs); ​ spring事务管理事务的关键性质： 原子性：单独的最小工作单元，要么全部动作都执行成功，否则就都不起作用。 一致性：事务动作完成，一旦事务被提交，数据就会保持一致。 隔离性：多个事务处理相同数据的行为表现 持久性： 已经完成的事务结果应被持久化 实现方式 AOP 提供了声明式的事务管理, Spring 实现了事务管理器 123456789101112131415161718192021222324252627&lt;!-- 1. 配置事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 2. 配置事务属性 --&gt;&lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;!-- 根据方法名指定事务的属性 --&gt; &lt;tx:method name="purchase" propagation="REQUIRES_NEW"/&gt; &lt;!-- 事务传播属性为新建事务 --&gt; &lt;tx:method name="get*" read-only="true"/&gt; &lt;tx:method name="find*" read-only="true"/&gt; &lt;tx:method name="*"/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; &lt;!-- 3. 配置事务切入点, 以及把事务切入点和事务属性关联起来 --&gt;&lt;aop:config&gt; &lt;aop:pointcut expression="execution(* com.helloworld.dao.*.*(..))" id="txPointCut"/&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="txPointCut"/&gt; &lt;/aop:config&gt;&lt;!-- 直接在类或共有方法上使用@Transactional注解更方便 ---&gt;&lt;!-- 需要开启事务注解支持，并配置事务管理器 --&gt;&lt;tx:annotation-driven/&gt; 或者，用@Transactional 注解声明式地管理事务。在方法或者类级别上添加 @Transactional 注解，只有public属性的方法才会应用事务管理。然后还要在配置中显示声明 &lt;tx:annotation-driven&gt;,并为其指定事务管理。 1234@Transactional(propagation = Propagation.REQUIRES_NEW, isolation = Isolation.READ_COMMITTED)public Boolean delete(Person b)&#123; // 数据操作相关代码&#125; 事务的传播属性 默认为REQUIRED，使用当前的事务。REQUIRED_NEW，挂起当前事务，并开辟新的事务。 事务隔离级别 并发处理事务时，容易导致： 脏读(读到别人更新的数据，但是别人事务失败对数据进行回滚) 不可重复读：先后访问同一数据，由于A的更新导致B读到了非原始数据。 幻读： A事务读后，B事务增加了新的记录。A再次读取就会多出n条记录。 因此需要事务隔离。原则上完全隔离最好，但是没有并发，性能极低。 Spring 支持的事务隔离级别： 还可以设置 回滚、不会滚、只读、超时属性。 回滚： 指定的异常回滚 不回滚： 指定的异常不回滚 只读：表示这个事务只读取数据但不更新数据, 这样可以帮助数据库引擎优化事务。 超时：以秒位单位，超时回滚，避免长期占用资源。 Spring MVCIOC容器 在web容器初始化时加载spring IOC容器，指定配置文件。然后将其绑定到web容器（ServletContext）的一个属性上。 123456789101112&lt;!-- IOC配置文件位置 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:META-INF/applicationContext.xml &lt;/param-value&gt;&lt;/context-param&gt; &lt;!-- 监听器，初始化spring --&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; 获取IOC容器的方法 WebApplicationContext ctx = WebApplicationContextUtils.getWebApplicationContext(servletContext); ​ Servlet拦截 创建一个web项目 在web.xml配置使用spring 调度servlet类org.springframework.web.servlet.DispatcherServlet处理全部的Servlet请求。 12345678910111213&lt;web-app&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt; org.springframework.web.servlet.DispatcherServlet &lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; Spring bean的配置文件，定义servlet类，定义URL与Servlet类的映射关系。 配置文件的名字和web.xml中的servlet name相关。 1234567891011&lt;beans&gt; &lt;bean id="indexController" class="controller.IndexController"&gt;&lt;/bean&gt; &lt;bean id="simpleUrlHandlerMapping" class="org.springframework.web.servlet.handler.SimpleUrlHandlerMapping"&gt; &lt;property name="mappings"&gt; &lt;props&gt; &lt;prop key="/index"&gt;indexController&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 控制类,实现controller接口 12345678910import org.springframework.web.servlet.ModelAndView;import org.springframework.web.servlet.mvc.Controller;public class IndexController implements Controller &#123; public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; ModelAndView mav = new ModelAndView("index.jsp"); mav.addObject("message", "Hello Spring MVC"); return mav; &#125;&#125; ​ 视图 12345678&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8" isELIgnored="false"%&gt;&lt;html&gt;&lt;body&gt;&lt;h2&gt;Hello World!&lt;/h2&gt;&lt;h1&gt;$&#123;message&#125;&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; ​ 视图模板文件位置这个是可以修改的，在springmvc-servlet.xml中定义一个viewResolver的bean，指定前缀即路径文件夹，后缀即文件格式。然后将模板文件移入指定的文件夹。 1234567891011121314151617&lt;beans&gt; &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/pages/"/&gt; &lt;!--&lt;property name="suffix" value=".jsp"/&gt;--&gt; &lt;/bean&gt; &lt;bean id="indexController" class="controller.IndexController"/&gt; &lt;bean id="simpleUrlHandlerMapping" class="org.springframework.web.servlet.handler.SimpleUrlHandlerMapping"&gt; &lt;property name="mappings"&gt; &lt;props&gt; &lt;prop key="/index"&gt;indexController&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 通过注解实现URL映射 在配置文件里使用组件扫描&lt;context:component-scan base-package=&quot;controller&quot; /&gt;查找有注解的类，注释掉原来的URLmapping bean。 1234567891011121314151617181920212223&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd"&gt; &lt;context:component-scan base-package="controller" /&gt; &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/pages/"/&gt; &lt;!--&lt;property name="suffix" value=".jsp"/&gt;--&gt; &lt;/bean&gt; &lt;!--&lt;bean id="indexController" class="controller.IndexController"/&gt;--&gt; &lt;!--&lt;bean id="simpleUrlHandlerMapping"--&gt; &lt;!--class="org.springframework.web.servlet.handler.SimpleUrlHandlerMapping"&gt;--&gt; &lt;!--&lt;property name="mappings"&gt;--&gt; &lt;!--&lt;props&gt;--&gt; &lt;!--&lt;prop key="/index"&gt;indexController&lt;/prop&gt;--&gt; &lt;!--&lt;/props&gt;--&gt; &lt;!--&lt;/property&gt;--&gt; &lt;!--&lt;/bean&gt;--&gt;&lt;/beans&gt; ​ 控制类不再继承接口，而是通过注解实现控制类和url mapping 12345678910@Controllerpublic class NewIndexController&#123; @RequestMapping("/index2") public ModelAndView handleResquest1(HttpServletRequest request, HttpServletResponse response) throws Exception&#123; ModelAndView modelAndView = new ModelAndView("index.jsp"); modelAndView.addObject("message", "hello, index2"); return modelAndView; &#125;&#125; SpringMVC 获取参数 1、直接把表单的参数写在Controller相应的方法的形参中，适用于get方式提交，不适用于post方式提交。 123456@RequestMapping("/addUser1")public String addUser1(String username,String password) &#123; System.out.println("username is:"+username); System.out.println("password is:"+password); return "demo/index";&#125; 2、通过HttpServletRequest接收，post方式和get方式都可以 123456@RequestMapping("/addUser2") public String addUser2(HttpServletRequest request) &#123; String username=request.getParameter("username"); String password=request.getParameter("password"); return "demo/index"; &#125; 3、通过一个bean来接收,post方式和get方式都可以 建立一个和表单中参数对应的bean，用一个bean作为Controller的形参，用户上传的参数会自动装载进bean里。 123456789101112131415161718192021222324252627282930public class UserModel &#123; private String username; private String password; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; &#125; /** * Controller方法，通过一个bean来接收 * @param user * @return */ @RequestMapping("/addUser3") public String addUser3(UserModel user) &#123; System.out.println("username is:"+user.getUsername()); System.out.println("password is:"+user.getPassword()); return "demo/index"; &#125; 4、获取URL路径参数 URL中模板变量{username}和{password}绑定到通过@PathVariable注解的同名参数上 123456@RequestMapping(value="/addUser4/&#123;username&#125;/&#123;password&#125;",method=RequestMethod.GET)public String addUser4(@PathVariable String username,@PathVariable String password) &#123; System.out.println("username is:"+username); System.out.println("password is:"+password); return "demo/index"; &#125; 5、使用@ModelAttribute注解获取POST请求的FORM表单数据 123456@RequestMapping(value="/addUser5",method=RequestMethod.POST) public String addUser5(@ModelAttribute("user") UserModel user) &#123; System.out.println("username is:"+user.getUsername()); System.out.println("password is:"+user.getPassword()); return "demo/index"; &#125; 6、用注解@RequestParam绑定请求参数到方法入参 当请求参数username不存在时会有异常发生,可以通过设置属性required=false解决,例如: @RequestParam(value=”username”, required=false) 123456@RequestMapping(value="/addUser6",method=RequestMethod.GET)public String addUser6(@RequestParam("username") String username,@RequestParam("password") String password) &#123; System.out.println("username is:"+username); System.out.println("password is:"+password); return "demo/index";&#125; ​ 中文编码处理 在web.xml中注册一个处理编码的filter类，spring中提供了CharacterEncodingFilter类。 123456789101112&lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 浏览器页面跳转redirect 12345678910111213141516@Controllerpublic class NewIndexController&#123; @RequestMapping("/index2") public ModelAndView handleResquest1(HttpServletRequest request, HttpServletResponse response) throws Exception&#123; ModelAndView modelAndView = new ModelAndView("index.jsp"); modelAndView.addObject("message", "hello, index2"); return modelAndView; &#125; @RequestMapping("/jump") public ModelAndView jump (HttpServletRequest request, HttpServletResponse response)&#123; ModelAndView indexView = new ModelAndView("redirect:/index2"); return indexView; &#125;&#125; 访问Session12345678910111213141516@RequestMapping("/count")public ModelAndView count (HttpSession session)&#123; Integer count = (Integer) session.getAttribute("count"); if(count == null) count = 0; count++; session.setAttribute("count", count); ModelAndView mav = new ModelAndView("redirect:/index2"); return mav;&#125;@RequestMapping("/clearcount")public ModelAndView clearCount (HttpSession session)&#123; session.setAttribute("count", 0); ModelAndView mav = new ModelAndView("redirect:/index2"); return mav;&#125; 上传图片 配置web.xml允许访问*.jpg 由于springmvc的servlet拦截器的匹配规则是/,导致静态资源无法访问。如果匹配的是“/*.action”这种形式就没问题。 因此必须在springmvc的servlet拦截器之前配置一个或多个default servlet，允许访问指定类型的资源。 配置springmvc-servlet.xml spring web提供了对上传功能的支持。 12345&lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="defaultEncoding" value="utf-8"/&gt; &lt;property name="maxUploadSize" value="10485760000"/&gt; &lt;property name="maxInMemorySize" value="40960"/&gt;&lt;/bean&gt; ​ form上传表单 form 的两个属性必须提供method=&quot;post&quot; 和enctype=&quot;multipart/form-data&quot; 缺一不可上传组件 增加一个属性 accept=”image/“ 表示只能选择图片进行上传`&lt;input type=”file” name=”image” accept=”image/“ /&gt;` 12345678910&lt;div&gt; &lt;form method="post" enctype="multipart/form-data" action="uploadimage"&gt; 姓名： &lt;input type="text" name="name"&gt; &lt;br&gt; 上传图片： &lt;input type="file" accept="image/*" name="image"&gt; &lt;br&gt; &lt;input type="submit" value="上传图片"&gt; &lt;br&gt; &lt;/form&gt; &lt;div&gt; &lt;img src="/image/$&#123;image_url&#125;" alt="哈哈哈！"&gt; &lt;/div&gt;&lt;/div&gt; ​ UploadedImageFile 在UploadedImageFile pojo类中封装MultipartFile类型的字段 image ，用于接受页面的文件对象注入这里的字段命名 image必须和上传表单的image域的name值保持一致。 使用pojo类也可以同时接收form里的非file字段。 12345678910111213141516171819202122import org.springframework.web.multipart.MultipartFile;public class UploadedImageFile &#123; MultipartFile image; String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public MultipartFile getImage() &#123; return image; &#125; public void setImage(MultipartFile image) &#123; this.image = image; &#125;&#125; ​ 上传控制方法 准备方法upload方法 映射上传路径/uploadImage,方法的第二个参数UploadedImageFile 中已经注入好了 image，为文件准备一个随机名，然后保存。根据request.getServletContext().getRealPath获取到web目录下的image目录，用于存放上传后的文件。调用file.getImage().transferTo(newFile);复制文件 把生成的随机文件名提交给视图，用于后续的显示 123456789101112131415@RequestMapping("/uploadimage")public ModelAndView upload(HttpServletRequest request, UploadeImageFile file) throws IllegalStateException, IOException &#123; String name = RandomStringUtils.randomAlphanumeric(10); String newFileName = name + ".jpg"; File newFile = new File(request.getServletContext().getRealPath("/image"), newFileName); newFile.getParentFile().mkdirs(); System.out.println(file.getName()); file.getImage().transferTo(newFile); ModelAndView mav = new ModelAndView("index.jsp"); mav.addObject("image_url", newFileName); mav.addObject("name", file.getName()); return mav;&#125; ​ 显示图片 `&lt; img src=”/image/${image_url}”&gt; 拦截器类似servlet中的filter。用于实现日志、登录检测等需要预处理和后处理的地方。 preHandle：预处理回调方法，实现预处理如登录检查； 返回值true表示继续流程, 如调用下一个拦截器或处理器; false表示流程中断，不会继续调用其他的拦截器或处理器，此时我们需要通过response来产生响应； postHandle：后处理回调方法，实现处理器的后处理（但在渲染视图之前），此时我们可以通过modelAndView对模型数据进行处理或对视图进行处理，modelAndView也可能为null。 afterCompletion：整个请求处理完毕回调方法，即在视图渲染完毕时回调，如性能监控中我们可以在此记录结束时间并输出消耗时间，还可以进行一些资源清理，类似于try-catch-finally中的finally。 实现Interceptor类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import org.springframework.web.servlet.handler.HandlerInterceptorAdapter;import org.springframework.web.servlet.ModelAndView;public class LoginInterceptor extends HandlerInterceptorAdapter &#123; public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //1、请求到登录页面 放行 if(request.getServletPath().startsWith("/login")) &#123; return true; &#125; //2、TODO 比如退出、首页等页面无需登录，即此处要放行 允许游客的请求 //3、如果用户已经登录 放行 if(request.getSession().getAttribute("username") != null) &#123; //更好的实现方式的使用cookie return true; &#125; //4、非法请求 即这些请求需要登录后才能访问 //重定向到登录页面 response.sendRedirect(request.getContextPath() + "/login"); System.out.println("未登录！"); return false; &#125; /** * 在业务处理器处理请求执行完成后,生成视图之前执行的动作 * 可在modelAndView中加入数据，比如当前时间 */ public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println("postHandle(), 在访问Controller之后，访问视图之前被调用,这里可以注入一个时间到modelAndView中，用于后续视图显示"); modelAndView.addObject("date","由拦截器生成的时间:" + new Date()); &#125; /** * 在DispatcherServlet完全处理完请求后被调用,可用于清理资源等 * * 当有拦截器抛出异常时,会从当前拦截器往回执行所有的拦截器的afterCompletion() */ public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("afterCompletion(), 在访问视图之后被调用"); &#125;&#125; ​ 配置interceptors 12345678&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/index2"/&gt; &lt;!-- 定义在mvc:interceptor下面的表示是对特定的请求才进行拦截的 --&gt; &lt;bean class="interceptor.LoginInterceptor"/&gt; &lt;/mvc:interceptor&gt; &lt;!-- 当设置多个拦截器时，先按顺序调用preHandle方法，然后逆序调用每个拦截器的postHandle和afterCompletion方法 --&gt;&lt;/mvc:interceptors&gt; ​ Spring Struct2使用IOC容器管理struct2的action]]></content>
      <categories>
        <category>技术</category>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven入门]]></title>
    <url>%2F2018%2F02%2F20%2F%E6%8A%80%E6%9C%AF%2FMaven%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[使用Maven配置环境 下载，解压，配置环境变量 配置仓库(repository)：本地存放位置，远程下载镜像 修改到D盘，以免重装系统时丢失。mirror使用阿里云，在conf/settings.xml下 12345678910 &lt;localRepository&gt;d:/maven/repository&lt;/localRepository&gt;&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt; ​ maven使用pom.xml维护项目依赖的jar 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.20&lt;/version&gt;&lt;/dependency&gt; IDEA中配置maven settings -&gt; build tools -&gt; maven 配置maven所在的路径，及其user settings文件。 file -》 other settings -》default settings -》 build tools 下设置默认的maven IDEA创建项目IDEA创建maven项目速度慢，1）修改源为阿里云；2）创建项目时添加参数DarchetypeCatalog=internal,或者在maven VM options添加。 new project -》 maven 选择create from archetype , archetype 即“原型、原始型” 选中需要的原型后，next 填写groupID 项目组织标识，对应包结构；ArtifactID 项目标识，对应项目名称。 初始化之后，会有import change提示，每当maven项目或pom文件改变都要import change。 IDEA maven增加jar包快速搜索、定位jar包 必须先要定位一个jar才能引用，groupId,artifacatId,version 打开project structure -》 Libraries -》 + -》 from Maven ： 输入关键词搜索，选中确认，然后在项目结构的外部依赖找到该包，在maven pom中引用。 也可以不引入，直接复制包名，然后在maven pom中添加依赖。 在maven中引入依赖 在pom.xml中添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.20&lt;/version&gt;&lt;/dependency&gt; 执行maven import， 可以让IDEA自动import 包依赖关系 在窗口右侧的maven工具栏可以查看, 按住Alt 后单击，可以用放大镜查看依赖图。 创建Maven web项目 create from archetype， 选中org.apache.maven.archetypes:maven-archetype-webapp maven web项目默认没有源码目录，新建一个源代码文件夹，然后mark as source root 右键 new , 可以选择创建servlet、filter、listener。 如果没有servlet选项，更新项目的.iml文件，sourceRoots下添加源码目录。 在pom中添加servlet依赖 在web.xml中配置路由 run configure下添加Tomcat服务器，启动测试。 创建SSM项目 创建maven web项目 导入SSM项目File-&gt;New-&gt;Project from existing sources 输入pom.xml文件的路径即可。]]></content>
      <categories>
        <category>技术</category>
        <category>Java</category>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis入门]]></title>
    <url>%2F2018%2F02%2F18%2F%E6%8A%80%E6%9C%AF%2FMybatis%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[MybatisMyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 Python Django的ORM框架提供了增删改查接口， mybatis必须要手动配置SQL语句。 官方文档 hello world 创建表和数据 12345678910USE how2java; CREATE TABLE category_ ( id int(11) NOT NULL AUTO_INCREMENT, name varchar(32) DEFAULT NULL, PRIMARY KEY (id)) ENGINE=MyISAM AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;INSERT INTO category_ VALUES (null,&apos;category1&apos;);INSERT INTO category_ VALUES (null,&apos;category2&apos;); 创建对应的pojo对象 12345678910111213141516171819package com.how2java.pojo; public class Category &#123; private int id; private String name; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; &#125; 配置文件mybatis-config.xml 配置数据库连接驱动、数据库名，用户密码，编码方式等 typeAliases， 类型-别名，在后面的配置中可以不必使用类的完整名字 1234567891011121314151617181920212223&lt;configuration&gt; &lt;typeAliases&gt; &lt;!-- 配置包或对象的别名，以简化全类名的书写 --&gt; &lt;package name="com.how2java.pojo"/&gt; &lt;/typeAliases&gt; &lt;properties resource="db.properties"/&gt; &lt;!-- 可以将一些配置单独文件，然后引用变量 $&#123;var&#125; --&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;dataSource type="POOLED"&gt; &lt;property name="driver" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/how2java?characterEncoding=UTF-8"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;!-- mapper配置文件 --&gt; &lt;mapper resource="com/how2java/pojo/Category.xml"/&gt; &lt;mapper resource="com/how2java/pojo/Product.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 创建类到数据操作的映射Category.xml,实现增删改查，模糊查询等操作。 注意：id用于mybatis session对象调用SQL语句， parameterType为入参类型， resultType为执行结果类型 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.how2java.pojo"&gt; &lt;!-- 增删改查 --&gt; &lt;insert id="addCategory" parameterType="Category"&gt; insert into category_ ( name ) values (#&#123;name&#125;) &lt;/insert&gt; &lt;delete id="deleteCategory" parameterType="Category" &gt; delete from category_ where id= #&#123;id&#125; &lt;/delete&gt; &lt;select id="getCategory" parameterType="_int" resultType="Category"&gt; select * from category_ where id= #&#123;id&#125; &lt;/select&gt; &lt;update id="updateCategory" parameterType="Category" &gt; update category_ set name=#&#123;name&#125; where id=#&#123;id&#125; &lt;/update&gt; &lt;!-- 查询全部 --&gt; &lt;select id="listCategory" resultType="Category"&gt; select * from category_ &lt;/select&gt; &lt;!-- 模糊查询 --&gt; &lt;select id="listCategoryByName" resultType="Category"&gt; select * from category_ WHERE name like concat('%',#&#123;0&#125;,'%') &lt;/select&gt; &lt;!-- 多条件查询 --&gt; &lt;select id="listCategoryByIdAndName" parameterType="map" resultType="Category"&gt; select * from category_ where id &gt; #&#123;id&#125; and name like concat('%',#&#123;name&#125;,'%') &lt;/select&gt;&lt;/mapper&gt; TestMybatis.java 载入mybatis配置文件 创建sqlsession 执行操作 提交、关闭会话 12345678910111213public class TestMybatis &#123; public static void main(String[] args) throws IOException &#123; String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session=sqlSessionFactory.openSession(); Category c1 = new Category(); c1.setName("new Category"); session.insert("addCategory", c1); session.commit(); session.close(); ​ 对象关系 通过resultMap建立映射，sql查询的列与Java pojo对象的属性对应。 一对一 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!-- 方式一：嵌套结果：使用嵌套结果映射来处理重复的联合结果的子集 封装联表查询的数据(去除重复的数据)select * from class c, teacher t where c.teacher_id=t.t_id and c.c_id=1--&gt;&lt;select id="getClass" parameterType="int" resultMap="ClassResultMap"&gt; select * from class c, teacher t where c.teacher_id=t.t_id and c.c_id=#&#123;id&#125;&lt;/select&gt;&lt;resultMap type="_Classes" id="ClassResultMap"&gt; &lt;id property="id" column="c_id"/&gt; &lt;result property="name" column="c_name"/&gt; &lt;association property="teacher" column="teacher_id" javaType="_Teacher"&gt; &lt;id property="id" column="t_id"/&gt; &lt;result property="name" column="t_name"/&gt; &lt;/association&gt;&lt;/resultMap&gt;&lt;!-- 方式二：嵌套查询：通过执行另外一个 SQL 映射语句来返回预期的复杂类型SELECT * FROM class WHERE c_id=1;SELECT * FROM teacher WHERE t_id=1 //1 是上一个查询得到的 teacher_id 的值--&gt;&lt;select id="getClass2" parameterType="int" resultMap="ClassResultMap2"&gt; select * from class where c_id=#&#123;id&#125;&lt;/select&gt;&lt;resultMap type="_Classes" id="ClassResultMap2"&gt; &lt;id property="id" column="c_id"/&gt; &lt;result property="name" column="c_name"/&gt; &lt;association property="teacher" column="teacher_id" javaType="_Teacher" select="getTeacher"&gt; &lt;/association&gt; &lt;/resultMap&gt;&lt;select id="getTeacher" parameterType="int" resultType="_Teacher"&gt; SELECT t_id id, t_name name FROM teacher WHERE t_id=#&#123;id&#125;&lt;/select&gt; ​ 一对多 p.cid： 一个product对应一个category List products: 一个category对应多个商品 取到一个category，然后可以获取其全部的product 使用left join查询category及其对应的全部product 123456789101112131415161718192021222324252627282930313233343536373839&lt;!-- Category.xml --&gt; &lt;!-- 通过Left Join多表联合查询 --&gt;&lt;resultMap id="categoryBean" type="Category"&gt; &lt;id column="cid" property="id"/&gt; &lt;result column="cname" property="name"/&gt; &lt;!--一对多映射, 属性products为collection类型，集合元素为Product类型--&gt; &lt;collection property="products" ofType="Product"&gt; &lt;id column="pid" property="id"/&gt; &lt;result column="pname" property="name"/&gt; &lt;result column="price" property="price"/&gt; &lt;/collection&gt;&lt;/resultMap&gt;&lt;!-- 一对多查询 --&gt;&lt;select id="showCategory" parameterType="int" resultMap="categoryBean"&gt; select c.*, p.*, c.id cid, c.name cname, p.id pid, p.name pname from category_ c LEFT join product_ p ON cid = p.cid where 1=1 and cid=#&#123;id&#125;&lt;/select&gt;&lt;!-- 2. 通过嵌套查询的方式 --&gt;&lt;select id="showCategory" parameterType="int" resultMap="categoryBean"&gt; select * from category_ where id = #&#123;id&#125;&lt;/select&gt;&lt;resultMap id="categoryBean" type="Category"&gt; &lt;id column="id" property="id"/&gt; &lt;result column="name" property="name"/&gt; &lt;!--一对多映射, 属性products为collection类型，集合元素为Product类型--&gt; &lt;collection property="products" ofType="Product" column="id" select="getProduct"&gt; &lt;id column="pid" property="id"/&gt; &lt;result column="pname" property="name"/&gt; &lt;result column="price" property="price"/&gt; &lt;/collection&gt;&lt;/resultMap&gt;&lt;select id="getProduct" parameterType="int", resultType="Product"&gt; select * from product_ p where p.cid=#&#123;id&#125;&lt;/select&gt; ​ 多对一 多个product 会对应一个category 取到一个product后，可以获取其对应的属性 12345678910111213141516&lt;resultMap type="Product" id="productBean"&gt; &lt;id column="pid" property="id" /&gt; &lt;result column="pname" property="name" /&gt; &lt;result column="price" property="price" /&gt; &lt;!-- 多对一的关系 --&gt; &lt;!-- property: 指的是属性名称, javaType：指的是属性的类型 --&gt; &lt;association property="category" javaType="Category"&gt; &lt;id column="cid" property="id"/&gt; &lt;result column="cname" property="name"/&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id="listProduct" resultMap="productBean"&gt; select c.*, p.*, c.id 'cid', p.id 'pid', c.name 'cname', p.name 'pname' from category_ c left join product_ p on c.id = p.cid &lt;/select&gt; ​ 多对多 以订单为例，一个订单有多种product，一种product也可以出现在多张订单里。 订单项包含product id，购买数量，所属订单ID。 在Order.xml中配置映射，以及listOrder， getOrder的查询方法 在OrderItem.xml中配置添加、删除订单项的SQL方法 无发使用update更新多对多的映射关系，但是可以先删除后在添加新的。 123456789101112131415161718192021222324252627282930313233343536373839&lt;!-- Order.xml --&gt;&lt;resultMap id="orderBean" type="Order"&gt; &lt;id column="oid" property="id"/&gt; &lt;result column="code" property="code"/&gt; &lt;!--一对多映射, 属性products为collection类型，集合元素为Product类型--&gt; &lt;collection property="orderItems" ofType="OrderItem"&gt; &lt;id column="oiid" property="id"/&gt; &lt;result column="number" property="number"/&gt; &lt;result column="number" property="number"/&gt; &lt;association property="product" javaType="Product"&gt; &lt;id column="pid" property="id"/&gt; &lt;result column="pname" property="name"/&gt; &lt;result column="price" property="price"/&gt; &lt;/association&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id="listOrder" resultMap="orderBean"&gt; select o.*,p.*,oi.*, o.id 'oid', p.id 'pid', oi.id 'oiid', p.name 'pname' from order_ o left join order_item_ oi on o.id =oi.oid left join product_ p on p.id = oi.pid &lt;/select&gt; &lt;select id="getOrder" resultMap="orderBean"&gt; select o.*,p.*,oi.*, o.id 'oid', p.id 'pid', oi.id 'oiid', p.name 'pname' from order_ o left join order_item_ oi on o.id =oi.oid left join product_ p on p.id = oi.pid where o.id = #&#123;id&#125; &lt;/select&gt;&lt;!-- OrderItem.xml --&gt; &lt;insert id="addOrderItem" parameterType="OrderItem"&gt; insert into order_item_ values (null, #&#123;order.id&#125;, #&#123;product.id&#125;, #&#123;number&#125;) &lt;/insert&gt; &lt;delete id="deleteOrderItem" parameterType="OrderItem" &gt; delete from order_item_ where oid= #&#123;order.id&#125; and pid = #&#123;product.id&#125; &lt;/delete&gt; java 123456789101112131415161718 Order o = sess.selectOne("getOrder", 1); OrderItem oi = new OrderItem(); Product p = sess.selectOne("getProductById", 1); oi.setProduct(p); oi.setNumber(10); oi.setOrder(o);// sess.insert("addOrderItem", oi); // sess.commit(); sess.delete("deleteOrderItem", oi); o = sess.selectOne("getOrder", 1); List&lt;OrderItem&gt; ois = o.getOrderItems(); for (OrderItem orderItem: ois)&#123; System.out.println(orderItem.getProduct() + "###" + orderItem.getNumber()); &#125; ​ 动态SQL在程序中拼接SQL语句不灵活，也很痛苦，比如要注意空格和逗号，条件分支等；Mybatis提供了动态SQL语法。 if 一条SQL实现2种不同条件的查询 123456&lt;select id="listProduct" resultType="Product"&gt; select * from product_ &lt;if test="name!=null"&gt; where name like concat('%',#&#123;name&#125;,'%') &lt;/if&gt; &lt;/select&gt; when和otherwise实现if-else 没有满足条件的when就会执行otherwise 12345678910111213141516&lt;select id="listProduct" resultType="Product"&gt; SELECT * FROM product_ &lt;where&gt; &lt;choose&gt; &lt;when test="name != null"&gt; and name like concat('%',#&#123;name&#125;,'%') &lt;/when&gt; &lt;when test="price !=null and price != 0"&gt; and price &gt; #&#123;price&#125; &lt;/when&gt; &lt;otherwise&gt; and id &gt;1 &lt;/otherwise&gt; &lt;/choose&gt; &lt;/where&gt;&lt;/select&gt; ​ where和set if没有else分支，多条件判断时可以使用where标签，会自动处理条件中的and or关键词 1234567891011&lt;select id="getCategory" parameterType="map" resultType="Category"&gt; select * from category_ &lt;where&gt; &lt;if test="id!=null"&gt; AND id= #&#123;id&#125; &lt;/if&gt; &lt;if test="name!=null"&gt; AND name LIKE concat("%", #&#123;name&#125;, "%") &lt;/if&gt; &lt;/where&gt; &lt;/select&gt; 在update中可以使用set标签 123456789&lt;update id="updateProduct" parameterType="Product" &gt; update product_ &lt;set&gt; &lt;if test="name != null"&gt;name=#&#123;name&#125;,&lt;/if&gt; &lt;if test="price != null"&gt;price=#&#123;price&#125;&lt;/if&gt; &lt;/set&gt; where id=#&#123;id&#125; &lt;/update&gt; ​ trim (where, set) foreach 可以实现in (a, b, c)的拼装 12345678&lt;select id="getProductsByIds"&gt; SELECT * FROM product_ where id in &lt;foreach collection="list" index="index" item="item" open="(" close=")" separator=","&gt; #&#123;item&#125; &lt;/foreach&gt;&lt;/select&gt; ​ 注解实现CRUD前面的做法是在Category.xml中配置类Category与SQL的映射关系&lt;mapper&gt; 可以实现一个Mapper接口，并在接口方法上使用注解绑定SQL映射。 12345678910111213141516public interface CategoryMapper &#123; @Insert(" insert into category_ ( name ) values (#&#123;name&#125;) ") public int add(Category category); @Delete(" delete from category_ where id= #&#123;id&#125; ") public void delete(int id); @Select("select * from category_ where id= #&#123;id&#125; ") public Category get(int id); @Update("update category_ set name=#&#123;name&#125; where id=#&#123;id&#125; ") public int update(Category category); @Select(" select * from category_ ") public List&lt;Category&gt; list();&#125; 使用时先获取mapper接口对象，然后调用CURD方法 123CategoryMapper mapper = session.getMapper(CategoryMapper.class);Category c = mapper.get(1);System.out.println(c); 对象关系 一对多 以Category-Product 1对多模型为例，一个category对象里有多个product的集合。 @select获取Category对象 @Results里，通过product mapper接口的getProductByCategoryId获取products集合。 12345678910public interface CategoryMapper &#123; @Select(" select * from category_ ") @Results(&#123;@Result(column = "id", property = "id"), @Result(column = "name", property = "name"), @Result(javaType = List.class, property = "products", column = "id", many = @Many(select = "com.how2java.mapper.ProductMapper.getProductByCID")), &#125;) public List&lt;Category&gt; list();&#125; 1234public interface ProductMapper &#123; @Select("select * from product_ where cid = #&#123;cid&#125;") public List&lt;Product&gt; getProductByCID(int cid);&#125; 多对一 通过一个product，找到其对应的category 1234567891011121314 // ProductMapper --&gt; @Select("select * from product_") @Results(&#123;@Result(property = "id", column = "id"), @Result(property = "cid", column = "cid"), @Result(property = "name", column = "name"), @Result(property = "price", column = "price"), @Result(column = "cid", property = "category", javaType = Category.class, one = @One(select = "com.how2java.mapper.CategoryMapper.get")), &#125;) public List&lt;Product&gt; list(); // CategoryMapper --&gt;@Select("select * from category_ where id= #&#123;id&#125; ")public Category get(int id); ​ 多对多 遍历所有订单，并计算订单价格 order mapper: 获取所有订单，通过OrderItem mapper 获取order下的orderitem 1234567891011121314public interface OrderMapper &#123; @Select("select * from order_") @Results(&#123; @Result(column = "id", property = "id"), @Result(column = "code", property = "code"), @Result(column = "id", property = "orderItems", javaType = List.class, many = @Many(select = "com.how2java.mapper.OrderItemMapper.list")) &#125;) public List&lt;Order&gt; list(); @Select("select * from order_ where id = #&#123;id&#125;") public Order get(int id);&#125; ​ OrderItem mapper: 通过 product mapper拿到product信息 123456789public interface OrderItemMapper &#123; @Select("select * from order_item_ where oid = #&#123;oid&#125;") @Results(&#123;@Result(column = "id", property = "id"), @Result(column = "number", property = "number"), @Result(column = "pid", property = "product", one = @One(select = "com.how2java.mapper.ProductMapper.getOne")), @Result(column = "oid", property = "order", one = @One(select = "com.how2java.mapper.OrderMapper.get")), &#125;) public List&lt;OrderItem&gt; list(int oid);&#125; ​ 动态SQLorg.apache.ibatis.jdbc.SQL可以动态生成sql语句，可以配合注解使用 SqlProvider类，用于动态生成sql字符串 123456789101112131415161718192021222324252627282930313233343536373839import org.apache.ibatis.jdbc.SQL; public class CategoryDynaSqlProvider &#123; public String list() &#123; return new SQL() .SELECT("*") .FROM("category_") .toString(); &#125; public String get() &#123; return new SQL() .SELECT("*") .FROM("category_") .WHERE("id=#&#123;id&#125;") .toString(); &#125; public String add()&#123; return new SQL() .INSERT_INTO("category_") .VALUES("name", "#&#123;name&#125;") .toString(); &#125; public String update()&#123; return new SQL() .UPDATE("category_") .SET("name=#&#123;name&#125;") .WHERE("id=#&#123;id&#125;") .toString(); &#125; public String delete()&#123; return new SQL() .DELETE_FROM("category_") .WHERE("id=#&#123;id&#125;") .toString(); &#125; &#125; 在mapper接口中使用@InsertProvider引用SqlProvider中的sql查询方法 1234567891011121314151617public interface CategoryMapper &#123; @InsertProvider(type=CategoryDynaSqlProvider.class,method="add") public int add(Category category); @DeleteProvider(type=CategoryDynaSqlProvider.class,method="delete") public void delete(int id); @SelectProvider(type=CategoryDynaSqlProvider.class,method="get") public Category get(int id); @UpdateProvider(type=CategoryDynaSqlProvider.class,method="update") public int update(Category category); @SelectProvider(type=CategoryDynaSqlProvider.class,method="list") public List&lt;Category&gt; list(); &#125; 一个复杂的查询示例 1234567891011121314151617181920private String selectPersonSql() &#123; return new SQL() &#123;&#123; SELECT("P.ID, P.USERNAME, P.PASSWORD, P.FULL_NAME"); SELECT("P.LAST_NAME, P.CREATED_ON, P.UPDATED_ON"); FROM("PERSON P"); FROM("ACCOUNT A"); INNER_JOIN("DEPARTMENT D on D.ID = P.DEPARTMENT_ID"); INNER_JOIN("COMPANY C on D.COMPANY_ID = C.ID"); WHERE("P.ID = A.ID"); WHERE("P.FIRST_NAME like ?"); OR(); WHERE("P.LAST_NAME like ?"); GROUP_BY("P.ID"); HAVING("P.LAST_NAME like ?"); OR(); HAVING("P.FIRST_NAME like ?"); ORDER_BY("P.ID"); ORDER_BY("P.FULL_NAME"); &#125;&#125;.toString();&#125; ​ 其他字段名与实体类属性命名不相同由于mybatis根据记录字段名将相应的数据注入实体类的属性中，如果字段名与实体类不一致，则对象映射会失败。 有2种解决方法： 在SQL语句中为字段定义别名，别名与实体类的属性名一致 1234&lt;!-- 字段的值的别名与Order对象的属性一致 --&gt;&lt;select id="selectOrder" parameterType="int" resultType="Order"&gt;select order_id id, order_no orderNo,order_price price from orders where order_id=#&#123;id&#125;&lt;/select&gt; ​ 通过resultMap定义字段与属性的映射关系 123456789&lt;select id="selectOrderResultMap" parameterType="int" resultMap="orderResultMap"&gt;select * from orders where order_id=#&#123;id&#125;&lt;/select&gt;&lt;resultMap type="Order" id="orderResultMap"&gt; &lt;id property="id" column="order_id"/&gt; &lt;result property="orderNo" column="order_no"/&gt; &lt;result property="price" column="order_price"/&gt;&lt;/resultMap&gt; ​ 日志输出Mybatis实现了日志工厂，支持Log4J等日志工具，只需导入相关的jar包，并进行相关配置即可。 mybatis-config.xml 1234&lt;settings&gt; &lt;setting name="logPrefix" value="mybatis_log"/&gt; &lt;setting name="logImpl" value="LOG4J" /&gt;&lt;/settings&gt; log4j.properties 12345678# Global logging configurationlog4j.rootLogger=TRACE, stdout# MyBatis logging configuration...log4j.logger.com.how2java=TRACE,stdout# Console output...log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%5p [%t] [%c] - %m%n ​ 事务支持 需要配置environments.transactionManger。 &lt;transactionManager type=&quot;JDBC&quot;/&gt; mysql表的数据引擎必须是innodb才支持事务 12alter table category_ ENGINE = innodb;show table status from how2java; ​ 在同一个session里的全部操作视为一个事务，支持回滚。 调用存储过程 创建存储过程 123456789/* 创建存储过程 */CREATE PROCEDURE test.get_user_count(IN sex_id INT, OUT user_count INT)BEGINSELECT COUNT(*) FROM test.user_ INTO user_count;END/* 调用存储过程 */SET @user_count = 0;CALL test.get_user_count(@user_count);SELECT @user_count; mybatis中调用 12345&lt;select id="getCount" resultType="java.util.Map" statementType="CALLABLE"&gt;&#123;call get_user_count(#&#123;sex_id,mode=IN,jdbcType=INTEGER&#125;,#&#123;result,mode=OUT,jdbcType=INTEGER&#125;)&#125;&lt;/select&gt; ​ 延迟加载在一对多的对象关系查询中，如果不使用延迟加载，则执行查询对象A时，也会同时执行查询A关联的多个B对象。 延迟加载则在访问了B对象时在进行数据库查询。 123456&lt;settings&gt; &lt;!-- 打开延迟加载的开关 --&gt; &lt;setting name="lazyLoadingEnabled" value="true" /&gt; &lt;!-- 将积极加载改为消息加载即按需加载 --&gt; &lt;setting name="aggressiveLazyLoading" value="false"/&gt; &lt;/settings&gt; 分页 &amp; PageHelper 普通的查询语句加上limit参数即可 123456&lt;select id="listCategory" resultType="Category"&gt; select * from category_ &lt;if test="start!=null and count!=null"&gt; limit #&#123;start&#125;,#&#123;count&#125; &lt;/if&gt;&lt;/select&gt; 或者使用注解： 123 @Select(" select * from category_ limit #&#123;start&#125;,#&#123;count&#125;") public List&lt;Category&gt; listByPage(@Param("start") int start, @Param("count")int count);&#125; 使用插件进行分页 需要导入第三方包，PageHelper主页 使用方法 mybatis配置中添加插件 1234567&lt;plugins&gt; &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt; &lt;plugin interceptor="com.github.pagehelper.PageInterceptor"&gt; &lt;!-- 使用下面的方式配置参数，后面会有所有的参数介绍 --&gt; &lt;property name="param1" value="value1"/&gt; &lt;/plugin&gt;&lt;/plugins&gt; 调用方式 12345678910//第一种，RowBounds方式的调用List&lt;Country&gt; list = sqlSession.selectList("x.y.selectIf", null, new RowBounds(0, 10));//第二种，Mapper接口方式的调用，推荐这种使用方式。PageHelper.startPage(1, 10);List&lt;Country&gt; list = countryMapper.selectIf(1);//第三种，Mapper接口方式的调用，推荐这种使用方式。PageHelper.offsetPage(1, 10);List&lt;Country&gt; list = countryMapper.selectIf(1); ​ 缓存一级缓存 同一session下的相同查询只执行一次数据库访问，后续从缓存中取查询结果 二级缓存 通过配置启用sessionFactory的缓存，同一个SessionFactory下查询只执行一次 &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; 开启缓存 pojo对象要实现Serializable接口 pojo的mapper配置文件里添加&lt;cached/&gt; 暂时没找到注解如何使用缓存 一般情况下不应使用mybatis自带的缓存机制，spring或其他框架会有更好的缓存实现。 使用Ehcache 导入jar包 配置ehcache，在 classpath 下 加入ehcache 的配置文件 ehcache.xml: 12345678910&lt;cache name="default" maxElementsInMemory="10000" eternal="false" timeToIdleSeconds="3600" timeToLiveSeconds="10" overflowToDisk="true" diskPersistent="true" diskExpiryThreadIntervalSeconds="120" maxElementsOnDisk="10000"/&gt; sql映射文件中使用： 1234567891011121314 &lt;mapper namespace="com.how2java.pojo"&gt; &lt;!-- 配置个性化缓存配置，默认使用&lt;cached/&gt;即开启缓存并使用ehcache的全局配置 --&gt; &lt;cache type="org.mybatis.caches.ehcache.LoggingEhcache" &gt; &lt;property name="timeToIdleSeconds" value="3600"/&gt;&lt;!--1 hour--&gt; &lt;property name="timeToLiveSeconds" value="3600"/&gt;&lt;!--1 hour--&gt; &lt;property name="maxEntriesLocalHeap" value="1000"/&gt; &lt;property name="maxEntriesLocalDisk" value="10000000"/&gt; &lt;property name="memoryStoreEvictionPolicy" value="LRU"/&gt; &lt;/cache&gt; &lt;select id="getCategory" parameterType="_int" resultType="Category" useCache="false"&gt; &lt;!-- 禁用缓存 ---&gt; select * from category_ where id= #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; ​ 连接池c3p0 、Druid等连接池比mybatis自带的高效，健壮。 mybatis需要自己写个DataSource的类，然后更改配置里DataSource的Type，自带的为POOLED 换成type=”C3P0DataSourceFactory” 12345678910111213import org.apache.ibatis.datasource.unpooled.UnpooledDataSourceFactory; import com.mchange.v2.c3p0.ComboPooledDataSource; public class C3P0DataSourceFactory extends UnpooledDataSourceFactory&#123; public C3P0DataSourceFactory()&#123; this.dataSource =new ComboPooledDataSource(); &#125; &#125; Spring &amp; Mybatis mybatis里先建立pojo和SQL的映射类mapper 映射可以使用注解的方式写在mapper类里，或者单独xml mapper配置文件,然后在SqlSessionFactoryBean中指定mapperLocations。 spring配置文件里，添加DataSource数据源、sqlSessionFactory工厂, MapperScannerConfigurer的bean。 123456789101112131415161718192021222324252627282930313233343536373839&lt;context:annotation-config /&gt; &lt;!-- 使用注解的方式加载context配置和装载bean --&gt;&lt;!-- 1. 数据源 : DriverManagerDataSource --&gt; &lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName"&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property name="url"&gt; &lt;value&gt;jdbc:mysql://localhost:3306/how2java?characterEncoding=UTF-8&lt;/value&gt; &lt;/property&gt; &lt;property name="username"&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;property name="password"&gt; &lt;value&gt;admin&lt;/value&gt; &lt;/property&gt; &lt;/bean&gt;&lt;!-- 2. mybatis 的 SqlSession 的工厂: SqlSessionFactoryBean --&gt;&lt;bean id="sqlSession" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="typeAliasesPackage" value="com.how2java.pojo" /&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="mapperLocations" value="classpath:com/how2java/mapper/*.xml"/&gt;&lt;/bean&gt;&lt;!-- 3. mybatis 自动扫描加载 Sql 映射文件 : MapperScannerConfigurer --&gt;&lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.how2java.mapper"/&gt; &lt;property name="sqlSessionFactory" ref="sqlSessionFactory"/&gt;&lt;/bean&gt;&lt;!-- 4. 事务管理 : DataSourceTransactionManager --&gt;&lt;bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!-- 5. 使用声明式事务 --&gt;&lt;tx:annotation-driven transaction-manager="txManager" /&gt; 测试代码 123456789101112131415161718192021222324@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration("classpath:applicationContext.xml")public class MybatisTest &#123; @Autowired private CategoryMapper categoryMapper; @Test public void testAdd() &#123; Category category = new Category(); category.setName("new Category"); categoryMapper.add(category); &#125; @Test public void testList() &#123; System.out.println(categoryMapper); List&lt;Category&gt; cs=categoryMapper.list(); for (Category c : cs) &#123; System.out.println(c.getName()); &#125; &#125; &#125; ​ SSMhello world 项目结构： controller接收request请求，通过service接口获取数据，然后将数据和模板组装好后返回给客户端。 1234567891011121314@Controller@RequestMapping("")public class CategoryController &#123; @Autowired private CategoryService categoryService; @RequestMapping("addCategory") public ModelAndView add(Category category)&#123; categoryService.add(category); ModelAndView mav = new ModelAndView("addResult"); mav.addObject("category", category); return mav; &#125;&#125; ​ service类通过mybatis mapper接口访问数据库获取数据。 1234567891011121314@Servicepublic class CategoryServiceImpl implements CategoryService &#123; @Autowired private CategoryMapper categoryMapper; public void add(Category category) &#123; categoryMapper.add(category); &#125; @Override public List&lt;Category&gt; list() &#123; return categoryMapper.list(); &#125;&#125; ​ Maven pom配置中指定相关依赖，在build的参数中添加编译插件，指定resource位置。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- 资源文件拷贝插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;2.7&lt;/version&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- java编译插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;.xml&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;include&gt;**/*.tld&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; Tomcat首先根据web.xml初始化web容器(生命周期同Tomcat， Servlet) web.xml定义了spring父容器（生命周期同servlet）和spring MVC子容器的初始化。 spring的初始化由监听ServletContext的Listener完成，父容器加载完后，加载spring MVC容器。 123456789&lt;!--把applicationContext.xml加入到配置文件中--&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;!-- 加载spring --&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; ​ web容器中定义的dispatcherServlet（调度）会转发web容器接收的请求，交给Spring MVC。 12345678910111213141516&lt;!--配置springmvc DispatcherServlet--&gt;&lt;servlet&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;!--配置springMVCr.xml作为mvc的配置文件--&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springMVC.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 由spring初始化的bean（和mybatis相关），dataSource， sqlSessionFactory， mapper 1234567891011121314151617&lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/ssm?characterEncoding=UTF-8"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt; &lt;/bean&gt; &lt;bean id="sqlSession" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="typeAliasesPackage" value="com.shuaiyy.pojo" /&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!--&lt;property name="mapperLocations" value="classpath:com/shuaiyy/mapper/*.xml"/&gt;--&gt; &lt;!--&lt;property name="mapperLocations" value="classpath:com/shuaiyy/mapper/*.*"/&gt;--&gt; &lt;/bean&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.shuaiyy.mapper"/&gt; &lt;/bean&gt; ​ spring mvc 负责定位资源及模板，扫描装配Controller bean。 123456789101112131415161718192021222324252627282930&lt;mvc:default-servlet-handler /&gt; &lt;!--启用spring的一些annotation --&gt; &lt;context:annotation-config/&gt; &lt;!-- 配置注解驱动 可以将request参数与绑定到controller参数上 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!--静态资源映射--&gt; &lt;!--本项目把静态资源放在了webapp的statics目录下，资源映射如下--&gt; &lt;mvc:resources mapping="/css/**" location="/WEB-INF/statics/css/"/&gt; &lt;mvc:resources mapping="/js/**" location="/WEB-INF/statics/js/"/&gt; &lt;mvc:resources mapping="/image/**" location="/WEB-INF/statics/image/"/&gt; &lt;!-- 视图定位 --&gt; &lt;!-- 对模型视图名称的解析，即在模型视图名称添加前后缀(如果最后一个还是表示文件夹,则最后的斜杠不要漏了) 使用JSP--&gt; &lt;!-- 默认的视图解析器 在上边的解析错误时使用 (默认使用html)- --&gt; &lt;bean id="defaultViewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView"/&gt; &lt;property name="prefix" value="/WEB-INF/view/jsp/"/&gt;&lt;!--设置JSP文件的目录位置--&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;property name="exposeContextBeansAsAttributes" value="true"/&gt; &lt;/bean&gt; &lt;!-- 自动扫描装配 --&gt; &lt;context:component-scan base-package="com.shuaiyy.controller"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;/context:component-scan&gt; ​ 分页首先定义一个Page对象来接收request参数，start， count， end。 在sql查询语句中使用limit关键字 ​ 使用PageHelper插件 在bean容器配置文件applicationContext中的sqlSessionFactory bean中配置插件 12345678910111213141516&lt;bean id="sqlSession" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="typeAliasesPackage" value="com.how2java.pojo" /&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;property name="mapperLocations" value="classpath:com/how2java/mapper/*.xml"/&gt; &lt;property name="plugins"&gt; &lt;array&gt; &lt;bean class="com.github.pagehelper.PageInterceptor"&gt; &lt;property name="properties"&gt; &lt;!--使用下面的方式配置参数，一行配置一个 --&gt; &lt;value&gt; &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; ​ 更换连接池123456789101112131415161718192021222324252627282930&lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource" init-method="init" destroy-method="close"&gt; &lt;!-- 基本属性 url、user、password --&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/ssm?characterEncoding=UTF-8" /&gt; &lt;property name="username" value="root" /&gt; &lt;property name="password" value="123456" /&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver" /&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="3" /&gt; &lt;property name="minIdle" value="3" /&gt; &lt;property name="maxActive" value="20" /&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="60000" /&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="60000" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="300000" /&gt; &lt;property name="validationQuery" value="SELECT 1" /&gt; &lt;property name="testWhileIdle" value="true" /&gt; &lt;property name="testOnBorrow" value="false" /&gt; &lt;property name="testOnReturn" value="false" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 --&gt; &lt;property name="poolPreparedStatements" value="true" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="20" /&gt; &lt;/bean&gt; 实现CRUD 控制器中配置相应URL映射和视图模型，调用service接口实现对应的数据操作 12345678910111213141516171819202122232425@RequestMapping("addCategory")public ModelAndView addCategory(Category category)&#123; categoryService.add(category); ModelAndView mav = new ModelAndView("redirect:/listCategory"); return mav;&#125; @RequestMapping("deleteCategory")public ModelAndView deleteCategory(Category category)&#123; categoryService.delete(category); ModelAndView mav = new ModelAndView("redirect:/listCategory"); return mav;&#125; @RequestMapping("editCategory")public ModelAndView editCategory(Category category)&#123; Category c= categoryService.get(category.getId()); ModelAndView mav = new ModelAndView("editCategory"); mav.addObject("c", c); return mav;&#125; @RequestMapping("updateCategory")public ModelAndView updateCategory(Category category)&#123; categoryService.update(category); ModelAndView mav = new ModelAndView("redirect:/listCategory"); return mav;&#125; ​ service接口的实现类中调用mapper接口进行数据库操作。 12345678910111213141516171819202122232425@Servicepublic class CategoryServiceImpl implements CategoryService &#123; @Autowired private CategoryMapper categoryMapper; public void add(Category category) &#123; categoryMapper.add(category); &#125; @Override public void delete(Category category) &#123; categoryMapper.delete(category); &#125; @Override public void update(Category category) &#123; categoryMapper.update(category); &#125; @Override public Category get(int id) &#123; return categoryMapper.get(id); &#125;&#125; ​ mapper接口实现数据库访问 1234567891011121314public interface CategoryMapper &#123; @Insert("insert into category_(id,NAME) VALUES(#&#123;id&#125;, #&#123;name&#125;)")// @Insert(" insert into category_ ( name ) values (#&#123;name&#125;)") public void add(Category category); @Delete("delete from category_ where id = #&#123;id&#125; and name= #&#123;name&#125;") public void delete(Category category); @Select(" select * from category_ where id = #&#123;id&#125;") public Category get(int id); @Update("update category_ set name=#&#123;name&#125; where id = #&#123;id&#125;" ) public void update(Category category);&#125; 事务管理需要导入aspectjweaver包依赖。 配置事务管理器和事务注解扫描器 applicationContext.xml 1234&lt;tx:annotation-driven transaction-manager="transactionManager"/&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; ​ 为指定的方法加上事务注解 12345678910111213@Override @Transactional(propagation=Propagation.REQUIRED,rollbackForClassName="Exception") public void addTwo() &#123; Category c1 = new Category(); c1.setName("短的名字"); categoryMapper.add(c1); Category c2 = new Category(); c2.setName("名字长对应字段放不下,名字长对应字段放不下,名字长对应字段放不下,名字长对应字段放不下,名字长对应字段放不下,名字长对应字段放不下,名字长对应字段放不下,名字长对应字段放不下,"); categoryMapper.add(c2); &#125;;&#125; 使用AOP方式配置事务管理 配置AOP 1234567891011121314&lt;tx:advice id="txadvice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;tx:method name="add*" propagation="REQUIRED" rollback-for="Exception" /&gt; &lt;tx:method name="del*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="edit*" propagation="REQUIRED" rollback-for="Exception" /&gt; &lt;tx:method name="update*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;tx:method name="list*" propagation="REQUIRED" rollback-for="Exception"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;aop:config&gt; &lt;aop:pointcut id="serviceMethod" expression="execution(* com.how2java.service.*.*(..))"/&gt; &lt;aop:advisor pointcut-ref="serviceMethod" advice-ref="txadvice"/&gt; &lt;/aop:config&gt; ​ JSON 使用fastjson依赖包处理json字符串 12JSONObject result = new JSONObject();result.put("OK", "OK"); ​ spring mvc 依赖jackson依赖包，处理RequestBody， ResponseBody中的json对象。 @RequestBody 从请求体解析json对象 @ResponseBody，将返回的json字符串作为响应体。 12345678@ResponseBody@RequestMapping("/submitCategory")public String submitCategory(@RequestBody Category category) &#123; System.out.println("SSM接受到浏览器提交的json，并转换为Category对象:"+category); JSONObject result = new JSONObject(); result.put("OK", "OK"); return result.toJSONString();&#125; jquery提交post请求 1234567891011121314151617181920212223242526&lt;form &gt; id：&lt;input type="text" id="id" value="123" /&gt;&lt;br/&gt; 名称：&lt;input type="text" id="name" value="category xxx"/&gt;&lt;br/&gt; &lt;input type="button" value="提交" id="sender3"&gt;&lt;/form&gt;&lt;div id="messageDiv3"&gt;&lt;/div&gt;&lt;script&gt; $('#sender3').click(function()&#123; var id=document.getElementById('id').value; var name=document.getElementById('name').value; var category=&#123;"name":name,"id":id&#125;; var jsonData = JSON.stringify(category); var page="submitCategory"; $.ajax(&#123; type:"post", url: page, data:jsonData, dataType:"json", contentType : "application/json;charset=UTF-8", success: function(result)&#123; alert("提交成功，请在Tomcat控制台查看服务端接收到的数据"); &#125; &#125;); &#125;); ​ RESTFUL APIrestful简单的讲URI指定资源，http请求的方法来决定对资源对象的操作。 SpringMVC的dispatcherServlet只能处理post和get，因此需要在web.xml中配置filter增加对put和delete方法的变相支持，会将POST请求转换为对应的方法。即在POST表单中指定_method为PUT或DELETE, 表单域可以设为hidden。 12345678&lt;filter&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 在jsp中实现CRUD对应的请求发起操作 在POST表单中定义_method隐藏域的请求方法属性值， 确定action的URI，最后jQuery POST提交函数。 jsp 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 &lt;c:forEach items="$&#123;categorys&#125;" var="c" varStatus="st"&gt; &lt;tr&gt; &lt;td&gt;$&#123;c.id&#125;&lt;/td&gt; &lt;td&gt;$&#123;c.name&#125;&lt;/td&gt; &lt;td&gt;&lt;a class="edit" name="$&#123;c.name&#125;/$&#123;c.id&#125;" href="#add_edit" &gt;编辑&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a class="delete" href="category/$&#123;c.id&#125;"&gt;删除&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;div&gt; &lt;!-- 增加使用PUT方法--&gt; &lt;form id="add_edit" method="post" action="category"&gt; &lt;input type="hidden" name="_method" value="PUT"&gt; 分类id： &lt;input name="id" value="" type="text" &gt; &lt;br&gt;&lt;br&gt; 分类名称： &lt;input name="name" value="" type="text"&gt; &lt;br&gt;&lt;br&gt; &lt;input type="submit" value="增加分类"&gt; &lt;input type="reset" value="清空输入"&gt; &lt;/form&gt; &lt;/div&gt;&lt;/div&gt;&lt;form id="formdelete" action="" method="POST" &gt; &lt;input type="hidden" name="_method" value="DELETE"&gt;&lt;/form&gt;&lt;script type="text/javascript"&gt; /*将post method 改变为delete*/ $(function()&#123; $(".delete").click(function()&#123; var href=$(this).attr("href"); $("#formdelete").attr("action",href).submit(); return false; &#125;) &#125;); /* 修改操作使用post method*/ $(function()&#123; $(".edit").click(function()&#123; var list =$(this).attr("name").split("/"); var cid = list.pop(); var name = list.pop(); var uri = "category/"+cid; $("#add_edit").attr("action", uri); $("#add_edit input[name=id]").attr("value", cid); $("#add_edit input[name=id]").attr("disabled", "disabled"); $("#add_edit input[name=name]").attr("value", name); $("#add_edit input[type=submit]").attr("value", "修改此分类"); $("#add_edit input[type=hidden]").remove(); &#125;); &#125;);&lt;/script&gt; ​ controller 123456789101112131415161718192021// 删除@RequestMapping(value = "category/&#123;id&#125;", method = RequestMethod.DELETE) public ModelAndView delete(@PathVariable int id)&#123; categoryService.deleteByID(id); ModelAndView mav = new ModelAndView("redirect:/listCategory"); return mav; &#125;// 修改 @RequestMapping(value = "category/&#123;id&#125;", method = RequestMethod.POST) public ModelAndView edit(Category category)&#123; categoryService.update(category); ModelAndView mav = new ModelAndView("redirect:/listCategory"); return mav; &#125;// 增加 @RequestMapping(value = "category", method = RequestMethod.PUT) public ModelAndView addCategoryByPost(Category category)&#123; categoryService.add(category); ModelAndView mav = new ModelAndView("redirect:/listCategory"); return mav; &#125; ​]]></content>
      <categories>
        <category>技术</category>
        <category>Java</category>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ORM</tag>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hibernate入门]]></title>
    <url>%2F2018%2F02%2F16%2F%E6%8A%80%E6%9C%AF%2FHibernate%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Hibernate入门一个Java 领域的持久化框架，ORM 框架。 “持久化”包括和数据库相关的各种操作：增删查改，根据OID加载对象。 Hello World 创建数据库表和POJO对象 Product.java 配置POJO到table的映射关系 Product.hbm.xml 123456789101112131415&lt;?xml version="1.0"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC "-//Hibernate/Hibernate Mapping DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;&lt;hibernate-mapping package="cn.shuaiyy.pojo"&gt; &lt;class name="Product" table="product_"&gt; &lt;id name="id" column="id"&gt; &lt;generator class="native"&gt; &lt;/generator&gt; &lt;/id&gt; &lt;property name="name" /&gt; &lt;property name="price" /&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; Hibernate配置文件hibernate.cfg.xml中配置数据库连接，并添加mapping配置。 ​ 12345678910111213141516171819202122&lt;?xml version='1.0' encoding='utf-8'?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC "-//Hibernate/Hibernate Configuration DTD 3.0//EN" "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- Database connection settings --&gt; &lt;property name="connection.driver_class"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name="connection.url"&gt;jdbc:mysql://localhost:3306/test?characterEncoding=UTF-8&lt;/property&gt; &lt;property name="connection.username"&gt;root&lt;/property&gt; &lt;property name="connection.password"&gt;123456&lt;/property&gt; &lt;!-- SQL dialect --&gt; &lt;property name="dialect"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;property name="show_sql"&gt;true&lt;/property&gt; &lt;property name="hbm2ddl.auto"&gt;update&lt;/property&gt; &lt;!-- 映射关系配置 --&gt; &lt;mapping resource="cn/shuaiyy/pojo/Product.hbm.xml" /&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt; 导入hibernate-core包，进行测试 TestHibernate.java 获取SessionFactory对象，并创建一个session 在session中开启一个事务 通过session进行CRUD session提交事务 关闭session和sessionFactory 1234567891011121314151617 // 获取session，开启事务 SessionFactory sf = new Configuration().configure().buildSessionFactory();// 如果配置文件不在classpath下目录，可以传入File对象。// File config = new File("xx/xxx/hibernate.cfg.xml");// new Configuration().configure(config) Session s = sf.openSession(); s.beginTransaction(); Product p = new Product(); p.setName("iphone8"); p.setPrice(8000); s.save(p); // 增加 p = s.get(Product.class, 1); // 查询 System.out.println(p.getName() + p.getPrice()); s.getTransaction().commit(); // 提交事务 s.close(); sf.close(); ​ hibernate配置cfg.xml show_sql：是否将运行期生成的SQL输出到日志以供调试 format_sql：是否将SQL 转化为格式良好的SQL hbm2ddl.auto：在启动和停止时自动地创建，更新或删除数据库。取值create | update | create-drop |validate hibernate.jdbc.fetch_size：需要底层数据库支持，每次查询取出的记录数。取100时性能较好。 hibernate.jdbc.batch_size：批量操作的批次大小，Oracle数据库取30较好。 hbm.xml hibernate-mapping的属性： default-cascade(默认为none): 设置hibernate默认的级联风格 default-access (默认为property): 指定Hibernate 的默认的属性访问策略。默认值为 property, 即使用getter, setter 方法来访问属性. 若指定access, 则通过反射访问成员变量. default-lazy(默认为true): 设置Hibernat morning的延迟加载策略. 该属性的默认值为 true, 即启用延迟加载策略. package (可选): 指定一个包前缀，配置类名时该包下的类可以不用全类名。 class节点的属性: 用于配置类与表的映射。 name:指定该持久化类映射的持久化类的类名 table:指定该持久化类映射的表名, Hibernate 默认以持久化类的类名作为表名 dynamic-insert: 若设置为true, 表示当保存一个对象时, 会动态生成 insert 语句, insert 语句中仅包含所有取值不为null 的字段. 默认值为false dynamic-update: 若设置为true, 表示当更新一个对象时, 会动态生成 update 语句, update 语句中仅包含所有取值需要更新的字段. 默认值为false select-before-update:设置Hibernate 在更新某个持久化对象之前是否需要先执行一次查询. 默认值为false batch-size:指定根据OID 来抓取实例时每批抓取的实例数. lazy: 指定是否使用延迟加载. mutable: 若设置为true, 等价于所有的&lt;property&gt; 元素的update 属性为false, 表示整个实例不能被更新. 默认为true. discriminator-value: 指定区分不同子类的值. 当使用&lt;subclass/&gt; 元素来定义持久化类的继承关系时需要使用该属性 id节点：设定持久化类的OID 和表的主键的映射 name: 标识持久化类OID 的属性名 column: 设置标识属性所映射的数据表的列名(主键字段的名字). unsaved-value:若设定了该属性, Hibernate 会通过比较持久化类的OID 值和该属性值来区分当前持久化类的对象是否为临时对象 type:指定Hibernate 映射类型. Hibernate 映射类型是Java 类型与SQL 类型的桥梁. 如果没有为某个属性显式设定映射类型, Hibernate 会运用反射机制先识别出持久化类的特定属性的Java 类型, 然后自动使用与之对应的默认的Hibernate 映射类型 ​ Java 的基本数据类型和包装类型对应相同的Hibernate 映射类型. 基本数据类型无法表达null, 所以对于持久化类的OID 推荐使用包装类型。对于时间类型，java类中应使用Date，Hibernate内部实现了对于的映射时间类型。 property节点： name:指定该持久化类的属性的名字 column:指定与类的属性映射的表的字段名. 如果没有设置该属性, Hibernate 将直接使用类的属性名作为字段名. type:指定Hibernate 映射类型. Hibernate 映射类型是Java 类型与SQL 类型的桥梁. 如果没有为某个属性显式设定映射类型, Hibernate 会运用反射机制先识别出持久化类的特定属性的 Java 类型, 然后自动使用与之对应的默认的 Hibernate 映射类型. not-null:若该属性值为true, 表明不允许为null, 默认为false access:指定Hibernate 的默认的属性访问策略。默认值为property, 即使用getter, setter 方法来访问属性. 若指定field, 则Hibernate 会忽略getter/setter 方法, 而通过反射访问成员变量 unique: 设置是否为该属性所映射的数据列添加唯一约束. index: 指定一个字符串的索引名称. 当系统需要Hibernate 自动建表时, 用于为该属性所映射的数据列创建索引, 从而加快该数据列的查询. length: 指定该属性所映射数据列的字段的长度 scale: 指定该属性所映射数据列的小数位数, 对double, float, decimal 等类型的数据列有效. formula：设置一个SQL 表达式, Hibernate 将根据它来计算出派生属性的值. 派生属性: 并不是持久化类的所有属性都直接和表的字段匹配, 持久化类的有些属性的值必须在运行时通过计算才能得出来, formula=&quot;(SELECT concat(author, &#39;: &#39;, title) FROM NEWS n WHERE n.id = id)&quot;, 必须把sql放到括号内，其中id 是入参, 和当前持久化对象的id 属性对应的列的 id 值将作为参数传入. component子节点： 一个实体类是另外一个实体类组成的一部分 parent：指定组成关系 property节点：同class下的property。 CRUD利用主键获取一个对象 get方式，立即调用SQL获取对象全部属性，如果不存在则返回null。 load方式，延迟加载，当访问对象属性时，才执行SQL语句。如果对象不存在会抛出异常。 12Product p1 = s.get(Product.class, 80); // 查询Product p2 = s.load(Product.class, 81); // 查询 增加123p.setName("shuaiyy" + i);p.setPrice(200*i);s.save(p); // 增加 删除123Product p2 = s.load(Product.class, 81); // 查询s.delete(p2); // 删除s.getTransaction().commit(); // 提交事务 修改12345s.beginTransaction();Product p =(Product) s.get(Product.class, 6); //获取修改对象p.setName("new_name"); // 修改s.update(p); // 更新s.getTransaction().commit(); 查询查询策略： 减少内存浪费，关联对象如果没被访问，则不应提前载入内存 class的延迟加载。set的lazy和fetch属性 提高查询效率：较少的发送SQL语句 batch-size HQL方式 hibernate query language， 不需要select，from后是对象，而不是数据表。 创建一个Query对象，根据hql语法 设置参数，参数起始于0 调用list或者getSingleResult 获取查询结果 12345678910111213141516171819202122232425262728293031//1. 创建 Query 对象，基于位置的参数. String hql = "FROM Employee e WHERE e.salary &gt; ? AND e.email LIKE ? AND e.dept = ? " + "ORDER BY e.salary";Query query = session.createQuery(hql);//2. 绑定参数， Query 对象调用 setXxx 方法支持方法链的编程风格.Department dept = new Department();dept.setId(80); query.setFloat(0, 6000) .setString(1, "%A%") .setEntity(2, dept);//3. 执行查询List&lt;Employee&gt; emps = query.list();System.out.println(emps.size()); /**** 使用命名参数 :name ***///1。基于命名参数的query查询，传入的值可以是entity实体类对象。String hql = "FROM Employee e WHERE e.salary &gt; :sal AND e.email LIKE :email";Query query = session.createQuery(hql);//2. 绑定参数query.setFloat("sal", 7000) .setString("email", "%A%");//3. 执行查询List&lt;Employee&gt; emps = query.list();System.out.println(emps.size()); // 分页查询int pageNo = 22;int pageSize = 5;List&lt;Employee&gt; emps = query.setFirstResult((pageNo - 1) * pageSize) .setMaxResults(pageSize) .list(); QBC（Query by Criteria）方式 criteria： 准则；条件；规准。 新版本中不被推荐使用了。 123456Criteria query = s.createCriteria(Product.class);query.add(Restrictions.like("name", "%uai%"));List&lt;Product&gt; ps= query.list();for (Product p : ps) &#123; System.out.println(p.getName());&#125; ​ 标准SQL方式 123456789String sql = "select * from product_ p where p.name like '%ai%'";Query q= s.createSQLQuery(sql);List&lt;Object[]&gt; records= q.list();for (Object[] record : records) &#123; for (Object filed: record) &#123; System.out.print(filed+"\t"); &#125; System.out.println();&#125; ​ 对象关系 如果需要把持久化类的实例放到Set 中(如多对一映射),需要重写eqauls 和hashCode 方法。 持久化类需要一个标识属性(identifier property): 通常映射为数据库表的主键字段.否则一些功能将不起作用，如：Session.saveOrUpdate() 持久化类为非final类，因为Hibernate的代理机制。类字段要设置setter 、getter访问方法。 一对一 基于外键的方式，在存在外键的一端使用many-to-one，为其加上unique=”true”。另一端使用one-to-one，其property-ref属性的值为关联实体many-to-one属性的name。 基于主键的方式：一端的主键采用foreign生成器的方式关联，并在one-to-one属性上添加constrained=true 属性, 以使当前的主键上添加外键约束。 123456789101112131415161718192021222324252627&lt;class name="Department" table="DEPARTMENTS"&gt; &lt;id name="deptId" type="java.lang.Integer"&gt; &lt;column name="DEPT_ID" /&gt; &lt;!-- 使用外键的方式来生成当前的主键，即department的主键生成要根据mgr的主键来生成，不能自己独立创建 --&gt; &lt;generator class="foreign"&gt; &lt;!-- property 属性指定使用当前持久化类的哪一个属性的主键作为外键 --&gt; &lt;param name="property"&gt;mgr&lt;/param&gt; &lt;/generator&gt; &lt;/id&gt; &lt;!-- 采用 foreign 主键生成器策略的一端增加 one-to-one 元素映射关联属性, 其 one-to-one 节点还应增加 constrained=true 属性, 以使当前的主键上添加外键约束 --&gt; &lt;one-to-one name="mgr" class="Manager" constrained="true"&gt;&lt;/one-to-one&gt;&lt;/class&gt;&lt;class name="Manager" table="MANAGERS"&gt; &lt;id name="mgrId" type="java.lang.Integer"&gt; &lt;column name="MGR_ID" /&gt; &lt;generator class="native" /&gt; &lt;/id&gt; &lt;one-to-one name="dept" class="Department"&gt;&lt;/one-to-one&gt;&lt;/class&gt; ​ 多对一一个category下有多个product，通过product找到其对应的category。 product pojo中增加category属性，数据表中增加一列cid，对应category_表中的id 配置category和product的hibernate 映射配置文件。product中增加一个&lt;many-to-one&gt; 1234567891011&lt;hibernate-mapping package="cn.shuaiyy.pojo"&gt; &lt;class name="Product" table="product_"&gt; &lt;id name="id" column="id"&gt; &lt;generator class="native"&gt; &lt;/generator&gt; &lt;/id&gt; &lt;property name="name" /&gt; &lt;property name="price" /&gt; &lt;many-to-one name="category" class="Category" column="cid" /&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 查询和访问 12345678s.beginTransaction();Query query = s.createQuery("from Product p where p.category.id=?");query.setParameter(0, 2);List&lt;Product&gt; ps= query.list();for (Product p : ps) &#123; System.out.println(p.getName()); System.out.println(p.getCategory().getName());&#125; ​ 一对多 通过一个category查找其对应的多个product categeory pojo 中增加属性products，可以是list set map类型，必须是集合接口，可以赋初值为null。 配置一对多的集合映射 xml会检查子元素的顺序，key， list-index， one-to-many 设置inverse=&quot;true&quot;，即本端不维护关联关系，有多的那端维护。 order-by，SQL中的排序条件 12345678910111213141516171819202122&lt;hibernate-mapping package="cn.shuaiyy.pojo"&gt; &lt;class name="Category" table="category_"&gt; &lt;id name="id" column="id"&gt; &lt;generator class="native"&gt; &lt;/generator&gt; &lt;/id&gt; &lt;property name="name" /&gt; &lt;list name="products" table="product_" &gt; &lt;key column="cid" not-null="false" /&gt; &lt;list-index column="id"/&gt; &lt;one-to-many class="Product" /&gt; &lt;/list&gt; &lt;set name="productsSet" table="product_" inverse="true" order-by="ORDER_NAME DESC" lazy="true" batch-size="2" fetch="subselect"&gt; &lt;key column="cid" not-null="false" /&gt; &lt;one-to-many class="Product" /&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 访问 12345678Query query = s.createQuery("from Category c");List&lt;Category&gt; cs= query.list();System.out.println(cs);for (Category c : cs) &#123; System.out.println(c.getName()); System.out.println(c.getProducts()); System.out.println(c.getProductsSet());&#125; ​ 多对多 一个用户可以购买多个商品，而一个商品也可以被多个用户购买，因此需要额外的user_product对应关系表。 many-to-many两边都要指定column属性，且指向相同的表。必须其中一端放弃维护关系(inverse=”true”)，否则有可能造成主键冲突。 实体类都有集合属性。User pojo中增加products属性，type为set。Product pojo中增加users属性，type为 set。 配置对应的mapping 1234567891011121314151617181920212223&lt;hibernate-mapping package="cn.shuaiyy.pojo"&gt; &lt;class name="Product" table="product_"&gt; &lt;id name="id" column="id"&gt; &lt;generator class="native"&gt; &lt;/generator&gt; &lt;/id&gt; &lt;property name="name" /&gt; &lt;property name="price" /&gt; &lt;many-to-one name="category" class="Category" column="cid" /&gt; &lt;set name="users" table="user_product_"&gt; &lt;key column="pid" not-null="false"/&gt; &lt;many-to-many column="uid" class="User"/&gt; &lt;/set&gt; &lt;/class&gt; &lt;class name="User" table="user_" &gt; &lt;id name="id" column="user_id"/&gt; &lt;property name="name" column="user_name"/&gt; &lt;set name="products" table="user_product_"&gt; &lt;key column="uid" not-null="false"/&gt; &lt;many-to-many class="Product" column="pid"/&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt; 访问对象 12345678910111213Query query = s.createQuery("from User c");List&lt;User&gt; users= query.list();System.out.println(users);for (User user : users) &#123; System.out.println(user.getName()); Set&lt;Product&gt; ps = user.getProducts(); // 通过user访问其购买的product for (Product p : ps) &#123; System.out.println(p.getName()); Set&lt;User&gt; pUsers = p.getUsers(); // 通过product访问购买者user System.out.println("购买&#123; "+p.getName()+"&#125; 的人共有："+ pUsers.size()); for(User u : pUsers) System.out.println(u.getName() + " 购买了" + p.getName()); &#125; &#125; ​ 继承映射 实现多态查询，当查询父类对象时，也可以将其所有子类一起找到。 subclass: 使用一张表保存父类和子类，使用一个辨别类型type字段discriminator column，并给父类和子类设定type的取值discriminator-value。子类自有的字段，在父类记录中为null值。 缺点是有冗余字段，子类独有字段不能加非空约束。 1234567891011121314151617&lt;class name="Person" table="PERSONS" discriminator-value="PERSON"&gt; &lt;id name="id" type="java.lang.Integer"&gt; &lt;column name="ID" /&gt; &lt;generator class="native" /&gt; &lt;/id&gt; &lt;property name="name" type="java.lang.String"&gt; &lt;column name="NAME" /&gt; &lt;/property&gt; &lt;!-- 配置辨别者列 --&gt; &lt;discriminator column="TYPE" type="string"&gt;&lt;/discriminator&gt; &lt;!-- 映射子类 Student, 使用 subclass 进行映射 --&gt; &lt;subclass name="Student" discriminator-value="STUDENT"&gt; &lt;!--子类独有的属性 --&gt; &lt;property name="school" type="string" column="SCHOOL"&gt;&lt;/property&gt; &lt;/subclass&gt; &lt;/class&gt; joined-subclass: 父类实例保存在父类表中，子类实例由父类表和子类表共同存储。父类表保存共同的属性，每个子类使用单独的表保存独有字段。 插入子类时，要插入2张数据表。查询时也要做内连接查询。 优点：没有冗余字段，子类独有字段可以加非空约束。 123456789101112&lt;class name="Person" table="PERSONS"&gt; &lt;id name="id" type="java.lang.Integer"&gt; &lt;column name="ID" /&gt; &lt;generator class="native" /&gt; &lt;/id&gt; &lt;joined-subclass name="Student" table="STUDENTS"&gt; &lt;key column="STUDENT_id"&gt;&lt;/key&gt; &lt;!-- 关联父类的ID --&gt; &lt;property name="school" type="string" column="SCHOOL"&gt;&lt;/property&gt; &lt;/joined-subclass&gt; &lt;/class&gt; ​ union-subclass 父类表只包含父类的记录，子类表里只包含子类的记录，子类表包含父类的全部字段以及专有字段，因此父表主键的生成策略不能是identity(native) 的主键生成策略， native 会根据数据库优先使identity或sequence。 1234567891011&lt;class name="Person" table="PERSONS"&gt; &lt;id name="id" type="java.lang.Integer"&gt; &lt;column name="ID" /&gt; &lt;!-- 主键生成策略不能是native或identity --&gt; &lt;generator class="hilo" /&gt; &lt;/id&gt; &lt;union-subclass name="Student" table="STUDENTS"&gt; &lt;property name="school" column="SCHOOL" type="string"&gt;&lt;/property&gt; &lt;/union-subclass&gt; &lt;/class&gt; ​ 注解 包括类，属性，关系的注解，及其他的注解。 使用注解和使用xml配置的优缺点 小的项目，简单的配置使用注解，开发速度快。大的项目，维护复杂，多人协同，用配置文件。 配置文件： 容易编辑修改，配置集中，方便别人理解，重启生效，无需编译。缺点是繁琐、丑陋，配置过多时难以管理。 注解：简洁，开发时方便，和代码聚合度高。缺点也很明显，配置分散在各个类文件里，不易维护，修改后必须重新编译、打包、发布、上线启动应用。 类、属性、关系注解 修饰类 @Entity 表示这是一个实体类，用于映射表@Table(name = “product”) 表示这是一个类，映射到的表名:product 123456789101112131415161718@Entity@Table(name = "product_")public class Product &#123; int id; String name; float price; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = "id") public int getId() &#123; return id; &#125; @Column(name = "name") public String getName() &#123; return name; &#125;&#125; 属性注解 注意：属性的注解是配置在对应属性的getter方法上。 @Id 表示这是主键@GeneratedValue(strategy = GenerationType.IDENTITY) identity 表示自增长方式使用mysql自带的 sequence 底层数据库序列生成标识符，mysql不支持 hilo 由Hibernate负责生成，应用high/low算法 native：自行依次匹配上面3种 @Column(name = “id”) 表示映射到字段id 多对一注解 多个Product对应一个category， 12345678910111213141516171819@Entity@Table(name = "product_")public class Product &#123; private Category category; @ManyToOne(targetEntity = Category.class) @JoinColumn(name = "cid") //外键 public Category getCategory() &#123; return category; &#125; // 或者使用JoinTable @ManyToOne(cascade=&#123;CascadeType.PERSIST,CascadeType.MERGE&#125;) @JoinTable(name="关联表名"， joinColumns = @JoinColumn(name="主表外键"), inverseJoinColumns = @JoinColumns(name="从表外键") ) public Category getCategory() &#123; return category; &#125; ​ 一对多注解 1个category可以获取多个product 12345678910111213141516@Entity@Table(name = "category_")public class Category &#123; private Set&lt;Product&gt; productsSet; @OneToMany(fetch = FetchType.EAGER) @JoinColumn(name="cid") // 外键 public Set&lt;Product&gt; getProductsSet() &#123; return productsSet; &#125; //或者 mappedBy= “多” pojo类的关联属性 @OneToMany(fetch = FetchType.EAGER, mappedBy = "category") // Product的 category属性 public Set&lt;Product&gt; getProductsSet() &#123; return productsSet; &#125;&#125; ​ 多对多注解 多个用户可以拥有多个物品，需要单独一张表维护用户-物品关系 12345678910111213141516171819202122232425 @Entity@Table(name = "user_")public class User &#123; private Set&lt;Product&gt; products; // 通过用户获取其多个物品 @ManyToMany(targetEntity = Product.class) @JoinTable(name = "user_product_", joinColumns = @JoinColumn(name="uid"), // user与user_product join inverseJoinColumns = @JoinColumn(name="pid")) // product与user_product 连接 public Set&lt;Product&gt; getProducts() &#123; return products; &#125;&#125;@Entity@Table(name = "product_")public class Product &#123; private Set&lt;User&gt; users; //获取拥有该物品的全部用户 @ManyToMany(targetEntity = User.class) @JoinTable(name = "user_product_", joinColumns = @JoinColumn(name = "pid"), // product 与user_product的关联列是pid inverseJoinColumns = @JoinColumn(name = "uid")) // user与user_product的关联列是uid public Set&lt;User&gt; getUsers() &#123; return users; &#125; ​ 其他事务对数据的修改操作应在事务中进行，以保护数据的完整性。 hibernate.connection.isolation 属性设置事务的隔离级别。 存储过程通过JDBC的API来实现，具体的方式是实现Work接口的匿名类。 触发器数据库底层的触发器对Session是透明的，会导致缓存与数据库里的数据不一致。尤其是update()方法，无论游离对象的属性是否变化，都会执行update查询，激活相应的触发器。 解决方法1、执行数据操作后立即显示的调用flush和refresh方法。2、映射文件的class级别设置属性select-before-update，更新前先检查对象是否发生变化。 延迟加载 属性延迟加载 使用load获取对象时，只有第一次访问到了对象的属性，才去数据库里取该对象数据。 关系延迟加载 映射关系的lazy设置为true &lt;setname=“products” lazy=“true”&gt; 一旦session关闭，访问延时加载的属性就会抛出延时加载异常 级联级联一般用在one-many 或many-to-many的关系上，在删除，保存，更新时，同时修改其关联的数据对象。 比如删除一个分类吗，则该分类下的产品都删除。 1234 &lt;set name="products" cascade="delete" lazy="false"&gt; &lt;key column="cid" not-null="false" /&gt; &lt;one-to-many class="Product" /&gt;&lt;/set&gt; cascade取值常用的有4种： none，默认值，不级联 delete， 删除操作级联 删除分类时，会将对应cid的product都删除。不级联时，只把cid设置为null。 save-update，保存更新时级联 保存category时，会将其products属性里的product写入数据库 all，即删除，保存，更新时级联 delete-orphan： 删除所有和当前对象解除关联关系的对象。比如删除一个category，则该分类下的商品都是孤儿，会被删除。 缓存 一级缓存 同一session下的相同查询，只访问一次数据库。 flush() 将缓存中对象的变更同步到数据库，commit事务之后才会执行写数据库。调用commit或执行查询之前都会调用flush方法。但是如果调用save方法，且OID为native生成器生成时，会立即执行sql写入数据库。因为必须访问数据库才能确定OID，所以是直接插入。 refresh()： 从数据库中更新session缓存 clear() 清除session缓存 二级缓存 不同session的相同查询，只第一次去数据库取数据 hibernate本身未实现二级缓存功能，，需要第三方插件，这里使用EhCache 导入ehcache包，并增加二级缓存的配置 12345&lt;session-factory&gt; ... &lt;property name="hibernate.cache.use_second_level_cache"&gt;true&lt;/property&gt; &lt;property name="hibernate.cache.provider_class"&gt;org.hibernate.cache.EhCacheProvider&lt;/property&gt;&lt;/session-factory&gt; 创建一个ehcache.xml用于EHCache的缓存配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;ehcache&gt; &lt;!-- 指定一个目录：当 EHCache 把数据写到硬盘上时, 将把数据写到这个目录下. --&gt; &lt;diskStore path="d:\\tempDirectory"/&gt; &lt;!--Default Cache configuration. These will applied to caches programmatically created through the CacheManager. The following attributes are required for defaultCache: maxInMemory - Sets the maximum number of objects that will be created in memory eternal - Sets whether elements are eternal. If eternal, timeouts are ignored and the element is never expired. timeToIdleSeconds - Sets the time to idle for an element before it expires. Is only used if the element is not eternal. Idle time is now - last accessed time timeToLiveSeconds - Sets the time to live for an element before it expires. Is only used if the element is not eternal. TTL is now - creation time overflowToDisk - Sets whether elements can overflow to disk when the in-memory cache has reached the maxInMemory limit. --&gt; &lt;!-- 设置缓存的默认数据过期策略 --&gt; &lt;defaultCache maxElementsInMemory="10000" eternal="false" timeToIdleSeconds="120" timeToLiveSeconds="120" overflowToDisk="true" /&gt; &lt;!-- 设定具体的命名缓存的数据过期策略。每个命名缓存代表一个缓存区域 缓存区域(region)：一个具有名称的缓存块，可以给每一个缓存块设置不同的缓存策略。 如果没有设置任何的缓存区域，则所有被缓存的对象，都将使用默认的缓存策略。即：&lt;defaultCache.../&gt; Hibernate 在不同的缓存区域保存不同的类/集合。 对于类而言，区域的名称是类名。如:com.atguigu.domain.Customer 对于集合而言，区域的名称是类名加属性名。如com.atguigu.domain.Customer.orders --&gt; &lt;!-- name: 设置缓存的名字,它的取值为类的全限定名或类的集合的名字 maxElementsInMemory: 设置基于内存的缓存中可存放的对象最大数目 eternal: 设置对象是否为永久的, true表示永不过期, 此时将忽略timeToIdleSeconds 和 timeToLiveSeconds属性; 默认值是false timeToIdleSeconds:设置对象空闲最长时间,以秒为单位, 超过这个时间,对象过期。 当对象过期时,EHCache会把它从缓存中清除。如果此值为0,表示对象可以无限期地处于空闲状态。 timeToLiveSeconds:设置对象生存最长时间,超过这个时间,对象过期。 如果此值为0,表示对象可以无限期地存在于缓存中. 该属性值必须大于或等于 timeToIdleSeconds 属性值 overflowToDisk:设置基于内存的缓存中的对象数目达到上限后,是否把溢出的对象写到基于硬盘的缓存中 --&gt; &lt;cache name="com.hello.entities.Employee" maxElementsInMemory="1" eternal="false" timeToIdleSeconds="300" timeToLiveSeconds="600" overflowToDisk="true" /&gt; &lt;cache name="com.hello.Department.emps" maxElementsInMemory="1000" eternal="true" timeToIdleSeconds="0" timeToLiveSeconds="0" overflowToDisk="false" /&gt;&lt;/ehcache&gt; 在需要缓存的pojo对象的mapping配置里增加一行 &lt;cacheusage=“read-only”/&gt; 对象缓存机制 Hibernate的缓存机制，可以通过ID将查询到的对象保存在缓存中。 但是query.list()的查询结果都是取自数据库的，而不是从缓存中获取已有对象。 可以通过N+1的查询方式，利用缓存。即分2步查询： 第一步查询获得N条记录，但只取出其ID； 第二部：如果ID存在缓存中，则从缓存获取对象，否则访问数据库获取ID对应的数据记录。 具体代码也很简单，query的Iterator对象会先得到ID集合，然后调用next()方法获取对象即可，hibernate自动访问缓存对象。 1234567891011String name = "iphone"; Query q =s.createQuery("from Product p where p.name like ?");q.setString(0, "%"+name+"%");Iterator&lt;Product&gt; it= q.iterate();while(it.hasNext())&#123; Product p =it.next(); System.out.println(p.getName());&#125; ​ 分页使用Criteria进行分页查询 无论你使用的是Oracle,Mysql,NoSQL还是DB2，分页查询的代码写法都是一样的。 12345678910111213141516171819202122232425Session s = sf.openSession();s.beginTransaction();String name = "iphone";Criteria c= s.createCriteria(Product.class); //得到滚动结果集ScrollableResults scroll = c.scroll();//滚动到最后一行scroll.last();int total = scroll.getRowNumber() + 1; // 全部记录数c.add(Restrictions.like("name", "%"+name+"%"));//起始c.setFirstResult(2);//每页数量c.setMaxResults(5);// 拿到数据List&lt;Product&gt; ps = c.list();for (Product p : ps) &#123; System.out.println(p.getName());&#125; s.getTransaction().commit(); 获取总数的另一种方式： 1234Query q =s.createQuery("select count(*) from Product p where p.name like ?");q.setString(0, "%"+name+"%");long total= (Long) q.uniqueResult();System.out.println(total); OpenSession获取session有两种方式： openSession 和getCurrentSession openSession每次都会得到一个新的Session对象， 只有在增加，删除，修改的时候需要事务，查询时不需要的 。 getCurrentSession在同一个线程中，每次都是获取相同的Session对象，但是在不同的线程中获取的是不同的Session对象 。getCurrentSession是所有操作都必须放在事务中进行，并且提交事务后，session就自动关闭，不能够调用close方法。 乐观锁数据库锁机制是为了保护数据完整性，防止产生脏数据的。 以脏读数据为例： 123456789101112i = 0;session1&#123; get i; i++; // i=1&#125;session2&#123; get i; i++; // i=1&#125;session1.commit()session1.commit()// 两次相加后i仍是1，而不是2.因为session在未提交时，没写回最新数据，旧数据又被读出 实现乐观锁的核心，版本控制： 为product pojo 增加version属性。 在mapping配置中，增加version节点，version必须紧挨着id节点的下一个。 1234567&lt;class name="Product" table="product_"&gt; &lt;id name="id" column="id"/&gt; &lt;!--version元素必须紧挨着id后面 --&gt; &lt;version name="version" column="ver" type="int"&gt;&lt;/version&gt; &lt;property name="name" /&gt; &lt;property name="price" /&gt;&lt;/class&gt; ​ 连接池导入c3p0包hibernate-c3p0，使用c3p0连接池，在cfg配置文件的session-factory中添加如下配置： 123456789101112&lt;!--&lt;property name="hibernate.connection.provider_class"&gt;--&gt; &lt;!--org.hibernate.c3p0.internal.C3P0ConnectionProvider--&gt; &lt;!--&lt;/property&gt;--&gt;&lt;property name="hibernate.c3p0.max_size"&gt;20&lt;/property&gt;&lt;property name="hibernate.c3p0.min_size"&gt;5&lt;/property&gt;&lt;property name="hibernate.c3p0.timeout"&gt;50000&lt;/property&gt;&lt;property name="hibernate.c3p0.max_statements"&gt;100&lt;/property&gt;&lt;property name="hibernate.c3p0.idle_test_period"&gt;3000&lt;/property&gt;&lt;!-- 当连接池耗尽并接到获得连接的请求，则新增加连接的数量 --&gt;&lt;property name="hibernate.c3p0.acquire_increment"&gt;2&lt;/property&gt;&lt;!-- 是否验证，检查连接 --&gt;&lt;property name="hibernate.c3p0.validate"&gt;false&lt;/property&gt; Spring + Hibernate由spring管理bean对象 和SessionFactory对象 数据库连接池 Hibernate SessionFactory session bean hibernate3需要一个继承 HibernateTemplate的子类来接收SessionFactory的注入 hibernate4不在需要由spring提供HibernateTemplate类的支持，使用原生的hibernate API更好。 因此可以在dao中直接获取sessionFactory使用session创建query查询。 12345678910111213141516171819202122232425262728293031323334353637&lt;!-- 连接池 --&gt;&lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt; &lt;property name="driverClassName" value="com.mysql.jdbc.Driver"/&gt; &lt;property name="url" value="jdbc:mysql://localhost:3306/test?characterEncoding=UTF-8"/&gt; &lt;property name="username" value="root"/&gt; &lt;property name="password" value="123456"/&gt;&lt;/bean&gt; &lt;bean name="sessionFactory" class="org.springframework.orm.hibernate5.LocalSessionFactoryBean"&gt; &lt;!-- 指定Hibernate配置文件的路径， 或者使用 property name="hibernateProperties"--&gt; &lt;property name="configLocation" value="hibernate.cfg.xml"/&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!-- 指定映射文件的位置 --&gt; &lt;property name="mappingResources"&gt; &lt;list&gt; &lt;value&gt;cn/shuaiyy/pojo/Category.hbm.xml&lt;/value&gt; &lt;value&gt;cn/shuaiyy/pojo/Product.hbm.xml&lt;/value&gt; &lt;value&gt;cn/shuaiyy/pojo/User.hbm.xml&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name="hibernateProperties"&gt; &lt;value&gt; hibernate.dialect=org.hibernate.dialect.MySQLDialect hibernate.show_sql=true hbm2ddl.auto=update &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean name="dao" class="cn.shuaiyy.dao.DAO"&gt; &lt;!-- 为dao注入sessionFactory属性 --&gt; &lt;property name="sessionFactory" ref="sessionFactory"/&gt; &lt;/bean&gt; &lt;context:component-scan base-package="cn.shuaiyy.pojo"/&gt; &lt;context:annotation-config/&gt; 测试 123456789101112131415public static void testSpring()&#123; ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml"); DAO dao = (DAO) context.getBean("dao"); Product p = dao.get(Product.class, 1); SessionFactory sf = (SessionFactory) context.getBean("sessionFactory"); Session session = sf.openSession(); System.out.println(session.get(Product.class, 1).toString()); System.out.println(p.getName()); List&lt;Category&gt; cs = (List&lt;Category&gt;) session.createQuery("from Category c ").list(); for (Category c : cs) &#123; System.out.println(c.getName()); &#125; &#125; ​ Spring + SpringMVC + Hibernate]]></content>
      <categories>
        <category>技术</category>
        <category>Java</category>
        <category>Hibernate</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ORM</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA创建Java Web项目]]></title>
    <url>%2F2018%2F02%2F11%2F%E6%8A%80%E6%9C%AF%2FIDEA%E5%88%9B%E5%BB%BAWEB%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[IDEA创建WEB项目 new project &gt; web application 更改编译输出的目录，引入项目依赖的包 ctrl alt shift s 打开project structure： 配置Tomcat 和项目自动部署 edit configure，添加Tomcat服务器 在deployment选项卡下，添加Artifact 选中server选项卡，配置项目自动更新和部署 应用设置后，运行Tomcat 修改webapp的部署路径 修改Project Structure—&gt;Artifacts中的Output的目录，如改到tomat的webapps下。 Java普通项目转为 Web Application 新建一个java普通项目 从已有的web项目中，将webapp文件夹复制到普通java项目中 File-&gt;project structure-&gt;Facts，然后点击绿色的“+”号，点击web， 在右侧框中，上半部分的路径修改为web.xml的路径，下半部分的路径修改为webapp文件夹的路径 如果有黄色的！，则fix -&gt; created。创建的artifacts中Output路径定位到web一级。 edit configure，配置Tomcat服务器和Deployment设置。]]></content>
      <categories>
        <category>技术</category>
        <category>Java</category>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程高级编程]]></title>
    <url>%2F2018%2F02%2F10%2F%E6%8A%80%E6%9C%AF%2FJ2EE%2F</url>
    <content type="text"><![CDATA[Tomcat下载Tomcat进入官网http://tomcat.apache.org/，选择download，下载所需Tomcat版本。 我用的是Tomcat7，core x64 zip。不同版本的比较参考官网。 解压后，点击bin里的startup.bat运行，访问http://127.0.0.1:8080，可以看到欢迎界面，运行shutdown.bat关闭Tomcat。 配置环境变量 在系统变量里添加2个变量 CATALINA_BASE，CATALINA_HOME 变量名：CATALINA_BASE 变量值：C:\Program Files\Java\apache-tomcat-7.0.85 //Tomcat安装目录 变量名：CATALINA_HOME 变量值：C:\Program Files\Java\apache-tomcat-7.0.85 修改classpath和path 在ClassPath的变量值中加入：%CATALINA_HOME%\lib\servlet-api.jar;（注意加的时候在原变量值后加;） 在path中添加 %CATALINA_HOME%\bin;%CATALINA_HOME%\lib; 验证 新打开一个cmd，输入startup： 123456C:\Users\20189&gt;startupUsing CATALINA_BASE: "C:\Program Files\Java\apache-tomcat-7.0.85"Using CATALINA_HOME: "C:\Program Files\Java\apache-tomcat-7.0.85"Using CATALINA_TMPDIR: "C:\Program Files\Java\apache-tomcat-7.0.85\temp"Using JRE_HOME: "C:\Program Files\Java\jdk1.8.0_151"Using CLASSPATH: "C:\Program Files\Java\apache-tomcat-7.0.85\bin\bootstrap.jar;C:\Program Files\Java\apache-tomcat-7.0.85\bin\tomcat-juli.jar" Tomcat的配置文件在conf目录下，server.xml中修改端口号和webapps所在的目录 Host下增加&lt;Context path=&quot;/web&quot; reloadable=&quot;false&quot; docBase=&quot;D:\\j2ee\\web&quot; /&gt; 123456789101112131415161718192021222324&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt;&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Context path="/web" reloadable="false" docBase="D:\\j2ee\\web" /&gt; &lt;!-- SingleSignOn valve, share authentication between web applications Documentation at: /docs/config/valve.html --&gt; &lt;!-- &lt;Valve className="org.apache.catalina.authenticator.SingleSignOn" /&gt; --&gt; &lt;!-- Access log processes all example. Documentation at: /docs/config/valve.html Note: The pattern used is equivalent to using pattern="common" --&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log." suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; cmd查看端口占用并kill相关进程 查看端口占用进程的pid netstat -ano|findstr &quot;80&quot; 找到对应PID的进程详情tasklist|findstr &quot;1828&quot; 根据进程名kill进程 taskkill /f /t /im java.exe 在IDEA中配置Tomcat 点击Run-Edit Configurations… 点击左侧“+”，选择Tomcat Server–Local 在Tomcat Server -&gt; Unnamed -&gt; Server -&gt; Application server下，点击 Configuration ，找到本地 Tomcat 服务器所在目录，点击 OK按钮。还可以修改name，端口号等其他配置。 IDEA中部署webapp到TomcatServlet简单的Servlet项目结构： 创建目录web\WEB-INF\classes ，将Servlet类的编译文件输出到classes目录下。 IDEA修改项目编译输出的位置：“ ctrl alt shift s” 打开project structure，module -&gt; Paths 与classes同级的位置创建web.xml配置文件，配置Servlet类的URL映射。 HelloServlet.java 1234567891011121314151617import javax.servlet.http.HttpServletResponse;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServlet;import java.io.IOException;import java.util.Date;public class HelloServlet extends HttpServlet&#123; public void doGet(HttpServletRequest req, HttpServletResponse resp)&#123; try &#123; resp.getWriter().println("&lt;h1&gt;Hello World！&lt;/h1&gt; &lt;br&gt;"); resp.getWriter().println(new Date().toString()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; web/WEB-INF/web.xml 123456789101112&lt;?xml version="1.0" encoding="utf-8" ?&gt;&lt;web-app&gt; &lt;servlet&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;HelloServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt; &lt;!-- URL映射 --&gt; &lt;url-pattern&gt;/hello&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; Tomcat/conf/server.xml Tomcat的server.xml中配置网站的prefix URL和对应的web文件目录。 123&lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;!-- webapp的前缀URL和对应的webapp的位置 --&gt; &lt;Context path="/web" reloadable="false" docBase="C:\Users\20189\IdeaProjects\HelloWeb\web" /&gt; request和response对象 定义处理get 、post请求 重写HttpServlet的doGet、doPost方法,或者使用service方法，会自动判读get、post请求 1234public class HelloServlet extends HttpServlet&#123; public void doGet(HttpServletRequest req, HttpServletResponse resp)&#123;&#125; public void doPost(HttpServletRequest req, HttpServletResponse resp)&#123;&#125;&#125; ​ 获取参数和中文解析 123456request.setCharacterEncoding("utf-8"); // 最开始设置编码后，就不用对每个参数都中文解码了String username = request.getParameter("username"); // get ,post 获取参数方式一样 //中文参数解码// byte[] bytes= username.getBytes("ISO-8859-1");// username = new String(bytes,"UTF-8"); ​ 返回响应 html标签要齐全，必须在头文件中声明html格式内容，这样浏览器才能正常解析 12345// 返回的响应支持中文编码response.setContentType("text/html; charset=UTF-8"); // 设置内容格式和编码格式response.setCharacterEncoding("UTF-8"); //设置编码格式的PrintWriter pw = response.getWriter();pw.println(html); URL跳转 12345678// 让Servlet进行页面跳转, 浏览器的url改变 302临时跳转 response.sendRedirect("fail.html");// 301永久重定向, url跳转 response.setStatus(301); response.setHeader("Location", "404.html");//服务器页面跳转，浏览器地址中的地址不变 request.getRequestDispatcher("success.html").forward(request, response); 常用方法 12345678910111213141516171819202122232425262728293031323334// 获取ip 端口等，默认的端口80，取到的值为空 System.out.println("完整的URL请求（协议、主机名、端口）: " + request.getRequestURL()); System.out.println("请求的资源名部分，去掉了协议和主机名: " + request.getRequestURI()); System.out.println("请求行中的参数部分: " + request.getQueryString()); System.out.println("浏览器所处于的客户机的IP地址: " + request.getRemoteAddr()); System.out.println("浏览器所处于的客户机的主机名: " + request.getRemoteHost()); System.out.println("浏览器所处于的客户机使用的网络端口: " + request.getRemotePort()); System.out.println("服务器的IP地址: " + request.getLocalAddr()); System.out.println("服务器的主机名: " + request.getLocalName()); System.out.println("得到客户机请求方式: " + request.getMethod());// 获取浏览器头信息 Enumeration&lt;String&gt; headerNames= request.getHeaderNames(); while(headerNames.hasMoreElements())&#123; String header = headerNames.nextElement(); String value = request.getHeader(header); System.out.printf("%s\t%s%n",header,value); &#125;// 获取用户提交的参数 Map&lt;String, String[]&gt; parameters = request.getParameterMap(); Set&lt;String&gt; paramNames = parameters.keySet(); for (String param : paramNames) &#123; String[] value = parameters.get(param); System.out.println(param + ":" + Arrays.asList(value)); &#125;// 设置编码格式，第一种会要求浏览器也使用utf-8编码 response.setContentType("text/html; charset=UTF-8"); response.setCharacterEncoding("UTF-8");// 浏览器不缓存页面 response.setDateHeader("Expires",0 ); response.setHeader("Cache-Control","no-cache"); response.setHeader("pragma","no-cache"); Servlet实例化与生命周期一个Servlet的生命周期由 实例化，初始化，提供服务，销毁，被回收 几个步骤组成。 实例化 一个servlet在webapp启动后只会被实例化一次。 初始化 覆写HttpServlet的init方法，可以在servlet被实例化时执行初始化相关代码。 123public void init(ServletConfig config) &#123; System.out.println("init(ServletConfig)"); &#125; ​ 提供服务 通过service或者doPost doGet方法提供http服务 销毁和GC回收 web应用重启时 或Tomcat服务器关闭时，销毁。 在server.xml中配置改为reloadable=”true”，任何类发生更新，则web应用自动重启。 &lt;Context path=&quot;/&quot; docBase=&quot;e:\\web&quot; debug=&quot;0&quot; reloadable=&quot;true&quot; /&gt; 上传文件 Post表单上传文件，提交数据为二进制文件 12345&lt;form action="/upload" method="post" enctype="multipart/form-data"&gt; 英雄名称:&lt;input type="text" name="userName" /&gt; &lt;br&gt; 上传头像 : &lt;input type="file" name="filepath" /&gt; &lt;br&gt; &lt;input type="submit" value="上传"&gt;&lt;/form&gt; 导入依赖包 下载第三方的jar包，commons-io.jar和commons-fileupload.jar,放在WEB-INF/lib下.然后在项目中引入。 UploadServlet 获取文件流，定义文件名，获取相对路径和存储位置，保存文件 12345678910111213141516171819202122232425262728293031323334353637383940public class FileUploadServlet extends HttpServlet&#123; @Override protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; String filename = null; // 不能直接使用上传文件的文件名，以免重复 DiskFileItemFactory factory = new DiskFileItemFactory(); factory.setSizeThreshold(1024*1024*5); // 上传大小不超过5M ServletFileUpload upload = new ServletFileUpload(factory); List items = null; try &#123; items = upload.parseRequest(request); &#125; catch (FileUploadException e) &#123; e.printStackTrace(); &#125; Iterator iter = items.iterator(); while (iter.hasNext())&#123; FileItem item = (FileItem) iter.next(); if (!item.isFormField())&#123; // 不是表单域，即上传的文件 filename = System.currentTimeMillis() + ".jpg"; // 自定义存储文件名 //通过getRealPath获取上传文件夹，如果项目在./web,那么就会自动获取到 ./web/uploaded String photoFolder =request.getServletContext().getRealPath("uploaded"); System.out.println(photoFolder); File f = new File(photoFolder, filename); f.getParentFile().mkdirs(); InputStream is = item.getInputStream(); FileOutputStream fout = new FileOutputStream(f); byte b[] = new byte[1024*1024]; int length = 0; while ((length = is.read(b)) != -1)&#123; fout.write(b, 0, length); &#125; fout.close(); &#125; else&#123; // 处理表单域 System.out.println(item.getFieldName()); // 中文处理 String value = new String(item.getString().getBytes("iso-8859-1"), "utf-8"); System.out.println(value); &#125; &#125; ​ 处理不是File的字段 由于form提交的是二进制数据，因此无法使用request.getParameter(&quot;XXX&quot;), 使用item取出的值如果有中文，还需要进行编码处理。 在web.xml中配置servlet和URL路由。 使用JQuery和JSON提交数据 下载json-lib包，放入WEB-INF/lib目录，并在项目中导入json包 要使用json-lib，必须同时导入其依赖的另外5个包： commons -beanutils-1.8.3.jar commons -lang -2.5.jar commons -logging.jar commons-collections-3.1.jar ezmorph-1.0.6.jar 不然使用json-lib库会报错，java.lang.ClassNotFoundException maven项目可以设置自动导入相关依赖包。 html前端使用jQuery ajax异步post提交数据 导入JQuery包 form中使用button，不使用submit input。submit按钮点击后就会自动提交。 12345678910111213141516171819202122232425262728&lt;head&gt; &lt;script type="text/javascript" src="jquery.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;div&gt; &lt;form id="form-data"&gt; 用户名称： &lt;input type="text" name="username" placeholder="用户名"&gt;&lt;br&gt; 年龄： &lt;input type="text" name="year" &gt;&lt;br&gt; &lt;br&gt; &lt;input type="button" value="以json方式提交" id="json-post"&gt; &lt;/form&gt;&lt;/div&gt;&lt;script&gt; $("#json-post").click(function () &#123; var url = "json"; var username = $("#form-data input[name='username']").val(); var year = $("#form-data input[name='year']").val(); var data=&#123;"username":username,"year":year&#125;; console.log(username); console.log(year); $.post( url, &#123;"data": JSON.stringify(data)&#125;, function (res) &#123; alert("已经提交数据"); console.log(res); &#125;); &#125;);&lt;/script&gt; 编写servlet，配置路由 123456789101112131415import net.sf.json.JSONObject;public class JsonServlet extends HttpServlet &#123; @Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String data = req.getParameter("data"); JSONObject json = JSONObject.fromObject(data); System.out.println("data: "+ data); System.out.println("json: "+ json);// Hero hero = (Hero)JSONObject.toBean(json,Hero.class);// System.out.println("转换为Hero对象之后是："+hero); resp.getWriter().println("submit success!"); &#125;&#125; 使用json和JQuery获取对象 jquery代码 12345678910111213&lt;div id="data"&gt;&lt;/div&gt;&lt;input type="button" value="获取json对象"&gt;&lt;script&gt; $("input").click(function()&#123; var url = "getdata"; $.post( url, function(res)&#123; var man = JSON.parse(res); $("#data").html("名字：" + man.name + "&lt;br&gt;年龄:" + man.year); &#125;); &#125;);&lt;/script&gt; ​ servlet 创建一个Hero对象并将其转换为JSONObject对象，用个一个新的JSONObject对象存放Hero JSONObject，其key值为man。 1234567891011121314151617import net.sf.json.JSONObject; public class GetOneServlet extends HttpServlet &#123; protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; Hero hero = new Hero(); hero.setName("盖伦"); hero.setYear(353); JSONObject json= new JSONObject(); json.put("hero", JSONObject.fromObject(hero)); response.setContentType("text/html;charset=utf-8"); response.getWriter().print(json); &#125; &#125; 获取多个对象，JSON数组 jQuery代码, 通过$.parseJSON转换为json数组 12345678910111213$('#sender').click(function()&#123; var url="getdata"; $.post( url, function(data) &#123; var heros = $.parseJSON(data); for(i in heros)&#123; var oldHtml = $("#data").html(); var hero = heros[i]; $("#data").html(oldHtml + "&lt;br&gt;"+hero.name+" ----- "+hero.hp); &#125; &#125;); &#125;); servlet 将10个Hero对象的集合，通过JSONSerializer.toJSON(heros)转化为JSON字符串,然后返回给浏览器。 12345678910111213141516171819import net.sf.json.JSONSerializer; public class GetManyServlet extends HttpServlet &#123; protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; List&lt;Hero&gt; heros = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; Hero hero = new Hero(); hero.setName("name"+i); hero.setYear(500+i); heros.add(hero); &#125; String result =JSONSerializer.toJSON(heros).toString(); response.setContentType("text/html;charset=utf-8"); response.getWriter().print(result); &#125; &#125; ​ HTTP协议请求头Host: 主机名Use-Agent: 浏览器基本资料Accept: 浏览器能够识别的响应类型Accept-Language: 浏览器默认语言Accept-Encoding: 浏览器能够识别的压缩方式Referer: 来路页面， /addHero 这个路径是通过addHero.html这个页面跳转过来的。Connecton：是否保持连接 请求数据GET参数 Post的form表单数据 响应状态码200 ok 301 表示客户端跳转，永久性的跳转 302 客户端跳转，临时性的跳转 304 表示资源未被修改。 404 页面不存在 500 表示服务端的错误 响应头Content-Length: 表示长度Content-Type: 内容格式Date: 日期Server: 服务器类型 响应正文html、css、js、img等。 JSP 在Servlet中写html代码很麻烦，既不直观，也很难处理页面样式和数据之间的关系。 JSP可以实现在HTML文件中编写执行Java代码，在页面需要数据、逻辑控制的地方调用java代码实现。 hello jsp hello.jsp 12345&lt;%@page contentType="text/html; charset=UTF-8" pageEncoding="UTF-8" import="java.util.*"%&gt; 你好 JSP&lt;br&gt;&lt;%=new Date().toLocaleString()%&gt; &lt;%@page jsp指令，配置页面 &lt;%= 调用java代码执行输出 在访问hello.jsp页面时，实际上hello.jsp已经被转换为hello_jsp.java，然后编译成hellojsp.class，是一个servlet，位于tomcat的子目录`\work\Catalina\localhost\\org\apache\jsp` ,servlet将生产的html返回给浏览器。 hello_jsp.java继承了HttpJspBase类，HttpJspBase是HttpServlet的子类。 JSP指令 指令 描述 &lt;%@ page ... %&gt; 定义网页依赖属性，比如脚本语言、error页面、缓存需求等等 &lt;%@ include ... %&gt; 包含其他文件 &lt;%@ taglib ... %&gt; 引入标签库的定义 语法格式&lt;%@ page attribute=&quot;value&quot; %&gt; 等价于XML格式&lt;jsp:directive.page attribute=&quot;value&quot; /&gt;。 属性 描述 buffer 指定out对象使用缓冲区的大小 autoFlush 控制out对象的 缓存区 contentType 指定当前JSP页面的MIME类型和字符编码 errorPage 指定当JSP页面发生异常时需要转向的错误处理页面 isErrorPage 指定当前页面是否可以作为另一个JSP页面的错误处理页面 extends 指定servlet从哪一个类继承 import 导入要使用的Java类，逗号隔开 info 定义JSP页面的描述信息 isThreadSafe 指定对JSP页面的访问是否为线程安全 language 定义JSP页面所用的脚本语言，默认是Java session 指定JSP页面是否使用session isELIgnored 指定是否执行EL表达式 isScriptingEnabled 确定脚本元素能否被使用 include指令&lt;%@ include file=&quot;文件相对 url 地址&quot; %&gt;,等价于xml &lt;jsp:directive.include file=&quot;文件相对 url 地址&quot; /&gt;， 被包含的文件可以是JSP文件、HTML文件或文本文件。 taglib指令： &lt;%@ taglib uri=&quot;uri&quot; prefix=&quot;prefixOfTag&quot; %, 等价XML &lt;jsp:directive.taglib uri=&quot;uri&quot; prefix=&quot;prefixOfTag&quot; /&gt;. uri属性确定标签库的位置，prefix属性指定标签库的前缀。 JSP页面元素 静态内容 html js css等 指令 表达式&lt;%= %&gt; 用于输出一段html，&lt;% out.println(&quot;hello&quot;);%&gt;也可以实现相同功能。 动作 XML格式的,如&lt;jsp:include page=&quot;xxx.jsp&quot;&gt; Scriptlet &lt;% %&gt; 在&lt;% %&gt;之间可以写任意java代码 声明字段或方法 &lt;%! %&gt; 不建议使用 注释&lt;%-- --%&gt; 不同于HTML的注释，在浏览器看不到该注释，相当于在servlet中的注释。 JSP动作语法格式： &lt;jsp:action_name attribute=&quot;value&quot; /&gt; 语法 描述 jsp:include 在页面被请求的时候引入一个文件。 jsp:useBean 寻找或者实例化一个JavaBean。 jsp:setProperty 设置JavaBean的属性。 jsp:getProperty 输出某个JavaBean的属性。 jsp:forward 把请求转到一个新的页面。 jsp:plugin 根据浏览器类型为Java插件生成OBJECT或EMBED标记。 jsp:element 定义动态XML元素 jsp:attribute 设置动态定义的XML元素属性。 jsp:body 设置动态定义的XML元素内容。 jsp:text 在JSP页面和文档中使用写入文本的模板 jsp:include 使用jsp动作include文件时，被include的页面单独编译成servlet，请求页面时，服务端会访问该servlet。可以传递参数进去，在jsp文件中使用&lt;%=request.getParameter(“year”)%&gt;获取参数。 使用include指令时，直接将被include的文件插入，而不是单独编译，服务端只有一个servlet。 12345&lt;jsp:include page="footer.jsp"&gt; &lt;jsp:param name="year" value="2017" /&gt;&lt;/jsp:include&gt;&lt;%@include file="footer.jsp" %&gt; jsp:forward 12345678910&lt;!-- 客户端跳转 --&gt;&lt;%response.sendRedirect("hello.jsp"); %&gt;&lt;!-- 服务端跳转 --&gt;&lt;%request.getRequestDispatcher("hello.jsp").forward(request, response); %&gt;&lt;!-- 服务端跳转，jsp动作的代码更简洁 --&gt;&lt;jsp:forward page="hello.jsp"/&gt; ​ JSP隐式对象 对象 描述 request HttpServletRequest类的实例 response HttpServletResponse类的实例 out JspWriter类的实例，用于把结果输出至网页上 session HttpSession类的实例 application ServletContext类的实例，与应用上下文有关 config ServletConfig类的实例 pageContext PageContext类的实例，提供对JSP页面所有对象以及命名空间的访问 page 类似于Java类中的this关键字 Exception Exception类的对象，代表发生错误的JSP页面中对应的异常对象 request对象提供了一系列方法，可以获取HTTP头，cookies等等。 session对象跟踪服务器-客户端请求的对话。 pageContext对象 提供获取request、response、out、session、config等对象实例的方法。 可以修改、获取、移除作用域中的属性，pageContext.removeAttribute(&quot;attrName&quot;, pageContext.PAGE_SCOPE); 不提供作用域参数时，则移除4个作用域中的属性，PAGE_SCOPE，REQUEST_SCOPE，SESSION_SCOPE， APPLICATION_SCOPE。 JSP作用域 pageContext ：当前页面的作用域，也可以管理其他作用域的变量。 page相当于java中的this，servlet实例。 123&lt;!-- 设置的属性只能在当前页面访问 --&gt;&lt;% pageContext.setAttribute("name","gareen"); %&gt;&lt;%=pageContext.getAttribute("name")%&gt; request： 一次请求，服务端跳转仍是同一请求。 1234567&lt;% request.setAttribute("name","gareen"); %&gt; &lt;%=request.getAttribute("name")%&gt;&lt;!-- 使用pageContext --&gt;&lt;% pageContext.setAttribute("name","gareen",pageContext.REQUEST_SCOPE); %&gt;&lt;%= pageContext.getAttribute("name",pageContext.REQUEST_SCOPE) %&gt; session：当前会话 页面间参数传递可以使用session 1234567891011&lt;% session.setAttribute("name","gareen"); response.sendRedirect("getContext.jsp");%&gt;&lt;%=session.getAttribute("name")%&gt;&lt;!-- 使用pageContext --&gt;&lt;% pageContext.setAttribute("name","gareen",pageContext.SESSION_SCOPE);pageContext.getAttribute("name",pageContext.SESSION_SCOPE);%&gt; application：全局，所有用户共享 application对象是ServletContext接口的实例,也可以通过 request.getServletContext()来获取. 123456789101112&lt;% application.setAttribute("name","gareen"); System.out.println(application == request.getServletContext()); response.sendRedirect("getContext.jsp");%&gt;&lt;%=application.getAttribute("name")%&gt;&lt;!-- 使用pageContext --&gt;&lt;% pageContext.setAttribute("name","gareen",pageContext.APPLICATION_SCOPE);pageContext.getAttribute("name",pageContext.APPLICATION_SCOPE)%&gt; JSTL标准标签库需要先导入两个包 jstl.jar 和standard.jar。 在jsp中使用taglib指令导入需要的标签库模块，常用的有core、format和function 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!-- 变量访问，移除 --&gt;&lt;%@ taglib uri="http://java.sun.com/jsp/jstl/core" prefix="c"%&gt; 设置值：&lt;c:set var="name" value="$&#123;'gareen'&#125;" scope="request" /&gt; 通过标签获取name: &lt;c:out value="$&#123;name&#125;" /&gt; &lt;br&gt; 移除变量：&lt;c:remove var="name" scope="request" /&gt; &lt;br&gt; &lt;!-- 实现if-else逻辑，JSTL没有else语法，可以用if非或choose实现 --&gt;&lt;c:set var="hp" value="$&#123;10&#125;" scope="request" /&gt;&lt;c:if test="$&#123;hp&lt;5&#125;"&gt; &lt;p&gt;这个英雄要挂了&lt;/p&gt;&lt;/c:if&gt;&lt;c:if test="$&#123;!(hp&lt;5)&#125;"&gt; &lt;p&gt;这个英雄觉得自己还可以再抢救抢救&lt;/p&gt;&lt;/c:if&gt;&lt;c:if test="$&#123;empty weapon&#125;"&gt; &lt;p&gt;没有装备武器&lt;/p&gt;&lt;/c:if&gt;&lt;c:choose&gt; &lt;c:when test="$&#123;hp&lt;5&#125;"&gt; &lt;p&gt;这个英雄要挂了&lt;/p&gt; &lt;/c:when&gt; &lt;c:otherwise&gt; &lt;p&gt;这个英雄觉得自己还可以再抢救抢救&lt;/p&gt; &lt;/c:otherwise&gt;&lt;/c:choose&gt;&lt;!-- for循环 --&gt;&lt;c:forEach items="$&#123;heros&#125;" var="hero" varStatus="st" &gt; &lt;!-- varStatus表示当前遍历的状态 --&gt; &lt;tr&gt; &lt;td&gt;&lt;c:out value="$&#123;st.count&#125;" /&gt;&lt;/td&gt; &lt;td&gt;&lt;c:out value="$&#123;hero&#125;" /&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/c:forEach&gt;&lt;!-- forTokes字符串拆分 --&gt;&lt;c:set var="strs" value="塔姆,艾克;巴德|雷克赛!卡莉丝塔" /&gt; &lt;c:forTokens items="$&#123;strs&#125;" delims=":;|!" var="sub_str"&gt; &lt;c:out value="$&#123;sub_str&#125;" /&gt; &lt;br /&gt;&lt;/c:forTokens&gt; format格式化数字和时间 yyyy 表示年份，MM 表示月份，dd 表示日期，E 表示星期几，a 表示是上午还是下午 HH 表示小时，mm 表示分钟，ss 表示秒，S 表示毫秒，z 表示时区 1234567891011121314&lt;%@ taglib uri="http://java.sun.com/jsp/jstl/fmt" prefix='fmt' %&gt;&lt;core:set var="money" value="39.45896"/&gt;&lt;!-- 最少2位，最多6位小数 --&gt;&lt;fmt:formatNumber type="number" value="$&#123;money&#125;" minFractionDigits="2" maxFractionDigits="6" /&gt; &lt;!-- 格式化date --&gt;&lt;% Date now = new Date(); pageContext.setAttribute("now",now);%&gt; 完整日期: &lt;fmt:formatDate value="$&#123;now&#125;" pattern="G yyyy年MM月dd日 E"/&gt;&lt;br&gt;完整时间: &lt;fmt:formatDate value="$&#123;now&#125;" pattern="a HH:mm:ss.S z"/&gt;&lt;br&gt;常见格式: &lt;fmt:formatDate value="$&#123;now&#125;" pattern="yyyy-MM-dd HH:mm:ss"/&gt; ​ function函数库 &lt;%@ taglib prefix=&quot;fn&quot; uri=&quot;http://java.sun.com/jsp/jstl/functions&quot; %&gt; 提供了很多实用的函数 | 函数 | 描述 || —————————————- | —————————————- || fn:contains(string, substring) | 如果参数string中包含参数substring，返回true || fn:containsIgnoreCase(string, substring) | 如果参数string中包含参数substring（忽略大小写），返回true || fn:endsWith(string, suffix) | 如果参数 string 以参数suffix结尾，返回true || fn:escapeXml(string) | 将有特殊意义的XML (和HTML)转换为对应的XML character entity code，并返回 || fn:indexOf(string, substring) | 返回参数substring在参数string中第一次出现的位置 || fn:join(array, separator) | 将一个给定的数组array用给定的间隔符separator串在一起，组成一个新的字符串并返回。 || fn:length(item) | 返回参数item中包含元素的数量。参数Item类型是数组、collection或者String。如果是String类型,返回值是String中的字符数。 || fn:replace(string, before, after) | 返回一个String对象。用参数after字符串替换参数string中所有出现参数before字符串的地方，并返回替换后的结果 || fn:split(string, separator) | 返回一个数组，以参数separator 为分割符分割参数string，分割后的每一部分就是数组的一个元素 || fn:startsWith(string, prefix) | 如果参数string以参数prefix开头，返回true || fn:substring(string, begin, end) | 返回参数string部分字符串, 从参数begin开始到参数end位置，包括end位置的字符 || fn:substringAfter(string, substring) | 返回参数substring在参数string中后面的那一部分字符串 || fn:substringBefore(string, substring) | 返回参数substring在参数string中前面的那一部分字符串 || fn:toLowerCase(string) | 将参数string所有的字符变为小写，并将其返回 || fn:toUpperCase(string) | 将参数string所有的字符变为大写，并将其返回 || fn:trim(string) | 去除参数string 首尾的空格，并将其返回 | EL表达式语言使用page指令开始EL表达式支持 &lt;%@ page isELIgnored =&quot;true|false&quot; %&gt; 语法： ${expression表达式} ${JavaBeanObjeact.attr} 取变量值： ${killNumber};取请求参数 ${param.name},用到了隐式对象 .获取JavaBean的属性 JavaBean是特殊的Java类，使用J ava语言书写，并且遵守JavaBean API规范。 提供一个默认的无参构造 可以被序列化，实现序列化接口Serializable接口 可读写的属性以setter、getter方法提供访问 Boolean属性提供isXXX方法。 1234567891011&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8"%&gt;&lt;!-- jsp创建JavaBean对象，设置和获取属性 --&gt;&lt;jsp:useBean id="students" class="com.runoob.StudentsBean"&gt; &lt;jsp:setProperty name="students" property="firstName" value="小强"/&gt; &lt;jsp:setProperty name="students" property="lastName" value="王"/&gt; &lt;jsp:setProperty name="students" property="age" value="10"/&gt;&lt;/jsp:useBean&gt;&lt;p&gt;学生名字: &lt;jsp:getProperty name="students" property="firstName"/&gt;&lt;/p&gt;&lt;p&gt;学生姓氏: &lt;jsp:getProperty name="students" property="lastName"/&gt; &lt;/p&gt;&lt;p&gt;学生年龄: &lt;jsp:getProperty name="students" property="age"/&gt;&lt;/p&gt; ​ 支持三元运算，可以替代if-else ${killNumber ge 10? &quot;超神&quot;:&quot;还没超神&quot; } 基础操作符： | 操作符 | 描述 || ———- | —————— || . | 访问一个Bean属性或者一个映射条目 || [] | 访问一个数组或者链表的元素 || ( ) | 组织一个子表达式以改变优先级 || + | 加 || - | 减或负 || * | 乘 || / or div | 除 || % or mod | 取模 || == or eq | 测试是否相等 || != or ne | 测试是否不等 || &lt; or lt | 测试是否小于 || &gt; or gt | 测试是否大于 || &lt;= or le | 测试是否小于等于 || &gt;= or ge | 测试是否大于等于 || &amp;&amp; or and | 测试逻辑与 || || or or | 测试逻辑或 || ! or not | 测试取反 || empty | 测试是否空值 | EL隐含对象 | 隐含对象 | 描述 || —————- | —————— || pageScope | page 作用域 || requestScope | request 作用域 || sessionScope | session 作用域 || applicationScope | application 作用域 || param | Request 对象的参数，字符串 || paramValues | Request对象的参数，字符串集合 || header | HTTP 信息头，字符串 || headerValues | HTTP 信息头，字符串集合 || initParam | 上下文初始化参数 || cookie | Cookie值 || pageContext | 当前页面的pageContext | 1234$&#123;pageContext.request.queryString&#125;$&#123;param["username"]&#125;$&#123;param.username&#125;$&#123;header["user-agent"]&#125; ​ MVCFilter 在请求访问服务器资源之前，拦截请求并处理； 在服务器返回响应之前，拦截响应并处理 Filter对象及方法过滤器是一个实现了 javax.servlet.Filter 接口的 Java 类。javax.servlet.Filter 接口定义了三个方法： 序号 方法 &amp; 描述 1 public void doFilter (ServletRequest, ServletResponse, FilterChain)该方法完成实际的过滤操作，当客户端请求方法与过滤器设置匹配的URL时，Servlet容器将先调用过滤器的doFilter方法。FilterChain用户访问后续过滤器。 2 public void init(FilterConfig filterConfig)web 应用程序启动时，web 服务器将创建Filter 的实例对象，并调用其init方法，读取web.xml配置，完成对象的初始化功能，从而为后续的用户请求作好拦截的准备工作（filter对象只会创建一次，init方法也只会执行一次）。开发人员通过init方法的参数，可获得代表当前filter配置信息的FilterConfig对象。 3 public void destroy()Servlet容器在销毁过滤器实例前调用该方法，在该方法中释放Servlet过滤器占用的资源。 init 方法中提供了一个 FilterConfig 对象,可以用于获取filter在web.xml下的配置。 filterConfig.getInitParameter(&quot;Site&quot;); 123456789101112&lt;filter&gt; &lt;filter-name&gt;LogFilter&lt;/filter-name&gt; &lt;filter-class&gt;LogFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;Site&lt;/param-name&gt; &lt;param-value&gt;测试&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;LogFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 一个处理中文编码的过滤器 12345678public class Utf8Filter implements Filter&#123; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; request.setCharacterEncoding("utf-8"); filterChain.doFilter(request, servletResponse); &#125;&#125; 应用过滤器的顺序多个过滤器应用的顺序依据web.xml中filter-mapping定义的顺序。 规范建议的过滤器 身份验证过滤器（Authentication Filters）。 指定页面不使用过滤器，在filter的init参数里定义不过滤的url，然后在Filter里先获取初始参数，然后过滤方法里判断是否需要过滤。 12345678&lt;filter&gt; &lt;filter-name&gt;LoginFilter&lt;/filter-name&gt; &lt;filter-class&gt;filter.LoginFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;excludedPages&lt;/param-name&gt; &lt;param-value&gt;/index.jsp,/register.html,/login.html,/login,/jquery.min.js,&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class LoginFilter implements Filter&#123; private String excludeParam; private String[] excludePages; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; excludeParam = filterConfig.getInitParameter("excludedPages"); if(excludeParam!=null &amp;&amp; excludeParam.length()&gt;0)&#123; excludePages = excludeParam.split(","); &#125; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; String username = (String) request.getSession().getAttribute("username"); boolean notFilter = false; // 判断是否过滤页面 for(String excludeUrl: excludePages)&#123;// System.out.println(excludeUrl);// System.out.println(request.getRequestURI()); String uri = request.getRequestURI(); if(excludeUrl.trim().equals(uri))&#123; notFilter = true; &#125; if(uri.endsWith(".css")||uri.endsWith(".js"))&#123; notFilter = true; &#125;// System.out.println(request.getServletPath());// if(excludeUrl.trim().equals(request.getRequestURI()))&#123;// NotFilter = true;// &#125; &#125; if (notFilter)&#123; filterChain.doFilter(request, response); &#125; else&#123; if (username!=null &amp;&amp; username.length()&gt;0)&#123; System.out.println(username); filterChain.doFilter(request, servletResponse); &#125;else&#123; response.sendRedirect("login.html");// request.getRequestDispatcher("login.html").forward(request, response); &#125; &#125; &#125;&#125; ​ 数据压缩过滤器（Data compression Filters）。 加密过滤器（Encryption Filters）。 触发资源访问事件过滤器。 图像转换过滤器（Image Conversion Filters）。 日志记录和审核过滤器（Logging and Auditing Filters）。 1234567891011121314151617public class LogFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; String ip = request.getRemoteAddr(); String url = request.getRequestURL().toString(); System.out.println(ip +"在"+ new Date().toString() + "访问了网址："+ url); // 允许过滤器链的后续过滤 filterChain.doFilter(servletRequest, servletResponse); &#125; @Override public void destroy() &#123;&#125;&#125; ​ MIME-TYPE 链过滤器（MIME-TYPE Chain Filters）。 标记化过滤器（Tokenizing Filters）。 XSL/T 过滤器（XSL/T Filters），转换 XML 内容。 Listener 监听 web应用的创建和销毁，以及其attribute发生的变化。 web应用即ServletContext对象(jsp的隐式对象application) 监听session和request的生命周期，以及其attribute发生的变化。 监听Context web.xml 123&lt;listener&gt; &lt;listener-class&gt;listener.ContextListener&lt;/listener-class&gt;&lt;/listener&gt; ​ Listener,实现两个接口方法 1234567891011121314151617181920212223242526272829public class ContextListener implements ServletContextListener, ServletContextAttributeListener &#123; @Override public void contextInitialized(ServletContextEvent servletContextEvent) &#123; System.out.println("web应用初始化"); &#125; @Override public void contextDestroyed(ServletContextEvent servletContextEvent) &#123; System.out.println("web 应用销毁"); &#125; @Override public void attributeAdded(ServletContextAttributeEvent servletContextAttributeEvent) &#123; ServletContextAttributeEvent e = servletContextAttributeEvent; System.out.println(String.format("添加了属性：%s ---- %s", e.getName(), e.getValue())); &#125; @Override public void attributeRemoved(ServletContextAttributeEvent servletContextAttributeEvent) &#123; ServletContextAttributeEvent e = servletContextAttributeEvent; System.out.println(String.format("移除了属性：%s ---- %s", e.getName(), e.getValue())); &#125; @Override public void attributeReplaced(ServletContextAttributeEvent servletContextAttributeEvent) &#123; ServletContextAttributeEvent e = servletContextAttributeEvent; System.out.println(String.format("替换了属性：%s ---- %s", e.getName(), e.getValue())); &#125;&#125; ​ 监听Session 实现HttpSessionListener HttpSessionAttributeListener 接口 12345678910111213141516171819202122232425262728public class SessionListener implements HttpSessionListener, HttpSessionAttributeListener&#123; @Override public void sessionCreated(HttpSessionEvent httpSessionEvent) &#123; System.out.println("session创建，session_id" + httpSessionEvent.getSession().getId()); &#125; @Override public void sessionDestroyed(HttpSessionEvent httpSessionEvent) &#123; System.out.println("session销毁，session_id" + httpSessionEvent.getSession().getId()); &#125; @Override public void attributeAdded(HttpSessionBindingEvent httpSessionBindingEvent) &#123; HttpSessionBindingEvent e = httpSessionBindingEvent; System.out.println(String.format("session属性添加：%s --- %s", e.getName(), e.getValue())); &#125; @Override public void attributeRemoved(HttpSessionBindingEvent httpSessionBindingEvent) &#123; HttpSessionBindingEvent e = httpSessionBindingEvent; System.out.println(String.format("session属性移除：%s --- %s", e.getName(), e.getValue()));&#125; @Override public void attributeReplaced(HttpSessionBindingEvent httpSessionBindingEvent) &#123; HttpSessionBindingEvent e = httpSessionBindingEvent; System.out.println(String.format("session属性替换：%s --- %s", e.getName(), e.getValue())); &#125;&#125; 监听Request 实现接口ServletRequestListener ,ServletRequestAttributeListener 1234567891011121314151617181920212223242526272829303132public class RequestListener implements ServletRequestListener,ServletRequestAttributeListener&#123; @Override public void requestDestroyed(ServletRequestEvent servletRequestEvent) &#123; ServletRequestEvent e = servletRequestEvent; System.out.println("request被销毁！"); &#125; @Override public void requestInitialized(ServletRequestEvent servletRequestEvent) &#123; ServletRequestEvent e = servletRequestEvent; System.out.println("request创建！"); &#125; @Override public void attributeAdded(ServletRequestAttributeEvent servletRequestAttributeEvent) &#123; ServletRequestAttributeEvent e = servletRequestAttributeEvent; System.out.println(String.format("request添加属性：%s --- %s", e.getName(), e.getValue())); &#125; @Override public void attributeRemoved(ServletRequestAttributeEvent servletRequestAttributeEvent) &#123; ServletRequestAttributeEvent e = servletRequestAttributeEvent; System.out.println(String.format("request移除了属性：%s --- %s", e.getName(), e.getValue())); &#125; @Override public void attributeReplaced(ServletRequestAttributeEvent servletRequestAttributeEvent) &#123; ServletRequestAttributeEvent e = servletRequestAttributeEvent; System.out.println(String.format("request替换属性：%s --- %s", e.getName(), e.getValue())); &#125;&#125; web在线人数统计监听session的创建和销毁，一个session对应一个在线用户，设置一个application全局变量userNum保存在线用户数。创建session时userNum 加1，销毁时-1，如果不存在，则初始化值为0。 OnlineUserListener 12345678910111213141516171819202122232425262728public class OnlineUserListener implements HttpSessionListener &#123; @Override public void sessionCreated(HttpSessionEvent httpSessionEvent) &#123; HttpSessionEvent e = httpSessionEvent; ServletContext application = e.getSession().getServletContext(); Integer userNum = (Integer) application.getAttribute("userNum"); if (userNum == null)&#123; application.setAttribute("userNum", 0); &#125; userNum++; application.setAttribute("userNum", userNum); &#125; @Override public void sessionDestroyed(HttpSessionEvent httpSessionEvent) &#123; HttpSessionEvent e = httpSessionEvent; ServletContext application = e.getSession().getServletContext(); Integer userNum = (Integer) application.getAttribute("userNum"); if (userNum == null || userNum &lt; 1)&#123; application.setAttribute("userNum", 0); &#125; else&#123; userNum--; application.setAttribute("userNum", userNum); &#125; &#125;&#125; ​]]></content>
      <categories>
        <category>技术</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript实现的部分功能]]></title>
    <url>%2F2018%2F02%2F05%2F%E6%8A%80%E6%9C%AF%2FJavaScript%E5%89%8D%E7%AB%AF%E9%83%A8%E5%88%86%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[JavaScript判断表单内容，不满足条件则不提交 &lt;form method=&quot;post&quot; action=&quot;/study/register.jsp&quot; onsubmit=&quot;return register()&quot;&gt;长度判断整数判断正则判断 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;body&gt;&lt;form method="post" action="/study/register.jsp" onsubmit="return register()"&gt;账号：&lt;input id="name" type="text" name="name"&gt; &lt;br&gt;&lt;br&gt;年龄：&lt;input id="age" type="text" name="age"&gt; &lt;br&gt;&lt;br&gt; EMail：&lt;input id="email" type="text" name="email"&gt; &lt;br&gt;&lt;br&gt; &lt;input type="submit" value="注册"&gt;&lt;br&gt;&lt;/form&gt; &lt;script&gt; function register()&#123; var name = document.getElementById("name"); if(name.value.length&lt;3)&#123; alert("用户名至少需要3位长度"); return false; &#125; var age = document.getElementById("age"); if(isNaN(age.value))&#123; alert("年龄必须是数字"); return false; &#125; var email = document.getElementById("email"); if(0==email.value.length)&#123; alert("email不能为空"); return false; &#125; var Regex = /^(?:\w+\.?)*\w+@(?:\w+\.)*\w+$/; if (!Regex.test(email.value))&#123; alert("email格式不正确"); return false; &#125; return true; &#125;&lt;/script&gt;&lt;/body&gt; javascript 显示或隐藏元素 12345678910function hide()&#123; var d = document.getElementById("d"); d.style.display="none";&#125;function show()&#123; var d = document.getElementById("d"); d.style.display="block";&#125; javascript 删除内容前提示 window.confirmparentNoderemoveChilddeleteRow(rowIndex) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;body&gt;&lt;script&gt;function deleteRow(link)&#123; var b = confirm("确定删除？") if(!b) return;var table = document.getElementById("heroTable");var td = link.parentNode;var tr = td.parentNode;var index=tr.rowIndex;table.deleteRow(index);&#125;&lt;/script&gt;&lt;table width="100%" border="1" cellspacing="0" id="heroTable"&gt;&lt;tbody&gt;&lt;tr&gt; &lt;td width="50%"&gt;英雄名称&lt;/td&gt; &lt;td&gt; 操作 &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;盖伦&lt;/td&gt; &lt;td&gt; &lt;a href="#" onclick="deleteRow(this)"&gt;删除&lt;/a&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;提莫&lt;/td&gt; &lt;td&gt; &lt;a href="#" onclick="deleteRow(this)"&gt;删除&lt;/a&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;祈求者&lt;/td&gt; &lt;td&gt; &lt;a href="#" onclick="deleteRow(this)"&gt;删除&lt;/a&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/body&gt; javascript 实现表格排序 使用col记录上次点击的列，reverse记录升序还是降序；如果再次点击该列，则排序方式取逆。table append节点时，由于插入的是原有的元素节点，因而tr的内容和总行数不会发生变化，只有顺序改变。比较器自定义，使用String.localeCompare比较字符串。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;body&gt;&lt;style&gt;table&#123;border-collapse:collapse;width:90%;&#125;tr&#123;border-bottom-style: solid;border-bottom-width: 1px;border-bottom-color: lightgray;height:35px;&#125; td&#123;width:25%;text-align:center;&#125; a&#123; text-decoration: none; color:skyblue;&#125; &lt;/style&gt;&lt;script&gt;var col = 0;var reverse = false;function sort(column)&#123; if(column == col) reverse = !reverse; col = column; var tbody = document.getElementById("tbody"); //通过getElementsByTagName取出来是一个Collection var trsCollection = document.getElementsByTagName("tr"); //因为Collection没有自带的排序函数，所以需要转换为数组，利用数组自带的排序 var trs =new Array(); for (var i=1; i &lt;trsCollection.length; i++) &#123; trs.push(trsCollection[i]); &#125; trs.sort(comparator); for (var i=0; i &lt;trs.length; i++) &#123; tbody.appendChild(trs[i]); &#125;&#125;function comparator(tr1,tr2)&#123; var td1 = tr1.children[col].innerHTML; //取某一行的第col列中的内容 var td2 = tr2.children[col].innerHTML; if(reverse) return td1.localeCompare(td2); else return td2.localeCompare(td1);&#125;&lt;/script&gt;&lt;table&gt; &lt;tbody id="tbody"&gt; &lt;tr&gt; &lt;td&gt;&lt;a href="javascript:void(0)" onclick="sort(0)"&gt;id&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href="javascript:void(0)" onclick="sort(1)"&gt;名称&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href="javascript:void(0)" onclick="sort(2)"&gt;血量&lt;/a&gt;&lt;/td&gt; &lt;td&gt;&lt;a href="javascript:void(0)" onclick="sort(3)"&gt;伤害&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;annie&lt;/td&gt; &lt;td&gt;380&lt;/td&gt; &lt;td&gt;38&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;gareen&lt;/td&gt; &lt;td&gt;340&lt;/td&gt; &lt;td&gt;58&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;teemo&lt;/td&gt; &lt;td&gt;320&lt;/td&gt; &lt;td&gt;76&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;deadbrother&lt;/td&gt; &lt;td&gt;400&lt;/td&gt; &lt;td&gt;90&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/body&gt; JavaScript中的json对象 定义和使用json对象和数组字符串转json对象，通过字符串拼接得到一个JSON结构的字符串，并不是一个JSON对象。 需要通过eval转换得到转换的时候注意,eval 函数的字符串参数以(开头 )结尾。或者使用JQuery的$.parseJSON转换函数 1234567891011121314151617181920&lt;script&gt;var gareen = &#123;&quot;name&quot;:&quot;盖伦&quot;,&quot;hp&quot;:616&#125;;alert(&quot;这是一个JSON对象: &quot;+gareen);alert(&quot;英雄名称: &quot; + gareen.name + &quot;&lt;br&gt;&quot;);alert(&quot;英雄血量: &quot; + gareen.hp + &quot;&lt;br&gt;&quot;);var heros=[ &#123;&quot;name&quot;:&quot;盖伦&quot;,&quot;hp&quot;:616&#125;, &#123;&quot;name&quot;:&quot;提莫&quot;,&quot;hp&quot;:313&#125;, &#123;&quot;name&quot;:&quot;死哥&quot;,&quot;hp&quot;:432&#125;, &#123;&quot;name&quot;:&quot;火女&quot;,&quot;hp&quot;:389&#125;]alert( &quot;第4个英雄是:&quot; + heros[3].name);var s1 = &quot;&#123;\&quot;name\&quot;:\&quot;盖伦\&quot;&quot;;var s2 = &quot;,\&quot;hp\&quot;:616&#125;&quot;;var s3 = s1+s2;var gareen = eval(&quot;(&quot;+s3+&quot;)&quot;);&lt;/script&gt; AJAX实现登录前表单验证 AJAX: Asynchronous JAvaScript and XML判断账户是否存在1、定义一个XMLHttpRequest对象，即XHR对象2、设置响应函数 xmlhttp.onreadystatechange=checkResult; //响应函数3、设置访问URL和参数4、执行请求 1234567891011121314151617181920212223&lt;span&gt;输入账号 :&lt;/span&gt;&lt;input id="name" name="name" onkeyup="check()" type="text"&gt; &lt;span id="checkResult"&gt;&lt;/span&gt; &lt;script&gt;var xmlhttp;function check()&#123; var name = document.getElementById("name").value; var url = "http://how2j.cn/study/checkName.jsp?name="+name; xmlhttp =new XMLHttpRequest(); xmlhttp.onreadystatechange=checkResult; //响应函数 xmlhttp.open("GET",url,true); //设置访问的页面 xmlhttp.send(null); //执行访问&#125; function checkResult()&#123; if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) document.getElementById('checkResult').innerHTML=xmlhttp.responseText; &#125; &lt;/script&gt; jquery 使用前先引入jQuery库 $(function(){...}); 表示在HTML文档加载完成后在执行()里的内容 function，防止jQuery代码被提前执行；$(&quot;css selector&quot;) 用于选中元素对象jQuery可以方便的在元素对象上监听事件$(&quot;css selector&quot;).click(function(){}) 1234567891011121314151617181920212223242526&lt;script src="http://how2j.cn/study/jquery.min.js"&gt;&lt;/script&gt; &lt;script&gt;$(function()&#123; $("#b1").click(function()&#123; $("#d").hide(); &#125;); $("#b2").click(function()&#123; $("#d").show(); &#125;);&#125;); &lt;/script&gt; &lt;button id="b1"&gt;隐藏div&lt;/button&gt; &lt;button id="b2"&gt;显示div&lt;/button&gt; &lt;br&gt;&lt;br&gt; &lt;div id="d"&gt; 这是一个div &lt;/div&gt; JQuery元素提取内容取值使用 $(&quot;css selector&quot;).val(); 相当于 document.getElementById(&quot;input1&quot;).value;获取元素使用 $(&quot;css selector&quot;).html();不包含标签的元素 $(&quot;css selector&quot;).text(); 操作css增加、移除class，切换class状态，以及css函数的使用 12345678910111213141516$(function()&#123; $("#b1").click(function()&#123; $("#d").addClass("pink"); //增加class pink，要有.pink的class定义，样式才会生效 $("#d").removeClass("pink");// 移除class $("#d").toggleClass("pink"); //切换class，如果存在pink则移除，不存在则添加 $("#d2").css(&#123;"background-color":"pink","color":"green"&#125;); // 使用css函数，修改style里的属性键值。 $("#d1").css("background-color","pink"); &#125;); &#125;);&lt;style&gt;.pink&#123; background-color:pink;&#125;&lt;/style&gt; jQuery选择器准确的将应该是css选择器，利用标签、样式、属性选择元素。 $(this) 表示当前元素 $(&quot;tagName&quot;) $(&quot;#id&quot;) $(&quot;.className&quot;) $(&quot;tagName&quot;) $(&quot;div#id1 span.red a&quot;) 有条件的选中元素 123456$("div:first").addClass("pink"); // 选中第一个元素$("div:last").addClass("pink"); // 选中最后一个元素$("div:odd").toggleClass("pink"); // 选中偶数元素$("div:even").toggleClass("pink"); // 选中奇数元素$("selector:hidden") // 满足选择器条件的不可见的元素$("selector:visible") // 满足选择器条件的可见的元素 根据属性选择元素，属性值的比较 123456$("selector[attribute]") // 满足选择器条件的有某属性的元素$("selector[attribute=value]") // 满足选择器条件的属性等于value的元素$("selector[attribute!=value]") // 满足选择器条件的属性不等于value的元素$("selector[attribute^=value]") // 满足选择器条件的属性以value开头的元素$("selector[attribute$=value]") // 满足选择器条件的属性以value结尾的元素$("selector[attribute*=value]") // 满足选择器条件的属性包含value的元素 表单对象和表单对象属性 123456789101112131415$("selector:input") // 会选择所有的输入元素，不仅仅是input标签开始的那些，还包括textarea,select和button$("selector:button") // 会选择type=button的input元素和button元素$("selector:radio") // 会选择单选框$("selector:checkbox") // 会选择复选框$("selector:text") // 会选择文本框，但是不会选择文本域$("selector:submit") // 会选择提交按钮$("selector:image") // 会选择图片型提交按钮$("selector:reset") // 会选择重置按钮//表单对象属性$("selector:enabled") // 会选择可用的输入元素 注：输入元素的默认状态都是可用 $("selector:disabled") // 会选择不可用的输入元素 $("selector:checked") // 会选择被选中的单选框和复选框 注： checked在部分浏览器上(火狐,chrome)也可以选中selected的option $("selector:select") // 会选择被选中的option元素 jQuery筛选器在选择器后可以使用的筛选函数 12345678$("div").first().toggleClass("pink"); // 选中第一个元素$("div").last().toggleClass("pink"); // 选中最后一个元素$("div").eq(4).toggleClass("pink"); // 选中第n个元素，n起始为0$("#currentDiv").parent().toggleClass("b"); // 选中父元素$("#currentDiv").parents().toggleClass("b"); // 选中祖先元素$("#currentDiv").children().toggleClass("b"); // 选中直接子元素$("#currentDiv").siblings().toggleClass("b"); // 选中同级元素$("#currentDiv").find("div").toggleClass("b"); // 在当前元素下继续使用selector查找 jQuery操作元素属性attr 和 prop 获取、修改、删除 12345678910$("#h").attr("align") // 获取align属性$("#h").attr("align","right") ; // 修改align属性$("#h").removeAttr("align"); // 删除属性// prop无法获取用户自定义的属性$("#c").prop("game");// 对于选中属性，如checked，attr获取的是初始值即checked, prop获取的是当前状态，返回的是true or false$("#c").attr("checked"); // 结果是不变的初始值$("#c").prop("checked"); // 结果为当前状态 jQuery动画效果效果函数允许传入一个延时参数和动画完成后的回调函数 显示 隐藏 切换显示 隐藏 切换 分别通过show(), hide(),toggle()实现；也可以加上毫秒数，表示延时操作,比如show(2000) 滑动向上滑动 向下滑动 滑动切换 分别通过slideUp(), slideDown(),slideToggle()实现也可以加上毫秒数，表示延时操作，比如slideUp(2000) 淡入 淡出淡入 淡出 淡入淡出切换 指定淡入程度 分别通过fadeIn(), fadeOut(),fadeToggle() fadeTo()实现也可以加上毫秒数，表示延时操作，比如fadeIn(2000)fadeTo跟的参数是0-1之间的小数。 0表示不淡入，1表示全部淡入 自定义动画效果通过animate 可以实现更为丰富的动画效果animate()第一个参数为css样式animate()第二个参数为延时毫秒注： 默认情况下，html中的元素都是固定，并且无法改变的位置的。 为了使用animate()自定义动画效果，需要通过css把元素的position设置为relative、absolute或者fixed。 回调函数效果一般需要一定的时间，并且这个时间可长可短，所以就无法精确的确定该效果合适结束。好在，效果方法都提供对回调函数callback()的支持。只需要在调用效果方法的最后一个参数传入一个function，当效果结束的时候，就会自动调用该function了。 1234567891011121314151617181920212223242526272829var div = $("#d");div.hide(); // 隐藏元素divdiv.show(); // 显示元素divdiv.toggle(); // 切换状态，显示或隐藏元素div// 延时1000毫秒div.hide(1000);div.show(1000);div.toggle(1000);div.slideUp(); // 向上滑动div.slideDown(1000); // 向下滑动div.slideToggle(); // 滑动切换div.fadeIn(2000); // 延时2000毫秒淡入div.fadeOut(2000); // 延时2000毫秒淡出div.fadeToggle(2000); // 淡入淡出切换// 指定淡入程度，0完全淡出元素不可见，1完全显示$("#d1").fadeTo("slow",0.2);$("#d2").fadeTo("slow",0.5);$("#d3").fadeTo("slow",0.8);// 自定义动画效果div.animate(&#123;left:'100px'&#125;,2000); // 移动到距离左侧100px的位置div.animate(&#123;left:'0px',top:'50px',height:'50px'&#125;,2000); // 移动到距左侧0px，距离顶部50px的位置，同时改变高度为50px；// 动画结束后调用回调函数div.animate(&#123;left:'0px',top:'50px',height:'50px'&#125;,2000,function()&#123; alert("动画演示结束"); &#125;); jQuery事件加载 ：$(document).ready() $()图片加载： load()鼠标事件：click() dblclick() mousedown() mouseup() mousemove() mouseenter() mouseleave() mouseover() mouseout() mousedown 表示鼠标按下mouseup表示鼠标弹起 mousemove表示鼠标进入mouseenter表示鼠标进入mouseover表示鼠标进入 mouseleave表示鼠标离开mouseout表示鼠标离开 进入事件有3个 mousemove mouseenter mouseovermousemove ：当鼠标进入元素，每移动一下都会被调用mouseenter ：当鼠标进入元素，调用一下，在其中移动，不调用mouseover：当鼠标进入元素，调用一下，在其中移动，不调用 mouseenter 和 mouseover的区别mouseenter: 当鼠标经过其子元素不会被调用mouseover：当鼠标经过其子元素会被调用 mouseleave 和 mouseout的区别mouseleave: 当鼠标经过其子元素不会被调用mouseout：当鼠标经过其子元素会被调用 键盘事件 keydown() keypress() keyup 先后顺序： 按照 keydown keypress keyup 顺序发生 键盘按钮值： 通过event对象的which属性获取键盘的值 keydown和keyup 能获取所有按键，不能识别大小写 keypress 不能获取功能键，如F1 SHIFT等，能够识别大小写 文本取值： keydown和keypress：不能获取最后一个字符 keyup： 获取所有字符 焦点： focus() blur()内容改变： change() 注： 对于文本框，只有当该文本失去焦点的时候，才会触发change事件。提交： submit()绑定事件：on()触发事件： trigger() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152 // 页面加载 $(function()&#123; $("#message1").html("页面加载成功"); &#125;); $(document).ready(function()&#123; // 不常用 $("#message1").html("页面加载成功"); &#125;); // 图片加载 $(function()&#123; $("#img").load(function()&#123; $("#message2").html("图片加载成功"); &#125;); &#125;); /* click() 表示单击 dblclick() 表示双击; 注: 空白键和回车键也可以触发click事件，但是只有双击鼠标才能造成dblclick事件 */ $("#b").click(function()&#123; $("#message").html("单击按钮"); &#125;); $("#b").dblclick(function()&#123; $("#message").html("双击按钮"); &#125;); // 键盘事件 $("#i").keydown(function(e)&#123; alert(e.which) &#125;); // 焦点 $("input").focus(function()&#123; $(this).val("获取了焦点"); &#125;); $("input").blur(function()&#123; $(this).val("失去了焦点"); &#125;); // 内容改变： $(function()&#123; $("#input1").change(function()&#123; var text = $(this).val(); $("#message").html("input1的内容变为了"+text); &#125;); &#125;); // 以上操作都可以用$(element).on(event,function)形式实现 $("#b").on("click",function()&#123; $("#message").html("单击按钮"); &#125;); // 事件也可以主动触发 $("#b").trigger("dblclick"); // 触发双击事件 JQuery实现AJAX $.ajax()默认type参数为GET请求方式重要的参数有url，data，type，回调函数success、error、complete，dataType包括”xml html script json jsonp text”, 不指定则由JQuery自行判断。 123456789101112$("#name").keyup(function()&#123; var page = "/study/checkName.jsp"; var value = $(this).val(); $.ajax(&#123; url: page, // 提交的页面 data:&#123;"name":value&#125;, // 提交的数据 success: function(result)&#123; // 成功后处理返回结果 $("#checkResult").html(result); &#125; &#125;); &#125;);&#125;); $.get() 和 s.post() 使用3个参数 访问的页面,提交的数据,回调函数 123456789101112131415$.get( page, &#123;"name":value&#125;, function(result)&#123; $("#checkResult").html(result); &#125; ); $.post( page, &#123;"name":value&#125;, function(result)&#123; $("#checkResult").html(result); &#125; ); $(&quot;div&quot;).load(pageUrl, data) 在指定的div里显示请求pageUrl获取到的数据 var data = $(&quot;#form&quot;).serialize(); 将表单输入值格式化字符串 JQuery操作数组、字符串、json $.each(array, function(index, data){}) 接收一个数组和一个回调函数，回调函数的参数为下标和数组元素值 $.unique(array) 数组去重，去重前需要先排序 $.inArray(data,array) 判断data是否在数组中 $.trim(&quot; Hello JQuery &quot;) 去掉字符串首尾的空格 $.parseJSON(&quot;{\&quot;name\&quot;: \&quot;Teemo\&quot;}&quot;) 将json字符串解析成json对象 JQuery对象和JavaScript DOM对象切换12345678// jQuery转DOMvar div= $("#d"); // jQuery对象var d = div[0]; // DOM对象var d = div.get(0); // DOM对象// DOM转jQueryvar div= document.getElementById("d"); //DOM对象var d = $(div); // jQuery对象]]></content>
      <categories>
        <category>技术</category>
        <category>Web</category>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zeal自制docset]]></title>
    <url>%2F2018%2F01%2F15%2F%E6%8A%80%E6%9C%AF%2FZeal%E8%87%AA%E5%88%B6docset%2F</url>
    <content type="text"><![CDATA[Zeal自制docsetZeal使用 Zeal是一款离线文档浏览器（类似于MAC下的dash），可以配合各种编辑器，IDE使用。官方提供的数百个不同应用的离线文档(docset格式)，当某个文档官方没有提供时，我们可以自己制作一个。本文以Scrapy 1.5的文档为例。 在IDEA、Pycharm中使用，安装Dash插件，选中要查找的字符串，ctrl shift b在Zeal中查看API。 docset文档源 任意的HTML文档 AppleDoc Python, Sphinx or PyDoctor javadoc Rdoc Scaladoc goDoc JSDoc Doxygen 基本上所有的文档都可以转换为docset。 生成Docset官方指南-生成docset 本例使用的是python doc生成docset，使用的工具为doc2dash, scrapy文档源可以下载官方源码，解压源码中的doc文件夹。 1234# 在Python的虚拟环境里安装pip install Sphinx&gt;=1.3pip install sphinx_rtd_themepip install doc2dash 下载doc源文档在github上下载scrapy的源码，其中包含doc文档的源码 编译doc文档使用sphinx编译doc文档源码。sphinx是Python下广泛使用的文档编写工具，可以将srt格式的文档编译成HTMl，大多数python第三方库使用的都是该工具，并且发布在免费的文档托管网站，read the doc。 编译sphinx-build -b html docs docs_dir , 如果想要自己创建、编写文档，可以参考sphix的用法 生成docset将编译好的html转换成docset，doc2dash用法 doc2dash -u https://doc.scrapy.org/en/1.5/ -n scrapy_1.5 docs_dir 将得到的 scrapy_1.5.docset 文件夹拷贝到Zeal的文档文件下。 添加图标和meta信息在docset文件夹里添加文件icon.png和meta.json 12345678# meta.json&#123; "name": "Scrapy", "revision": "0", "title": "Scrapy", "version": "1.5.0"&#125; 打开Zeal查看效果： 发布docset参考 可以将其贡献给Dash，方便其他的dash用户下载使用。 制作feed分享 12345# scrapy.xml&lt;entry&gt; &lt;version&gt;1.5.0&lt;/version&gt; &lt;url&gt;https://github.com/shuaiyy/Scrapy_1.5.docset/files/1658982/Scrapy_1.5.docset.tar.gz&lt;/url&gt;&lt;/entry&gt; feed 的url https://raw.githubusercontent.com/shuaiyy/Scrapy_1.5.docset/master/scrapy.xml]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Zeal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python logging 模块编码错误]]></title>
    <url>%2F2018%2F01%2F08%2F%E6%8A%80%E6%9C%AF%2FLogging%20unicode%20decode%20error%2F</url>
    <content type="text"><![CDATA[python logging UnicodeDecodeError解决方法一般是python2.7写入中文时编码错误在logging中加上 123import sys reload(sys) sys.setdefaultencoding("utf-8") 如果是 stream.write(fs % msg.encode(&quot;UTF-8&quot;)) 这行代码异常， 123456try: stream.write(fs % msg.encode("UTF-8")) except UnicodeError: stream.write(fs % msg.decode("gbk").encode("UTF-8"))except Exception as e: print e.msg]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java编程高级编程]]></title>
    <url>%2F2018%2F01%2F07%2F%E6%8A%80%E6%9C%AF%2FJava%E9%AB%98%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[Java编程高级多线程JVM至少启动2个线程，main和gc 三种实现方式 继承Thread类 必须覆写Thread类中的run方法，是线程运行的主体。 start方法启动线程，运行的是run内的代码 实现Runnable接口 解决单继承的限制 覆写run方法 Runnable对象没有start方法，Thread类可以接收Runnable接口对象，构造Thread实例，然后并调用start启动。 Callable接口Runnable接口的run方法不能返回操作接口，java.util.concurrent.Callable提供。 Callable由FutureTask对象接收。FutureTask对象可以取得返回结果，由Thread类启动FutureTask。 实现区别 接口可以解决单继承问题 Thread内部实现了Runnable接口，是其子类 Thread实现系统资源分配和执行目标功能，Runnable负责执行目标功能。 Thread很像代理设计模式，但是start方法不是接口提供的。 Runnable能更好的描述线程间的数据共享 线程对象命名与获取 Thread对象构造时传入 使用setName,getName方法 取得当前线程对象 Thread.currentThread() 休眠、优先级 sleep() 单位是毫秒，中断sleep会抛出中断异常。 setPriority getPriority 同步和死锁多个线程访问同一数据时，需要同步。 多个线程互相等待，陷入死锁。 同步代码块 使用同步关键字 synchronizied定义同步代码块，锁定一个对象。 同步方法 生产者消费者实现等待和唤醒机制，Object类提供了实现方法notify, wait。 product设置一个flag标志，如果生产者可以生产则生产一个，并唤醒消费者线程来消费。如果不能生产，则需等待，当满足条件时会被唤醒生产。 消费者如果可以消费，则消费一个并唤醒生产者生产，否则等待生产者来唤醒消费。 sleep和wait的区别sleep是Thread实现的方法，线程睡眠到时自动唤醒。 wait是Object类实现的，必须由notify实现。 StringBuffer对象 StringBuffer可以修改内容，不能直接赋值实例化，可以使用append拼接字符串。 StringBuffer(String obj) StringBuffer().append(String obj) StringBuffer(&quot;hello world&quot;).toString() String(StringBuffer obj) String与StringBuffer的内容比较 contentEquals String与StringBuffer都是CharSequence接口的子类。 reverse sbf字符串反转，常规实现入栈出栈。 insert 指定位置插入字符串 delete(start, end) 删除指定位置的字符串 StringBuilder定义和方法与StringBuffer很相似，在是否同步上有区别。 StringBuffer类的方法都是同步方法，属于线程安全的操作 StringBuilder的方法是异步方法 Runtime类每个JVM进程都有唯一一个Runtime对象，其构造方法被私有化，属于单例设计，有一个static方法可以取得实例对象。 totalMemory 返回全部内存大小 maxMemory 最大可用内存空间 freeMemory 空余可用空间 gc 释放垃圾空间 exec 创建Process进程对象 Process p = runtime.exec(&#39;cmd.exe&#39;); p.destory() System类 System.out.println() System.arraycopy() System.currentTimeMillis() 获取当前时间毫秒 gc() 等价于调用runtime对象的GC 覆写Object对象的finalize方法，对象回收前被调用。 对象克隆Object对象提供Clone方法 protected Object clone() throws CloneNotSupportedException 可克隆对象必须实现Cloneable接口，Cloneable是标识接口，没有抽象方法。覆写Object类的Clone方法，实现clone操作。 @override clone(){return super().clone();} 数学操作类Math类math提供的一切方法都是static方法。 Math.E Math.PI round() 四舍五入取整， 注意该方法的负数-15.5不产生进位。 Random类产生随机数 12Random rand = new Random()rand.nextInt(100) // 产生100以内随机整数 BigInteger和BigDecimal大整数，超过double范围的值为Infinity，可以用String保存，使用时按位取出计算真实值。 大浮点数，可以保存小数。 BigInteger(String num) BigDecimal 可以利用其divide方法实现准确小数位的四舍五入。 ​ Datejava.util.Date new Date() 当前日期信息 new Date(long 时间戳) date.getTime() 获取Date对象的时间戳 日期格式化java.text.SimpleDateFormat 构造方法传入string 日期转换格式 格式转换：“yyyy年-MM月–dd日-ss秒-SSS毫秒” format(Date date) parse(String date) Calendar类java.util.Calendar 比较器Arrays类与数组有关的操作 java.util.Arrays.sort() 可以实现对象数组排序，对象必须实现Comparable接口 binarySearch() 二分查找 equals() 两个数组元素顺序，数值一样 fill() 填充数组 toString() 将数组以字符串的形式输出 Comparable接口定义对象的比较规则，String也是Comparable的子类。 Arrays.sort()会调用compareTo方法。 二叉树Comparator接口挽救的接口 开发完成的对象，在初期没有实现Comparable接口，后期需要比较，在不修改原对象的前提下，使用java.util.Comparator 接口。实现一个用于排序的工具类，排序时传入数组和排序工具类 Arrays.sort(books, new BookComparator()) 正则表达式java.util.regex compile(‘regex str’) 返回Pattern对象 Matcher类 \\ 转义字符 [^abc]不是abc里的任何一个 数量表达 String的正则支持 matches(regex str) 判断是否满足某种格式 repalceAll 替换全部 replaceFirst 替换匹配的第一个 split 拆分 split(str regex, int limit) 有个数限制的拆分 反射机制先有类才能产生对象。类实例化对象的方式，new， clone，反射 反是指通过对象找到其类。getClass方法 java.util.Class是所有反射操作开始的源头 obj.getClass() cls.class 类的class属性，没有实例化对象就拿到了类 Class.forName(‘java.lang.String’) 可以不用显式的import，而是通过类名获得类 利用反射实例化对象工厂设计模式，解耦合，可扩展性强。 利用反射调用构造java.lang.reflect.Constructor Class.getConstructor()获取类的构造方法 调用普通方法java.lang.reflect.Method Class.getMethod() 调用成员属性java.lang.reflect.Field 反射可以实现取消封装，访问私有field field.get(‘fieldName’) field.set(‘fieldName’) field.setAccessible(true) 取消封装，设置可以访问 国际化支持java.text.MessageFormat 将语言支持放入资源文件里，key=value，占位符，字符串里的可变内容。 info = 欢迎{0}来到{1} 如果是中文，则必须是Unicode编码 读取信息 获取国家的区域和语言编码，默认调用全局资源文件。 zh_CN Message_zh_CN.properties 访问时不加语言和文件类型后缀 en_US Locale类 Local(‘语言’, ‘国家’) getDefault() 获取当前语言环境 Properties类是Hashtable的子类，利用key-value保存String信息。 setProperty(k, v) getProperty(k, default v) store(输出流，注释说明) load(输入流) 从读中取属性内容 也可以用ResourceBundle类读取。 IO操作 File类java.io.File 定义File对象，传入文件路径 创建新文件createNewFile() 删除文件 delete() 判断是否存在 exists() isDirectory() isFile() lastModified() 最近修改日期 File.separator 属性值，文件系统的分隔符 取得文件大小 length() 目录操作 getParent() 返回字符串，父路径 getParentFile() 取得父路径作为File类型，可以调用exists方法 mkdir() 创建一级目录 mkdirs() 创建多级目录 list 获取路径下的全部文件和文件夹的名字 listFiles() 返回的是File对象数组。 递归遍历或删除 ​ 字节流InputStream OutputStream 定义File对象 实例化字节流或字符流对象 数据读写 关闭数据流 OutputStream抽象类实现了2个接口Closeable、Flushable。write方法输出。 FileOutputStream 接收一个File对象，可以覆盖内容或追加内容。 InputStream 的方法，skip跳过，read读取内容。使用FileInputStream读取文件。 使用while循环读取文件内容： 字符流输出流Writer 对象，在Appendable接口里提供了append追加操作， write方法输出对象是字符数组char []，也可以是Str类型。 输入流Reader read(char [] cbuf)，输入流不能是Str接收。 FileWrite FileReader 字节流与字符流的区别 字节流可以与终端直接数据交互，字符流需要经过缓冲区处理后才能输出。 flush()操作可以清空缓冲区 字符流利于避免中文乱码问题，字符输出流可以直接输出Str对象 转换流 InputStreamReader OutputStreamWriter 将字节流转换成字符流。 实现文件copy 字符编码java内部使用的是Unicode，常见的是英文ASCII码。 程序编码使用UTF-8 强制编码 &quot;hello&quot;.getBytes(&quot;GBK&quot;) 获取JVM默认编码 乱码解决 内存流 字节内存流 ByteArrayOutputStream ByteArrayInputStream 字符内存流 output.toByteArray() 打印流PrintStream PrintWriter 装饰设计类 : 对功能不足的OutputStream进行功能扩充。 System.out.printf(String format, args) %d, %m.nf , %s String.format(String fmt, args) System类的IO支持 缓冲流 BufferedReader BufferedWriter BufferedInputStream BufferedOutputStream BufferedReader的String readLine()读取一行数据，返回String对象。 键盘输入处理: 超级麻烦 将System.in 转换成Reader对象 利用BufferedReader的readLine方法进行数据读取 缓冲区读取文本文件 Scannerjava.util.Scanner BufferedReader有两个不足，只能返回字符串，分隔符固定为回车。 Scanner(InputStream source) 构造 hasNext() next() hasNextDouble() 判断输入的是否是小数 NextDouble() 取得输入的小数，不用类型转换。 标准输入数据键盘： 处理文本文件： scan.useDelimiter(“\n”) 设置使用回车作为分隔符， 默认的以回车、空格。 总结 对象序列化序列化支持将内存中数据对象转换为二进制数据流，用于传输。 对象必须实现java.io.Serializable接口才能被序列化。 Serializable和Cloneable都是标识接口，没有内部方法。 序列化java.io.ObjectOutputStream 反序列化java.io.ObjectInputStream transient关键字声明不能被序列化的属性 类集实现了很多数据结构 Collection接口两个子接口，List Set add 向集合里添加数据 addAll 追加一个集合 clear contains isEmpty remove 需要对象的equals方法支持 size toArray 将集合元素转换为对象数组 iterator() 获取iterator的实例 List接口 list.get(int index) list.set(int index, value) list.listIterator() ArrayList List接口的子类，元素按插入顺序保存，允许重复对象。 Set接口Set接口下的两个子类： HashSet和TreeSet。 HashSet 元素无序无重复 TreeSet 元素自动排序。 依靠Comparable接口的compareTo方法实现排序。 重复元素的判断依靠的是Object的hashCode()和equals()方法。 集合的输出方式 Iterator 迭代输出 ListIterator 让List支持双向输出，可以从后向前输出。但是必须先进行一次由前向后，才能进行由后向前输出。 hasPrevious() previous() foreach输出 Enumeration 枚举 只能依靠Vector子类，不能是List和Set Map接口key-value，可以作为key的自定义对象必须实现hashCode和equals方法。 一般使用String作为key。 put(key, value) get(key) 获得对应的value，不存在则返回null entrySet() keySet() 两个子类HashMap、HashTable HashMap HashTableHashTable的key和value的数据都不允许设置为null。但是使用的同步处理，性能较低，线程安全。 Iterator输出Map使用Map.Entry对象保存key-value。 使用Map.entrySet()获取Entry的集合，然后调用set.iterator()方法，实现输出。 栈java.util.Stack push pop 栈空异常和满异常 Collections工具类提供了操作map、list、set对象的一系列方法 addAll() 一次添加多个元素 reverse 反转 数据流Lambda表达式、方法引用、函数式接口、MapReduce。 default接口方法，所有子类对象都默认实现该方法，不用在每个子类对象里单独实现。 forEach(消费型接口) Collection.Stream() Stream接口提供了大量操作集合对象的方法 count distinct collect方法、collector接口和Collectors对象 filter过滤，断言式函数式接口 map，接收function式接口，接收参数并返回结果 ​ Stream的结果分页 skip(n) 跳过 limit(n) 取出个数 多条件匹配 allMatch， anyMatch reduce mapToDouble().summaryStatistics() JDBC 数据库连接 加载驱动程序 下载对应数据库的JDBC驱动 连接数据库 进行数据操作 关闭数据库 Statement接口操作数据库一个Connection可以打开多个Statement。 插入 修改 删除 查询 尽量按列的顺序取内容，同一字段只取一次 ​ PreparedStatementStatement存在Sql安全隐患 sql语句Like %x% 中的%应该和参数一起传入占位符 批处理与事务处理 批处理： 一次执行多条语句 ​ DAO设计模式DAO（Data Access Object,数据访问对象），主要的功能是用于进行数据操作的，在程序的标准开发框架中属于数据层的操作。 分层思想显示层 - 控制层 - | - 业务层 - 数据层 - | - 数据层 前台 - | - 后台 数据库操作类数据对象类 必须实现支持序列化标准的接口 类的名字与表的名字一致 类中的属性必须使用包装类，包装类的默认值为null。 属性的名字与表字段名字一致 属性使用private包装，并提供set、get方法 必须保留一个无参构造方法 数据层接口 所有的对象定义在dao包下面 对于表student，其在数据层的 接口定义为IStudentDAO 数据更新方法，以doXxx定义 数据查询，查询表中数据findXxxx表示，统计以getXxx定义 findByUserID， getAllCount 数据层实现类数据库的打开与关闭由业务层负责，因为一个业务层可能会调用多个数据层获取数据。 数据层工厂类使用工厂类获取数据层接口对象实例。 业务层接口标准业务层子类业务层工厂类控制层通过工厂类获取业务层对象实例。 前台逻辑ServiceFrontFactory 后台逻辑ServiceBackFactory 代码测试调用测试产生对象，并调用方法 junit测试]]></content>
      <categories>
        <category>技术</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python时间格式转换]]></title>
    <url>%2F2018%2F01%2F07%2F%E6%8A%80%E6%9C%AF%2Fpython%E6%97%B6%E9%97%B4%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[python时间转换字符串和时间格式化123456789101112131415import time# 时间字符串time_str = '2018-01-15 15:27:54'# 字符串的time formattime_fmt = '%Y-%m-%d %H:%M:%S'# str parse time, 转换成时间数组,time_array = time.strptime(time_str, time_fmt)print time_array# str from time, 时间数组转字符串time_str = time.strftime(time_fmt, time_array)print time_str# 默认时间为当前时间time_str = time.strftime(time_fmt)print time_str 时间数组和时间戳1234567891011# 当前时间的时间戳，秒，3位小数timestamp = time.time()print timestamp# 时间数组转换为时间戳timestamp = time.mktime(time_array)print timestamp# 时间戳转换为当地时间，然后在格式化成字符串localtime = time.localtime(timestamp)print localtime # 时间数组time_str = time.strftime(time_fmt, localtime)print time_str 当前时间格式化字符串12345# 转换成localtimetime_local = time.localtime(time.time())# 转换成新的时间格式(2018-01-15 15:27:54)dt = time.strftime("%Y-%m-%d %H:%M:%S", time_local)print dt]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 入门学习笔记]]></title>
    <url>%2F2018%2F01%2F04%2F%E6%8A%80%E6%9C%AF%2FJava%20%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[java 入门hello worldpublic class一个java文件只能有一个定义， 类名称必须与其所在的文件名一致。 编译后，一个class生成一个对应的*.class文件。 执行从主方法开始，主方法所在的类成为主类。 1234567891011// Main.javapublic class Main &#123; public static void main(String[] args) &#123; // write your code here int a = 0; a++; System.out.println("Hello World!"); &#125;&#125;class A&#123;&#125; 标识符 CLASSPATH环境变量，JVM执行class时，从加载路径进行类的加载。 java的文档注释 /** ... */ 标识符：类名，属性名，变量名， $不要使用，可以字母下划线数字等组成。 关键字：java语法保留字，以及true，false，null jdk1.7之后，标识符可以用中文，如int 年龄 = 20;,但是不要用。 数据类型基本数据类型由jvm分配内存，引用数据类型需要开发者为其分配内存。 “”是空字符串，长度为0，”\u0000”是一个字符，表示空字符，长度为1。 数值范围： 符号位，0为正，1为负。超长数据范围会导致内存溢出。类型转换,自动转换和强制转换。 1L, (long) 1 String类型 format格式化输出 基本运算 自增自减 符号放到前面和后面结果不同 三目运算 int num = numA &gt; numB ? numA:numB 有一个布尔运算 逻辑运算，与、或、非 A &amp;&amp; B, 短路的与， A &amp; B,非短路的与，每个条件判断都执行 使用短路的逻辑运算，性能、效率高 位运算 移位操作，左移1为乘2，不改变原变量的值。 位的与&amp;、||或运算，没有&amp;&amp;和|| 程序结构 分支结构 if 和switch switch不支持布尔运算，只能判断内容。 1234567891011switch (int | char | 枚举 | String )&#123; case 值1: 执行; break; case 值2: 执行; break; default: 条件都不满足时，执行; break; &#125; 循环结构 while循环和do while循环。实际项目避免do while,不利于代码阅读。 for循环 循环控制 continue、break Java面向对象类和对象 类是对象的模板，对象是类的可操作实例。 引用对象创建时必须先申请内存空间。 声明对象时，栈内存空间会生成一个该对象的引用(指向其真实堆内存空间所在的地址，类似c指针)。 new实例化对象时，会在堆内存中分配一块空间用于保存数据，并将栈内存里的对象引用指向堆内存中的实际地址，没有实例化时引用指向null。 堆内存空间中没有被任何对象引用的已分配空间，将被java的GC进行垃圾回收 类方法重载根据方法参数的类型或个数不同，调用不同的方法。不是根据方法的返回值类型。 类封装类对自己的属性负责，因此将属性声明private，需要外部访问时定义setter，getter方法setter或getter方法的命名要求严格,以set/get开头，后面接上属性名，首字母大写。 123456789class Test&#123; private String title; public void setTitle(String t)&#123; title = t; &#125; public String getTitle(String t)&#123; return title; &#125;&#125; 构造方法和匿名对象构造方法在实例化新对象时自动调用一次，进行初始化工作。构造方法也是可以重载的。 没有栈指向的堆空间中的对象即为匿名对象，只能使用一次，然后就等待被GC回收。 Java简单类 必须保留一个无参数构造方法 访问控制权限 数组一维数组 下标从0开始 data.length获取数组的长度，长度不变 超过长度的访问会造成数组越界访问 数组引用传递，即同一块堆空间数据可以被不同的栈地址指向。 动态初始化和静态初始化 12345int nums [] = new int [3]； # 声明并开辟一个长度为3的数组，值为类型的默认值int nums [] = null; nums = new int [3];//int nums [] = new int [] &#123;1, 2, 3, 4&#125; 二维数组123int nums [][] = new int [3][3]int nums [] [] new int [][]&#123;&#123;1, 2, 3&#125;, &#123;1, 2, 3&#125;, &#123;1, 2, 3&#125;,&#125; 数组用作方法参数引用传递，方法对数组的修改会影响到原始数据； 数组对象的方法 数组copy System.arraycopy(dataA, 4, dataB, 6, 3) 从A的第4个开始，向B的第6位置起始复制3个元素，会覆盖B上的元素 数组排序 java.util.Arrays.sort(data) 对象数组数组里的元素是引用对象 String类字符串常量是String类的匿名对象，String一旦定义对象就不可改变（如果变了，则是生成了新的String对象，引用关系发生变化）。 字符串比较==比较的是对象的内存地址，即是不是同一个对象，而不是比较的其内容 1234567891011String s1 = "hello";String s2 = new String("hello");String s3 = s2; //引用传递// s1==s2 false// s1==s3 false// s2==s3 trues1.equals(s2); // 内容比较s1.equalsIgnoreCase(s2); // 内容比较，不区分大小写String s4 = "hello";String s5 = "hello";s4==s5 //true 匿名对象，JVM的共享设计模式，维护一个对象池。 在python中 ==比较的是值是否相等， is是判断对象是否为同一内存地址，是否表示同一对象。 String实例化String a = new String(&#39;hello&#39;),这种方法会开辟2块堆内存，一块变成垃圾，String对象不会自动入池。 字符串与字符、字节 字符数组与字符串对象之间的转化 字节数组与字符串对象之间的转化 IO操作，转码时，常用byte 字符串查找 子串查找 str.contains(subStr) 以指定字符串开头， startsWith 以指定字符串结束endsWith 字符串替换 repalceAll replaceFirst 字符串截取 subString 字符串拆分将字符串拆分成多个字符串的数组 注意re正则表达式 split() ,但参数为””时，按每个字符拆分 字符串连接 + concat 与 +一样 join toUpperCase toLowerCase trim 去掉开头和结尾的空格 str.length() 返回字符串长度 isEmpty 判断是否为空串（空串的长度为0， str.equals(“”)） this表示当前对象，可以在对象/类内调用属性或方法 this互相调用类构造方法，简化对象的创建过程代码 1234567891011121314151617181920//构造方法互相调用this() //必须在构造函数内，且为首行 //互相调用必须由出口，避免递归调用 public class Hello&#123; private int num; private String name; public Hello()&#123; System.out.print('Create Hello'); &#125; public Hello(int num)&#123; this(); this.num = num; &#125; public Hello(int num, String name)&#123; this(); this.num = num; this.name = name; &#125; &#125; 引用传递同一块堆内存可以被不同的栈内存指向，指向同一堆内存的不同栈内存可以修改堆内存内容。 输出结果为Hello，原因是String对象的内容一旦声明则不可改变，如果改变，则会创建新的String对象。 String内容不可改变，一个字符串值，在堆内存中开辟一块空间，其数据不可改变。 对象比较一个类的方法可以接收本类的对象实例作为参数 1234567891011121314151617public class Test&#123; private int id; private String 20; //对象比较 public boolean compare(Test test)&#123; if(test==null)&#123; return false; &#125; if(this==test)&#123; return true; &#125; if(this.id==test.id &amp;&amp; this.name==test.name)&#123; return true; &#125; return false; &#125;&#125; Static关键字用于声明类、方法、属性。 声明属性为static后，属性为共享属性，任何一个对象修改该属性，其他对象的属性也会变化。static数据存储于程序的全局共享内存。 static属性属于类，非static属性必须由实例化对象访问。 static静态方法，可以直接由类调用 非static的方法可以访问static属性、方法 static方法无法访问非static属性、方法 主方法 public static void main(String args[]) 命令行参数以空格分开，有空格的参数用双引号包围 构造块和静态块在构造方法里的代码块，优先于构造方法执行，创建n个对象就执行n次。静态块执行优先于构造块，且只会被执行1次。 1234567891011public class Test&#123; //对象比较 public Test()&#123; System.out.print('这是构造函数部分'); &#123; System.out.print('这是构造块'); &#125; static &#123; System.out.print('这是静态块'); &#125;&#125; 在主类中定义的静态块将优先于主方法运行。 内部类在一个类的内部定义新的类，也可以在代码块、方法里定义。 内部类可以访问外部类的私有属性，外部类也可以访问内部类的私有属性。 内部类在外部类的外部实例化： 如果内部类声明了private，则内部类无法在外部类以外实例化。 如果内部类声明了static，则内部类与外部类相对独立。 经常会有这样的类实例化方法类.类.类.类(args) 方法中的内部类，在jdk1.8可以访问方法的参数、属性。在1.7及之前，参数或变量类型前要加final修饰。 为了兼容性，还是加上final 链表由节点连接起来的链表 Node定义 节点关系处理 Node对象应该只能由Link对象操作。因此node应该作为link的私有内部类。 链表的方法 add增加新节点，size取得链表中保存元素的个数（使用count属性），isEmpty判断是否为空链表（root节点为空或长度为0），contains数据查询（循环链表的全部节点并进行数据比对，自定义对象的对比方法实现compare）， get通过index返回node，set 替换index处节点的数据，remove删除指定数据，删除指定index，insert指定数据，toArray,链表转换为数组。 处理根节点 添加新节点 遍历链表 链表使用自定义类链表 继承和多态解决代码复用问题 继承的限制 不允许多重继承，但是可以多层继承，一般不要超过3层。 私有操作属于隐式继承，公开操作显示继承 子类构造时，默认先调用父类的无参构造，有参数的父类构造，必须在首行使用super显示调用 方法覆写 子类覆写父类的方法，子类方法权限不能高于父类，public &gt; default &gt; private 如果父类使用private修饰方法，则其对子类不可见，子类同名同参方法无法将其覆盖。 super.func调用父类的方法 重载和覆写的区别 发生的地方，方法名、参数，权限，返回值。 属性覆盖父类的private属性被封装，对子类不可见。覆盖属性是没有意义的，相当于定义新的属性。 多态性 方法的多态性：依赖于方法的覆写和重载 对象的多态性：发生在继承关系之中，子类与父类的转换。 instanceof 判断 a是否为对象A的实例 final final类不能有子类 final方法不能被子类覆写 final修饰的变量将变为常量，即定义时设置好值，且不能被修改。 public static final 变量，全局常量。 常量命名全用大写字母。 抽象类含有抽象方法，类和抽象方法使用abstract关键字声明 由子类继承 子类如果不是抽象类，则必须覆写父类全部抽象方法 实例化必须依靠子类完成 外部的抽象类不允许使用static声明，内部的抽象类可以使用static声明。 使用static声明的内部抽象类使用时相当于外部抽象类，声明时A.B a_b = new X() class X extends A.B{ xxx } 下面的程序输出为0 构造函数对属性赋值之前，属性值为默认值。 父类的构造先于子类进行，调用print方法时，num还未被初始化，其值默认为0。 抽象类主要用于模板设计 Java接口接口是一种特殊的抽象类，只有抽象方法和全局常量(final)，没有构造方法。 interface X { xxx} 一个子类可以使用implents关键字实现多个接口 接口的子类如果不是抽象类，必须覆盖全部方法 可以利用子类的向上转型实现接口的实例化 子类要先继承父类在实现接口 extends A implents B, C 接口可以用extends继承多个接口 在接口里定义内部普通类、抽象类、接口都是可以的。使用static修饰的内部接口，相当于外部接口。即A.B 工厂设计模式 Factory好的程序设计标准： 用户不需要关注代码细节 用户不需要关注代码的变更 new导致耦合度高，工厂类屏蔽了子类的细节。 代理设计模式 Proxy一个主题操作接口类（可能有多种方法），核心业务主题主完成核心操作，代理主题负责其他辅助操作。 客户端代码只用关注接口 接口定义增强jdk1.8允许在接口里定义抽象方法外的普通方法，但是必须使用default或static修饰。。 default 1.8之前，假如在项目中一个接口有N个子类，项目升级时接口需要增加新的方法，则N个子类必须都重写该抽象方法，很费力。 static 该方法只能由接口直接调用 抽象类和接口的区别 当抽象类和接口都可以使用时，优先使用接口 使用工厂类实例化接口子类，不要直接new Object类Object类是所有类的父类。 利用Object可以接收任何对象，本身有一个无参构造方法。统一参数。 Object提供了很多内置方法 子类一般覆写3个方法 toString print函数会调用对象的该方法 equals hashCode 匿名内部类必须基于接口或抽象类的应用，如果子类只需要使用一次，可以使用匿名内部类，以减少类文件的创建。 包装类对基本数据类型包装 对象型包装类： Boolean，Character 数值型包装类 ： Integer，Long，Float等 装箱与拆箱基本数据类型与包装类互相转换。jdk1.5之后java自动实现拆箱装箱和数值计算 数据类型转换字符串与包装类互相转换 将String类转换成对应的包装类，比如 Sting ‘1’ 和Integer 1。 +任何对象与字符串相加的结果都是字符串 String.valueOf(数据) Package 包同一目录下不能存在相同名字的文件 package cn.java.study javac -d . xxx.java 打包编译，会在当前路径下自动生成目录 java cn.java.study.Hello 运行 导入包import xxx.xxx.ClassA 可以被导入的包必须是public。 一个*.java里只能有一个public类，且必须与文件名保持一致。 import 包.* 编译时只会导入代码需要的包，不用担心性能。 如果导入的多个包里有同名类，则实例化类时，为避免冲突使用包.类完整包名。 系统常见包 java.lang java.lang.reflect 反射 java.util 工具包 java.util.regex 正则化 java.text 国际化处理 java.io 输入输出、文件流 java.net 网络 java.sql 数据库 第三方包jar打包程序构造方法私有化private修饰的构造方法，只能在类的内部调用，无法用new创建对象。 为了控制类实例化对象的个数，必须锁定构造方法。 单例设计可以用static final在类内部定义一个唯一的对象。 饿汉式：定义时就实例化 懒汉式：使用时在实例化一次 this.instance = new Singleton() 多例设计可以实例化固定个数实例对象的类 类内部定义多个static final的实例 异常捕获处理 所有异常都是Throwable的子类 Throwable的直接子类Error和Exception。Error是JVM错误，程序还没执行。Exception是程序运行中的，用户可以处理的。 e.printStackTrace() 打印异常详细信息 程序运行出现自动生成Exception对象，然后交由try语句依次匹配catch。 如果没被catch捕获到，则finally会交给jvm处理，即异常退出。如果匹配到了则继续执行finally后续操作。 catch异常必须先捕获小的exception，然后在捕获大的。 throws和throw用throws声明的方法，表示调用该方法时必须用try进行异常处理。强制异常处理 在程序执行代码中用throw抛出异常。 RuntimeException类throws该异常类时，用户可以选择性处理，如果不处理则交由JVM处理。 NullPointerException 断言判断是否得到预期的结果，程序默认运行时不启用断言代码。 assert 自定义异常继承自Exception或RuntimeException。 可变参数int add(int ... data) …相当于把出入的多个参数作为一个数组传入 foreach123for(int x: data)&#123; //从data中取出每个元素&#125; 泛型可以接收不同类型的变量，避免利用object向下转型的不安全操作，类中属性的类型是动态设置的。 Type类型不能是基本类型。不设置时，Type则变为Object 简化声明泛型，实例化中的Type类型可以省略。 通配符 void func(Point temp) 不指定Point的泛型类型，则为Object类对象，此时传入的对象在函数内可以被改变。 ?可以保证泛型对象不被改变，void func(Point&lt;?&gt; temp) ?extends Number 泛型可以设置为Number及其子类，用在类声明或方法的参数类型声明。 ?super String 泛型可以设置为String及其父类，仅用在方法传入参数的类型声明上。 泛型接口123456789101112131415161718192021222324252627interface IMessage&lt;T&gt; &#123; public void func(T t);&#125; //接口子类也用 T， 实例化时指定类型class Message&lt;T&gt; implements IMessage&lt;T&gt;&#123; public void func(T t)&#123; // xxx &#125;&#125;public class Test&#123; psvm main()&#123; IMessage&lt;String&gt; msg = new Message&lt;string&gt;(); //指定String类型 &#125;&#125;// 接口子类使用具体类型class Message implements IMessage&lt;String&gt;&#123; public void func(String t)&#123; // xxx &#125;&#125;public class Test&#123; psvm main()&#123; IMessage&lt;String&gt; msg = new Message(); &#125;&#125; 泛型方法泛型的方法可以在非泛型类里定义 枚举类型enum, Enum是抽象类， enum可以实现多例设计和接口 多例设计 接口 在枚举里每个实例单独实现方法覆写，使用匿名内部类 在枚举里定义抽象方法，此时枚举对象必须覆写抽象方法 枚举应用在switch中 Lambda表达式在接口子类中用lambda表达式实现匿名内部类，覆写接口的抽象方法。 方法引用在函数式接口里使用方法引用 引用静态方法引用对象方法引用特定类型方法引用构造方法内建函数式接口java.util.function提供有4类函数式接口 Function Consumer Supplier Predict Annotation利用注解的形式来实现程序的不同功能。类似于利用配置文件。 @override 精确覆写，告诉编译器，这个方法要被覆写 @Deprecated 声明过期的方法，不被推荐，有新的方法替代 @SupressWarning 压制警告，告诉编译器取消警告 类图与软件设计UML 类图，描述类及类间关系。 时序图， JAVA API文档查询]]></content>
      <categories>
        <category>技术</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML代码转义和URL编解码]]></title>
    <url>%2F2018%2F01%2F02%2F%E6%8A%80%E6%9C%AF%2FHTML%E8%BD%AC%E4%B9%89%E5%92%8CURL%E7%BC%96%E8%A7%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[HTML代码转义和URL编解码HTML代码转义html转义字符表当爬虫抓到的html字符串是这种 &#39;&amp;lt;abc&amp;gt;&#39;, 其对应的文本为 &lt;abc&gt;,需要进行反转义处理。 1234567891011# 标准库即可实现import HTMLParserhtml_parser = HTMLParser.HTMLParser()txt = html_parser.unescape(html)# 或者用BSfrom bs4 import BeautifulSoup soup = BeautifulSoup(html, \ convertEntities=BeautifulSoup.HTML_ENTITIES)# 转义的功能在cgi模块import cgihtml = cgi.escape(txt) URL编解码当url中get参数的取值存在特殊字符，如&amp; ? = /等会产生歧义，需要对URL内容进行编码 1234import urllibrawurl = "%E6%B2%B3%E6%BA%90"url = urllib.unquote(rawurl)url = urllib.quote("呵呵")]]></content>
      <categories>
        <category>技术</category>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Web</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA使用技巧]]></title>
    <url>%2F2018%2F01%2F01%2F%E6%8A%80%E6%9C%AF%2FIDEA%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[IDEA配置代码补全中关掉首字母大小写敏感。 IDEA使用技巧 主方法补全，public static void main首字母，psvm for循环补全，输入fori 根据提示后选择 System.out.println();在IntellJ中是输入sout IDEA编辑框背景图片Settings -&gt; Appearance &amp; Behaviour -&gt; Appearance里有设置，如果没有可以安装插件。 安装插件BackgroundImage Plus，可以随机切换一个文件夹里的图片作为背景。 Settings -&gt; Appearance &amp; Behaviour -&gt; Background Image Plus 使用详情见 插件的github主页]]></content>
      <categories>
        <category>技术</category>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2017%2F11%2F17%2F%E6%8A%80%E6%9C%AF%2FPython%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Python多线程进程与线程 python解释器的GIL限制了线程的多核并行 进程 程序的一次执行 由代码段、数据段和进程控制块组成 基本状态：就绪、阻塞、执行 是拥有资源的独立单位 线程 进程中的任务执行的实体 一个进程里可以有多个线程，线程占有极少资源，多个线程共享进程的资源。这就会涉及同步和通信的问题。 通常认为线程不拥有系统资源 线程的开销比进程小 线程状态和生命周期 python内置模块threadingThread对象用来创建线程的主要对象 Thread( target=None, name=None,args=(), kwargs=None) start() :启动线程 run()：启动线程调用的方法。 join([timeout]):等待到被调用线程终止或超时为止。 is_alive():返回线程的活动状态（run()方法期间）。 name:线程名 ident：线程ID daemon:后台标志（在启动之前设置） 获取当前线程的方法current_thread(), 获取所有活动线程的方法enumerate():包括当前线程 线程创建方法12345678from threading import Threaddef hello(name): print 'hello' + name t = Thread(target=hello, args=('lio', ))t.start()t.join() 主动停止线程 线程并未提供stop或kill方法，如果用了死循环，则线程会一直运行。 可以使用线程的信号机制，或者设置一个全局变量作为停止的flag。 控制多线程的并发 threading模块没有实现线程池，可以用第三方分threadpool模块。 自己实现线程池pool： pool是一个有size，可以遍历，pop，add的对象，如list，dict，queue等 如果pool没满，可以向pool里添加线程 从pool里移除运行结束的线程，pop后del Timer计时器对象定时执行任务，threading.Timer(3, hello).start()，3秒后运行函数。 线程同步和通信 线程等待 t.join([timeout])用来实现线程等待。被调用join()方法的线程会一直阻塞调用者的线程，直到自己结束（正常结束，或引发未处理异常），或超出timeout的时间。 daemon线程，后台线程 t.setDaemon(True),被设定为后台运行的线程，会在主程序退出时主动自杀。 线程通信 事件Event 事件Event比Condition条件锁简单一点。它通过维护内部的标识符来实现线程间的同步问题。 Event.wait([timeout])堵塞线程，直到Event对象内部标识位被设为True或超时（如果提供了参数timeout）。 Event.set()将标识位设为Ture Event.clear()将标识设为False。 Event.isSet()判断标识位是否为Ture 线程同步 锁 定义一个锁，执行互斥操作时，先请求锁，执行完互斥操作后释放锁。获得锁的线程会阻塞其他请求锁的线程。 123456789101112131415161718192021222324252627import threadingfrom threading import Threadimport time, randombase_number = 0number_lock = threading.Lock()class Add(Thread): def __init__(self, step): super(Add, self).__init__() self.step = step def run(self): global base_number for i in range(3): number_lock.acquire() base_number += self.step number_lock.release() time.sleep(random.random())if __name__ == '__main__': t1 = Add(2) t2= Add(3) t1.start() t2.start() ​ 可重入锁 threading.RLock,允许对一个资源多次加锁，加锁和释放的次数要一样，否则会出错。 条件变量 threading.Condition, 可以实现线程之间相互通知。 实例化时可以使用默认锁或指定用户创建的锁，使用前先获取锁，调用wait时自动释放锁，调用notify不会释放锁。 等待条件发生的地方，调用wait方法阻塞线程，触发条件的地方使用notify方法唤醒线程。 notify(n=1)默认唤醒一个等待的线程，notify_all()唤醒所有等待的线程。 可以实现严格依照次序操作的线程之间的通信，如生产者消费者模式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import threadingfrom threading import Threadimport time, randomproduct = [] # list是线程不安全的，使用时要加锁。queue是线程安全的。maxsize = 4product_condition = threading.Condition() # 默认使用一个RLock锁，lock=threading.RLock(),也可以自己定义一个锁传入class Producer(Thread): def __init__(self): super(Producer, self).__init__() def run(self): global product, maxsize while True: product_condition.acquire() # 加锁，开始生产 if len(product) &lt; maxsize: data = random.randint(1, 9) product.append(data) print data, ' add!' product_condition.notify(1) # 唤醒一个消费者，消费产品 product_condition.release() # 释放锁 else: product_condition.wait() # 最大生产4个产品，等待消费者通知继续生产。wait等待会主动释放锁class Consumer(Thread): def __init__(self, name): super(Consumer, self).__init__() self.name = name # 'consumer1' def run(self): global product, maxsize while True: product_condition.acquire() if len(product) &lt; 1: product_condition.wait() # 等待生产者进程唤醒,wait方法会释放锁 else: print self.name, '消费了产品：', product.pop() product_condition.notify() #通知生产者进程继续生产 product_condition.release() # notify不会释放锁，主动释放 time.sleep(2)if __name__ == '__main__': for i in range(5): t = Consumer('consumer&#123;&#125;'.format(i)) t.start() # 启用5个生产者和一个消费者 p1 = Producer() p1.start() 信号量 threading.Semaphore控制稀缺资源，内部有计数器，当计数器值为0时，阻塞。 锁定时计数器-1，释放时计数器+1 1234567891011121314151617sema = threading.Semaphore(2) # 资源可用量为2class Consumer1(Thread): def __init__(self, name): super(Consumer1, self).__init__() self.name = name # 'consumer1' def run(self): sema.acquire() print '&#123;&#125;获得了资源'.format(self.name) time.sleep(3) sema.release()if __name__ == '__main__': for i in range(5): t = Consumer1('consumer&#123;&#125;'.format(i)) t.start() ​ 第三方模块threadpool 定义pool，设置最大并发 makeRequests生成线程 将线程加入pool 调用pool.wait等待执行结束 123456789import threadpool def hello(name, froms='Lili'): print froms + ' say hello to '+ namepool = threadpool.ThreadPool(4)requests = threadpool.makeRequests(hello, [('a', 'b'), ('c', 'd')])[pool.putRequest(req) for req in requests]pool.wait()]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2017%2F11%2F07%2F%E6%8A%80%E6%9C%AF%2FPyQt5%20%E4%BD%BF%E7%94%A8pyinstaller%E6%89%93%E5%8C%85PyQt5%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[使用pyinstaller打包PyQt5程序]]></content>
  </entry>
  <entry>
    <title><![CDATA[Gevent 源码分析]]></title>
    <url>%2F2017%2F11%2F05%2F%E6%8A%80%E6%9C%AF%2FGevent%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Gevent 源码分析 gevent包括2个重要的部分，libev和greenlet。 libev实现事件循环， watcher(叶子，事件监控处理)，ev_run(主干，事件循环引擎)，ev_loop(watcher管理)。 greenlet提供对协程的完整支持，用于执行异步任务。 源码分析工具：pycharm ctrl + B 跳转到对象声明的源码位置， ctrl + alt + 箭头 前进或后退 选择右侧导航栏的Structure窗口，可以快速的查看类的属性和方法。 下载gevent源码 从github上下载源码 源码目录结构 doc：项目文档 examples：简单的使用示例 benchmarks：压力测试 src：源代码所在目录 __init__.py __all__属性由列表构成，它规定了模块的所有可见方法，会使属性列表之外的成员全部私有化。 只有在执行语句 from module import * 时，__all__属性才会起作用。此时所有枚举的成员被import，而其他成员被私有化。 它不仅在第一时间展现了模块的内容大纲，而且也更清晰的提供了外部访问接口。 __dependencies_for_freezing() ，为打包工具如py2exe等指明hidden-import 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849__version__ = '1.3.0.dev0'__all__ = ['get_hub', 'Greenlet', 'GreenletExit', 'spawn', 'spawn_later', 'spawn_raw', 'iwait', 'wait', 'killall', 'Timeout', 'with_timeout', 'getcurrent', 'sleep', 'idle', 'kill', 'signal', 'fork', 'reinit']import sysif sys.platform == 'win32': # trigger WSAStartup call import socket # pylint:disable=unused-import,useless-suppression del socketfrom gevent.hub import get_hub, iwait, waitfrom gevent.greenlet import Greenlet, joinall, killalljoinall = joinall # export for pylintspawn = Greenlet.spawnspawn_later = Greenlet.spawn_laterfrom gevent.timeout import Timeout, with_timeoutfrom gevent.hub import getcurrent, GreenletExit, spawn_raw, sleep, idle, kill, reinittry: from gevent.os import forkexcept ImportError: __all__.remove('fork')from gevent.hub import signal as _signal_classfrom gevent import signal as _signal_moduledef __dependencies_for_freezing(): # pylint:disable=unused-variable from gevent import core from gevent import resolver_thread from gevent import resolver_ares from gevent import socket as _socket from gevent import threadpool from gevent import thread from gevent import threading from gevent import select from gevent import subprocess import pprint import traceback import signal as _signaldel __dependencies_for_freezing libev原理libev源码解读 Reactor模式 工作流程： 获取ev_loop实例，它代表了一个事件循环，也是代码的主要组织者。 创建和初始化watcher，并绑定到loop实例。libev中定义了一系列的watcher（如io，timer），每类watcher负责一类特定的事件。当loop中检测到感兴趣的事件发生，便会通知相关的watcher。 启动事件循环，ev_run函数。事件循环启动后，当前线程/进程将会被阻塞，直到循环被终止。 当watcher监听的事件发生时，wathcher被放入就绪状态队列，等待调用（执行watcher的回调函数）。 watcher对象： watcher是Reactor中的Event Handler。一方面，它向事件循环提供了统一的调用接口，监听事件;另一方面，它是外部代码的注入口，维护着具体的watcher信息，如：绑定的回调函数，watcher的优先级，是否激活等。 active: 表示当前watcher是否被激活。 pending: 表示当前watcher有事件就绪，等待处理。 priority: 是当前watcher的优先级； data: 附加数据指针，用来在watcher中携带额外所需的数据； cb：是事件触发后的回调函数定义。 ev_loop对象: ev_loop则是一个Reactor的角色，是事件循环的上下文环境，就像一根竹签，把前面的watcher实例像糖葫芦一样串起来。ev_loop实现对watcher的管理，维护watcher就绪队列，触发watcher执行。 ev_run： 执行事件循环的的引擎，即Reactor模式中的select方法。通过向ev_run函数传递一个ev_loop实例，便可以开启一个事件循环。 ev_run实际上是一个巨大的do-while循环，期间会检查loop中注册的各种watcher的事件。如果有事件就绪，则触发相应的watcher。这个循环会一直持续到ev_break被调用或者无active的watcher为止。当然，也可以通过传递EVRUN_NOWAIT或EVRUN_ONCE等flag来控制循环的阻塞行为。 gevent core 由于gevent封装的libev是c语言实现的事件循环框架，因此了解libev的工作原理是非常重要的。 core.py 123from gevent.libev import corecext as _core# CFFI/PyPyfrom gevent.libev import corecffi as _core 从gevent.libev中导入_core,分python版和pypy版本。 gevent.libev corecext.ppyx gevent封装了libev。libev是c实现的高效事件循环框架，其核心为ev_run,主要要做了五件事情： 更新更改的FD事件 进行必要的sleep backend_poll收集pending的IO事件 收集pending的timer事件 调用所有pending的事件 corecext.ppyx是cython写的，看不懂 corecext.ppyx用Cython实现loop类，编译时会转换为gevent.core.c-&gt;gevent.core.so，对libev的结构体和接口进行封装，比如时间循环loop，回调callback，观察者watcher 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354def __init__(self, object flags=None, object default=None, size_t ptr=0): cdef unsigned int c_flags cdef object old_handler = None libev.ev_prepare_init(&amp;self._prepare, &lt;void*&gt;gevent_run_callbacks)#ifdef _WIN32 libev.ev_timer_init(&amp;self._periodic_signal_checker, &lt;void*&gt;gevent_periodic_signal_check, 0.3, 0.3)#endif libev.ev_timer_init(&amp;self._timer0, &lt;void*&gt;gevent_noop, 0.0, 0.0) # ........................ libev.ev_prepare_start(self._ptr, &amp;self._prepare) libev.ev_unref(self._ptr) self._callbacks = []# ........cdef public class loop [object PyGeventLoopObject, type PyGeventLoop_Type]: # loop对象的实现 cdef public class watcher [object PyGeventWatcherObject, type PyGeventWatcher_Type]: cdef public class io(watcher) [object PyGeventIOObject, type PyGeventIO_Type]: cdef public class timer(watcher) [object PyGeventTimerObject, type PyGeventTimer_Type]: cdef _run_callbacks(self): cdef callback cb cdef object callbacks cdef int count = 1000 libev.ev_timer_stop(self._ptr, &amp;self._timer0) while self._callbacks and count &gt; 0: callbacks = self._callbacks self._callbacks = [] for cb in callbacks: libev.ev_unref(self._ptr) gevent_call(self, cb) count -= 1 if self._callbacks: libev.ev_timer_start(self._ptr, &amp;self._timer0) def run(self, nowait=False, once=False): CHECK_LOOP2(self) cdef unsigned int flags = 0 if nowait: flags |= libev.EVRUN_NOWAIT if once: flags |= libev.EVRUN_ONCE with nogil: libev.ev_run(self._ptr, flags) def run_callback(self, func, *args): CHECK_LOOP2(self) cdef callback cb = callback(func, args) self._callbacks.append(cb) libev.ev_ref(self._ptr) return cb 查看core的对象loop及其方法 pycharm的python shell（ipython）有自动补全，当单步执行时，可以利用其查看对象对外提供的方法 或者使用debug查看对象 12345678910111213141516171819202122232425262728def hello(): print 'hello'from gevent import coreloop = core.loop()# loop对象对外提供的方法和属性loop.run_callback(hello)loop.run()loop.depthloop.fileno()loop.update()loop.now()t = loop.timer(3, 2) # 每3秒执行2次t = loop.timer(3) # 3秒后执行并退出t.start(hello)loop.run() # 必须loop运行起来，timer事件监听才会执行。# ------- timer对象的声明和start方法class timer(watcher): _watcher_type = 'ev_timer' def __init__(self, loop, after=0.0, repeat=0.0, ref=True, priority=None): if repeat &lt; 0.0: raise ValueError("repeat must be positive or zero: %r" % repeat) watcher.__init__(self, loop, ref=ref, priority=priority, args=(after, repeat)) def start(self, callback, *args, **kw): # ... 直接ctrl + B，查看loop对象的声明。loop初始化了几个watcher，重要的方法有run_callback, run, timer 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class loop(object): error_handler = None def __init__(self, flags=None, default=None): self._in_callback = False self._callbacks = [] # self._check is a watcher that runs in each iteration of the mainloop, just after the blocking call self._check = ffi.new("struct ev_check *") # self._prepare is a watcher that runs in each iteration of the mainloop, just before the blocking call self._prepare = ffi.new("struct ev_prepare *") # A timer we start and stop on demand. If we have callbacks, self._timer0 = ffi.new("struct ev_timer *") libev.ev_timer_init(self._timer0, libev.gevent_noop, 0.0, 0.0) def _run_callbacks(self, _evloop, _, _revents): count = 1000 libev.ev_timer_stop(self._ptr, self._timer0) while self._callbacks and count &gt; 0: callbacks = self._callbacks self._callbacks = [] for cb in callbacks: self.unref() callback = cb.callback args = cb.args if callback is None or args is None: # it's been stopped continue cb.callback = None try: callback(*args) except: # 。。。 if self._callbacks: libev.ev_timer_start(self._ptr, self._timer0) def destroy(self): # 销毁loop对象 def run(self, nowait=False, once=False): flags = 0 if nowait: flags |= libev.EVRUN_NOWAIT if once: flags |= libev.EVRUN_ONCE libev.ev_run(self._ptr, flags) def timer(self, after, repeat=0.0, ref=True, priority=None): return timer(self, after, repeat, ref, priority) def callback(self, priority=None): return callback(self, priority) def run_callback(self, func, *args): cb = callback(func, args) self._callbacks.append(cb) self.ref() return cb def fileno(self): if self._ptr: fd = self._ptr.backend_fd if fd &gt;= 0: return fd gevent hub hub是greentlet子类，一个greenlet对象，是main greenlet。 hub是gevent的核心，依赖libev调度所有greenlet 当有协程需要调度时，主协程调用switch方法切换到子协程。子协程阻塞或者主动调用switch时，切回主协程，由主协程调度其他协程运行。 主要的对象和方法 get_hub sleep kill wait iwait signalClass HubClass WaiterClass sleep触发调度当执行gevent.sleep(0)语句时，当前协程立即被切换出去，回到gevent的主协程，紧接着主协程执行调度其他协程执行。我们从sleep函数入手分析。 gevent.sleep sleep(0)意味着，协程立即yield，其他runnable greenlets将有机会被执行。等到下次loop到该协程时，它才会被恢复执行。 具体流程：通过get_hub获取主协程和loop对象，然后调用waiter.switch或者hub.wait 12345678910111213# ------- hub.py -----def sleep(seconds=0, ref=True): """ Put the current greenlet to sleep for at least *seconds*. """ hub = get_hub() loop = hub.loop if seconds &lt;= 0: waiter = Waiter() loop.run_callback(waiter.switch) waiter.get() else: hub.wait(loop.timer(seconds, ref=ref)) get_hub 从当前线程上下文中获取hub对象，如果没有就创建一个 12345678910# ------- hub.py -----def get_hub(*args, **kwargs): """ Return the hub for the current thread. """ hub = _threadlocal.hub if hub is None: hubtype = get_hub_class() hub = _threadlocal.hub = hubtype(*args, **kwargs) return hub hub.loop 默认是一个GEVENT_LOOP对象 Waiter Waiter是低层次的greenlets通信工具，用来安全的实现switch()或throw()调用。类中的doc如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Waiter(object): """ A low level communication utility for greenlets. Waiter is a wrapper around greenlet's ``switch()`` and ``throw()`` calls that makes them somewhat safer: * switching will occur only if the waiting greenlet is executing :meth:`get` method currently; * any error raised in the greenlet is handled inside :meth:`switch` and :meth:`throw` * if :meth:`switch`/:meth:`throw` is called before the receiver calls :meth:`get`, then :class:`Waiter` will store the value/exception. The following :meth:`get` will return the value/raise the exception. The :meth:`switch` and :meth:`throw` methods must only be called from the :class:`Hub` greenlet. The :meth:`get` method must be called from a greenlet other than :class:`Hub`. &gt;&gt;&gt; result = Waiter() &gt;&gt;&gt; timer = get_hub().loop.timer(0.1) &gt;&gt;&gt; timer.start(result.switch, 'hello from Waiter') &gt;&gt;&gt; result.get() # blocks for 0.1 seconds 'hello from Waiter' If switch is called before the greenlet gets a chance to call :meth:`get` then :class:`Waiter` stores the value. &gt;&gt;&gt; result = Waiter() &gt;&gt;&gt; timer = get_hub().loop.timer(0.1) &gt;&gt;&gt; timer.start(result.switch, 'hi from Waiter') &gt;&gt;&gt; sleep(0.2) &gt;&gt;&gt; result.get() # returns immediatelly without blocking 'hi from Waiter' .. warning:: This a limited and dangerous way to communicate between greenlets. It can easily leave a greenlet unscheduled forever if used incorrectly. Consider using safer classes such as :class:`gevent.event.Event`, :class:`gevent.event.AsyncResult`, or :class:`gevent.queue.Queue`. """ def switch(self, value=None): """Switch to the greenlet if one's available. Otherwise store the value.""" greenlet = self.greenlet if greenlet is None: self.value = value self._exception = None else: assert getcurrent() is self.hub, "Can only use Waiter.switch method from the Hub greenlet" switch = greenlet.switch try: switch(value) except: # pylint:disable=bare-except self.hub.handle_error(switch, *sys.exc_info()) def get(self): """If a value/an exception is stored, return/raise it. Otherwise until switch() or throw() is called.""" Waiter的switch方法，如果Waiter对象当前绑定了greenlet对象(hub实例)，就调用greenlet.switch方法。 hub.wait(loop.timer(seconds, ref=ref)) 等待watcher对象（计时器timer）就绪之前，阻塞该协程 12345678910111213141516171819202122# -------- hub.py ------- def wait(self, watcher): """ Wait until the *watcher* (which should not be started) is ready. The current greenlet will be unscheduled during this time. .. seealso:: :class:`gevent.core.io`, :class:`gevent.core.timer`, :class:`gevent.core.signal`, :class:`gevent.core.idle`, :class:`gevent.core.prepare`, :class:`gevent.core.check`, :class:`gevent.core.fork`, :class:`gevent.core.async`, :class:`gevent.core.child`, :class:`gevent.core.stat` """ waiter = Waiter() unique = object() watcher.start(waiter.switch, unique) try: result = waiter.get() if result is not unique: raise InvalidSwitchError('Invalid switch into %s: %r (expected %r)' % (getcurrent(), result, unique)) finally: watcher.stop() ​ gevent socket 当python底层的socket使用非阻塞模式时，执行socket操作会立即返回exception。gevent的socket在原始socket的基础上，通过处理exception，并监听socket 可读可写事件来实现异步。 12345import geventfrom gevent import socketconn = socket.create_connection(('localhost', '8888'))print conn socket.py 协作式底层网络接口 提供了套接字操作和相关函数。API与python标准库一致。但同步函数只会阻塞当前协程，其他协程会继续运行。 主要方法分析： create_connection 创建socket对象,调用socket.connect方法 主要sock = socket(af, socktype, proto) ,这里的socket是gevent封装的一个对象，在_socket2.py中定义的。 123456789101112131415161718192021# ----- gevent socket.py -------def create_connection(address, timeout=_GLOBAL_DEFAULT_TIMEOUT, source_address=None): """Connect to *address* and return the socket object. and return the socket object. """ host, port = address err = None for res in getaddrinfo(host, port, 0 if has_ipv6 else AF_INET, SOCK_STREAM): af, socktype, proto, _, sa = res sock = None try: sock = socket(af, socktype, proto) if timeout is not _GLOBAL_DEFAULT_TIMEOUT: sock.settimeout(timeout) if source_address: sock.bind(source_address) sock.connect(sa) return sock except error as ex: # .... _socket2.py 中socket对象 实现gevent封装的socket对象，接口和python原始的socket一致。 self._sock = _realsocket(family, type, proto)创建一个real socket（python的socket对象） self._sock.setblocking(0)设置real socket为非阻塞的工作模式 self.hub = get_hub()拿到gevent中的主协程greenlet对象，hub 设置两个监听事件，可读和可写事件监听 self._read_event = io(fileno, 1) self._write_event = io(fileno, 2) 1234567891011121314151617181920212223242526# ----- gevent _socket2.py -----class socket(object): """ gevent `socket.socket &lt;https://docs.python.org/2/library/socket.html#socket-objects&gt;`_ for Python 2. This object should have the same API as the standard library socket linked to above. """ def __init__(self, family=AF_INET, type=SOCK_STREAM, proto=0, _sock=None): if _sock is None: self._sock = _realsocket(family, type, proto) self.timeout = _socket.getdefaulttimeout() else: if hasattr(_sock, '_sock'): self._sock = _sock._sock self.timeout = getattr(_sock, 'timeout', False) if self.timeout is False: self.timeout = _socket.getdefaulttimeout() else: self._sock = _sock self.timeout = _socket.getdefaulttimeout() self._sock.setblocking(0) fileno = self._sock.fileno() self.hub = get_hub() io = self.hub.loop.io self._read_event = io(fileno, 1) self._write_event = io(fileno, 2) gevent socket对象的方法实现: 打开pycharm的Structure导航窗口。 connect 使用了非常巧妙的while循环，执行result = sock.connect_ex(address)进行socket连接，如果没有异常，则连接成功，跳出while。如果返回异常如连接未建立，缓冲区满等，则调用self._wait(self._write_event)等待socket变成可写状态(表示连接成功)，在继续while，等待期间协程交出运行权。 重点socket._wait,它调用了self.hub.wait(watcher),实现阻塞当前的greenlet，等待对应的watcher就绪 123456789101112131415161718192021222324252627282930313233343536373839404142434445# ----- gevent _socket2.py -----class socket(object): def connect(self, address): if self.timeout == 0.0: return self._sock.connect(address) sock = self._sock if isinstance(address, tuple): r = getaddrinfo(address[0], address[1], sock.family) address = r[0][-1] if self.timeout is not None: timer = Timeout.start_new(self.timeout, timeout('timed out')) else: timer = None try: while True: err = sock.getsockopt(SOL_SOCKET, SO_ERROR) if err: raise error(err, strerror(err)) result = sock.connect_ex(address) if not result or result == EISCONN: break elif (result in (EWOULDBLOCK, EINPROGRESS, EALREADY)) or (result == EINVAL and is_windows): self._wait(self._write_event) else: raise error(result, strerror(result)) finally: if timer is not None: timer.cancel() def _wait(self, watcher, timeout_exc=timeout('timed out')): """Block the current greenlet until *watcher* has pending events.""" if watcher.callback is not None: raise _socketcommon.ConcurrentObjectUseError('This socket is already used by another greenlet: %r' % (watcher.callback, )) if self.timeout is not None: timeout = Timeout.start_new(self.timeout, timeout_exc, ref=False) else: timeout = None try: self.hub.wait(watcher) finally: if timeout is not None: timeout.cancel() send 首先拿到原生的socket(self._sock),然后调用socket.send发送数据，因为socket是非阻塞的，所以会立即抛出异常 EWOULDBLOCK，然后调用 self._wait(self._write_event), 等待可写事件发生后再次send数据。 1234567891011121314151617181920# ----- gevent _socket2.py -----class socket(object): def send(self, data, flags=0, timeout=timeout_default): sock = self._sock if timeout is timeout_default: timeout = self.timeout try: return sock.send(data, flags) except error as ex: if ex.args[0] != EWOULDBLOCK or timeout == 0.0: raise sys.exc_clear() self._wait(self._write_event) try: return sock.send(data, flags) except error as ex2: if ex2.args[0] == EWOULDBLOCK: return 0 raise recv send重试一次如果失败就会 return 0，而recv使用while循环，不停的尝试读数据，知道成功返回数据。 当有EWOULDBLOCK异常时，等待self._wait(self._read_event)可读事件发生，然后再次尝试读取数据。 1234567891011121314# ----- gevent _socket2.py -----class socket(object): def recv(self, *args): sock = self._sock # keeping the reference so that fd is not closed during waiting while True: try: return sock.recv(*args) except error as ex: if ex.args[0] != EWOULDBLOCK or self.timeout == 0.0: raise # QQQ without clearing exc_info test__refcount.test_clean_exit fails sys.exc_clear() self._wait(self._read_event) accept 同样是while循环，当接收连接成功时跳出循环，然后创建一个gevent socket对象（sockobj = socket(_sock=client_socket)）并返回。如果发生异常则阻塞等待可读事件发生（self._wait(self._read_event)）。 123456789101112131415161718# ----- gevent _socket2.py -----class socket(object): def accept(self): sock = self._sock while True: try: client_socket, address = sock.accept() break except error as ex: if ex.args[0] != EWOULDBLOCK or self.timeout == 0.0: raise sys.exc_clear() self._wait(self._read_event) sockobj = socket(_sock=client_socket) if PYPY: client_socket._drop() return sockobj, address gevent server BaseServer为服务器端实现了一些基础功能的抽象基类 StreamServer实现了通用TCPServer，在监听端口上接受新连接并为每个连接创建一个协程，协程函数是用户提供的。 分析Select，Poll部分的实现 12345678910111213141516from gevent import monkeyfrom gevent.server import StreamServermonkey.patch_all()def handler(sock, addr): while True: data = sock.recv(1024) if data: print data else: print addr, 'closed!' returnif __name__ == '__main__': server = StreamServer(('localhost', 12222), handler) server.serve_forever() StreamServer从StreamServer对象入手，其doc文档表明，这是一个通用的TCP Server，从监听的sock里接收连接，然后根据用户提供的handle回调函数spawn（生成，创建并运行greenlet）出协程。handle回调函数接收两个对象，socket连接和客户端地址。 backlog为服务器最大接收的连接数，默认为256. 只有服务器初始化，新创建socket时才需要在init里传入此参数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# ---- gevent server.py ------class StreamServer(BaseServer): """ A generic TCP server. Accepts connections on a listening socket and spawns user-provided *handle* function for each connection with 2 arguments: the client socket and the client address. """ # the default backlog to use if none was provided in __init__ backlog = 256 reuse_addr = DEFAULT_REUSE_ADDR def __init__(self, listener, handle=None, backlog=None, spawn='default', **ssl_args): BaseServer.__init__(self, listener, handle=handle, spawn=spawn) try: if ssl_args: # 初始化ssl参数 if backlog is not None: if hasattr(self, 'socket'): raise TypeError('backlog must be None when a socket instance is passed') self.backlog = backlog except: self.close() raise def set_listener(self, listener): BaseServer.set_listener(self, listener) try: self.socket = self.socket._sock except AttributeError: pass def init_socket(self): if not hasattr(self, 'socket'): self.socket = self.get_listener(self.address, self.backlog, self.family) self.address = self.socket.getsockname() if self.ssl_args: # 封装支持ssl socket的handle函数 self._handle = self.wrap_socket_and_handle else: self._handle = self.handle if PY3: def do_read(self): # 。。。 else: # 针对python2的 do_read函数 def do_read(self): try: client_socket, address = self.socket.accept() except _socket.error as err: if err.args[0] == EWOULDBLOCK: return raise sockobj = socket(_sock=client_socket) if PYPY: client_socket._drop() return sockobj, address def do_close(self, sock, *args): sock.close() def wrap_socket_and_handle(self, client_socket, address): # used in case of ssl sockets ssl_socket = self.wrap_socket(client_socket, **self.ssl_args) return self.handle(ssl_socket, address) BaseServer.__init__ 主要是初始化listener，spawn，handle， loop。 1234567891011121314151617# ----- BaseServer.__init__ ---- def __init__(self, listener, handle=None, spawn='default'): self._stop_event = Event() self._stop_event.set() self._watcher = None self._timer = None self._handle = None self.pool = None try: self.set_listener(listener) self.set_spawn(spawn) self.set_handle(handle) self.delay = self.min_delay self.loop = get_hub().loop except: self.close() raise server_forever() 是基类BaseServer里提供的方法，如果server没有启动，则启动(start方法)并ready for 接收数据，直至停止。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# ----- baseserver.py BaseServer ---- def serve_forever(self, stop_timeout=None): """Start the server if it hasn't been already started and wait until it's stopped.""" if not self.started: self.start() try: self._stop_event.wait() finally: Greenlet.spawn(self.stop, timeout=stop_timeout).join() def start(self): self.init_socket() self._stop_event.clear() try: self.start_accepting() except: self.close() raise def start_accepting(self): if self._watcher is None: self._watcher = self.loop.io(self.socket.fileno(), 1) self._watcher.start(self._do_read) def _do_read(self): for _ in xrange(self.max_accept): if self.full(): self.stop_accepting() return try: args = self.do_read() self.delay = self.min_delay if not args: return except: # 。。。。 else: try: self.do_handle(*args) except: self.loop.handle_error((args[1:], self), *sys.exc_info()) if self.delay &gt;= 0: self.stop_accepting() self._timer = self.loop.timer(self.delay) self._timer.start(self._start_accepting_if_started) self.delay = min(self.max_delay, self.delay * 2) break def do_read(self): raise NotImplementedError() def do_handle(self, *args): spawn = self._spawn handle = self._handle close = self.do_close try: if spawn is None: _handle_and_close_when_done(handle, close, args) else: spawn(_handle_and_close_when_done, handle, close, args) except: close(*args) raise start()方法 首先self.init_socket()初始化socket，用clear将self._stop_event停止事件设为false状态，然后调用self.start_accepting() 接收连接请求。 init_socket() init_socket由继承BaseServer的StreamServer实现,主要是获取socket和address，然后绑定handle方法，如果是ssl，则要先对handle方法进行ssl支持的封装。 123456789# --- server.py StreamServer ---- def init_socket(self): if not hasattr(self, 'socket'): self.socket = self.get_listener(self.address, self.backlog, self.family) self.address = self.socket.getsockname() if self.ssl_args: self._handle = self.wrap_socket_and_handle else: self._handle = self.handle self.start_accepting() 设置一个watcher进行事件监听，watcher绑定了_do_read()方法 _do_read()： 如果达到最大连接数，停止接收新连接， 否则执行do_read()方法 do_read()由子类实现，在StreamServer中的实现如下，就是通过self.socket.accept()获取socket连接对象，并返回gevent socket对象和客户端地址。 123456789101112# server.py StreamServerdef do_read(self): try: client_socket, address = self.socket.accept() except _socket.error as err: if err.args[0] == EWOULDBLOCK: return raise sockobj = socket(_sock=client_socket) if PYPY: client_socket._drop() return sockobj, address ​ 然后执行self.do_handle(*args)方法 self.do_handle(*args)方法调用的是_handle_and_close_when_done,这是个函数，不是类方法 _handle_and_close_when_done 函数主要是执行handle，并调用close关闭handle。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# ----- baseserver.py BaseServer ----def _handle_and_close_when_done(handle, close, args_tuple): # 6 try: return handle(*args_tuple) finally: close(*args_tuple)class BaseServer(object): def start_accepting(self): if self._watcher is None: self._watcher = self.loop.io(self.socket.fileno(), 1) self._watcher.start(self._do_read) # 1 def _do_read(self): # 1 for _ in xrange(self.max_accept): if self.full(): self.stop_accepting() # 2 return try: args = self.do_read() # 3 self.delay = self.min_delay if not args: return except: self.loop.handle_error(self, *sys.exc_info()) ex = sys.exc_info()[1] if self.is_fatal_error(ex): self.close() sys.stderr.write('ERROR: %s failed with %s\n' % (self, str(ex) or repr(ex))) return if self.delay &gt;= 0: self.stop_accepting() self._timer = self.loop.timer(self.delay) self._timer.start(self._start_accepting_if_started) self.delay = min(self.max_delay, self.delay * 2) break else: # 4 try: self.do_handle(*args) # 4 except: self.loop.handle_error((args[1:], self), *sys.exc_info()) if self.delay &gt;= 0: self.stop_accepting() self._timer = self.loop.timer(self.delay) self._timer.start(self._start_accepting_if_started) self.delay = min(self.max_delay, self.delay * 2) break def do_handle(self, *args): # 4 spawn = self._spawn handle = self._handle close = self.do_close try: if spawn is None: _handle_and_close_when_done(handle, close, args) # 5 else: spawn(_handle_and_close_when_done, handle, close, args) # 5 except: close(*args) raise ​ ​]]></content>
      <categories>
        <category>技术</category>
        <category>并发编程</category>
        <category>Gevent</category>
      </categories>
      <tags>
        <tag>gevent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python wordcloud生成词云]]></title>
    <url>%2F2017%2F11%2F05%2F%E6%8A%80%E6%9C%AF%2FPython%20wordcloud%E7%94%9F%E6%88%90%E8%AF%8D%E4%BA%91%2F</url>
    <content type="text"><![CDATA[Python wordcloud生成词云wordcloud官网，github 主要步骤： 安装wordcloud 创建WordCloud对象，定义生成词云的布局参数，如背景颜色，字体库、单词最大最小像素，词云图片长宽，最大单词数，随机配色种类，使用掩膜等 通过文本或统计好的词频生成词云，即将词按词频绘制到词云布局图片上。 显示、保存词云图片文件 WordCloud对象 创建时，传入配置参数，具体见doc string WordCloud(self, font_path=None, width=400, height=200, margin=2, ranks_only=None, prefer_horizontal=0.9, mask=None, scale=1, color_func=None, max_words=200, min_font_size=4, stopwords=None, random_state=None, background_color=&#39;black&#39;, max_font_size=None, font_step=1, mode=&#39;RGB&#39;, relative_scaling=0.5, regexp=None, collocations=True, colormap=None, normalize_plurals=True) 生成词云的函数 将词按对应的词频在词云布局图上生成图片，核心方法是generate_from_frequencies,不论是generate（）还是generate_from_text（）都最终用到generate_from_frequencies完成词云上各词的着色,默认是随机着色 示例代码 12345678910111213141516171819202122232425262728293031323334# 测试数据是豆瓣读书热门标签的词频all_words = &#123;u'\u5916\u56fd\u540d\u8457': 84857, u'\u793e\u4f1a\u5b66': 590925, u'\u52b1\u5fd7': 362798, u'\u7f8e\u672f': 33100, u'\u5fc3\u7406\u5b66': 1200006, u'\u8bd7\u8bcd': 70763, u'\u5916\u56fd\u6587\u5b66': 1716128, u'\u60c5\u611f': 72526, u'\u897f\u65b9\u54f2\u5b66': 61787, u'\u8bbe\u8ba1': 373956, u'web': 21242, u'\u6587\u5b66': 1344359, u'\u4eba\u6587': 111407, u'\u7535\u5f71': 222370, u'\u7406\u8d22': 97220, u'UCD': 3517, u'\u5f20\u5c0f\u5a34': 97471, u'\u7c73\u5170\xb7\u6606\u5fb7\u62c9': 50510, u'\u6e2f\u53f0': 6904, u'\u653f\u6cbb\u5b66': 195558, u'\u653f\u6cbb': 320641, u'\u843d\u843d': 58448, u'\u5546\u4e1a': 264136, u'\u8f7b\u5c0f\u8bf4': 137336, u'\u513f\u7ae5\u6587\u5b66': 209248, u'\u79d1\u5b66': 115359, u'\u9752\u6625\u6587\u5b66': 110718, u'\u65e5\u672c\u6f2b\u753b': 268990, u'\u5065\u5eb7': 73083, u'\u5b97\u6559': 230071, u'\u4ea6\u8212': 232463, u'\u9ad8\u6728\u76f4\u5b50': 71579, u'\u91d1\u878d': 247852, u'\u4eba\u7269\u4f20\u8bb0': 106837, u'\u79d1\u6280': 21923, u'\u827a\u672f\u53f2': 98192, u'\u81ea\u52a9\u6e38': 2635, u'\u7f51\u7edc\u5c0f\u8bf4': 194533, u'\u6559\u80b2': 181616, u'\u4ea4\u4e92': 4507, u'\u963f\u52a0\u838e\xb7\u514b\u91cc\u65af\u8482': 140070, u'\u6751\u4e0a\u6625\u6811': 410205, u'\u94b1\u949f\u4e66': 97394, u'\u9c81\u8fc5': 81995, u'\u9b54\u5e7b': 108292, u'\u521b\u4e1a': 101110, u'\u8bd7\u6b4c': 292956, u'\u5fc3\u7406': 337962, u'\u4e2d\u56fd\u5386\u53f2': 150383, u'\u7b56\u5212': 7865, u'\u8328\u5a01\u683c': 58270, u'\u60ac\u7591': 427890, u'\u519b\u4e8b': 64337, u'\u5c0f\u8bf4': 4836526, u'\u7ba1\u7406': 373936, u'\u4eba\u9645\u5173\u7cfb': 32141, u'\u97e9\u5bd2': 261086, u'\u7ae5\u8bdd': 274365, u'\u79d1\u5e7b\u5c0f\u8bf4': 118837, u'\u5f53\u4ee3\u6587\u5b66': 124970, u'\u5973\u6027': 260571, u'\u4e8c\u6218': 61933, u'\u6444\u5f71': 274433, u'\u56de\u5fc6\u5f55': 155101, u'\u6742\u6587': 204031, u'\u624b\u5de5': 39266, u'\u8a00\u60c5': 467793, u'\u80a1\u7968': 57220, u'\u4f20\u8bb0': 706782, u'\u56fd\u5b66': 131244, u'\u4e2d\u56fd\u6587\u5b66': 914012, u'\u804c\u573a': 191402, u'\u5386\u53f2': 1831830, u'\u601d\u60f3': 140789, u'\u7a0b\u5e8f': 1228, u'\u7528\u6237\u4f53\u9a8c': 51529, u'\u4e1c\u91ce\u572d\u543e': 495900, u'\u5e7f\u544a': 61104, u'\u6f2b\u753b': 1203437, u'\u968f\u7b14': 1037335, u'\u63a8\u7406': 852405, u'\u4e09\u6bdb': 197016, u'\u8fd1\u4ee3\u53f2': 58041, u'\u620f\u5267': 96981, u'\u4f5b\u6559': 65193, u'\u7ecf\u6d4e\u5b66': 382231, u'UE': 4894, u'\u901a\u4fe1': 4556, u'\u6b66\u4fa0': 297293, u'\u795e\u7ecf\u7f51\u7edc': 2175, u'\u6e38\u8bb0': 142629, u'\u5b89\u59ae\u5b9d\u8d1d': 172265, u'\u793e\u4f1a': 339416, u'\u8425\u9500': 139198, u'\u54f2\u5b66': 998389, u'\u6570\u5b66': 200099, u'\u7a7f\u8d8a': 147747, u'\u53e4\u9f99': 72338, u'\u6295\u8d44': 198723, u'\u5efa\u7b51': 253809, u'\u6ca7\u6708': 65008, u'\u4e24\u6027': 37553, u'\u79d1\u5e7b': 474318, u'\u97f3\u4e50': 110843, u'\u6210\u957f': 439250, u'\u81ea\u7531\u4e3b\u4e49': 41215, u'\u9752\u6625': 615963, u'\u4f01\u4e1a\u53f2': 18254, u'\u7f16\u7a0b': 143976, u'\u79d1\u666e': 503806, u'\u4ea4\u4e92\u8bbe\u8ba1': 64467, u'\u5947\u5e7b': 297252, u'\u63a8\u7406\u5c0f\u8bf4': 222021, u'\u675c\u62c9\u65af': 42901, u'\u5f20\u7231\u73b2': 181350, u'\u4f59\u534e': 184440, u'\u91d1\u5eb8': 143676, u'\u5e7e\u7c73': 97562, u'\u90ed\u656c\u660e': 152101, u'\u7231\u60c5': 787234, u'\u751f\u6d3b': 465841, u'\u7ed8\u672c': 838757, u'\u738b\u5c0f\u6ce2': 206659, u'\u517b\u751f': 33840, u'\u8003\u53e4': 45231, u'\u7ed8\u753b': 100734, u'\u540d\u8457': 195566, u'\u7075\u4fee': 117161, u'\u6587\u5316': 646049, u'\u827a\u672f': 436899, u'\u65e5\u672c\u6587\u5b66': 722390, u'J.K.\u7f57\u7433': 82487, u'\u6821\u56ed': 56805, u'\u51e0\u7c73': 114200, u'\u7b97\u6cd5': 47242, u'\u53e4\u5178\u6587\u5b66': 207377, u'\u7ecf\u5178': 800417, u'\u7ecf\u6d4e': 303485, u'\u5bb6\u5c45': 20761, u'\u5f20\u60a6\u7136': 57515, u'\u6563\u6587': 631865, u'\u4e92\u8054\u7f51': 216614, u'\u65c5\u884c': 540931, u'\u7f8e\u98df': 179070, u'\u803d\u7f8e': 239324&#125;from wordcloud import WordCloud, ImageColorGeneratorimport matplotlib.pyplot as pltfrom scipy.misc import imreadimport numpy as npfrom PIL import Image# background_mask = np.array(Image.open(r'ssss.png'))background_mask = imread(r'ssss.png') # 掩膜图片，词云生成按照其形状在非白色区域显示单词wc = WordCloud( font_path=r'C:\Windows\Fonts\simfang.ttf', # 设置字体格式，支持中文 width=2400, height=2400, margin=2, background_color='white', # 白色背景 mask=background_mask, # 背景形状的掩膜 max_font_size = 50, # 设置字体最大值 random_state = 30, # 设置有多少种随机生成状态，即有多少种配色方案 max_words=2000,# 词云显示的最大词数)wc = wc.generate_from_frequencies(all_words)# all_words为字典, &#123;'word': freq_num&#125;# 中文乱码需要指定中文字体路径# 根据指定的图片生成词云颜色image_colors = ImageColorGenerator(background_mask)# 显示图片plt.axis('off')plt.imshow(wc.recolor(color_func=image_colors))plt.show()# 保存图片wc.to_file('tags.png')]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>WordCloud</tag>
        <tag>词云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gevent 实现网络爬虫]]></title>
    <url>%2F2017%2F11%2F04%2F%E6%8A%80%E6%9C%AF%2FGevent%E7%88%AC%E8%99%AB%E4%B8%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[Gevent爬虫与多线程爬虫对比爬虫通用网页解析模块 网页字符集检测 根据指定规则解析数据 url处理子模块 能够抽取页面中所有的url以供后续爬取 抽取的url过滤处理，如图片，文件等url肯定不需要递归爬取 抽取的url分类http 和 https 判断url中是否有非法字符 Gevent爬虫 每个任务是一个url object，存储url，页面深度等信息 1234class UrlObject(object): def __init__(self, url, depth): self.url = url self.depth = depth 使用greenlet来执行下载网页、解析内容、feed url的任务,任务从队列里获取 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Handler(Greenlet): # urlObj：任务对象；spider爬虫对象；setting爬虫的设置信息 def __init__(self, urlObj, spider, settings): super(Handler, self).__init__() self.url_obj = urlObj self.spider = spider self.settings = settings # 下载html def download(self, url): print u'开始下载：', url res = requests.get(url) text = res.text print u'下载完成！' return text # 从html中发掘新的任务url def feed(self, html): soup = BeautifulSoup(html, 'lxml') urls = [i.get('href') for i in soup.select('a[href^="http"]')] return urls # 从Html中提取数据 def parse_html(self, html): soup = BeautifulSoup(html, 'lxml') title = soup.find('title') print title.text if title else '' # 处理文本也可以用greenlet对象 pass def _run(self): if not hash(self.url_obj.url) in self.spider.finished_set: # 如果没下载过该网页，则下载，并处理 html = self.download(self.url_obj.url) # 加入已处理的集合 self.parse_html(html) self.spider.finished_set.add(hash(self.url_obj.url)) # 页面深度+1 depth = self.url_obj.depth + 1 # 发现新的url任务,如果没被执行就加入到任务队列 for url in self.feed(html): if not hash(url) in self.spider.finished_set: url_obj = UrlObject(url, depth) self.spider.queue.put(url_obj) pool控制greenlet的并发 使用threading的Timer计时器来控制主线程，当计时结束，结束爬虫。 pool.join() 等待pool里的greenlet结束。 timer.cancel 跳出spider调度的主循环的条件 任务调度的主循环内，判断timer的状态，如果timer是激活状态，则执行任务。否则跳出循环，程序结束。 12345678910111213141516171819202122232425262728293031323334353637383940414243class GeventSpider(object): def __init__(self, root_url, max_depth=5, max_count=100, concurrancy=5, live_time=60*12): monkey.patch_all() self.setting = dict(zip(['root_url', 'max_depth', 'max_count', 'concurrancy', 'live_time'], [root_url, max_depth, max_count, concurrancy, live_time])) self.queue = Queue() self.pool = Pool(concurrancy) self.timer = Timer(live_time, self.stop_spider) self.finished_set = set() # 将种子任务添加到队列 self.queue.put(UrlObject(root_url, 0)) def stop_spider(self): # 将timer取消，则 _run_loop就会跳出循环，主线程结束 self.timer.cancel() # 等待协程池里的所有greenlet结束后，程序结束 self.pool.join() def run(self): self.timer.start() self._run_loop() # 任务执行部分 def _run_loop(self): page_count = 0 while self.timer.is_alive(): # 从pool中踢出执行完毕的greenlet for greenlet in list(self.pool): if greenlet.dead: self.pool.discard(greenlet) try: url_obj = self.queue.get(timeout=5) except Empty: continue # 创建执行下载任务的greenlet对象 # 这里传入的spider对象为self自己 self.pool.start(Handler(url_obj, self, self.setting)) # 爬取数量+1，如果超过所需结果，则调用stop page_count += 1 print '已下载%d个网页' %page_count if page_count &gt;= self.setting['max_count']: print u'下载网页数量达到最大值' self.stop_spider() 完整代码： requests库不是异步的，因此monkey patch 前后的执行时间分别为44s和11s。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130#!/usr/bin/env python# -*- coding:utf-8 -*-# @File : gspider.py# @Author: Shuaiyy# @Date : 2017/10/31 15:45# @Desc : import geventfrom gevent.queue import Queue, Emptyfrom gevent import monkey, Greenletfrom gevent.pool import Poolfrom threading import Timerimport requestsfrom bs4 import BeautifulSoupclass UrlObject(object): def __init__(self, url, depth): self.url = url self.depth = depth class Handler(Greenlet): def __init__(self, urlObj, spider, settings): super(Handler, self).__init__() self.url_obj = urlObj self.spider = spider self.settings = settings # 下载html def download(self, url): print u'开始下载：', url res = requests.get(url) text = res.text print u'下载完成！' return text # 从html中发掘新的任务url def feed(self, html): soup = BeautifulSoup(html, 'lxml') urls = [i.get('href') for i in soup.select('a[href^="http"]')] return urls # 从Html中提取数据 def parse_html(self, html): soup = BeautifulSoup(html, 'lxml') title = soup.find('title') print title.text if title else '' # 处理文本也可以用greenlet对象 pass def _run(self): if not hash(self.url_obj.url) in self.spider.finished_set: # 如果没下载过该网页，则下载，并处理 html = self.download(self.url_obj.url) # 加入已处理的集合 self.parse_html(html) self.spider.finished_set.add(hash(self.url_obj.url)) # 页面深度+1 depth = self.url_obj.depth + 1 # 发现新的url任务,如果没被执行就加入到任务队列 for url in self.feed(html): if not hash(url) in self.spider.finished_set: url_obj = UrlObject(url, depth) self.spider.queue.put(url_obj)class GeventSpider(object): def __init__(self, root_url, max_depth=5, max_count=100, concurrancy=5, live_time=60*12): monkey.patch_all() self.setting = dict(zip(['root_url', 'max_depth', 'max_count', 'concurrancy', 'live_time'], [root_url, max_depth, max_count, concurrancy, live_time])) self.queue = Queue() self.pool = Pool(concurrancy) self.timer = Timer(live_time, self.stop_spider) self.finished_set = set() # 将种子任务添加到队列 self.queue.put(UrlObject(root_url, 0)) def stop_spider(self): # 将timer取消，则 _run_loop就会跳出循环，主线程结束 self.timer.cancel() # 等待协程池里的所有greenlet结束后，程序结束 self.pool.join() def run(self): self.timer.start() self._run_loop() # 任务执行部分 def _run_loop(self): page_count = 0 while self.timer.is_alive(): # 从pool中踢出执行完毕的greenlet for greenlet in list(self.pool): if greenlet.dead: self.pool.discard(greenlet) try: url_obj = self.queue.get(timeout=5) except Empty: continue # 创建执行下载任务的greenlet对象 # 这里传入的spider对象为self自己 self.pool.start(Handler(url_obj, self, self.setting)) # 爬取数量+1，如果超过所需结果，则调用stop page_count += 1 print '已下载%d个网页' %page_count if page_count &gt;= self.setting['max_count']: print u'下载网页数量达到最大值' self.stop_spider()class MySpider(object): def __init__(self, max_depth, max_count, root_url): self.spider = GeventSpider(max_dept h=max_depth, max_count=max_count, root_url=root_url) def run(self): self.spider.run()if __name__ == '__main__': root_url = 'http://www.csdn.com' max_depth, max_count = 3, 100 import time t1 = time.time() MySpider(max_depth, max_count, root_url).run() print time.time() - t1 # 44.4679999352 # 11.4879999161 多线程爬虫基本逻辑：不停的往任务队列里添加url任务，从队列取出任务，创建任务线程添加到线程池，将完成的任务线程从线程池移除。根据条件控制线程并发，停止。注意多线程的同步锁问题。 多线程必须要考虑同步的问题，要使用Lock python 内置的线程池没有实现pool，可以使用第三方的threadpool或者自己实现 计算pool的长度，往pool里添加线程，从队列里移除线程时，必须加锁 检查url是否重复时，需要lock python的Queue对象是线程安全的，向队列里添加，获取任务无需加锁。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111# 爬虫主线程class ThreadSpider(object): def __init__(self, max_depth, max_count, root_url): self.strategy = Strategy(max_depth, max_count) self.queue = Queue() # 任务队列 self.url_set = set() # url去重的集合 self.handler_num = 0 self.lock = Lock() self.thread_lock = Lock() self.thread_pool = &#123;&#125; self.thread_id = 0 self.is_stop = False # 停止爬虫 self.thread_num = 0 self.currency_limit = False # 停止往pool里添加线程 self.last_data = None obj = UrlObject(root_url, 0) self.put(obj) def put(self, obj): # 添加任务前，判断去重 hash_val = hash(obj.url) self.lock.acquire() res = hash_val in self.url_set # 操作集合时加锁 self.lock.release() if res: return self.url_set.add(hash_val) self.queue.put(obj) def _run_loop(self): while True: if self.is_stop: time.sleep(1) continue if self.currency_limit: # 如果达到并发上限，则线程sleep 1s后在判断pool是否已满 time.sleep(1) self.thread_lock.acquire() # 操作pool要上锁 self.thread_num = len(self.thread_pool) if self.thread_num == self.strategy.concurrency: self.thread_lock.release() continue else: self.currency_limit = False self.thread_lock.release() else: # 没有达到并发上限，则从队列获取任务，创建新的子线程 try: url = self.queue.get() except: continue # 创建任务子线程，并发子线程对象放入pool队列里 self.thread_id = self.thread_id+1 thd = Handler(url, self, self.thread_id) self.thread_lock.acquire() self.thread_pool[self.thread_id] = thd # 判断pool是否已满 if len(self.thread_pool) == self.strategy.concurrency: self.currency_limit = True self.thread_lock.release() self.thread_num = self.thread_num+1 print "add thread ", self.thread_id thd.start() # 运行线程 self.handler_num = self.handler_num+1 if self.strategy.max_count &lt;= self.handler_num: print "handler num %d is full so stop " % self.handler_num self.is_stop = True def remove_thread(self, thd_id): # 当任务线程执行完毕时，调用该方法 self.thread_lock.acquire() if thd_id in self.thread_pool: del self.thread_pool[thd_id] print "del threadid ", thd_id self.thread_lock.release() def run(self): self._run_loop()# 执行下载任务的线程对象class Handler(Thread): def __init__(self, urlobj, spider, thd_id): Thread.__init__(self) print "begin thread %d with url %s" %(thd_id, urlobj.url) self.urlobj= urlobj self.spider = spider self.thread_id = thd_id self.charset = "utf-8" def run(self): try : html = self.open(self.urlobj.url) except Exception,why: return depth = self.urlobj.depth + 1 if depth &gt; self.spider.strategy.max_depth: return # 生成新的任务放入任务队列 for link in self.feed(html): if hash(link) in self.spider.url_set: continue url = UrlObject(link, depth) self.spider.put(url) # 任务线程到此结束，调用从pool移除线程的方法 self.spider.remove_thread(self.thread_id) def open(self, url): '''下载，处理网页''' return resp.text def feed(self, html): '''挖掘新的url任务''' return urls]]></content>
      <categories>
        <category>技术</category>
        <category>并发编程</category>
        <category>Gevent</category>
      </categories>
      <tags>
        <tag>gevent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gevent 学习笔记]]></title>
    <url>%2F2017%2F11%2F01%2F%E6%8A%80%E6%9C%AF%2FGevent%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[python Gevent 进程、线程、协程 python 中的yield提供对协程的有限支持。 进程 正在运行的程序的实例 具有独立地址空间 是操作系统资源分配的基本单位 进程上下文： 进程的物理实体与支持进程运行的物理环境，包括地址空间，系统栈，打开文件表，…… 上下文切换：由一个进程的上下文转到另外一个进程的上下文 系统开销：操作系统完成系统管理工作所花费的时间和空间 一个进程可以包含多个线程 线程 线程是程序执行的最小单位 多线程可以提高程序的并发性 由于python的GIL机制，一个进程只能使用一个cpu核心，因此多线程并不适合解决CPU密集的运算，此时应该使用多进程。 协程 可以认为是一种用户态的线程 线程是由系统调度，而协程需要主动让出CPU时间，即控制权在程序员手中 线程里可以包含多个协程 优缺点 进程创建和销毁成本高 线程开销比进程低，但切换成本高，线程间同步复杂 协程在不陷入内核的情况下进行上下文切换，没有同步问题，但需要手动切换。 简单示例 进程与进程池 要注意，进程的开销很大 123456789101112131415161718192021222324252627#!/usr/bin/env python# -*- coding:utf-8 -*-import multiprocessingimport timedef hello(name): # print threading.currentThread().getName() print multiprocessing.current_process().name print name time.sleep(1)def process1(): print multiprocessing.current_process().name # thread1 = threading.Thread(target=hello, args=['a']) # thread1.start() # thread1.join() processes = [ multiprocessing.Process(target=hello, args=(x,)) for x in 'abcde'] for p in processes: p.start() p.join()def process2(): print multiprocessing.current_process().name pool = multiprocessing.Pool(10) result = pool.map(hello,[x for x in 'abcde']) # result是子进程返回的结果，顺序不定 pool.close() # 关闭进程池，不在接收新的进程加入 pool.join() # 主进程阻塞，等该子进程的退出 if name == ‘main‘: start_time = time.time() process1() print &apos;finished time: %d&apos; %(time.time() - start_time) start_time = time.time() process2() print &apos;finished time: %d&apos; %(time.time() - start_time) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 ​+ 线程与线程池 threadpool是第三方模块，要注意python的GIL机制，CPU密集任务不要使用多进程 ```python #!/usr/bin/env python # -*- coding:utf-8 -*- import threading import threadpool import time def hello(name): print threading.currentThread().getName() print name time.sleep(1) # 线程，按顺序执行 def func1(): print threading.currentThread().getName() # thread1 = threading.Thread(target=hello, args=[&apos;a&apos;]) # thread1.start() # thread1.join() threads = [ threading.Thread(target=hello, args=[x]) for x in &apos;abcde&apos;] for thread in threads: thread.start() thread.join() # 线程池，并发执行，理论上效率更高 def func2(): # pip install thradpool print threading.currentThread().getName() pool = threadpool.ThreadPool(10) requests = threadpool.makeRequests(hello,[x for x in &apos;abcde&apos;]) for req in requests: pool.putRequest(req) pool.wait() if __name__ == &apos;__main__&apos;: start_time = time.time() func1() print &apos;finished time: %d&apos; %(time.time() - start_time) start_time = time.time() func2() print &apos;finished time: %d&apos; %(time.time() - start_time) 协程 12 ​ 网络IO阻塞和非阻塞 阻塞调用是指在调用结果返回之前，当前线程会被挂起。函数只有在得到结果之后才会返回 非阻塞是指在不能立即得到结果之前，函数不会阻塞当前进程，而是立即返回。 网络IO阻塞 网络IO主要指socket socket会在connect/read/write时发生阻塞 连接时阻塞 接收数据时阻塞 ​ 非阻塞模型 接收数据非阻塞模型 非阻塞面临的问题 非阻塞的socket连接要捕获处理相应的异常 使用select判断socket是否可读写 或者捕获非阻塞的exception，不断重试发送、读取数据 123456import loggingimport timeimport errnoimport sysimport socketimport select logger = logging.getLogger(‘Client’)console_handler = logging.StreamHandler(sys.stdout)format = logging.Formatter(‘%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s: %(message)s’, &apos;%Y-%m-%d %H:%M:%S&apos;) console_handler.setFormatter(format)logger.addHandler(console_handler)logger.setLevel(logging.DEBUG) if name == ‘main‘: ip = ‘localhost’ port = 13518 logger.debug(‘creating socket’) s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) logger.debug(‘connecting to server’) s.setblocking(0) # 设置成非阻塞 try: s.connect((ip, port)) # 非阻塞下，立即返回，此时不一定建立好连接 except socket.error, msg: if msg[0] not in [errno.EINPROGRESS, errno.EWOULDBLOCK]: # 如果不是正在连接,或者数据阻塞 exit(1) # 使用select判断socket是否可写，即发送数据 while True: ready_to_read, read_to_write, in_error = select.select([], [s,], [], 0.001) if read_to_write: break message = &apos;Hello, world&apos; logger.debug(&apos;sending data: &quot;%s&quot;&apos;, message) while True: try: len_sent = s.send(message) break except socket.error, msg: # Eagain Linux下，缓冲区数据不可用，请重试。数据还在准备中 # EWouldBlock， Windows下，缓冲区数据不可用，请重试。数据还在准备中 if msg[0] not in [errno.EWOULDBLOCK, errno.EAGAIN]: print 1 exit(1) # Receive a response logger.debug(&apos;waiting for response&apos;) while True: try: response = s.recv(len_sent) break except socket.error, msg: if msg[0] not in [errno.EWOULDBLOCK, errno.EAGAIN]: logger.exception(&apos;recv error&apos;) exit(1) logger.debug(&apos;response from server: &quot;%s&quot;&apos;, response) # Clean up logger.debug(&apos;closing socket&apos;) s.close() logger.debug(&apos;done&apos;) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495 ​### 同步异步+ 同步：发生调用时，一定等待结果返回整个调用才结束+ 异步：调用发生后，立即返回，不用等待结果。被调用者通过状态、通知来告知调用者，或者通过回调函数来处理这个调用。#### 实例：异步查询数据库+ 主线程将查询任务交给逻辑线程处理+ 使用队列Queue来实现同步+ Queue中存放任务对象task_item，task_item包含任务所需数据，任务执行结果等，完成任务后回调函数等+ 逻辑线程执行数据库查询操作后，2种处理方式 + 将task_item交由主线程处理 使用全局变量Queue保存task_item,并在主线程中处理 + 在子线程中直接调用task_item回调函数处理结果​```python#!/usr/bin/env python# -*- coding:utf-8 -*-# @File : redis_client.py# @Author: Shuaiyy# @Date : 2017/10/27 9:44# @Desc : import sysimport timeimport redisfrom threading import Thread, current_threadfrom queue import Queuemain_queue = Queue(maxsize=1024) # 为了在主线程中同步task_itemdef handle_res(res): # 处理结果的回调函数，只是打印结果 print current_thread().getName() print &quot;获取到data：&quot; + str(res) class GetValueTask(object): # task_item对象，保存数据，回调函数和任务结果 result = None def __init__(self, key, handler): self.key = key self.callback = handlerclass RedisAsyncGet(Thread): def __init__(self): super(RedisAsyncGet, self).__init__() self.r = redis.Redis(&apos;localhost&apos;, 6379, 0, password=&apos;mima&apos;) self.queue = Queue(maxsize=1024) def get_value_cmd(self, key): task_item = GetValueTask(key, handle_res) self.queue.put(task_item) def run(self): while True: if not self.queue.empty(): # 获取任务 task_item = self.queue.get() # 执行任务，得到结果 res = self.r.get(task_item.key) # 直接在子线程中调用回调函数处理结果 task_item.callback(res) # 将任务放到全局队列中，以便主线程处理task_item task_item.result = res main_queue.put(task_item) time.sleep(0.1) # 避免cpu空转在多if __name__ == &apos;__main__&apos;: handle = RedisAsyncGet() handle.start() handle.get_value_cmd(&apos;a&apos;) handle.get_value_cmd(&apos;test&apos;) # handle.join() # # 下面是主线程中处理task_item的返回结果 while True: if not main_queue.empty(): task_item = main_queue.get() res = task_item.result task_item.callback(res) time.sleep(0.1) 同步异步与阻塞非阻塞的区别 阻塞/非阻塞，描述的是程序在等待消息（不管是同步消息还是异步消息）是的状态。 同步/异步, 描述的是程序获得其关注消息的通知机制。 同步异步与阻塞非阻塞的组合 同步阻塞：效率最低 同步非阻塞：效率也低，需要伦旭 异步阻塞：一般模式的线程回调 异步非阻塞：IOCP机制，难度高，一般用的少 并发和并行并发•并发是指两个或多个事件在同一时间间隔发生。就是同时处理很多事情，比如串行同时处理一件事情。 •在单核系统中，为了提高cpu利用率，系统采用时间片轮询等调度方式，对多个线程轮换执行，在宏观上看，线程是同时执行的，从微观上看，某一时刻只执行一个线程。 在发生资源竞争或者大量的上下文切换会导致性能消耗 。 并行 并行是同时处理多件事情。 比如线程可以真正的做到同一时刻多个运行，每个线程可以在不同的CPU核上运行。 greenlet实现并发 greenlet是stacklesspython（支持微线程tasklet的CPython版本）的副产品。Tasklet以伪并发运行着（如果在单个或者很少的系统级线程内） greenlet是一个原始的微线程的概念，没有调度，可以称为协程。所以green需要自己调度。 如果有阻塞调用，将greenlet主动切换出去。 单个线程内可以运行任意哥greenlet微线程，不同线程之间不能切换greenlet。 pip install greenlet 123456789101112131415161718192021import threadingfrom greenlet import greenletdef test1(): print threading.current_thread().getName() print '1' g2.switch() print "2" g2.switch()def test2(): print threading.current_thread().getName() print '3' g1.switch() print "4"if __name__ == '__main__': g1 = greenlet(test1) g2 = greenlet(test2) g1.switch() # 输出：1324 Gevent简介 gevent是一个基于libev和greenlet的并发库。它为各种并发和网络相关的任务提供了整洁的API。libev是高性能事件循环/事件模型的网络库，并且包含大量新特性。 Python通过yield提供了对协程的基本支持，但是不完全。而第三方的gevent为Python提供了比较完善的协程支持。 gevent是第三方库，通过greenlet实现协程，其基本思想是： 当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。 由于切换是在IO操作时自动完成，所以gevent需要修改Python自带的一些标准库，这一过程在启动时通过monkey patch完成。 Gevent特点 Gevent之Greenlet对象 继承greetlet Greentlet(run=None, args, *kwargs)创建一个greenlet greenlet.start()将greenlet置入geventIO调度内 greenlet.spawn(args,*kwargs) 创建greenlet，并运行start greenlet.kill()杀死greenlet greenlet间的切换由,gevent.sleep()方法交出控制权，然后由gevent进行调度协程 下面程序的输出顺序为1,2,,1-1,2-1 1234567891011121314151617181920212223242526272829303132import threadingimport geventfrom gevent import Greenletdef run_in_greenlet1(arg_x): print threading.current_thread().getName() print '1' , arg_x gevent.sleep(0) print "1-1" , arg_xdef run_in_greenlet2(arg_x): print threading.current_thread().getName() print '2' , arg_x gevent.sleep(0) print "2-1" , arg_xif __name__ == '__main__': g1 = Greenlet(run_in_greenlet1, '这是参数') g2 = Greenlet(run_in_greenlet2, '这是参数') g1.start() g2.start() # 构造和启动可以由spawn函数实现 # g1 = gevent.spawn(run_in_greenlet1, '参数') g1.join() g2.join() # 可以一次join多个greenlet # gevent.joinall([g1, g2]) # 更为简洁的写法 gevent.joinall([gevent.spawn(run_in_greenlet1) , gevent.spawn(run_in_greenlet2)]) Greenlet状态与超时处理超时处理当协程对运行时间有要求时，可以设置Timeout计时器，超时的协议会引发timeout异常 gevent.Timeout(seconds, exception)，没有指定exception时，超时会抛出gevent.Timeout。 1234567891011121314151617181920212223def run_in_greenlet1(arg_x): print '1' , arg_x gevent.sleep(5) # 强制协程等待5秒，使用time.sleep无效 print "1-1" , arg_xif __name__ == '__main__': # 或者使用with上下文管理器 max_time = 2 try: with gevent.Timeout(max_time, Exception("超时了")): gevent.spawn(run_in_greenlet1, '参数').join() except gevent.Timeout: print 'timeout' except Exception as e: print e.message # 或者调用timeout对象的start方法 max_time = 2 timeout = gevent.Timeout(max_time) timeout.start() try: gevent.spawn(run_in_greenlet1, '参数').join() except gevent.Timeout : print 'timeout' 状态 started– Boolean, 指示此Greenlet是否已经启动 ready()– Boolean, 指示此Greenlet是否已经停止 successful()– Boolean, 指示此Greenlet是否已经停止而且没抛异常，即运行成功 value– 任意值, 此Greenlet代码返回的值 exception– 异常, 此Greenlet内抛出的未捕获异常 定制Greentlet进行数据管理，超时设置等。 1234567891011121314class MyGreenlet(Greenlet): def __init__(self, message, timeout=2): super(MyGreenlet, self).__init__() self.message = message self.timeout = gevent.Timeout(timeout) # 这里重载了run方法，因此可以不必在构造对象时传入回调函数 def _run(self): self.timeout.start() print self.message if __name__ == '__main__': g1 = MyGreenlet('hello', timeout=3) g1.start() g1.join() Event对象，协程间同步如果不用event事件通知，可以用全局变量进行消息传递，但全局变量会有很多问题，同步不安全，浪费cpu资源等。 windows中有Events，作为线程间同步的方法 Gevent中则是Greenlet间“同步”的一种方法 使用方法 Event对象 AsyncResult可以传递任意类型的数据 1234567891011121314151617181920212223242526from gevent.event import Event, AsyncResultevt1 = Event()evt2 = AsyncResult()def boss(): global evt1, evt2 print 'start to work!' tasklist = dict(zip(range(3), 'abc')) evt2.set(tasklist) gevent.sleep(5) print 'time to relax!' evt1.set()def worker(n): global evt1, evt2 tasklist = evt2.get(timeout=2) print '%d is working task %s!' %(n, tasklist[n]) evt1.wait() print '%d stop working!' %nif __name__ == '__main__': b = Greenlet(boss) b.start() gevent.joinall([gevent.spawn(worker, i) for i in range(3)]) b.join() Queue对象，实现通信python内置的Queue Queue（队列），用于存取数据的有序数据结构。Queue(先进先出)，LifoQueue(先进后出)和PriorityQueue(优先级队列) Queue模块实现了多生产者、多消费者队列。它特别适用于信息必须在多个线程间安全地交换的多线程程序中。这个模块中的Queue 类实现了所有必须的锁语义。 模块实现了三类队列，主要差别在于取得数据的顺序上。FIFO队列中，最早加入的任务会被最先得到。LIFO队列中，最后加入的任务会被最先得到（就像栈一样）。在优先队列中，任务被保持有序，拥有最小值的任务（优先级最高）被最先得到。 虽然线程安全，但同步线程开销 Gevent中的Queue 无线程同步开销，但有Greenlet之间的线程内同步，无法线程间操作。 注意queue是否为空 12345678910111213141516171819202122232425262728from gevent.queue import Queue, LifoQueue, PriorityQueue, Emptytasks_queue = Queue()def boss(): for i in xrange(30): tasks_queue.put_nowait(i) # put_nowait不用判断队列是否满了，直接入队。因为此处的queue没指定大小 # tasks_queue.put(i) 如果对满了，会等待。def worker(name): while True: while not tasks_queue.empty(): task = tasks_queue.get(timeout=2) # 如果没有数据会阻塞，因此设置超时时间，并捕获错误 print 'worker %s got task %d' %(name, task) gevent.sleep(0) gevent.sleep(1) # 捕获队列为空的异常 try: while True: task = tasks_queue.get(timeout=0.1) except gevent.queue.Empty: print 'quit'if __name__ == '__main__': gevent.joinall([gevent.spawn(boss),].extend(gevent.spawn(worker, name) for name in 'abcde')) # gevent.joinall([gevent.spawn(worker, name) for name in 'abcde'].append(gevent.spawn(boss))) 优先级队列 123456789101112131415161718192021222324252627282930313233343536373839from gevent.queue import Queue, LifoQueue, PriorityQueue, Emptyclass Job(object): def __init__(self, no, priority, desc): self.priority = priority self.desc = desc self.no = no def __cmp__(self, other): return cmp(self.priority, other.priority) def __str__(self): return 'Job %d:: %d :: %s' %(self.no, self.priority, self.desc)tasks_queue = PriorityQueue()def boss(): for i in xrange(30): tasks_queue.put_nowait(Job(i, 30 - i, str(i)*5)) # put_nowait不用判断队列是否满了，直接入队。因为此处的queue没指定大小 # tasks_queue.put(i) 如果对满了，会等待。def worker(name): while True: while not tasks_queue.empty(): task = tasks_queue.get(timeout=2) # 如果没有数据会阻塞，因此设置超时时间，并捕获错误 print task gevent.sleep(0) gevent.sleep(1) # 捕获队列为空的异常 try: while True: task = tasks_queue.get(timeout=0.1) except gevent.queue.Empty: print 'quit'if __name__ == '__main__': gevent.joinall([gevent.spawn(boss),].extend(gevent.spawn(worker, name) for name in 'abcde')) 自定义一个Queue 随机取出的队列 12345678910111213141516from gevent.queue import Queue, LifoQueue, PriorityQueue, Emptyimport randomclass RandomQueue(Queue): def _init(self, maxsize, items=None): self.queue = [] def _put(self, item): self.queue.append(item) def _get(self): return self.queue.pop(random.randint(0, len(self.queue) - 1))q = RandomQueue()for i in range(10): q.put(i)for i in range(10): print q.get() Greenlet间同步机制semaphore(信号量) 信号量是一个允许Greenlet相互合作，限制并发访问或运行的低层次的同步原语。信号量也被称为锁。 信号量有两个方法，acquire和release。在信号量是否已经被acquire或release，和拥有资源的数量之间不同,被称为此信号量的范围。 如果一个信号量的范围已经降低到0，它会阻塞acquire操作直到另一个已经获得信号量的greenlet作出释放。 1234567891011121314151617181920212223import geventfrom gevent.pool import Poolfrom gevent.lock import BoundedSemaphoresem = BoundedSemaphore(1)def worker1(n): sem.acquire() print('worker %d acquire sem' %n) gevent.sleep(0) sem.release() print('woker %d release sem' %n)def worker2(n): # 可以用with上下文管理器 with sem: print('worker %d acquire sem' %n) gevent.sleep(0) print('woker %d release sem' %n)pool = Pool()pool.map(worker2, xrange(0,5))pool.join() Greenlet管理Group Group是一个运行中Greenlet的集合，集合中的Greenlet会像一个组一样被共同管理和调度。 API：add,join,kill,killone,map 1234567891011121314151617from gevent.pool import Pool, Groupif __name__ == '__main__': print 1 group = Group() group.add(gevent.spawn(run_in_greenlet1, 'a')) group.add(gevent.spawn(run_in_greenlet1, 'b')) group.add(gevent.spawn(run_in_greenlet1, 'c')) # map方法 group.map(run_in_greenlet1, 'defg') group.join() # imap生成的是迭代器对象，不会立即执行 for result in group.imap(run_in_greenlet1, 'hijk'): print result for result in group.imap_unordered(run_in_greenlet1, 'lmnopq'): print result Pool+ Pool来自子类化Group，是一个为处理数量变化并且需要限制并发Greenlet而设计的类。+ 在需要并行的受限于网络和IO的任务时常常需要用到它。+ 设置最大并发数 1234567pool = Pool(4)pool.map(run_in_greenlet1, 'hijk')pool.spawn(run_in_greenlet1, 'm')pool.join()# 杀死所有的协程pool.kill() 子进程与协程协作 python内置的子进程无法与greenlet协作,当子进程空闲时，协程也无法执行 1234567891011121314151617import geventimport subprocessdef test(): while True: print 'test' gevent.sleep(2)if __name__ == '__main__': g = gevent.spawn(test) # 等待10秒后打印用户 sub = subprocess.Popen('ping 1.1.1.1 -n 1 -w 10000 &amp;&amp; dir', stdout=subprocess.PIPE, shell=True) sub.wait() output, err = sub.communicate() print output.decode('gbk').encode('utf-8'), err # 在子进程等待10秒的过程中协程g没有被调用，就被kill掉了 g.kill() 使用gevent.subprocess 在子进程执行的10多秒的时间里， 协程g调用了6次test函数 1234567891011121314151617import gevent# import subprocessfrom gevent import subprocessdef test(): while True: print 'test' gevent.sleep(2)if __name__ == '__main__': g = gevent.spawn(test) # 等待10秒后打印用户 sub = subprocess.Popen('ping 1.1.1.1 -n 1 -w 10000 &amp;&amp; dir', stdout=subprocess.PIPE, shell=True) sub.wait() output, err = sub.communicate() print output.decode('gbk').encode('utf-8'), err # 在子进程等待10秒的过程中协程g没有被调用，就被kill掉了 g.kill() gevent.socket 与multiprocessing模块协作 multiprocessing模块多进程本身也无法和greenlet进行协作， 下面的例子在Linux下实现，使用两个Pipe进行进程间通信，两个协程一个从a写入pipe1，一个从d读取pipe2，子进程负责从b端接受pipe1数据，从c端写入pipe2. 子进程中的msg = b.recv()是阻塞的，此时协程可以获得cpu控制权 123456789101112131415161718192021222324252627from multiprocessing import Process, Pipefrom gevent import socketa, b = Pipe() # Pipe返回的是两个连接到管道2端的对象c, d = Pipe()def relay(): for i in range(10): msg = b.recv() # 没有数据时会阻塞 c.send('%s in %d' %(msg, i))def put_msg(): for i in range(10): socket.wait_write(a.fileno()) a.send('hi %d' %i)def get_msg(): for i in range(10): socket.wait_read(d.fileno()) print d.recv()if __name__ == '__main__': proc = Process(target=relay) proc.start() # 创建进程 g1 = gevent.spawn(put_msg) g2 = gevent.spawn(get_msg) gevent.joinall([g1, g2]) Monkey Patch什么是monkey patch在动态语言中，不去改变源码而对功能进行追加和变更就叫做MonkeyPatching（猴子补丁） 追加功能 功能变更 修正程序错误 增加钩子，在执行某个方法的同时执行一些其他的处理，如打印日志，实现AOP等， python实现monkey patch 123456789101112131415161718class Bird(object): def fly(self): print 'i can fly!'def fly(self): print 'i cannot fly!'def run(self): print 'i can run!'if __name__ == '__main__': bird = Bird() bird.fly() # 下面是动态补丁，对象的方法会发生改变 Bird.fly = fly Bird.run = run bird.fly() bird.run() Gevent 中的monkey patch patch的模块有：socket,dns, time, select, thread, os, ssl, subprocess, sys, builtins, signal 默认阻塞的模块都被替换成非阻塞，协作式的。比如gevent支持异步协作的DNS，gevent的time.sleep只是协程内休眠，不阻塞线程。 12345678910111213141516171819import timeitimport urllib2import geventfrom gevent import monkeydef download(url): data = urllib2.urlopen(url) gevent.sleep(0) text = data.read()[:50] print url, textdef test(): urls = ['http://gunicorn.org/#docs', 'http://gunicorn.org/', 'https://www.liaoxuefeng.com'] gevent.joinall([gevent.spawn(download, url) for url in urls])monkey.patch_all()# 没有patch之前，用时24.5653685739,使用patch后执行时间为13.973405013# timeit是python的计时器模块print timeit.Timer(stmt="test()", setup="from __main__ import test").timeit(number=20) Server的使用服务器概念一个管理资源并为用户提供服务的计算机软件，通常分为文件服务器（能使用户在其它计算机访问文件），数据库服务器和应用程序服务器。 服务器软件工作在客户端-服务器或浏览器-服务器的方式，常用的分类： 文件服务器（FileServer） 数据库服务器（DatabaseServer）——MySQL 邮件服务器（MailServer）——Microsoft Exchange 网页服务器（WebServer）——如Apache 应用程序服务器 TCP服务器python的socket，select，以及SocketServer模块都是阻塞的。 Gevent提供了非阻塞的socket server python socket的简单服务器 123456789101112131415import socketimport sysif __name__ == '__main__': s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.bind(('localhost', 12222)) s.listen(100) while True: coon, addr = s.accept() print 'connected with %s:%s ' % (addr[0], addr[1]) # 阻塞，只有recv操作完成后， s才能接受新的连接 data = coon.recv(1024) print data coon.close() s.close() 基于python select的异步服务器 123456789101112131415161718192021222324252627import socketimport selectif __name__ == '__main__': s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) s.bind(('localhost', 12222)) s.listen(100) read_list = [s] address = &#123;&#125; while True: read_socks, write_socks, error = select.select(read_list, [], []) for sock in read_socks: if sock == s: # 如果是服务器的sock，则允许服务器接收一个连接,并加入可读list coon, addr = s.accept() print 'connected with %s:%s '%(addr[0], addr[1]) read_list.append(coon) address[coon] = addr else: # 来自客户端的socket可读时 data = sock.recv(1024) if data: print 'get:', data else: read_list.remove(sock) print 'client %s:%s closed!'% address[sock] del address[sock] sock.close() s.close() 使用SocketServer类 123456789101112131415import SocketServer# 需要定义一个Handler类处理socket连接class MyRequestHandler(SocketServer.BaseRequestHandler): def handle(self): while True: data = self.request.recv(1024) if not data or len(data) == 0: return print data returnif __name__ == '__main__': address = ('localhost', 12222) server = SocketServer.TCPServer(address, MyRequestHandler) server.serve_forever() Gevent Server 12345678910111213141516from gevent import monkeyfrom gevent.server import StreamServermonkey.patch_all()def handler(sock, addr): while True: data = sock.recv(1024) if data: print data else: print addr, 'closed!' returnif __name__ == '__main__': server = StreamServer(('localhost', 12222), handler) server.serve_forever() 使用基于协程的client对上述服务器测试 可以看到Gevent的server是支持协程的，能同时处理多个连接。 1234567891011121314151617181920from gevent import monkeymonkey.patch_all()import geventimport socketdef do_connect(addr, index): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.connect(addr) sock.send("hello world from %d" %index) gevent.sleep(2) sock.send("hello world2 from %d" %index) sock.close()addr = ('localhost', 12222)greenlets = []num = 10for i in xrange(num): g = gevent.spawn(do_connect, addr, i) greenlets.append(g)gevent.joinall(greenlets) ​ WSGIServer Web服务器网关接口（Python Web Server Gateway Interface，缩写为WSGI）是为Python语言定义的Web服务器和Web应用程序或框架之间的一种简单而通用的接口。 WSGIserver所做的工作仅仅是将从客户端收到的请求传递给WSGI application，然后将WSGI application的返回值作为响应传给客户端。 WSGI application可以是Flask，Django等web框架 WSGI application接口应该实现为一个可调用对象，例如函数、方法、类、含call方法的实例。这个可调用对象可以接收2个参数： 一个字典，该字典可以包含了客户端请求的信息以及其他信息，可以认为是请求上下文，一般叫做environment（编码中多简写为environ、env）； 一个用于发送HTTP响应状态（HTTP status ）、响应头（HTTP headers）的回调函数。 同时，可调用对象的返回值是响应正文（response body），响应正文是可迭代的、并包含了多个字符串。 Python内置的简单的WSGI Server不支持并发，Gunicore是基于gevent的，协程支持的协作式并发。 Gevent WSGI server 支持的并发度比python内置的wsgi高很多 123456789101112from flask import Flaskimport gevent.pywsgiimport geventapp = Flask(__name__)@app.route('/')def handle(): return 'welcome to gevent lesson!'gevent_server = gevent.pywsgi.WSGIServer(('', 5000), app)gevent_server.serve_forever() 在实际的web项目部署时，我们一般使用Gunicore或Uwsgi做wsgi服务器。 Gevent 长轮询浏览网页时，浏览器会传HTTP请求到服务器，服务器会根据请求将网页的内容传给浏览器，但是在很多的情况下，使用者会需要看到最新的即时性资讯，例如观看股票市场行情，如果靠重新载入网页才能获得最新信息，不但很浪费时间，实时效果差，也会浪费网络资源。 轮询：每隔一段时间向服务器发送一次请求，以获取最新的数据。 长时间轮询（long-polling）是让服务器在接收到浏览器发出的HTTP请求后，服务器会等待一段时间，若在这段时间里面伺服器有新的数据更新，它就会把最新的数据传给浏览器，如果等待的时间到了之后也没有新资料的话，就会送一个回应给浏览器，告知浏览器资料没有更新。 长时间轮询可以减少产生轮询（polling）造成网路频宽浪费的状况。 实现原理 浏览器向服务器发送Ajax请求，当接收到服务器响应后，需要向服务求发送新的请求 服务器端要能够一直保持住客户端的请求，直到有响应消息；同时服务器对请求的处理要支持非阻塞模式 需要使用Event，python内置Event是阻塞的，gevent的却是非阻塞的。 示例不停请求数据的ajax js脚本：complete: longPolling 执行完成后继续回调自身，循环执行。 Post的数据包含请求服务器数据的ID，服务器根据ID返回的数据对浏览器来说就是最新的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Long Pooling&lt;/title&gt;&lt;head&gt;&lt;body&gt; &lt;div id="main"&gt; &lt;div id="inbox"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div id="state"&gt;&lt;/div&gt; &lt;script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" charset="utf-8"&gt; var id = null; // id为空时，服务器返回最新的数据 function longPolling() &#123; $.ajax(&#123; url: "update", data: &#123;"id": id&#125;, type: "POST", error: function (XMLHttpRequest, textStatus, errorThrown) &#123; $("#state").append("[state: " + textStatus + ", error: " + errorThrown + " ]&lt;br/&gt;"); &#125;, success: function (result, textStatus) &#123; console.log(result) msg_data = eval("(" + result + ")"); $("#inbox").append(msg_data.html); id = msg_data.id; console.log(msg_data) $("#message").val(""); $("#state").append("[state: " + textStatus + " ]&lt;br/&gt;"); &#125;, complete: longPolling &#125;); &#125; $(function()&#123; longPolling(); &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 服务端要记录数据的编号，根据浏览器请求数据的ID返回数据： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273from gevent.pywsgi import WSGIServerfrom gevent.event import Eventfrom cgi import escapeimport uuidimport urlparseimport stringimport randomdef get_request_data(field, env): try: request_body_size = int(env.get('CONTENT_LENGTH', 0)) except (ValueError): request_body_size = 0 request_body = env['wsgi.input'].read(request_body_size) d = urlparse.parse_qs(request_body) data = d.get(field, [''])[0] return datadef generate_response_data(response_body, start_response): response_headers = [('Content-Type', 'text/html'), ('Content-Length', str(len(response_body)))] start_response('200 OK', response_headers) return [response_body]def generate_json_data(msg_list): msg_dict = &#123;&#125; msg_dict["html"] = "" for msg in msg_list: msg_dict["html"] += "&lt;div&gt;&#123;0&#125;&lt;/div&gt;".format(msg["msg"]) msg_dict["id"] = msg_list[-1]["id"] res = str(msg_dict) return resdef id_generator(size=6, chars=string.ascii_uppercase + string.digits): return ''.join(random.choice(chars) for _ in range(size))file = open('longpooling.html')chat_html = file.read()class MessgaeBuffer(object): def __init__(self): self.cache = [] self.message_event = Event() def empty(self): return len(self.cache) == 0def application(env, start_response): env_val = env['PATH_INFO'] if env_val == "/create": msg_item = &#123;&#125; msg_item["id"] = str(uuid.uuid4()) msg_item["msg"] = id_generator() print "create msg %s" % str(msg_item) msgBuffer.cache.append(msg_item) # 当有新数据时，通知协程 msgBuffer.message_event.set() # 此时event.wait()不会阻塞 msgBuffer.message_event.clear() # 此时event.wait()会阻塞 return generate_response_data("", start_response) elif env_val == "/update": lastid = escape(get_request_data("id", env)) if msgBuffer.empty() or msgBuffer.cache[-1]["id"] == lastid: msgBuffer.message_event.wait() # 没有数据或没有新数据，协程阻塞等待 for index,m in enumerate(msgBuffer.cache): if m["id"] == lastid: return generate_response_data( generate_json_data( msgBuffer.cache[index+1:]) , start_response) return generate_response_data(generate_json_data(msgBuffer.cache), start_response) else: return generate_response_data(chat_html, start_response)msgBuffer = MessgaeBuffer()WSGIServer(('localhost', 8080), application).serve_forever() 使用websocket替代轮询实现推送web socket WebSocket是HTML5开始提供的一种在单个TCP 连接上进行全双工通讯的协议。WebSocket通讯协议于2011年被IETF定为标准RFC 6455，WebSocketAPI被W3C定为标准。 在WebSocketAPI中，浏览器和服务器只需要做一个握手的动作，然后，浏览器和服务器之间就形成了一条快速通道。两者之间就直接可以数据互相传送 很多网站实现推送技术所用的技术都是轮询。轮询是在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTPrequest，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTPrequest的header是非常长的，里面包含的数据可能只是一个很小的值，这样会占用很多的带宽和服务器资源。 而比较新的技术去做轮询的效果是Comet，使用了AJAX。但这种技术虽然可达到双向通信，但依然需要发出请求，而且在Comet中，普遍采用了长链接，这也会大量消耗服务器带宽和资源。 面对这种状况，HTML5定义了WebSocket协议，能更好的节省服务器资源和带宽并达到实时通讯。 web socket优势 服务器与客户端之间交换的数据包档头很小，大概只有2字节 服务器可以主动传送数据给客户端。 websocket实例 html中创建websocket对象, ws.onmessage当有新message时进行处理 1234567891011121314151617181920212223242526272829303132&lt;html&gt; &lt;head&gt; &lt;title&gt;Minimal websocket application&lt;/title&gt; &lt;script type="text/javascript" src="http://libs.baidu.com/jquery/2.1.4/jquery.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; $(function() &#123; // Open up a connection to our server var ws = new WebSocket("ws://localhost:10000/"); // What do we do when we get a message? ws.onmessage = function(evt) &#123; $("#placeholder").append('&lt;p&gt;' + evt.data + '&lt;/p&gt;') &#125; // Just update our conn_status field with the connection status ws.onopen = function(evt) &#123; $('#conn_status').html('&lt;b&gt;Connected&lt;/b&gt;'); &#125; ws.onerror = function(evt) &#123; $('#conn_status').html('&lt;b&gt;Error&lt;/b&gt;'); &#125; ws.onclose = function(evt) &#123; $('#conn_status').html('&lt;b&gt;Closed&lt;/b&gt;'); &#125; &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;WebSocket Example&lt;/h1&gt; &lt;div id="conn_status"&gt;Not Connected&lt;/div&gt; &lt;div id="placeholder" style="width:600px;height:300px;"&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; ​ 服务器中实现websocket处理 1234567891011121314151617import jsonimport randomfrom gevent import pywsgi, sleepfrom geventwebsocket.handler import WebSocketHandlerclass WebSocketApp(object): def __call__(self, env, start_response): ws = env['wsgi.websocket'] # 获取websocket对象 x = 0 while True: # 创建并发送消息 data = json.dumps(&#123;'x':x, 'y' :random.randint(1,5)&#125;) ws.send(data) x += 1 sleep(0.5)server = pywsgi.WSGIServer(('', 10000), WebSocketApp(), handler_class=WebSocketHandler)server.serve_forever() ​]]></content>
      <categories>
        <category>技术</category>
        <category>并发编程</category>
        <category>Gevent</category>
      </categories>
      <tags>
        <tag>gevent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow 安装]]></title>
    <url>%2F2017%2F10%2F18%2F%E6%8A%80%E6%9C%AF%2FTensorFlow%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[安装TensorFlow_GPU 环境：TensorFlow 1.4，windows 10 x64，python3.6（Anaconda），显卡gtx610m(笔记本渣显卡)，vs2015， cuda8.0， cuDnn6 截至2017.11，tensorflow最新版本为1.4，不支持cuda9和cuDnn7，下载时注意版本。 TensorFlow官网为https://tensorflow.google.cn/install/install_windows，www.tensorflow.org貌似被墙了，打不开。 1、安装vs studio 20152013或2017 社区或专业版都可以，我装的VS 2015中文社区版。 建议使用离线安装包，大概耗时1小时，使用在线安装估计要装一个晚上。 安装时勾选 vc++组件，其他的组件可以不装。 cuda安装依赖vs studio。 2、安装cuda下载cuda8.0，并安装。安装后提示安装失败，后者找不到cuda安装的目录，原因是没装vs studio，安装之。已经安装了vs的，可能是没装vc++组件，打开vs，新建c工程时，会提醒安装vc++，安装之。 3、安装cuDnn下载cuDnn6，需要先注册NVIDIA并填一份调查问卷。 下载后解压对应的文件，放到NVIDIA CUDA对应的安装目录里。 4、测试cuda安装是否成功打开一个cuda sample工程，用vs studio编译生成exe后，在cmd里执行。 5、安装Anaconda3最新的基于python3.6的也可以支持。 6、安装TensorFlow GPU版如果之前安装了CPU版本的，先卸载，然后pip安装。使用conda创建虚拟环境，或者直接在conda里执行pip install --ignore-installed --upgrade tensorflow-gpu 7、测试是否安装成功1234&gt;&gt;&gt; import tensorflow as tf&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')&gt;&gt;&gt; sess = tf.Session()&gt;&gt;&gt; print(sess.run(hello))]]></content>
      <categories>
        <category>技术</category>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 内省机制]]></title>
    <url>%2F2017%2F10%2F17%2F%E6%8A%80%E6%9C%AF%2FPython-%E5%86%85%E7%9C%81(Introspection)%2F</url>
    <content type="text"><![CDATA[Python 内省机制 内省(Introspection) 是什么？在计算机科学中，内省指一种能力，可以确定对象是什么，包含何种信息，可以做什么。Python 就是一门提供了内省机制的语言。 Python 的内省机制 help 函数 sys 模块sys模块中包含了系统，当前进程等相关的信息，例如 123456sys.platformsys.versionsys.maxintsys.argsys.pathsys.modules123456 keyword模块keyword.kwlist 包含Python所有的关键词 123&gt;&gt;&gt; import keyword&gt;&gt;&gt; keyword.kwlist[&apos;and&apos;, &apos;as&apos;, &apos;assert&apos;, &apos;break&apos;, &apos;class&apos;, &apos;continue&apos;, &apos;def&apos;, &apos;del&apos;, &apos;elif&apos;, &apos;else&apos;, &apos;except&apos;, &apos;exec&apos;, &apos;finally&apos;, &apos;for&apos;, &apos;from&apos;, &apos;global&apos;, &apos;if&apos;, &apos;import&apos;, &apos;in&apos;, &apos;is&apos;, &apos;lambda&apos;, &apos;not&apos;, &apos;or&apos;, &apos;pass&apos;, &apos;print&apos;, &apos;raise&apos;, &apos;return&apos;, &apos;try&apos;, &apos;while&apos;, &apos;with&apos;, &apos;yield&apos;] dir函数返回由传入对象的属性排序后构成的列表 builtins模块包含Python中的内建函数 docstring __name__属性 hasattr函数 getattr函数 type函数 id函数 callable函数 isinstance函数 issubclass函数 type() type()函数可以查看一个类型或变量的类型 type也可以用来动态地创建一个class对象,传入3个参数 class name， 继承的父类集合（元组） class的方法名称与函数绑定（字典） 123456def f(self, x): print 'hello', x Hello = type('Hello', (object,), dict(hello=f))h = Hello()h.hello('x') ​ Python metaclass “元类就是深度的魔法，99%的用户应该根本不必为此操心。如果你想搞清楚究竟是否需要用到元类，那么你就不需要它。那些实际用到元类的人都非常清楚地知道他们需要做什么，而且根本不需要解释为什么要用元类。” —— Python界的领袖 Tim Peters metaclass，直译为元类，简单的解释就是：当我们定义了类以后，就可以根据这个类创建出实例，所以：先定义类，然后创建实例。 拦截类的创建 修改类 返回修改后的类 Django的ORM框架就是使用元类创建操作数据库的api 参考：廖雪峰的博客, 深入理解元类 定义一个Metaclass类 按照默认习惯，metaclass的类名总是以Metaclass结尾，以便清楚地表示这是一个metaclass： 下面使用metaclass为List class添加一个方法add metaclass必须继承type类，重写其__new__()方法，依次传入4个参数。 __new__()方法接收到的参数依次是： 当前准备创建的类的对象； 类的名字； 类继承的父类集合； 类的方法集合。 1234567891011121314151617# metaclass是创建类，所以必须从`type`类型派生：class ListMetaclass(type): def __new__(cls, name, bases, attrs): attrs['add'] = lambda self, value: self.append(value) return type.__new__(cls, name, bases, attrs) # return super(ListMetaclass, cls).__new__(cls, name, bases, uppercase_attr)class MyList(list): __metaclass__ = ListMetaclassif __name__ == '__main__': l = MyList() l.append(1) l.add(1) print l # [1, 1] 什么时候用到metaclass 99%时间的99% 情况下用不到动态修改类 当我们需要动态修改类时，一般使用： monkey patch 类装饰器 ORM框架中常用metaclass来创建hook数据库操作的API]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python socket编程]]></title>
    <url>%2F2017%2F10%2F15%2F%E6%8A%80%E6%9C%AF%2FPython%20socket%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[python socket编程参考资料： socket编程 SocketServer Socket简介file可以对指定的文件进行打开、读写、关闭操作。socket是针对网络IO通信的，服务器和客户端之间进行打开、读写、关闭操作，也就是网络通信的核心与基础。 socket套接字，由Ip地址和port端口组成的元组，可以唯一确定网络通信的主体。 python标准库socket模块 这里的socket对象是用来实现网络通信的，支持tcp和udp 创建套接字：socket.socket(family,type),返回建立的套接字引用。 family：地址簇协议，（AF_INET、AF_INET6）,默认为AF_INET,即ipv4地址。 type：传输层协议，（SOCK_STREAM、SOCK_DGRAM），默认为SOCK_STREAM，即TCP协议 获取本地主机名gethostname() gethostbyname_ex(hostname): 返回元组(hostname,aliaslist, ipaddrlist) 服务器端socket对象方法 UDO协议无需使用listen和accept来接收连接，直接接收数据即可 bind(address), 绑定监听地址，address为（IP地址，port）构成的元组。 listen(backlog), backlog允许接收的最大连接数 accept(), 接收TCP连接，返回套接字对象和客户端地址构成的元组。返回的连接上的套接字对象可用于接收和发送信息。 客户端socket对象方法 connect(address), 建立与服务器的连接，address为（IP地址，port）构成的元组。 UDP协议无需建立连接，直接收发数据即可 TCP协议socket收发数据方法 recv([buffersize]),接收数据，buffersize指定接收最大数据量,返回接收的数据 send(bytes),通过socket发送data sendall(bytes),通过socket发送data（返回前将数据发送完） UDP协议socket收发数据方法 recvfrom([bufferszie]),接收数据，参数与recv()相同。返回（data,address）元组，address是发来数据的主机addres sendto(bytes,address),bytes:要发送的字节串,address为(ipaddr,port)的元组，指定发送的目的地。 关闭socket close() TCP socket 示例 这个示例是阻塞型的，即服务器只能一次处理一个连接 同时处理多个连接，可以使用进程fork，线程，以及异步I/O 服务器端 123456789101112131415161718192021222324252627282930#!/usr/bin/env python# -*- coding:utf-8 -*-import socketclass Server(object): def __init__(self, Host=None, Port=None): self.socket = socket.socket() host = Host if Host else socket.gethostname() port = Port if Port else 12345 self.socket.bind((host, port)) print u'服务器主机名：', host def run_server(self): self.socket.listen(5) coon, addr = self.socket.accept() print u'地址为%s的主机已连接！' % str(addr) coon.send(u'连接成功！你的地址%s' % str(addr)) while True: if str(coon.recv(1024)) == 'q': coon.send('bye!') coon.close() break else: text = coon.recv(1024) coon.send(u'你的问题是：%s' %text) if __name__ == '__main__': s = Server() s.run_server() 客户端 12345678910111213141516171819# -*- coding:utf-8 -*-import socketif __name__ == '__main__': s = socket.socket() s.connect((socket.gethostname(), 12345)) print s.recv(1024) s.send(u'hello, 这是一个客户端连接！') while True: text = raw_input("请输入：\n") if text == 'q': s.send(text) print s.recv(1024) break else: s.send(text) ret_text = s.recv(1024) print str(ret_text) UDP socket示例 服务器端 1234567891011121314151617181920212223242526272829import socketclass Server(object): def __init__(self, Host=None, Port=None): # 创建udp的socket对象 self.socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) host = Host if Host else 'localhost' port = Port if Port else 12345 self.socket.bind((host, port)) print u'服务器连接：', host, port def run_server(self): while True: data, addr = self.socket.recvfrom(1024) if str(data) == 'q': self.socket.sendto('bye!', addr) self.socket.close() break else: print u'你输入了：%s' % data self.socket.sendto(data, addr)if __name__ == '__main__': s = Server() s.run_server() 客户端 12345678910111213141516import socketif __name__ == '__main__': host = 'localhost' port = 12345 s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) while True: data = raw_input('请输入：\n') s.sendto(data, (host, port)) data, addr = s.recvfrom(1024) if data == 'bye!': break else: print data s.close() ​ SocketServer利用socket模块创建的服务无法进行多进程的处理，当需要进行大量请求处理时，请求就会阻塞在队列中，甚至发生请求丢弃。并且如果我们需要大量的socket时，就需要重复创建许多socket、绑定端口….. SocketServer简化了网络服务器的编写。在进行socket创建时，使用SocketServer会大大减少创建的步骤，并且SocketServer使用了select它有4个类：TCPServer，UDPServer，UnixStreamServer，UnixDatagramServer。这4个类是同步进行处理的，另外通过ForkingMixIn和ThreadingMixIn类来支持异步。 使用步骤使用SocketServer的步骤简介 创建服务器的步骤。首先，你必须创建一个请求处理类，它是BaseRequestHandler的子类并重载其handle()方法。 实例化一个服务器类，传入服务器的地址和请求处理程序类。 最后，调用handle_request()(一般是调用其他事件循环或者使用select())或serve_forever()。 集成ThreadingMixIn类时需要处理异常关闭。daemon_threads指示服务器是否要等待线程终止，要是线程互相独立，必须要设置为True，默认是False。 无论用什么网络协议，服务器类有相同的外部方法和属性 TCP实例：echo服务器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#!/usr/bin/env python# -*- coding:utf-8 -*-import loggingimport sysimport SocketServerimport timelogging.basicConfig(level=logging.DEBUG, format='%(name)s: %(message)s',)class EchoRequestHandler(SocketServer.BaseRequestHandler): def __init__(self, request, client_address, server): self.logger = logging.getLogger('EchoRequestHandler') self.logger.debug('__init__') SocketServer.BaseRequestHandler.__init__(self, request, client_address, server) def setup(self): self.logger.debug('setup') return SocketServer.BaseRequestHandler.setup(self) def handle(self): self.logger.debug('handle') # Echo the back to the client data = self.request.recv(1024) self.logger.debug('recv()-&gt;"%s"', data) self.request.send(data) return def finish(self): self.logger.debug('finish') return SocketServer.BaseRequestHandler.finish(self)class EchoServer(SocketServer.TCPServer): def __init__(self, server_address, handler_class=EchoRequestHandler): self.logger = logging.getLogger('EchoServer') self.logger.debug('__init__') SocketServer.TCPServer.__init__(self, server_address, handler_class) return def server_activate(self): self.logger.debug('server_activate') SocketServer.TCPServer.server_activate(self) return def serve_forever(self): self.logger.debug('waiting for request') self.logger.info('Handling requests, press &lt;Ctrl-C&gt; to quit') while True: self.handle_request() return def handle_request(self): self.logger.debug('handle_request') return SocketServer.TCPServer.handle_request(self) def verify_request(self, request, client_address): self.logger.debug('verify_request(%s, %s)', request, client_address) return SocketServer.TCPServer.verify_request(self, request, client_address) def process_request(self, request, client_address): self.logger.debug('process_request(%s, %s)', request, client_address) return SocketServer.TCPServer.process_request(self, request, client_address) def server_close(self): self.logger.debug('server_close') return SocketServer.TCPServer.server_close(self) def finish_request(self, request, client_address): self.logger.debug('finish_request(%s, %s)', request, client_address) return SocketServer.TCPServer.finish_request(self, request, client_address) def close_request(self, request_address): self.logger.debug('close_request(%s)', request_address) return SocketServer.TCPServer.close_request(self, request_address)if __name__ == '__main__': address = ('localhost', 0) # let the kernel give us a port server = EchoServer(address, EchoRequestHandler) ip, port = server.server_address # find out what port we were given logger = logging.getLogger('client') logger.info('Server on %s:%s', ip, port) server.serve_forever() UDP示例1234567891011121314import socketserverclass Handle(socketserver.DatagramRequestHandler): def handle(self): data, socket = self.request print data, socket socket.sendto(data, self.client_address)if __name__ == '__main__': host = 'localhost' ip = 12345 server = socketserver.UDPServer((host, ip), Handle) server.serve_forever()]]></content>
      <categories>
        <category>技术</category>
        <category>网络编程</category>
        <category>socket</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python logging模块使用]]></title>
    <url>%2F2017%2F10%2F14%2F%E6%8A%80%E6%9C%AF%2FPython%20logging%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[Python logging模块 为啥要用日志模块当我们编写python程序时，希望能到输出一些调试信息，一般情况我们用print打印出想要的信息。 使用print的缺点： 输出信息没有分级 程序发布时，要修改所有的print语句 无法输出信息到文件，或者发邮件 使用python的日志系统，就可以解决上述问题。 简单使用示例1234567891011121314151617181920212223242526272829303132333435# -*- coding: utf-8 -*- import loggingimport sys # 获取logger实例，如果参数为空则返回root loggerlogger = logging.getLogger("AppName") # 指定logger输出格式formatter = logging.Formatter('%(asctime)s %(levelname)-8s: %(message)s') # 文件日志file_handler = logging.FileHandler("test.log")file_handler.setFormatter(formatter) # 可以通过setFormatter指定输出格式 # 控制台日志console_handler = logging.StreamHandler(sys.stdout)console_handler.formatter = formatter # 也可以直接给formatter赋值 # 为logger添加的日志处理器logger.addHandler(file_handler)logger.addHandler(console_handler) # 指定日志的最低输出级别，默认为WARN级别logger.setLevel(logging.INFO) # 输出不同级别的loglogger.debug('this is debug info')logger.info('this is information')logger.warn('this is warning message')logger.error('this is error message')logger.fatal('this is fatal message, it is same as logger.critical')logger.critical('this is critical message')# 移除一些日志处理器logger.removeHandler(file_handler) 获取一个logger对象 添加Handler日志处理器 设置logger输出级别 GetLogger这是最基本的入口，该方法参数可以为空，默认的logger名称是root，如果在同一个程序中一直都使用同名的logger，其实会拿到同一个实例，使用这个技巧就可以跨模块调用同样的logger来记录日志。 另外你也可以通过日志名称来区分同一程序的不同模块，比如这个例子。 12logger = logging.getLogger("App.UI")logger = logging.getLogger("App.Service") 注意： 尽量不使用root logger，因为所有其他logger的输出，默认都会传给root一份，因而会出现多次root的日志输出。 同一日志被多次输出的原因，是绑定了多个handler。 比如下面这种常见的错误，每次调用get_logger()拿到的都是同一个logger实例App，但是每次调用都绑定一个console_handler，当这个函数被调用3次，App logger就会一次输出3条信息。 12345678def get_logger(): fmt = '%(levelname)s: %(message)s' console_handler = logging.StreamHandler() console_handler.setFormatter(logging.Formatter(fmt)) logger = logging.getLogger('App') # 返回的是同一个实例 logger.setLevel(logging.INFO) logger.addHandler(console_handler) return logger Formatter日志格式format = logging.Formatter(fmt=&quot;&quot;, datefmt=&quot;&quot;) Formatter对象定义了log信息的结构和内容，构造时需要带两个参数： 一个是格式化的模板fmt，默认会包含最基本的level和 message信息 一个是格式化的时间样式datefmt，默认为 2003-07-08 16:49:45,896 (%Y-%m-%d %H:%M:%S) fmt中允许使用的变量可以参考下表。 %(name)s Logger的名字 %(levelno)s 数字形式的日志级别 %(levelname)s 文本形式的日志级别 %(pathname)s 调用日志输出函数的模块的完整路径名，可能没有 %(filename)s 调用日志输出函数的模块的文件名 %(module)s 调用日志输出函数的模块名| %(funcName)s 调用日志输出函数的函数名| %(lineno)d 调用日志输出函数的语句所在的代码行 %(created)f 当前时间，用UNIX标准的表示时间的浮点数表示| %(relativeCreated)d 输出日志信息时的，自Logger创建以来的毫秒数| %(asctime)s 字符串形式的当前时间。默认格式是“2003-07-08 16:49:45,896”。逗号后面的是毫秒 %(thread)d 线程ID。可能没有 %(threadName)s 线程名。可能没有 %(process)d 进程ID。可能没有 %(message)s 用户输出的消息 fmt示例 123format = '%(asctime)s %(filename)s[line:%(lineno)d] %(levelname)s %(message)s'datefmt='%a, %d %b %Y %H:%M:%S'# output: Sun, 24 May 2009 21:48:54 demo2.py[line:11] DEBUG This is debug message SetLevel 日志级别Logging有如下级别: NOTSET， DEBUG，INFO，WARNING，ERROR，CRITICAL，默认级别是WARNING，logging模块只会输出指定level以上的log。这样的好处, 就是在项目开发时debug用的log，在产品release阶段不用一一注释，只需要调整logger的级别就可以了，很方便。 Handler 日志处理器最常用的是StreamHandler和FileHandler, Handler用于向不同的输出端打log。Logging包含很多handler, 可能用到的有下面几种 StreamHandler instances send error messages to streams (file-like objects). FileHandler instances send error messages to disk files. RotatingFileHandler instances send error messages to disk files, with support for maximum log file sizes and log file rotation. TimedRotatingFileHandler instances send error messages to disk files, rotating the log file at certain timed intervals. SocketHandler instances send error messages to TCP/IP sockets. DatagramHandler instances send error messages to UDP sockets. SMTPHandler instances send error messages to a designated email address. Configuration 配置方法logging的配置大致有下面几种方式。 通过代码进行完整配置，主要是通过getLogger方法实现,并绑定handler。 通过代码进行简单配置，主要是通过basicConfig方法实现。 basicConfig获取到的是root logger，默认的handler是stream。 传入的参数: 12345678filename FileHandler be created, using the filename, rather than a StreamHandler.filemode the mode to open the file, if filename is specified ( defaults to &apos;a&apos;).format Use the specified format string for the handler.datefmt Use the specified date/time format.level Set the root logger level to the specified level.stream Use the specified stream to initialize the StreamHandler. Note that this argument is incompatible with &apos;filename&apos; - if both are present, &apos;stream&apos; is ignored. 通过配置文件，下面有例子，主要是通过 logging.config.fileConfig(filepath)]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络通信基础TCP/IP]]></title>
    <url>%2F2017%2F10%2F14%2F%E6%8A%80%E6%9C%AF%2F%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[网络协议 一种抽象的网络体系结构的现实规则 规定了组成计算机网络的硬件和软件工件方式和运行规则 目前主要采用结构化的分层设计 它是通信双方必须遵循的控制信息交换的规则的集合 由语法、语义和同步三个要素组成 语法：信息的结构与格式约定 语义：控制信息所表达的意义 同步：事件的顺序、速度匹配 TCP/IP协议特点 独立于计算机硬件和操作系统，并免费使用。 统一分配网络地址 高层协议标准化，提供了可靠的服务 建立一个统一的逻辑网络，隔离了物理网络的硬件差异 协议分层 网络接口层 网际层（IP） 传输层(TCP/IP) 应用层(FTP/HTTP等) 通信过程 IP地址和端口IP地址 IP地址是网际层使用的给互联网上每个设备唯一的地址（二进制代码） 目前广泛使用的是32位的IPv4版本的IP地址 人们常用点分十进制的形式表示ip地址，比如192.168.1.1 在网络路由时需要ip地址 IP地址标志了一台网络主机，而主机上的某个网络程序由TCP/UDP的IP地址与端口来标志 IP地址分类 A-E 5类地址 特殊地质 环回地址 127.0.0.1/localhost 私有地址，数据包不会出现在Internet上 10.0.0.0-10.255.255.255 172.16.0.0-172.31.255.255 192.168.0.0-192.168.255.255 端口 端口号范围0-65535 熟知端口号：0-1023，系统保留，一半分配给了特殊的系统服务 登记端口号：1024-49151，用户程序注册即可使用 短暂端口号：49152-65535 建立网络连接时应指定ip和端口号 UDP协议和TCP协议UDP协议 传输控制协议 无连接，减少网络开销和时延 尽最大努力交付，上层应对数据作验证处理 无拥塞控制，用在保证速率的数据传送中（IP电话、网络视频） 基于UDP的应用协议 TFTP DNS SNMP VoIP QQ TCP协议 用户数据报协议 面向连接的通讯协议（通信前应先建立连接，实质为虚连接） 提供可靠的交付服务 实现了全双工通信 面向字节流（传输的任何数据被视为二进制代码流） 一个连接只能有两个传输端点 基于TCP协议的应用 HTTP FTP TELNET POP、SMTP Socket套接字 TCP连接的端点称作套接字或插口,表示方法：IP地址:端口号 一个socket就是：（IP地址:端口号） 一个TCP连接就是两个套接字，也即{（IP地址:端口号），（IP地址:端口号）} 每一条TCP连接被两个套接字（代表连接的两个端点）确定 同一IP地址可以有不同的TCP连接，同一端口号可以出现在不同TCP连接中。 ​ TCP和UDP的异同不同点 TCP应先建立连接，再通信，最后应释放连接；UDP不用管理连接。 TCP保证数据可靠交付，用起来更省心；UDP不保证可靠交付，用户应自行处理可靠性。 TCP连接开销大；UDP则开销小。 TCP适用实时性低，但数据可靠性高的场合；UDP适用实时性高，但数据可靠性低的场合。 相同点 位于TCP/IP协议的第四层。 为应用层提供服务。 都要通过网际层来具体实现数据传输]]></content>
      <categories>
        <category>技术</category>
        <category>网络编程</category>
        <category>socket</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python super与多重继承顺序]]></title>
    <url>%2F2017%2F10%2F14%2F%E6%8A%80%E6%9C%AF%2FPython-super%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[python多重继承的顺序 Python super对象 Base.__init__(self, args) 在Python2.2以前，未绑定的父类构造方法经常被使用A.__init__(self) 这种做法的缺点是， 当多重继承以后，想要修改代码的话，比如某个基类改名字了，那么所有调用该类方法的代码部分都要修改。 基类的方法可能会被多次调用 要保证子类能够覆盖父类，及生成所有的子类后再生成父类。这要看代码的质量，如果继承关系复杂，很容易把人搞晕。 super(Child, self).__init__(args) 在Python类的方法中，要调用父类的某个方法，一般会用super(X, self).func(args),尤其是在类初始化中。 使用super不会显示的调用父类方法。super对象会根据继承关系的顺序依次执行每个父类的__init__方法,如果每个类都使用super调用父类方法的话，那么可以确保每个类的__init__只会执行一次。 12345678910111213141516class A(object)： def __init__(self): print 'A'class B(A): # 直接调用类方法 def __init__(self): A.__init__(self) print 'B' class C(A): # 使用super构造 def __init__(self): super(C, self).__init__(self) print 'C' 假如有如下继承关系，F继承E, D; E继承B和C；C和D都继承A， A和B都继承Object对象，且ABCDE都使用了super() 那么实例化F对象时，继承顺序为F E B C D A object,符合拓扑排序。 拓扑排序满足关系，A的子节点B，一定不会出现在A之前。对于继承关系，这可以保证所有的子类先被访问，然后在访问它们的父类，不然就会造成父类方法没有被子类覆盖的情况。 MRO算法和C3算法MRO(Method Resolution Order决定python多重继承的继承顺序)。 MRO在python2.7和python3中没有采用BFS或DFS，而是C3算法，能够产生一个拓扑序列，保证唯一性和可重载性。 拓扑排序对一个有向无环图(Directed Acyclic Graph简称DAG)G进行拓扑排序，是将G中所有顶点排成一个线性序列，使得图中任意一对顶点u和v，若边(u,v)∈E(G)，则u在线性序列中出现在v之前。通常，这样的线性序列称为满足拓扑次序(Topological Order)的序列，简称拓扑序列。简单的说，由某个集合上的一个偏序得到该集合上的一个全序，这个操作称之为拓扑排序 ### C3算法的原理1234567L[D(B,C)] = D + merge(L[B],L[C],[B,C])以上表达式也等同于： ==&gt; Ｌ[D(B,C)] = D + merge(mro(B,object),mro(C,object),[B,C]) ==&gt; Ｌ[D(B,C)] = D + merge( [B,object], [C, object],[B,C]) [] : 列表表达式merge: Ｃ3算法的核心 《python高级编程》中是这样写的： 取第一个列表的头，也就是L[B,object] ，如果这个头不在任何表的尾部，那么将它加到class D的线性表中，并且从合并中的列表里删除 ；否则查找下一个列表的头，如果是个好的表头则取出它。 需要注意的是： 表头指是第一个元素 ，尾部是指除表头之外的其它所有元素 。如[A,B,C,D,E,F],A是表头，[B,C,D,E,F]是尾部。 方式解析： L(D(B,C)) = D + merge( [B,object] ,[C,object] , [B,C] ) ​ #列表[B,object]的表头是Ｂ，没有出现在其它表([C,object] 、[B,C] )的尾部 ​ = [D, B] + merge( [object], [C,object] , [C] ) ​ #列表[Ｃ,object]的表头是Ｃ，没有出现在其它表([object] 、[C] )的尾部 ，注意 [C] 这个列表只有表头，没有尾部 ​ = [D, B,C] + merge( [object] , [object] ) ​ = [D, B,C,object] C3算法产生拓扑序列对于以下的继承关系，其顺序为：ABECDF object 首先找入度为0的点，只有一个A，把A拿出来，把A相关的边剪掉，再找下一个入度为0的点，有两个点（B,C）,取最左原则，拿B，这是排序是AB，然后剪B相关的边，这时候入度为0的点有E和C，取最左。这时候排序为ABE，接着剪E相关的边，这时只有一个点入度为0，那就是C，取C，顺序为ABEC。剪C的边得到两个入度为0的点（DF），取最左D，顺序为ABECD，然后剪D相关的边，那么下一个入度为0的就是F，然后是object。那么最后的排序就为ABECDF object。]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyQt5 编译PyQt5 (python27, windows x64)]]></title>
    <url>%2F2017%2F10%2F13%2F%E6%8A%80%E6%9C%AF%2FPyQt5.9%E7%BC%96%E8%AF%91%20python27%2064%E4%BD%8DWindows%E7%89%88%2F</url>
    <content type="text"><![CDATA[编译PyQt5.9 基于python2.7 Windows 64位版 写在前面自己编译的PyQt5的原因 python27下，pyqt5没有官方支持的安装包， python3下可以直接安装 python-qt5是第三方编译提供的，pypi上pyqt版本为5.3，github上源码为5.7，不是最新版 使用python-qt5编写的程序使用pyinstaller打包，import sip error， sip对于py27也是需要自己编译安装的。 在我折腾了1天编译成功PyQt5.9后，突发奇想，尝试把PyQt5.sip这个包，直接复制到site-packages目录下，然后打包时使用--hidden-import import sip就可以了。 参考相关资料和教程： 构建PyQt5.8/python2.7 py32版本的，作者给出了编译后的win，linux，mac下的PyQt包，编译步骤较为详细 记录在Python2.7 x64 bit 下 PyQt5.8的编译过程 配置编译环境可供参考，编译过程嘛，呵呵。 编译的configure参数，可以参考pyqt5官网 记录编译过程准备工作 vs2015编译环境 我用的 visual studio 2015社区版本，安装的时候选择自定义，把c++的组件勾选上。 由于我选了默认安装，没有c++编译工具，安装好后还得打开vs2015，在新建c++项目的界面选择安装C++组件，又多花了近一个小时。 VS的安装过程十分漫长，需要数个小时，因为是在线安装。如果下载了完整的离线安装包，应该会很快。 Qt5.8环境 如果是vs2013环境，就下对应MSVC2013的Qt MSVC2015版64位Qt5.8 python2.7 在虚拟python环境下编译sip失败，编译pyqt5时没有报错。 后来干脆搞个全新的python27来编译PyQt5，干净清爽。 环境变量 新增变量名：QTDIR，值：C:\Qt\Qt5.8.0\5.8\msvc2015_64 在path变量中添加路径：C:\Qt\Qt5.8.0\5.8\msvc2015_64\bin 在path变量中添加新装的python27的路径。 为了避免不必要的问题，新增的变量放在path的最前面，编译完成后再删掉即可。 PyQt相关源码包 下载对应版本的pyqt，PyQt5， PyQt3D，Qscintilla2，Sip。 应该是pyqt5.8对应qt5.8。一开始我用的pyqt5.9+qt5.8，智障了。 开始编译编译SIP1234$ cd sip-4.19.2$ c:\python27\python.exe configure.py$ nmake$ nmake install # 这个安装命令放到最最后面在执行 得到的sip可执行文件在sipgen中，sip的Python模块（sip.pyd或sip.so）在siplib中。这时不要nmake install安装sip，先编译安装pyqt5。 编译时出现问题LINK : fatal error LNK1181: 无法打开输入文件“python27.lib” 原因可能是我用的anaconda的Python虚拟环境，后来用c:\python27\python.exe 没有报错。 编译PyQt5这里的sip使用的是编译生成的，不要使用nmake install之后的python路径下的那个。 QtNfc存在bug，不安装这个模块。 整个编译过程大概半个小时。 c:\Python27\python.exe configure.py --sip=..\sip-4.19.2\sipgen\sip.exe --sip-incdir=..\sip-4.19.2\siplib --disable=QtNfc --qmake=C:\Qt\Qt5.8.0\5.8\msvc2015_64\bin\qmake.exe 1234$ cd PyQt5_gpl-5.8.2$ c:\Python27\python.exe configure.py --sip=..\sip-4.19.2\sipgen\sip.exe --sip-incdir=..\sip-4.19.2\siplib --disable=QtNfc --qmake=C:\Qt\Qt5.8.0\5.8\msvc2015_64\bin\qmake.exe$ nmake$ nmake install 此时安装成功后，import PyQt5.QtCore 提示找不到dll，后面给解决方法。看打包整理部分。 编译PyQt3D1234$ cd PyQt3D_gpl-5.9$ c:\Python27\python.exe configure.py --sip=..\sip-4.19.3\sipgen\sip.exe --sip-incdir=..\sip-4.19.3\siplib --qmake=C:\Qt\Qt5.8.0\5.8\msvc2015_64\bin\qmake.exe$ nmake$ nmake install 编译QScintilla21234$ cd QScintilla_gpl-2.10\Qt4Qt5$ C:\Qt\Qt5.8.0\5.8\msvc2015_64\bin\qmake.exe$ nmake release$ nmake install 打包整理问题描述 PyQt5 ImportError: DLL load failed from PyQt5 import QtCore时提示找不到dll ‘unresolved reference’ pycharm idea里导入包没有自动补全提示 原因 由于nmake install安装的PyQt5只是把 编译生成的文件copy到了Python site-packages的PyQt5文件夹下，bat，exe和dll文件需要我们手动复制，很麻烦的说。 解决 复制相应的文件到PyQt5对应的位置 建议使用everything这个软件，可以快速定位windows上的文件。 Plugins 从C:\Qt\Qt5.8.0\5.8\msvc2015_64\plugins\复制到PyQt5下plugins文件夹， 会有3种文件，只保留xxx.dll,删除xxxd.dll和xxxd.pdb文件。 *.dll 从C:\Qt\Qt5.8.0\5.8\msvc2015_64\bin\下全部内容复制到PyQt5目录下 同上，包括xxx.dll，*.exe 等文件。不要复制xxxd.dll，*.pdb sip lib siplib中的sip.pyd或sip.so复制到pyqt5 上面的操作就是PyQt5.sip模块，如果还同时想安装sip包，nmake install sip包 将这4个文件复制进PyQt5。 同时将其复制到site-packages下。 bat文件复制到python安装目录下 pylupdate5.bat、pyrcc5.bat和pyuic5.bat 编辑C:\Python27\Lib\site-packages\PyQt5\__init__.py 我直接借用python-qt5包里的 1234567891011121314151617181920212223242526272829303132import osimport sys# Setup environment variablesdirname = os.path.dirname(__file__)sys.path.insert(0, dirname)os.environ['PATH'] += os.pathsep + dirname# Addresses error: "QtQuick" is not installedos.environ['QML2_IMPORT_PATH'] = os.path.join(dirname, 'qml')# Addresses error: Problem creating accessible interfaceos.environ['QT_PLUGIN_PATH'] = os.path.join(dirname, 'plugins')# Addresses error: ..could not find or load the Qt platform plugin "windows"os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = os.path.join(dirname, 'plugins', 'platforms')# Expose versionsversion_info = (0, 1, 1) # Version of this releaseversion = "%s.%s.%s" % version_info__version__ = versionpyqt_version_info = (5, 9, 1)pyqt_version = "%s.%s.%s" % pyqt_version_info__pyqt_version__ = pyqt_versionqt_version_info = (5, 8, 1)qt_version = "%s.%s.%s" % qt_version_info__qt_version__ = qt_version 这是知乎上给出的 123456import sysimport ospyqt5_path = os.path.realpath(os.path.dirname(__file__))sys.path.append(pyqt5_path)os.environ['QT_QPA_PLATFORM_PLUGIN_PATH'] = pyqt5_path + '/plugins/platforms'os.environ['QT_PLUGIN_PATH'] = pyqt5_path + '/plugins' 复制到其他python，并配置系统环境变量 复制PyQt5整个文件夹到其他python27 64的site-packages即可完成PyQt5.9的安装。 为了可以正常运行qt designer.exe等，需要配置系统环境变量： QT_QPA_PLATFORM_PLUGIN_PATH QT_PLUGIN_PATH QML2_IMPORT_PATH 使用编译好的PyQt5 复制PyQt5和sip到site-packages 复制3个bat文件到python.exe同级目录 复制sip.h 到Python的include目录下 配置环境变量 QT_QPA_PLATFORM_PLUGIN_PATH QT_PLUGIN_PATH QML2_IMPORT_PATH 经过我在本机测试，PyQt5运行正常。编译好的文件分享给大家。 ​ ​]]></content>
      <categories>
        <category>技术</category>
        <category>GUI编程</category>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyQt5入门]]></title>
    <url>%2F2017%2F10%2F12%2F%E6%8A%80%E6%9C%AF%2FPyQt%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[PyQt入门开发环境配置Python2.7 + PyQt5 + Pycharm pypi源下载超时的话可以切换豆瓣pip源 我用的是python27，pyqt5.3， pycharm 安装PyQt5 如果你想使用py27+ pyqt58，参考知乎上的这篇，自行编译或使用作者提供的编译好的二进制包。我没试过，不保证成功。 python3 PyQt5官方编译版本仅支持python3，pip install pyqt5 python2.7 好在网上有编译的python2.7版本的pyqt，官网主页指出使用pip安装的版本为qt5.3,git安装的版本为qt5.7 pip install --index-url https://pypi.douban.com/simple python-qt5 pyqt5 designer python3需要单独安装pip install pyqt5-tools python2 python-qt5 里打包了designer工具，无需单独安装 配置Pycharm下面以python2为例，python3对应的designer.exe的位置不同。 打开Pycharm，进入设置，添加外部工具，QtDesigner和PyUIC QtDesigner QtDesigner用来生成ui文件 $FileDir$是pycharm的宏变量，即当前文件的路径 PyUIC 将ui文件转换成对应的python文件 参数为-m PyQt5.uic.pyuic $FileName$ -o $FileNameWithoutExtension$.py pyrcc 用于生成资源文件 我在虚拟环境的pyqt5文件夹里没找到pyrcc5.exe,但在系统Python的bin目录下有一个，就copy了一份，使用正常。系统的Python用pip list看了一下，并没有安装pyqt5，但是有qtpy这个包，有点奇怪，我系统的Python是anaconda发行版。 使用方法 首先生成资源的qrc文件： 然后右键生成资源的py文件 然后在需要引用资源的地方，先import py文件，然后资源的路径使用格式:文件路径/prefix_dir/文件名,冒号必不可少，文件路径是指_rc.py文件相对qrc资源文件的路径。当两者在同一路径时，可以不写。 问题描述 在pycharm &gt; tools &gt; external-tools中打开Qtdesigner时， This application failed to start because it could not find or load the Qt platform plugin “windows”. 原因： 环境变量没有添加。如果已经配置了环境变量，需要关闭并重新打开pycharm。 解决方法： 参考官方wiki在环境变量中增加： 路径中的替换为PyQt包所在的位置，查看你的安装位置 123import PyQt5PyQt5.__path__['D:\\qt_env\\lib\\site-packages\\PyQt5'] QT_QPA_PLATFORM_PLUGIN_PATH：&lt;QT_DIR&gt;/plugins/platforms QT_PLUGIN_PATH Example: &lt;QT_DIR&gt;/plugins QML_IMPORT_PATH： &lt;QT_DIR&gt;/qml QML2_IMPORT_PATH： &lt;QT_DIR&gt;/qml 配置eric6 这玩意儿是智障，自动补全一点也不智能 唯一优势就是可以通过选择组件和触发事件的方式批量生成一堆槽函数。 我还是用的pycharm 由于Qscintilla2在python2下没有编译的安装包，需要自行编译安装。 故选择在python3下安装。 如果使用了Python虚拟环境，则需要临时将python3.exe的目录设置在系统环境变量path里。 下载eric6，解压， 执行 ..\..\python.exe install.py PyQt学习教程和资料 建议先看完鱼c网友的帖子 知乎 - 大家是怎么学pyqt5的？ pyqt5教程-鱼c论坛 pyqt5 reference 官方 Qt官方文档 PyQt5与PyQt4的区别信号槽的不同 qt5中没有以下： QObject.connect() QObject.emit() SIGNAL() SLOT() All methods that had arguments that are usually the results of calls to SIGNAL() or SLOT() are no longer supported disconnect() takes no arguments and disconnects all connections to the QObject instance. Moudle组件的变化 PyQt4’s QtGui module has been split into PyQt5’s QtGui, QtPrintSupport and QtWidgets modules. Only the QGLContext, QGLFormat and QGLWidget classes are supported by PyQt5. PyQt4’s QtDeclarative, QtScript and QtScriptTools modules are not supported. These have been replaced by PyQt5’s QtQml andQtQuick modules. Unlike PyQt4, PyQt5 supports the creation of Python objects from QML. PyQt4’s QtWebKit module has been split into PyQt5’s QtWebKit and QtWebKitWidgets modules. PyQt4’s pyqtconfig module is not supported. The section The PyQt5 Extension API describes the support that PyQt5 provides to third-party packages (e.g. QScintilla) that want to build on top of PyQt5. 更多内容 Qt组件label 改变文本 改变字体 使用图片 buttonradio button 使用GroupBox放置一组互斥的单选框 LineEdit object.setText(“”) object.text() TextEdit多行文本框，只读/编辑属性,多行文本持续输出 TextBrowserProgressBar MenuBar 每个菜单选项为一个Qaction对象 Qdesigner中可以拖拽菜单项进行排序 Qaction可以添加图标， png格式的。在属性的icon中右边有个…打开文件按钮，点击添加icon 打开/关闭文件 QFileDialog.getSaveFileName QFileDialog.getOpenFileName win32com操作word打开文档 SliderBar Dial对话框 通知对话框 询问对话框 警告对话框 严重警告对话框 关于对话框 AboutQt对话框 标准输入对话框 getText getInt getItem 下拉 123456reply, ok = QInputDialog.getText( self, &apos;输入框&apos;, &apos;请输入姓名&apos;, QLineEdit.Normal, &apos;在此处输入你的姓名...&apos;)# title，提示，当前值，最小值，最大值reply, ok = QInputDialog.getInt(self, &apos;输入框&apos;, &apos;请输入你的年龄&apos;, 10, 5, 25)reply, ok = QInputDialog.getItem( self, &apos;请选择&apos;, &apos;最爱的水果是？&apos;, [&apos;香蕉&apos;, &apos;苹果&apos;, &apos;大菠萝&apos;]) 自定义输入对话框 一次获取多个变量 修改全区变量 个性化定制 通过额外创建一个窗体ui界面实现， 图片显示 使用designer右键组件，选择更改样式表，添加图片资源。 boader-img，自适应组件大小的填充图片。背景图片，按原图显示。原比例显示，自动缩放，保持比例不变。 可以在图片上添加自定义点击事件 label显示图片Qt Designer 右键 change StyleSheet GraphView图片Qt Designer 右键 change StyleSheet 为图片绑定鼠标点击事件 self.graphicsView.mousePressEvent = self.photo_clicked 更换图片 self.graphicsView_photo.setStyleSheet(&quot;border-image: url(:/source/3345.jpg);&quot;) 启动界面 QSplashScreen简介 程序启动时加载大量资源，启动缓慢，使用启动界面告知用户，程序运行中 显示logo 一些重要或有趣的图片和文字信息 显示启动界面时不能阻塞gui事件响应 实例 sleep是因为主窗口初始化很快就完成了，为了看到启动效果而加的延迟 123456789101112131415161718app = QApplication(sys.argv)splash = QSplashScreen(QPixmap(':source/4532.png'))splash.show()sleep(2)# 显示文字信息，文字的位置和颜色splash.showMessage('正在加载图片资源...', Qt.AlignBottom, Qt.blue)sleep(2)splash.showMessage('正在加载视频资源...', Qt.AlignBottom, Qt.blue)sleep(2)splash.showMessage('正在启动中...', Qt.AlignBottom, Qt.blue)sleep(2)app.processEvents() # 避免阻塞gui事件# 主窗口初始化mywindow = MyWindow()mywindow.show()# 关闭启动窗口splash.close()sys.exit(app.exec_()) 效果： 信号槽机制信号种类事件源：鼠标点击拖拽等，值改变。。。 信号和槽 所有的组件都可以产生信号，组件只负责发射信号。 信号需要连接到槽函数，才能得到处理。 通过QtDesigner连接信号与槽 通过手动代码连接信号与槽 装饰器方法 自定义信号参考博客 多重载的信号 1234567891011# 声明一个多重载版本的信号，包括了一个带int和str类型参数的信号，以及带str参数的信号preview_signal = pyqtSignal([int,str],[str])# 参数为int，str的信号help_signal = pyqtSignal(int, str)# 信号发射self.preview_signal[int, str].emit(1, 'ok') # 指定信号的版本self.preview_signal[str].emit('success!')# 槽函数绑定，同样需要指定信号的版本self.preview_signal[int, str].connect(self.func_1) # 指定信号的版本self.preview_signal[str].connect(self.func_2) ​ 一般流程如下：1、定义信号2、定义槽函数3、绑定信号和槽4、发射信号 注意事项： 1、自定义的信号在init()函数之前定义；2、自定义型号可以传递，str、int、list、object、float、tuple、dict等很多类型的参数；3、注意signal和slot的调用逻辑，避免signal和slot之间出现死循环。如在slot方法中继续发射该信号； 问题描述 &#39;PyQt5.QtCore.pyqtSignal&#39; object has no attribute &#39;connect&#39; 原因 pyqtSignal只有绑定了对象后才有connect方法 解决方法 在Qobject对象init()初始化之前定义信号pyqtSignal, 使其成为类变量而不是实例变量 使用connect方法时，要先创建Qobject对象的实例，然后调用实例的信号变量，直接Qobject.signal.connect就会出现这种错误 ​]]></content>
      <categories>
        <category>技术</category>
        <category>GUI编程</category>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyQt5 不同窗体之间传值]]></title>
    <url>%2F2017%2F10%2F11%2F%E6%8A%80%E6%9C%AF%2FPyQt5%E4%B8%8D%E5%90%8C%E7%AA%97%E4%BD%93%E4%B9%8B%E9%97%B4%E4%BC%A0%E5%80%BC%2F</url>
    <content type="text"><![CDATA[PyQt5 不同窗体之间传值 类静态方法自定义对话框返回值给主窗体 PyQt提供了一系列的标准对话框用于获取用户输入，QFileDialog、QInputDialog、QColorDialog、QFontDialog 第一种，自定义的Dialog对话框，我们可以通过类静态方法实现传值 主要注意几点：1、使用两个button(ok和cancel)分别连接accept()和reject()槽函数。2、实现一个静态函数，将参数通过该函数传出。3、在静态函数中实例化该类，并调用.exec()函数来显示执行这个对话框。4、通过.exec()的返回值来判断用户点的是ok还是cancel按钮，进而做出下一步判断。 在主窗口中调用静态函数方法，就可以得到传递的参数值，代码如下： data, ok = TestDialog.get_user() 1234567891011121314151617181920212223242526# 自定义对话框from test import Ui_Dialog as Test_Uiclass TestDialog(QDialog, Test_Ui): def __init__(self): super(TestDialog, self).__init__() self.setupUi(self) # accept/reject关闭窗口返回 1/0 self.buttonBox.accepted.connect(self.accept) self.buttonBox.rejected.connect(self.reject) self.data = &#123;'ok':1&#125; @staticmethod def get_user(parent=None): test_dialog = TestDialog() ok = test_dialog.exec_() data = test_dialog.data data['user'] = 'test input' return data, ok # 在主窗口中使用data, ok = TestDialog.get_user()if ok: print 'ok button clicked!'else: print 'cancel button clicked!' ​ 第二种，在主窗体中实例化自定义对话框，然后调用其属性和方法，最后destory对话框实例 12345test = TestDialog()ok = test.exec_()if ok: print test.datatest.destroy() 信号槽对于自定义的信号，使用方法是： 自定义的信号在init()函数之前定义signal_test= pyqtSignal(str) 在子对话框的槽函数发射信号，或在事件中发射信号。self.signal_test.emit((self.datetime.dateTime()).toString()) 在主窗体中连接信号和槽。dialog.signal_test.connect(self.getStrDate) 然后实现槽函数。 在自定义对话框里定义一个信号 12345678910111213141516171819from PyQt5.QtCore import pyqtSignal, pyqtSlotfrom test import Ui_Dialog as Test_Uiclass TestDialog(QDialog, Test_Ui): mysignal = pyqtSignal(dict) def __init__(self): super(TestDialog, self).__init__() self.setupUi(self) # accept/reject关闭窗口返回 1/0 self.buttonBox.accepted.connect(self.accepted) self.buttonBox.rejected.connect(self.reject) self.data = &#123;'ok':1&#125; @pyqtSlot(bool) def accepted(self, value): self.accept() data = self.data data['user'] = 'test input' self.mysignal.emit(data) # 发射信号，将dict数据传递出去 ​ 在主窗体里实例化自定义对话框，并为信号绑定槽函数 12345678test = TestDialog()test.mysignal.connect(self.process_data) # 绑定槽函数，接收数据test.exec_()test.destroy()# 处理数据的槽函数def process_data(self, data): print data 使用信号与槽需要注意的事项： 信号与槽机制与普通函数的调用一样，如果使用不当，在程序执行时也有可能产生死循环。所以在定义槽函数时一定要注意避免间接形成无限循环，即在槽中再次发射所接收到的同样信号。 ​ 如果一个信号与多个槽相连，当这个信号被发射时，与之相连的槽被激活的顺序是随机的。 ​ 宏定义不能用在signal 和slot的参数中。 ​ 信号和槽的参数个数与类型必须一致。]]></content>
      <categories>
        <category>技术</category>
        <category>GUI编程</category>
        <category>PyQt5</category>
      </categories>
      <tags>
        <tag>PyQt5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL生成测试数据]]></title>
    <url>%2F2017%2F10%2F08%2F%E6%8A%80%E6%9C%AF%2FMysql%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Ubuntu安装配置MySQL 安装mysqlsudo apt-get install mysql-server 安装过程中会提示设置root用户的密码 启动sudo service mysql start 重启sudo service mysql restart 停止sudo service mysql stop 配置文件主配置入口文件/etc/mysql/mysql.cnf, 这个文件里是全局配置，默认只设置了2个目录，告诉我们其中的配置文件，文件名后缀为cnf。 12!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/ 挨个查看后发现mysql.conf.d/mysqld.cnf文件配置[client]和[mysqld]。 1234567891011121314151617181920212223242526[client]# 设置utf8可以支持中文default-character-set = utf8[mysqld_safe]socket = /var/run/mysqld/mysqld.socknice = 0[mysqld]user = mysqlpid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockport = 3306basedir = /usr# 需要远程连接时，注释掉下面语句bind-address = 0.0.0.0 datadir = /var/lib/mysqltmpdir = /tmplc-messages-dir = /usr/share/mysqlmyisam-recover-options = BACKUPquery_cache_limit = 1Mquery_cache_size = 16Mlog_error = /var/log/mysql/error.log 设置MySQL允许远程访问注释掉bind-address = 0.0.0.0 设置用户允许远程登录mysql -h localhost -u root -p, 连接数据库，在命令台输入命令： use mysql; select host, user from user; GRANT ALL PRIVILEGES ON *.* TO root@&quot;%&quot; IDENTIFIED BY &#39;用户root的密码&#39;; 现在root可以支持远程登陆了，root的host变为%通配符。 允许root用户以任意ip地址远程登陆，一旦密码泄露是非常危险的。 推荐的做法: 允许root从内网ip 192.168.1.122上登陆，指定内网单个ip GRANT ALL PRIVILEGES ON *.* TO root@&quot;192.168.1.122&quot; IDENTIFIED BY &#39;用户root的密码&#39;; 创建新的用户，为其分配有限的权限，指定ip 12345678//创建库create database dbTest;//创建用户，设置密码create user &apos;useTest&apos;@&apos;%&apos; IDENTIFIED BY &apos;pwdTest&apos;;// 赋给该用户在dbTest数据上增删查，插入的权限， 连接ip为%，任意ipgrant select,update,delete,insert on dbTest.* to useTest@&apos;%&apos;;flush privileges;use dbTest; ​ 设置utf8字符集解决中文乱码问题，打开mysql控制台，输入命令show variables like &#39;character%&#39;;查看字符集。 修改配置文件 1234567[client]default-character-set=utf8[mysqld]default-storage-engine=INNODBcharacter-set-server=utf8collation-server=utf8_general_ci 在命令台输入命令set names utf8; 重启mysql后，使用命令查看字符集。 character_set_client character_set_connection character_set_results 以上三个控制mysql client的字符集 character_set_database ​ 设置数据库的默认字符集 character_set_server ​ 设置以上所有的默认字符集 安装MySQL驱动Python sudo apt-get install python-pipsudo apt-get install python-devsudo pip install mysql-python pip install mysql-python mysql-python安装时EnvironmentError: mysql_config not found 在安装 mysql-python时，会出现： 123456789sh: mysql_config: not foundTraceback (most recent call last): File &quot;setup.py&quot;, line 15, in &lt;module&gt; metadata, options = get_config() File &quot;/home/zhxia/apps/source/MySQL-python-1.2.3/setup_posix.py&quot;, line 43, in get_config libs = mysql_config(&quot;libs_r&quot;) File &quot;/home/zhxia/apps/source/MySQL-python-1.2.3/setup_posix.py&quot;, line 24, in mysql_config raise EnvironmentError(&quot;%s not found&quot; % (mysql_config.path,))EnvironmentError: mysql_config not found 只要原因是没有安装:libmysqlclient-dev 1sudo apt-get install libmysqlclient-dev 找到mysql_config文件的路径 12sudo updatedblocate mysql_config mysql_config的位置为：/usr/bin/mysql_config 在mysql-python源码包下找到：setup_posix.py 文件，然后找到文件中的 mysql_config.path 将其值改为：/usr/bin/mysql_config,然后 sudo python setup.py install ,就ok了 创建测试数据使用DB 存储过程生成数据 存储过程比较复杂，且sql提供的函数无法实现高级的数据处理功能 创建库和用户 12345create database dbTest;create user 'useTest'@'%' IDENTIFIED BY 'pwdTest';grant select,update,delete,insert on dbTest.* to useTest@'%';flush privileges;use dbTest; 创建表 12345678910DROP TABLE IF EXISTS `tabTest`;CREATE TABLE `tabTest` ( `testID` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT 'ID', `testTitle` varchar(10) DEFAULT NULL COMMENT 'title', `testBody` varchar(100) DEFAULT NULL COMMENT 'boey', `testType` tinyint(10) unsigned DEFAULT NULL COMMENT 'title len', `testValue` int(10) unsigned DEFAULT NULL COMMENT 'body len', PRIMARY KEY (`testID`)) ENGINE=MyISAM AUTO_INCREMENT=3 DEFAULT CHARSET=utf8 COMMENT='test';alter table tabTest auto_increment=1; 创建存储过程 1234567891011121314151617181920212223//创建存储过程，里面一长段汉字，用于随机抽取内容，可以随便改这段文字，但其中最好不要含用符号。DELIMITER $$DROP PROCEDURE IF EXISTS `addTest`$$CREATE DEFINER=`root`@`localhost` PROCEDURE `addTest`(IN insSum int,IN lenTitle int,IN lenBody int)BEGIN DECLARE i INT UNSIGNED DEFAULT 1; SET i=0; set @str='据新华社电日前，中共中央政治局常委、国务院总理李克强主持国务院专题讲座，讨论加快发展先进制造与3D打印等问题。李克强指出，推动中国制造由大变强，要紧紧依靠深化改革和创新驱动' loop1: LOOP SET i=i+1; if i&gt;insSum then LEAVE loop1; end if; set @key=SUBSTRING(@str,FLOOR(rand()*(length(@str)/3-10)),2+FLOOR(rand()*lenTitle)); set @title=SUBSTRING(@str,FLOOR(rand()*(length(@str)/3-20)),5+FLOOR(rand()*lenBody)); insert INTO tabTest(testTitle,testBody,testType,testValue) values (@key,@title,length(@title),length(@key)); select i,insSum-i; END LOOP loop1;END$$DELIMITER ; ​ 调用存储过程插入数据 12//调用过程开始添加数据，数字为要添加的条数call addTest(2,5,80); 使用Python生成数据 使用Python批量插入数据 表结构： 1234567891011121314151617181920212223242526272829303132333435363738394041424344SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for major-- ----------------------------DROP TABLE IF EXISTS `major`;CREATE TABLE `major` ( `majorID` int(10) NOT NULL AUTO_INCREMENT, `schooltype` varchar(40) DEFAULT NULL, `major_name` varchar(255) DEFAULT NULL, `major_category` varchar(255) DEFAULT NULL, `major_hot` int(4) DEFAULT NULL, PRIMARY KEY (`majorID`)) ENGINE=InnoDB AUTO_INCREMENT=3787 DEFAULT CHARSET=utf8;-- ------------------------------ Table structure for school-- ----------------------------DROP TABLE IF EXISTS `school`;CREATE TABLE `school` ( `schoolID` int(10) NOT NULL AUTO_INCREMENT, `sname` varchar(255) NOT NULL, `location` varchar(255) DEFAULT NULL, `school_type` varchar(255) DEFAULT NULL, `school_category` varchar(50) DEFAULT NULL, `school_hot` int(4) DEFAULT NULL, PRIMARY KEY (`schoolID`)) ENGINE=InnoDB AUTO_INCREMENT=2779 DEFAULT CHARSET=utf8;-- ------------------------------ Table structure for student-- ----------------------------DROP TABLE IF EXISTS `student`;CREATE TABLE `student` ( `studentID` int(10) unsigned NOT NULL AUTO_INCREMENT, `studentName` varchar(50) NOT NULL, `age` int(2) NOT NULL, `schoolID` int(3) NOT NULL, `majorID` int(3) NOT NULL, `sex` varchar(4) NOT NULL DEFAULT '男', `score_4` int(3) DEFAULT '0', `score_6` int(3) DEFAULT '0', PRIMARY KEY (`studentID`)) ENGINE=InnoDB AUTO_INCREMENT=250708001 DEFAULT CHARSET=utf8; 一次插入多条数据： 1234567conn = MySQLdb.Connection("123.207.235.76", "root", "123456", "dbTest", charset='utf8')data = [(1,1,1), (2,2,2)]cursor = conn.cursor()sql = "insert into student(schoolID, score_4, score_6) " \ "VALUES (%s, %s, %s)"cursor.executemany(sql, data)conn.commit() 生成随机数据： forgery_py模块可以生成随机的英文名，地址，ip，品牌等测试数据。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#!/usr/bin/env python# coding:utf-8import MySQLdbimport csvimport timeimport forgery_py''' 写入major table'''def insert_major(): t1 = time.time() reader = csv.reader(file('major_result.csv')) reader.next() # 调过csv的第一行 data = [(x[0], x[1], int(x[2]), x[3]) for x in reader ] conn = MySQLdb.Connection("123.207.235.76","root","123456","dbTest", charset='utf8') cursor = conn.cursor() sql = """insert into major(major_name, major_category, major_hot,schooltype) VALUES (%s, %s, %s, %s)""" cursor.executemany(sql, data) conn.commit() cursor.close() conn.close() print time.time() - t1 # 1.23699998856''' 写入school table'''def insert_school(): reader = csv.reader(file('result.csv')) reader.next() data = [(x[0], x[1], x[2], x[4], int(x[3])) for x in reader ] t1 = time.time() conn = MySQLdb.Connection("123.207.235.76","root","123456","dbTest", charset='utf8') cursor = conn.cursor() sql = """insert into school(sname, location, school_type, school_category, school_hot) VALUES (%s, %s, %s, %s, %s)""" cursor.executemany(sql, data) conn.commit() cursor.close() conn.close() print time.time() - t1 #0.851999998093 ''' 写入school table''' def create_one(): name = forgery_py.name.full_name() sid = forgery_py.name.random.randint(1, 2778) mid = forgery_py.name.random.randint(2525, 3786) age = forgery_py.name.random.randint(18, 35) score_4 = forgery_py.name.random.uniform(400, 750) score_6 = forgery_py.name.random.uniform(400, 750) sex = forgery_py.name.random.choice([u'男', u'女']) return (name, age, sid, mid, sex, score_4, score_6) def insert_student(): conn = MySQLdb.Connection("localhost", "root", "123456", "dbTest", charset='utf8') cursor = conn.cursor() t1 = time.time() for i in range(200): data = [create_one() for n in range(2000)] sql = "insert into student(studentName, age, schoolID, majorID, sex, score_4, score_6) " \ "VALUES (%s, %s, %s, %s, %s, %s, %s)" cursor.executemany(sql, data) conn.commit() del data cursor.close() conn.close() print time.time() - t1 # 1.23699998856if name == 'main': insert_major() insert_school() insert_student() 查询测试单表查询 在有索引的情况下执行查询： 表的主键、外键是必须有索引的，经常与其他表连接的字段，经常出现在where子句中的字段都应该有索引。 123456789101112131415SELECT * from student where studentID=250000000;/*受影响的行: 0 时间: 0.037s */ UPDATE student SET studentName = 'Wanda Lawrence1' WHERE studentID=250000000; /* 受影响的行: 1 时间: 0.101s */ ​ 在没有索引的字段执行查询 使用LIMIT进行分页查询，一次查询想要拿到的结果越多，扫描权标花费的时间就越多。 123456789101112131415161718192021222324252627282930313233343536373839404142434445SELECT * from student where studentName = 'Wanda Lawrence1';/* studentName = 'Wanda Lawrence1'的记录仅有一条，且是第第2.5亿条记录受影响的行: 0时间: 1651.702s， 27分钟。*/SELECT * FROM studentWHERE studentName = 'Wanda Lawrence'LIMIT 0, 100;/*受影响的行: 0时间: 6.525s 第100个符合条件的记录，其位置为2297114，也就是条件查询6.5s遍历了229万条数据。*/[SQL]SELECT * FROM studentWHERE studentName = 'Wanda Lawrence'LIMIT 0, 100;/*受影响的行: 0时间: 1.599s第100个符合条件的记录，其位置为2297114。相比上次的6.525秒的执行速度，这次只用了1.599s,说明mysql内部有缓存机制*/[SQL]SELECT * FROM studentWHERE studentName = 'Wanda Lawrence'LIMIT 0, 10;/*受影响的行: 0时间: 0.257s第10个符合条件的记录，其位置为289394， 0.257s遍历了29万条记录， 可能会受到缓存的影响*/[SQL]SELECT * FROM studentWHERE studentName = 'Michelle Warren'LIMIT 0, 10;/*受影响的行: 0时间: 0.161s第10个符合条件的记录，其位置为236033， 与上面的结果相比，mysql内部缓存机制对于30万级别的记录影响不大。*/ 数据库中避免使用空值变量null 对于一个数值字段可以设置0代替null,速度差别10倍 1234567891011121314151617[SQL]SELECT * FROM studentWHERE age = nullLIMIT 0, 10;/*受影响的行: 0时间: 2.161s第10个符合条件的记录，其位置为199712*/[SQL]SELECT * FROM studentWHERE age = 0LIMIT 0, 10;/*受影响的行: 0时间: 0.191s第10个符合条件的记录，其位置为2558733*/ 避免在where子句中使用or 使用Union all 连接2个子查询，比使用or的逻辑条件查询速度快很多。 从下面的执行结果可以看出二者相差8倍，这还是在查询字段有索引的情况下。 1234567891011121314151617181920212223242526-- 有索引的字段[SQL]SELECT * FROM studentWHERE studentID = 254000 or studentID = 220000000;/*受影响的行: 0时间: 0.224s*/[SQL]SELECT * FROM studentWHERE studentID = 254000 UNION ALLSELECT * FROM studentWHERE studentID = 220000000;/*受影响的行: 0时间: 0.038s*/-- 没有索引的字段-- union 联合查询无法配合分页Limit使用，下面的sql语句语法错误[SQL]SELECT * FROM student WHERE studentName = 'Carol Henderson'UNION ALLSELECT * FROM student WHERE studentName = 'Andrea Griffin'LIMIT 0, 100; 不要用模糊匹配，如果有必要可以使用全文检索提高效率。 123456789101112[SQL]SELECT * FROM student WHERE studentName LIKE 'Wanda%2' LIMIT 1;/* 受影响的行: 0时间: 1.046s*/[SQL]SELECT * FROM student WHERE studentName = 'Wanda Lawrence2' LIMIT 1;/* 受影响的行: 0时间: 0.975s*/ in和 not in也要慎用，否则会导致全表扫描： 当查询条件是连续型数值时，使用between替换in语法 1234567891011121314[SQL]SELECT * FROM student WHERE majorID in (2841, 2842, 2843, 2844, 2845)LIMIT 10000;/*受影响的行: 0时间: 7.291s*/[SQL]SELECT * FROM student WHERE majorID BETWEEN 2841 AND 2845LIMIT 10000;/*受影响的行: 0时间: 7.019s*/ 、应尽量避免在 where子句中对字段进行表达式操作 123456789101112131415[SQL]SELECT * FROM student WHERE majorID/2 = 1422LIMIT 1000;/*受影响的行: 0时间: 3.733s*/[SQL]SELECT * FROM student WHERE majorID = 1422*2LIMIT 1000;/*受影响的行: 0时间: 1.174s*/ 应尽量避免在where子句中对字段进行函数操作,不要在 where子句中的“=”左边进行函数、算术运算或其他表达式运算 123456789101112131415[SQL]SELECT * FROM student WHERE SUBSTRING(studentName, 1, 5) = 'Wanda'LIMIT 10000;/*受影响的行: 0时间: 3.015s*/[SQL]SELECT * FROM student WHERE studentName LIKE 'Wanda%'LIMIT 10000;/*受影响的行: 0时间: 2.871s*/ 多表查询 用 exists代替 in执行嵌套查询： 123456789101112131415161718192021222324252627282930313233343536[SQL]SELECT *FROM student st WHERE st.majorID in (SELECT majorID FROM major mj WHERE mj.major_category = '财经类' AND mj.major_name = '证券投资与管理') AND st.schoolID in (SELECT schoolID FROM school sc WHERE sc.school_category = '财经类' AND sc.school_type = '高职高专' AND sc.location = '上海') AND st.age = 33 AND st.sex = '女'LIMIT 1;/*受影响的行: 0时间: 62.578s*/[SQL]SELECT *FROM student st WHERE EXISTS (SELECT 1 FROM major mj WHERE st.majorID = mj.majorID AND mj.major_category = '财经类' AND mj.major_name = '证券投资与管理') AND EXISTS (SELECT 1 FROM school sc WHERE sc.schoolID=st.schoolID AND sc.school_category = '财经类' AND sc.school_type = '高职高专' AND sc.location = '上海') AND st.age = 33 AND st.sex = '女'LIMIT 1;/*受影响的行: 0时间: 68.563s*/ join 123456789101112131415161718192021222324252627282930313233343536[SQL]SELECT *FROM student st, major mj, school scWHERE st.age = 33 AND st.sex = '女' AND st.majorID = mj.majorID AND st.schoolID = sc.schoolID AND sc.school_category = '财经类' AND sc.school_type = '高职高专' AND sc.location = '上海' AND mj.major_category = '财经类' AND mj.major_name = '证券投资与管理'LIMIT 1;/*受影响的行: 0时间: 76.140s扫描到第200万行记录*/[SQL]SELECT *FROM student st JOIN major mj ON (st.majorID = mj.majorID AND mj.major_category = '财经类' AND mj.major_name = '证券投资与管理') JOIN school sc ON (st.schoolID = sc.schoolID AND sc.school_category = '财经类' AND sc.school_type = '高职高专' AND sc.location = '上海')WHERE st.age = 33 AND st.sex = '女'LIMIT 1;/*受影响的行: 0时间: 65.335s*/ ​]]></content>
      <categories>
        <category>技术</category>
        <category>数据库</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bootstrap 学习笔记]]></title>
    <url>%2F2017%2F10%2F08%2F%E6%8A%80%E6%9C%AF%2FBootStrap%2F</url>
    <content type="text"><![CDATA[Bootstrap入门 html5文件 引入css 引入jquery和bootstrap.js 查看官网文档和教程 栅格系统布局 grid grid文档 Bootstrap 需要为页面内容和栅格系统包裹一个 .container 容器 grid将屏幕横向像素12等分 媒体查询 媒体查询是进行响应式设计的核心要素，其功能非常强大Bootstrap主要用到min-width,max-width以及and语法，用于在不同的分辨率下设置不同的css样式 示例： 1234567891011@media(max-width:767px)&#123;/在小于767px的屏幕里，这里的样式才生效/&#125;@media(min-width:768px) and (max-width:991px)&#123;/768-991px屏幕里，这里的样式才生效/&#125;@media(min-width:1200px)&#123;/大于1200px屏幕里，这里的样式才生效/&#125; ​ ​ Bootstrap文本排版 列表与代码 Bootstrap Bootstrap表格样式 Bootstrap表单样式 Bootstrap按钮样式 Bootstrap图片 Bootstrap小图标 Bootstrap下拉菜单 Bootstrap按钮组 Bootstrap按钮下拉菜单 Bootstrap输入框 Bootstrap导航 Bootstrap导航条 Bootstrap面包屑导航和分页导航 标签 徽章 大屏展播 页面标题 缩略图和警告框 可关闭的警告框，data-dismiss是html5中绑定方法用的 1234&lt;div class="alert alert-info alert-dismissable" role="alert"&gt; &lt;button class="close " type="button" data-dismiss="alert"&gt;&amp;times;&lt;/button&gt; &lt;p&gt; 登录成功！返回 &lt;a href="#" class="alert-link"&gt;首页&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; ​ ##进度条和媒体内容 媒体对象：图文混排的风格 ##选项卡/标签页 导航栏中点击不同的选项卡，显示其对应的面板页面 可以用date-toggle=&quot;tab&quot;或date-toggle=&quot;pill&quot; 属性绑定面板切换动作 href指向对应面板的id，data-toggle绑定方法 1234567891011121314151617181920&lt;div class="container"&gt; &lt;!--选项卡 --&gt; &lt;ul class="nav nav-tabs"&gt; &lt;li&gt;&lt;a href="#pan1" data-toggle="tab"&gt;tab面板1&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#pan2" data-toggle="tab"&gt;tab面板2&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#pan3" data-toggle="tab"&gt;tab面板3&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;!--面板--&gt; &lt;div class="tab-content"&gt; &lt;div class="tab-pane active" id="pan1"&gt; &lt;h1&gt;第一个面板页面&lt;/h1&gt; &lt;/div&gt; &lt;div class="tab-pane" id="pan2"&gt; &lt;h1&gt;第二个面板页面&lt;/h1&gt; &lt;/div&gt; &lt;div class="tab-pane" id="pan3"&gt; &lt;h1&gt;第三个面板页面&lt;/h1&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; js绑定面板显示，参考文档 12345678&lt;script type="application/javascript"&gt; $(function () &#123; $(".nav.nav-pills li a ").click(function (e) &#123; e.preventDefault(); $(this).tab('show'); &#125;); &#125;)&lt;/script&gt; 事件监听，当点击了某个选项卡，触发事件 12345678&lt;script language="JavaScript"&gt; $(function()&#123; $('a[data-toggle="tab"]').on('shown.bs.tab', function (e) &#123; // e.target // newly activated tab // e.relatedTarget // previous active tab var newobj=e.target.innerHTML; $("#testshow").html(newobj);&#125;); ​ ##工具提示框 移动到某个元素上弹出提示信息 文档 需要声明式语法和javascript配合，指定data-toggle、data-placement、$(“select”).tooltip() ##折叠 Collapse ##焦点广告/轮播图 ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ## ##]]></content>
      <categories>
        <category>技术</category>
        <category>Web</category>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Bootstrap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo lightum 博客折腾之旅]]></title>
    <url>%2F2017%2F10%2F07%2F%E6%8A%98%E8%85%BE%2Fhexo-lightum%2F</url>
    <content type="text"><![CDATA[最近打算将原来的博客从jekyll转到hexo，瞎折腾了好久。最初用的是next主题，好处是next文档丰富，插件齐全。 后来又看上了light主题，但是light用的人不多，相关的插件、功能只好参考next以及其他hexo主题提供的解决方案，自己整合。 我喜欢的博客主题风格 有哪些简洁明快的jekyll模板 我最开始用的是jekyll，主题是首页 | 林安亚的博客 闫肃的博客 现在依然觉得这个博客好看且实用 hexo-next 用了一段时间，功能丰富，配置简单。不过后来看到了light主题，个人审美更喜欢light hexo-lightum 基于light的改进主题，也是我现在在使用的 其他好看的博客 琉璃之鸟 wordpress的博客，当初玩饥荒查攻略时进入的网站，感觉挺不错的。 Crazy Coder SimplyNetKeeper电信E信路由器破解连接软件，作者的博客。 图月志 这个很酷炫，不过是Bo-Blog，mysql+PHP，模板不清楚。 Hexo博客折腾之路 确定主题模板 基于light改进的lightum 提供我现在博客的模板及配置 更改category分级 参考 分级可以设置显示到几级 在theme的config中设置 1234# category显示的层级# 0显示所有分级，-1显示所有但不分级，1 只显示第一层的分类， n显示n层分级。# 不想分级时设值为1category_depth: 3 ​ 在每篇post文章的Front-matter 中category: 可以设置多个值 归档和文章目录 日历云挂件 参考 配置 12calendar: language: zh-CN ​ ​ 自定义layout 一个md文件或html，txt，采用哪种layout渲染，是由Front-matter中的layout字段定义的。默认使用post，如果使用样式，则layout:false hexo默认提供了post和scraft两种样式，这里我自己定义了resume、game、book三种样式。 看了这2个例子，应该就会写自己的layout了，关键还是看网页设计的能力 resume简历 参考教程 book和game ejs语法和百度静态文件cdn 12345678910111213141516//ejs语法//for ，if-else-if&lt;% for (var i in page.books)&#123; %&gt; &lt;% if (page.books[i].status == '已读') &#123;%&gt; &lt;span class="label label-success"&gt;&lt;%- page.books[i].status %&gt;&lt;/span&gt; &lt;% &#125; else if (page.books[i].status == '在读')&#123; %&gt; &lt;span class="label label-info"&gt;&lt;%- page.books[i].status %&gt;&lt;/span&gt; &lt;% &#125; else if (page.books[i].status == '未读') &#123; %&gt; &lt;span class="label label-default"&gt;&lt;%- page.books[i].status %&gt;&lt;/span&gt; &lt;% &#125; %&gt;&lt;% &#125; %&gt; //forEach&lt;% item.photos.forEach(function(photo)&#123; %&gt; &lt;%- photo.url %&gt;&lt;% &#125; %&gt; 使用了bootstrap 百度静态文件cdn资源 在lightum\layout\_partial\head.ejs引入js和css文件 12&lt;% if (page.books || page.games)&#123; %&gt;&lt;script src="//apps.bdimg.com/libs/bootstrap/3.2.0/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;% &#125; %&gt;&lt;% if (page.books || page.games) &#123; %&gt;&lt;link rel="stylesheet" href="http://apps.bdimg.com/libs/bootstrap/3.2.0/css/bootstrap.min.css" type="text/css"&gt;&lt;%&#125; %&gt; ​ 添加源码 lightum\layout\game.ejs 内容指向实际存放模板的位置&lt;%- partial(&#39;_partial/game&#39;) %&gt; lightum\layout\_partial/game.ejs 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;div class="row"&gt; &lt;div class="col-md-13 aside3-title"&gt; &lt;br&gt; &lt;h2 id="#identifier"&gt;&lt;%- page.title %&gt;&lt;/h2&gt; &lt;/div&gt; &lt;div class="col-md-13 aside3-content"&gt; &lt;br /&gt; &lt;br /&gt; &lt;div class="row"&gt; &lt;% page.games.forEach(function(game)&#123; %&gt; &lt;div class="col-md-12"&gt; &lt;div class="panel panel-primary"&gt; &lt;div class="panel-heading"&gt;&lt;%- game.title %&gt;&lt;/div&gt; &lt;div class="panel-body"&gt; &lt;div class="row"&gt; &lt;div class="col-md-4 col-xs-12 center"&gt; &lt;img src="&lt;%- game.cover %&gt;" alt="cover" class="img-thumbnail"&gt; &lt;/div&gt; &lt;div class="col-md-8 col-xs-12"&gt; &lt;table class="table table-bordered"&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td style="width:80px;"&gt;游戏平台&lt;/td&gt;&lt;td&gt;&lt;%- game.platform %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;出版商&lt;/td&gt;&lt;td&gt;&lt;%- game.publisher %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;语言&lt;/td&gt;&lt;td&gt;&lt;%- game.language %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;链接&lt;/td&gt;&lt;td&gt; &lt;a href="&lt;%- game.link %&gt;" title="&lt;%- game.link %&gt;"&gt;游戏链接&lt;/a&gt; &lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;状态&lt;/td&gt; &lt;td&gt; &lt;% if (game.status == '已通关')&#123; %&gt; &lt;span class="label label-success"&gt;&lt;%- game.status %&gt;&lt;/span&gt; &lt;% &#125; else if (game.status == '进行中') &#123; %&gt; &lt;span class="label label-info"&gt;&lt;%- game.status %&gt;&lt;/span&gt; &lt;% &#125; else if (game.status == '未开始') &#123;%&gt; &lt;span class="label label-default"&gt;&lt;%- game.status %&gt;&lt;/span&gt; &lt;% &#125;%&gt; &lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;类型&lt;/td&gt;&lt;td&gt;&lt;%- game.type %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;评价&lt;/td&gt;&lt;td&gt;&lt;%- game.description %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;% &#125;) %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; ​ front-matter 1234567891011121314151617181920212223242526272829303132---layout: gametitle: 2016年玩过的游戏category: - 生活 - 游戏keywords: - 游戏 - 娱乐 - 2016tags: - Enjoygames: - title: 饥荒联机版（Don't starve together） cover: http://ww4.sinaimg.cn/large/af9df239gw1f5dmat61rdj209q0d3jrq.jpg link: http://www.gamersky.com/z/dontstarve/ publisher: Klei Entertainment platform: steam type: 动作冒险，收集生存类沙盒游戏，2D画风,背景音乐超赞，在线多人联机 description: steam好评如潮 status: 进行中 language: 可用中文mod - title: 传送门2（Portal 2） cover: http://ww2.sinaimg.cn/large/af9df239gw1f5dmc8dce8j20dw0jjabi.jpg link: http://www.gamersky.com/z/portal2/ publisher: Valve Software language: 支持中文 platform: steam type: 第一人称视角，解迷，冒险，科幻,在线双人合作 description: steam好评如潮 status: 进行中--- ​ 效果 添加导航栏icon图标hexo theme大多数都是用的font-awesome字体图标库，在主题下的config文件，导航栏配置相应的icon即可。 1234567891011121314151617menu: home: / archives: /archives about: /resume Books: /books #This is your books page Movies: /movies #This is your movies page #Leetcode: /leetcode #tools: /toolsmenu_icon: home: home archives: archive about: user Books: book Movies: play-circle #Leetcode: file-text #tools: user 添加打赏 挂件中的打赏，直接替换支付宝图片的url即可 文章内的打赏，我用的是github上别人的代码 在主题的配置文件中设置donate为true 功能实现代码在\themes\lightum\layout\_partial\post\donate.ejs 在\themes\lightum\layout\_partial\article.ejs中引用上述文件 百度分享 去百度分享获取分享代码 功能实现 \themes\lightum\layout\_partial\post\share.ejs 在article的样式中引用 \themes\lightum\layout\_partial\article.ejs 在主题config中添加一个开关 share: true 百度统计和谷歌统计 还有百度收录和谷歌收录 获取百度和谷歌统计的代码，将其中的id或content写入主题配置 1234567google_analytics: UA-107525911-1# &lt;meta name="google-site-verification" content="hLu-CnRbqpthWxa76MJ-vpnGr7yMChNtTW6KA0pRMQo" /&gt;google_site_verification: hLu-CnRbqpthWxa76MJ-vpnGr7yMChNtTW6KA0pRMQo# &lt;meta name="baidu-site-verification" content="SOcrumVYOq" /&gt;# hm.src = "https://hm.baidu.com/hm.js?02f792017724a2c2af494ece7edc5fd1";baidu_analytics: 02f792017724a2c2af494ece7edc5fd1baidu_site_verification: WTddywKheI 安装sitemap和baidu-sitemap插件 站点配置文件中生成sitemap的选项 12345# 自动生成sitemapsitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 在谷歌或百度中设置自动爬取sitemap或手动提交 百度有个自动提交push脚本，放在每个页面的head中的。 ​ 本地搜索 参考教程1 参考教程2 需要安装插件本地搜索的插件 在站点配置文件中设置 12345search: path: search.xml field: post format: html limit: 10000 微博秀微博秀的API接口，获取代码后贴到微博挂件的ejs文件里即可。 评论系统 disqus国内被q，多说倒闭，其他的不知道还能挺多久。我用的是来必力，支持qq、微博、微信登录后评论 在主题配置文件中添加livere_uid: MTAyMC8yOTQxxxxxxooooo id去官网注册获取 相关代码在article.ejs中引用comment.ejs，更换其他评论系统也不难 豆瓣读书和电影 使用了hexo-douban插件 npm install hexo-douban 安装插件，然后站点配置文件，填入豆瓣ID 123456789# hexo-doubandouban: user: shuaiyy book: title: 我的阅读 quote: 2017年，我使用&lt;a href="https://www.douban.com/people/shuaiyy/" target="_blank"&gt;豆瓣&lt;/a&gt;记录我的阅读。 movie: title: 我的电影 quote: 2017年，我使用&lt;a href="https://www.douban.com/people/shuaiyy/" target="_blank"&gt;豆瓣&lt;/a&gt;记录我看的电影。 ​ 详细参考插件地址 增加返回顶部 toTop css footer.styl里添加样式 layout after_footer.ejs里添加对to_top.ejs的引用 to_top.ejs里 1234&lt;div id="toTop"&gt; &lt;a href="#"&gt;▲&lt;/a&gt; &lt;a href="#footer"&gt;▼&lt;/a&gt;&lt;/div&gt; 网站标题前增加头像 css header.styl里添加样式 .avatar layout header.ejs里在div.header-nav下添加div.avater ​ 写文章markdown神器 Typora不多BB，本文就是这么写的。 插入网易云音乐歌曲点击生成外链播放器，获取分享的html代码，直接黏贴，比如下面的 flash的代码 iframe的代码 部署和发布 部署到github和coding上，域名解析国内解析到coding，国外解析到github 使用ssh git部署 部署 创建代码仓库并配置ssh公钥 在站点config中添加 12345deploy: type: git repo: coding: git@git.coding.net:shuaiyy/shuaiyy.git,master github: git@github.com:shuaiyy/shuaiyy.github.io.git,master ​ 在git bash中使用ssh-add 添加ssh私钥 这样主机就能和github或coding ssh上传数据了 执行命令hexo d 发布绑定域名 首先去github，告诉github xxx.com对应的是哪个blog。 然后去域名解析商那里，告诉任何访问xxx.com的人，xxx.com是github的服务器提供的。 github github的CNAME文件指定你的域名xxx.com，然后域名解析商那里的CNAME记录国外线路指定’xxx.github.io’,即github page给你的二级域名 ​ coding coding是由pages.coding.me服务器为你做的地址跳转，因此国内DNS解析的CNAME记录指向pages.coding.me，而不是coding为你博客提供的二级域名。 github使用网站根目录的CNAME文件绑定域名，而coding需要在项目的page服务选项里设置绑定域名。 示例 github：source目录下的CNAME文件下，写入你的域名。CNAME文件名必须大写 coding：可以最多绑定5个，github由于是CNAME文件，只能绑定一个 dns解析：我的是dnspod解析商 404页面你的404.html的Front-matter中要设置layout: false title: 404。 然后把他丢到source根目录下即可。 1234567---layout: falsetitle: "404"---&lt;html&gt;你访问的页面找不到了！&lt;/html&gt; 网站的icon图标将favicon.ico文件丢入source目录即可 待改进的地方代码高亮的样式这个不会改，如果可以，我想换成night的代码高亮主题 重写标签云 现在的标签云挂件是一排的，占的地方多且不美观，有空改成一行好几个tag的那种。 点击回到顶部按钮]]></content>
      <categories>
        <category>折腾</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo lightum 博客折腾之旅]]></title>
    <url>%2F2017%2F10%2F07%2F%E6%8A%80%E6%9C%AF%2FHexo-lightum%2F</url>
    <content type="text"><![CDATA[最近打算将原来的博客从jekyll转到hexo，瞎折腾了好久。最初用的是next主题，好处是next文档丰富，插件齐全。 后来又看上了light主题，但是light用的人不多，相关的插件、功能只好参考next以及其他hexo主题提供的解决方案，自己整合。 我喜欢的博客主题风格 有哪些简洁明快的jekyll模板 我最开始用的是jekyll，主题是首页 | 林安亚的博客 闫肃的博客 现在依然觉得这个博客好看且实用 hexo-next 用了一段时间，功能丰富，配置简单。不过后来看到了light主题，个人审美更喜欢light hexo-lightum 基于light的改进主题，也是我现在在使用的 其他好看的博客 琉璃之鸟 wordpress的博客，当初玩饥荒查攻略时进入的网站，感觉挺不错的。 Crazy Coder SimplyNetKeeper电信E信路由器破解连接软件，作者的博客。 图月志 这个很酷炫，不过是Bo-Blog，mysql+PHP，模板不清楚。 Hexo博客折腾之路 确定主题模板 基于light改进的lightum 提供我现在博客的模板及配置 更改category分级 参考 分级可以设置显示到几级 在theme的config中设置 1234# category显示的层级# 0显示所有分级，-1显示所有但不分级，1 只显示第一层的分类， n显示n层分级。# 不想分级时设值为1category_depth: 3 ​ 在每篇post文章的Front-matter 中category: 可以设置多个值 归档和文章目录 日历云挂件 参考 配置 12calendar: language: zh-CN ​ ​ 自定义layout 一个md文件或html，txt，采用哪种layout渲染，是由Front-matter中的layout字段定义的。默认使用post，如果使用样式，则layout:false hexo默认提供了post和scraft两种样式，这里我自己定义了resume、game、book三种样式。 看了这2个例子，应该就会写自己的layout了，关键还是看网页设计的能力 resume简历 参考教程 book和game ejs语法和百度静态文件cdn 12345678910111213141516//ejs语法//for ，if-else-if&lt;% for (var i in page.books)&#123; %&gt; &lt;% if (page.books[i].status == '已读') &#123;%&gt; &lt;span class="label label-success"&gt;&lt;%- page.books[i].status %&gt;&lt;/span&gt; &lt;% &#125; else if (page.books[i].status == '在读')&#123; %&gt; &lt;span class="label label-info"&gt;&lt;%- page.books[i].status %&gt;&lt;/span&gt; &lt;% &#125; else if (page.books[i].status == '未读') &#123; %&gt; &lt;span class="label label-default"&gt;&lt;%- page.books[i].status %&gt;&lt;/span&gt; &lt;% &#125; %&gt;&lt;% &#125; %&gt; //forEach&lt;% item.photos.forEach(function(photo)&#123; %&gt; &lt;%- photo.url %&gt;&lt;% &#125; %&gt; 使用了bootstrap 百度静态文件cdn资源 在lightum\layout\_partial\head.ejs引入js和css文件 12&lt;% if (page.books || page.games)&#123; %&gt;&lt;script src="//apps.bdimg.com/libs/bootstrap/3.2.0/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;% &#125; %&gt;&lt;% if (page.books || page.games) &#123; %&gt;&lt;link rel="stylesheet" href="http://apps.bdimg.com/libs/bootstrap/3.2.0/css/bootstrap.min.css" type="text/css"&gt;&lt;%&#125; %&gt; ​ 添加源码 lightum\layout\game.ejs 内容指向实际存放模板的位置&lt;%- partial(&#39;_partial/game&#39;) %&gt; lightum\layout\_partial/game.ejs 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;div class="row"&gt; &lt;div class="col-md-13 aside3-title"&gt; &lt;br&gt; &lt;h2 id="#identifier"&gt;&lt;%- page.title %&gt;&lt;/h2&gt; &lt;/div&gt; &lt;div class="col-md-13 aside3-content"&gt; &lt;br /&gt; &lt;br /&gt; &lt;div class="row"&gt; &lt;% page.games.forEach(function(game)&#123; %&gt; &lt;div class="col-md-12"&gt; &lt;div class="panel panel-primary"&gt; &lt;div class="panel-heading"&gt;&lt;%- game.title %&gt;&lt;/div&gt; &lt;div class="panel-body"&gt; &lt;div class="row"&gt; &lt;div class="col-md-4 col-xs-12 center"&gt; &lt;img src="&lt;%- game.cover %&gt;" alt="cover" class="img-thumbnail"&gt; &lt;/div&gt; &lt;div class="col-md-8 col-xs-12"&gt; &lt;table class="table table-bordered"&gt; &lt;tbody&gt; &lt;tr&gt;&lt;td style="width:80px;"&gt;游戏平台&lt;/td&gt;&lt;td&gt;&lt;%- game.platform %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;出版商&lt;/td&gt;&lt;td&gt;&lt;%- game.publisher %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;语言&lt;/td&gt;&lt;td&gt;&lt;%- game.language %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;链接&lt;/td&gt;&lt;td&gt; &lt;a href="&lt;%- game.link %&gt;" title="&lt;%- game.link %&gt;"&gt;游戏链接&lt;/a&gt; &lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;状态&lt;/td&gt; &lt;td&gt; &lt;% if (game.status == '已通关')&#123; %&gt; &lt;span class="label label-success"&gt;&lt;%- game.status %&gt;&lt;/span&gt; &lt;% &#125; else if (game.status == '进行中') &#123; %&gt; &lt;span class="label label-info"&gt;&lt;%- game.status %&gt;&lt;/span&gt; &lt;% &#125; else if (game.status == '未开始') &#123;%&gt; &lt;span class="label label-default"&gt;&lt;%- game.status %&gt;&lt;/span&gt; &lt;% &#125;%&gt; &lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;类型&lt;/td&gt;&lt;td&gt;&lt;%- game.type %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;td&gt;评价&lt;/td&gt;&lt;td&gt;&lt;%- game.description %&gt;&lt;/td&gt;&lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;% &#125;) %&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; ​ front-matter 1234567891011121314151617181920212223242526272829303132---layout: gametitle: 2016年玩过的游戏category: - 生活 - 游戏keywords: - 游戏 - 娱乐 - 2016tags: - Enjoygames: - title: 饥荒联机版（Don't starve together） cover: http://ww4.sinaimg.cn/large/af9df239gw1f5dmat61rdj209q0d3jrq.jpg link: http://www.gamersky.com/z/dontstarve/ publisher: Klei Entertainment platform: steam type: 动作冒险，收集生存类沙盒游戏，2D画风,背景音乐超赞，在线多人联机 description: steam好评如潮 status: 进行中 language: 可用中文mod - title: 传送门2（Portal 2） cover: http://ww2.sinaimg.cn/large/af9df239gw1f5dmc8dce8j20dw0jjabi.jpg link: http://www.gamersky.com/z/portal2/ publisher: Valve Software language: 支持中文 platform: steam type: 第一人称视角，解迷，冒险，科幻,在线双人合作 description: steam好评如潮 status: 进行中--- ​ 效果 添加导航栏icon图标hexo theme大多数都是用的font-awesome字体图标库，在主题下的config文件，导航栏配置相应的icon即可。 1234567891011121314151617menu: home: / archives: /archives about: /resume Books: /books #This is your books page Movies: /movies #This is your movies page #Leetcode: /leetcode #tools: /toolsmenu_icon: home: home archives: archive about: user Books: book Movies: play-circle #Leetcode: file-text #tools: user 添加打赏 挂件中的打赏，直接替换支付宝图片的url即可 文章内的打赏，我用的是github上别人的代码 在主题的配置文件中设置donate为true 功能实现代码在\themes\lightum\layout\_partial\post\donate.ejs 在\themes\lightum\layout\_partial\article.ejs中引用上述文件 百度分享 去百度分享获取分享代码 功能实现 \themes\lightum\layout\_partial\post\share.ejs 在article的样式中引用 \themes\lightum\layout\_partial\article.ejs 在主题config中添加一个开关 share: true 百度统计和谷歌统计 还有百度收录和谷歌收录 获取百度和谷歌统计的代码，将其中的id或content写入主题配置 1234567google_analytics: UA-107525911-1# &lt;meta name="google-site-verification" content="hLu-CnRbqpthWxa76MJ-vpnGr7yMChNtTW6KA0pRMQo" /&gt;google_site_verification: hLu-CnRbqpthWxa76MJ-vpnGr7yMChNtTW6KA0pRMQo# &lt;meta name="baidu-site-verification" content="SOcrumVYOq" /&gt;# hm.src = "https://hm.baidu.com/hm.js?02f792017724a2c2af494ece7edc5fd1";baidu_analytics: 02f792017724a2c2af494ece7edc5fd1baidu_site_verification: WTddywKheI 安装sitemap和baidu-sitemap插件 站点配置文件中生成sitemap的选项 12345# 自动生成sitemapsitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xml 在谷歌或百度中设置自动爬取sitemap或手动提交 百度有个自动提交push脚本，放在每个页面的head中的。 ​ 本地搜索 参考教程1 参考教程2 需要安装插件本地搜索的插件 在站点配置文件中设置 12345search: path: search.xml field: post format: html limit: 10000 微博秀微博秀的API接口，获取代码后贴到微博挂件的ejs文件里即可。 评论系统 disqus国内被q，多说倒闭，其他的不知道还能挺多久。我用的是来必力，支持qq、微博、微信登录后评论 在主题配置文件中添加livere_uid: MTAyMC8yOTQxxxxxxooooo id去官网注册获取 相关代码在article.ejs中引用comment.ejs，更换其他评论系统也不难 豆瓣读书和电影 使用了hexo-douban插件 npm install hexo-douban 安装插件，然后站点配置文件，填入豆瓣ID 123456789# hexo-doubandouban: user: shuaiyy book: title: 我的阅读 quote: 2017年，我使用&lt;a href="https://www.douban.com/people/shuaiyy/" target="_blank"&gt;豆瓣&lt;/a&gt;记录我的阅读。 movie: title: 我的电影 quote: 2017年，我使用&lt;a href="https://www.douban.com/people/shuaiyy/" target="_blank"&gt;豆瓣&lt;/a&gt;记录我看的电影。 ​ 详细参考插件地址 写文章markdown神器 Typora不多BB，本文就是这么写的。 插入网易云音乐歌曲点击生成外链播放器，获取分享的html代码，直接黏贴，比如下面的 flash的代码 iframe的代码 部署和发布 部署到github和coding上，域名解析国内解析到coding，国外解析到github 使用ssh git部署 部署 创建代码仓库并配置ssh公钥 在站点config中添加 12345deploy: type: git repo: coding: git@git.coding.net:shuaiyy/shuaiyy.git,master github: git@github.com:shuaiyy/shuaiyy.github.io.git,master ​ 在git bash中使用ssh-add 添加ssh私钥 这样主机就能和github或coding ssh上传数据了 执行命令hexo d 发布绑定域名 首先去github，告诉github xxx.com对应的是哪个blog。 然后去域名解析商那里，告诉任何访问xxx.com的人，xxx.com是github的服务器提供的。 github github的CNAME文件指定你的域名xxx.com，然后域名解析商那里的CNAME记录国外线路指定’xxx.github.io’,即github page给你的二级域名 ​ coding coding是由pages.coding.me服务器为你做的地址跳转，因此国内DNS解析的CNAME记录指向pages.coding.me，而不是coding为你博客提供的二级域名。 github使用网站根目录的CNAME文件绑定域名，而coding需要在项目的page服务选项里设置绑定域名。 示例 github：source目录下的CNAME文件下，写入你的域名。CNAME文件名必须大写 coding：可以最多绑定5个，github由于是CNAME文件，只能绑定一个 dns解析：我的是dnspod解析商 404页面你的404.html的Front-matter中要设置layout: false title: 404。 然后把他丢到source根目录下即可。 1234567---layout: falsetitle: "404"---&lt;html&gt;你访问的页面找不到了！&lt;/html&gt; 网站的icon图标将favicon.ico文件丢入source目录即可 待改进的地方代码高亮的样式这个不会改，如果可以，我想换成night的代码高亮主题 重写标签云 现在的标签云挂件是一排的，占的地方多且不美观，有空改成一行好几个tag的那种。 点击回到顶部按钮]]></content>
      <categories>
        <category>折腾</category>
        <category>博客</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask-Login 登录插件]]></title>
    <url>%2F2017%2F09%2F23%2F%E6%8A%80%E6%9C%AF%2FFlask-Login%2F</url>
    <content type="text"><![CDATA[Flask-Login 在Flask app中注册插件1234567# auth/__init__.pyfrom flask_login import LoginManagerlogin_manager = LoginManager()login_manager.session_protection = 'strong'login_manager.login_view = 'auth.login'login_manager.init_app(app) 扩展User Model 需要继承flask-login中的UserMixin，python支持多重继承 AnonymousUserMixin类是匿名用户 @login_manager.user_loader装饰的方法用于实现用户查找 1234567891011121314151617181920212223242526272829from . import db, login_managerfrom flask_login import UserMixin, AnonymousUserMixinclass User(UserMixin, db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) name = db.Column(db.String) email = db.Column(db.String) password = db.Column(db.String) role_id = db.Column(db.Integer, db.ForeignKey('roles.id')) posts = db.relationship('Post', backref='author') comments = db.relationship('Comment', backref='author') locale = db.Column(db.String, default='zh')class AnonymousUser(AnonymousUserMixin): @property def locale(self): return 'zh' def is_administrator(self): return False login_manager.anonymous_user = AnonymousUser@login_manager.user_loaderdef load_user(user_id): return User.query.get(int(user_id)) Form表单1234567891011121314151617181920from flask.ext.wtf import Formfrom wtforms import StringField, PasswordField, SubmitFieldfrom wtforms.validators import DataRequired, EqualTo, Email, Regexp, Lengthclass RegistrationForm(Form): email = StringField(u'邮箱地址', validators=[DataRequired(), Length(1, 64), Email()]) username = StringField(u'用户名', validators=[DataRequired(), Length(1, 64), Regexp('^[A-Za-z][A-Za-z0-9_.]*$', 0, u'用户名必须由字母数、字数、下划线或 . 组成')]) password = PasswordField(u'密码', validators=[DataRequired(), EqualTo('password2', message=u'密码必须一至')]) password2 = PasswordField(u'确认密码', validators=[DataRequired()]) submit = SubmitField(u'马上注册') 视图 需要登录才能访问的视图使用装饰器login_required 123456789101112131415161718192021222324252627282930313233343536373839404142434445# coding=utf-8from flask import render_template, request, flash, redirect, url_forfrom . import authfrom .forms import LoginForm, RegistrationFormfrom ..models import Userfrom .. import dbfrom flask_login import login_user, logout_user, current_user, login_required@auth.route('/login', methods=['GET', 'POST'])def login(): form = LoginForm() if form.validate_on_submit(): user = User.query.filter_by(name=form.username.data, password=form.password.data).first() if user : login_user(user) return redirect(url_for('main.index')) return render_template('login.html', title=u'登录', form=form)@auth.route('/logout')def logout(): logout_user() return redirect(url_for('auth.login'))@auth.route('/register', methods=['GET', 'POST'])def register(): form = RegistrationForm() if form.validate_on_submit(): user = User(email=form.email.data, name=form.username.data, password=form.password.data) db.session.add(user) db.session.commit() return redirect(url_for('auth.login')) return render_template('register.html', title=u'注册', form=form) 前端模板 判断用户是否登录 current_user.is_authenticated 1234567891011&#123;% raw %&#125;&lt;ul class="nav navbar-nav navbar-right"&gt; &#123;% if current_user.is_authenticated() %&#125; &lt;li&gt;&lt;a href="#"&gt;&#123;&#123; current_user.name &#125;&#125;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="&#123;&#123; url_for('auth.logout') &#125;&#125;"&gt;&#123;&#123; _("退出") &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% else %&#125; &lt;li&gt;&lt;a href="&#123;&#123; url_for('auth.login') &#125;&#125;"&gt;&#123;&#123; _("登录") &#125;&#125;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="&#123;&#123; url_for('auth.register') &#125;&#125;"&gt;&#123;&#123; _("注册") &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &lt;/ul&gt;&#123;% endraw %&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 表单]]></title>
    <url>%2F2017%2F09%2F22%2F%E6%8A%80%E6%9C%AF%2FFlask%E8%A1%A8%E5%8D%95%2F</url>
    <content type="text"><![CDATA[表单元素 什么是表单 表单标签 表单域 表单域的种类 表单按钮 提交按钮 复位按钮 一般按钮 表单提交方式有2种方式，get和post，在form的method属性中声明 GET和POST区别 GET适用场合 POST适用场合 一个示例 一个包含多种元素的表单，可以提交数据到后台，JavaScript可以获取元素的值。 html 1234567891011121314151617181920212223242526&lt;html&gt;&lt;head&gt; &lt;script type="text/javascript" src="checkValue.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;form name="form1"&gt; &lt;!-- 单行文本框，密码框不显示明文 --&gt; &lt;input type="text" placeholder="Text" name="text1" /&gt; &lt;input type="password" placeholder="password" name="password" /&gt; &lt;!-- 多行文本框，默认可以调节大小 --&gt; &lt;textarea placeholder="Textarea" name="textarea" style="resize:none"&gt; &lt;/textarea&gt; &lt;!-- 文件上传 --&gt; &lt;input type="file" name="file" /&gt; &lt;!-- 单选框 --&gt; &lt;input type="radio" name="Option" value="Option1" /&gt;选项 1 &lt;input type="radio" name="Option" value="Option2" /&gt;选项 2 &lt;!-- 复选框 --&gt; &lt;input type="checkbox" name="check" value="Option1" /&gt;选项 1 &lt;input type="checkbox" name="check" value="Option2" /&gt;选项 2&lt;!-- 提交、重置、普通按钮， 普通按钮需要绑定onclick方法 --&gt; &lt;input type="submit" value="Submit" /&gt; &lt;input type="reset" value="Reset"/&gt; &lt;input type="button" value="button" onclick="getValue()"/&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; JavaScript 12345678910function getValue()&#123; /* 通过tag的name定位元素，value属性取值*/ /* 当选择单选框时，只有页面中被选中的框才会被选中 */ var value = document.form1.Option.value; /* 复选框通过name取到的是obkect数组，是被选中的项 */ var arr=document.form1.check; alert(arr[0].value);&#125; wtforms 表单扩展 当你必须处理浏览器提交的表单数据时，视图代码很快会变得难以阅读。有一些库可以 简化这个工作，其中之一便是 WTForms ，下面我们将介绍这个库。如果你必须处理 许多表单，那么应当尝试使用这个库。 wtforms可以实现表单验证的组件，使用pip安装。Flask-WTF是二者的简单整合。 定义一个form对象 下面是一个常见的注册用的表单对象，包含用户名，密码，确认密码，接受协议等field。 1234567891011from wtforms import Form, BooleanField, TextField, PasswordField, validatorsclass RegistrationForm(Form): username = TextField('Username', [validators.Length(min=4, max=25)]) email = TextField('Email Address', [validators.Length(min=6, max=35)]) password = PasswordField('New Password', [ validators.Required(), validators.EqualTo('confirm', message='Passwords must match') ]) confirm = PasswordField('Repeat Password') accept_tos = BooleanField('I accept the TOS', [validators.Required()]) ​ 在视图中实例化form 调用 validate() 函数来验证数据 通过 form..data 可以访问表单中单个值 123456789@app.route('/register', methods=['GET', 'POST'])def register(): # 实例化form对象，如果是通过 GET 方法提交的，则相应的是 request.args form = RegistrationForm(request.form) if request.method == 'POST' and form.validate(): # 注册用户 flash('Thanks for registering') return redirect(url_for('login')) return render_template('register.html', form=form) ​ 模板中的form wtform已经帮我们做了很多表单生成的工作 视图函数向模板传递form对象 使用form.生成对应的表单域 12345678910111213141516171819&#123;% raw %&#125;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt; &lt;div align="center"&gt; &lt;h1&gt;User Management&lt;/h1&gt; &#123;% if message %&#125; &#123;&#123;message&#125;&#125; &#123;% endif %&#125; &lt;form method="post"&gt; Username :&#123;&#123;form.username&#125;&#125; &lt;br/&gt; Password :&#123;&#123;form.password&#125;&#125; &lt;br/&gt; &lt;input type="submit" value="Submit" /&gt; &lt;input type="reset" value="reset" /&gt; &lt;/form&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;&#123;% endraw %&#125; ​ 使用Flask-Wtf表单安全提交，需要配置csrf secret key 使用flash进行错误提示 定义form对象123456789101112131415161718192021222324252627from flask_wtf import Formfrom wtforms import StringField, PasswordField, DateTimeField, SubmitFieldfrom wtforms.validators import DataRequired, Length, Email, EqualTo, Regexpclass LoginForm(Form): name = StringField(label=u'用户名', validators=[DataRequired(), Length(min=4, max=20)]) password = PasswordField(label=u'密码', validators=[DataRequired(), Length(min=4, max=20)]) submit = SubmitField(label=u'提交') class RegistrationForm(Form): email = StringField(u'邮箱地址', validators=[DataRequired(), Length(1, 64), Email()]) username = StringField(u'用户名', validators=[DataRequired(), Length(1, 64), Regexp('^[A-Za-z][A-Za-z0-9_.]*$', 0, u'用户名必须由字母数、字数、下划线或 . 组成')]) password = PasswordField(u'密码', validators=[DataRequired(), EqualTo('password2', message=u'密码必须一至')]) password2 = PasswordField(u'确认密码', validators=[DataRequired()]) submit = SubmitField(u'马上注册') 在模板中引用12345678910&#123;% raw %&#125;&lt;form action="/add" method="post"&gt; &#123;&#123; form.hidden_tag() &#125;&#125; &#123;&#123; form.name.label &#125;&#125; &#123;&#123; form.name(class='text') &#125;&#125; &#123;&#123; form.password.label &#125;&#125; &#123;&#123; form.password() &#125;&#125; &#123;&#123; form.submit() &#125;&#125; &lt;/form&gt;&#123;% endraw %&#125; Field type Validator 使用Bootstrap wtf宏渲染表单12345&#123;% raw %&#125;&lt;form action="/login" method="post"&gt; &#123;&#123; wtf.quick_form(form) &#125;&#125; &lt;/form&gt;&#123;% endraw %&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 开发环境搭建]]></title>
    <url>%2F2017%2F09%2F20%2F%E6%8A%80%E6%9C%AF%2FFlask%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Flask 开发环境搭建安装python pip 和虚拟环境virtualenv 虚拟机 docker 开发工具vim 插件 vundle vim包管理工具]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask模块化 蓝图]]></title>
    <url>%2F2017%2F09%2F19%2F%E6%8A%80%E6%9C%AF%2FFlask%E8%93%9D%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[Flask模块化 – 蓝图概念简介 在Django项目中，一个网站可以按模块划分，分别实现几个子APP，然后在settings里注册APP，并在urls里为不同的APP分配不同的url路由。 Flask也有相似的设计模式，被称为蓝图 新建一个py文件，存放一个模块的全部视图函数 ​ 1234567891011# user.pyfrom models import Userfrom flask import Blueprintuser = Blueprint('user', __name__)@user.route('/&lt;r_id&gt;')def get_user_by_id(r_id): u = User.objects(user_id=r_id).first() print u return "&#123;&#125;---&#123;&#125;".format(u.user_name, u.user_id) if u else "Not Exist!" model文件app = Flask(__name__)，可以避免循环引用 123456789101112from flask_mongoengine import MongoEnginefrom flask import Flaskapp = Flask(__name__)app.config['MONGODB_SETTINGS'] = &#123;'db': 'test'&#125;db = MongoEngine(app)class User(db.Document): user_id = db.StringField() user_name = db.StringField() def __str__(self): return "id: &#123;&#125;---name:&#123;&#125;".format(self.user_id, self.user_name) ​ 在主文件中注册蓝图，并指定路由 12from user import userapp.register_blueprint(user, url_prefix=&apos;/user&apos;) 然后访问url localhost:port/user/1 项目模块划分 蓝图的概念类似django中的app，可以将一个项目按功能拆分组织 蓝图是Flask() app对象的一个子集 将相同逻辑的功能放在同一个模块里，并且可以为其分配路由 比如登录注册找回密码等功能放到auth模块，url为/auth/xxxx 假设一个Flask APP项目有登录模块和主模块。 项目结构 在模块中使用蓝图 定义一个蓝图 在 auth/__init__.py中定义,并导入本模块中其他的py文件，避免在其他地方导入产生循环引用 12345from flask import Blueprintauth = Blueprint('auth', __name__)import forms, views 在视图中使用蓝图 auth同app对象一样有route等装饰器 反向路由时可以使用auth.login auth/views.py 1234567891011121314151617181920212223# coding=utf-8from flask import render_template, request, flash, redirect, url_forfrom . import authfrom .forms import LoginForm, RegistrationFormfrom ..models import Userfrom .. import dbfrom flask_login import login_user, logout_user, current_user@auth.route('/login', methods=['GET', 'POST'])def login(): return render_template('login.html', title=u'登录', form=form)@auth.route('/logout')def logout(): return redirect(url_for('auth.login'))@auth.route('/register', methods=['GET', 'POST'])def register(): return 'ok' ​ 蓝图注册 在app初始化方法或工厂方法中注册蓝图 url_prefix指定模块的URL路由域 static_folder指定模块自己的static文件夹路径 123456# /app/__init__.py from auth import auth as auth_blueprint from main import main as main_blueprint app.register_blueprint(auth_blueprint, url_prefix='/auth') app.register_blueprint(main_blueprint, static_folder='static')]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2016年玩过的游戏]]></title>
    <url>%2F2017%2F09%2F17%2F%E7%94%9F%E6%B4%BB-%E7%94%B5%E5%BD%B1%E9%9F%B3%E4%B9%90%E6%97%85%E8%A1%8C%E6%91%84%E5%BD%B1%2F2016-06-01-Game-of-2016%2F</url>
    <content type="text"></content>
      <categories>
        <category>生活</category>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>Enjoy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask实战 -- Todo List]]></title>
    <url>%2F2017%2F09%2F17%2F%E6%8A%80%E6%9C%AF%2FFlask%E5%AE%9E%E6%88%98%20--%20Todo%20List%2F</url>
    <content type="text"><![CDATA[Flask实战 – Todo ListFlask应用设计功能介绍 开发流程 项目开发流程 后端开发流程 架构设计 开发技术 前端：Bootstrap 后端：Flask 数据库：MongoDB 插件扩展 Flask-MongoEngine Flask-Script Flask-WTF 项目结构 数据模型 mongo orm 对象 model_form 通过类自动生成对应的表单 12345678910111213from app import dbimport datetimefrom flask_mongoengine.wtf import model_formclass Todo(db.Document): content = db.StringField(required=True, max_length=30) time = db.DateTimeField(default=datetime.datetime.now) status = db.IntField(default=0) def __str__(self): return "content:&#123;&#125; time:&#123;&#125; status:&#123;&#125;".format(self.content, self.time, self.status)TodoFrom = model_form(Todo) 前端模板 pycharm识别指定模板语法 ctrl + alt + s 搜索template，在Python template下选择jinja2 pycharm模板文件自动引用 ctrl + alt + s 搜索 project， 在project structure 里面的选项卡mark template director。 或右键templates文件夹，mark as ，template directory 基类模板 静态文件引用，反向url 1234567891011121314151617181920212223242526272829&#123;% raw %&#125;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang="en"&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&lt;/title&gt; &lt;link href="&#123;&#123; url_for('static',filename='bootstrap.min.css') &#125;&#125;" rel="stylesheet" type="text/css"/&gt; &lt;link href="&#123;&#123; url_for('static',filename='index.css') &#125;&#125;" rel="stylesheet" type="text/css"/&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="container"&gt; &lt;div class="header clearfix"&gt; &lt;h3 class="text-muted"&gt;Todo&lt;/h3&gt; &lt;/div&gt; &lt;div class="jumbotron"&gt; &#123;% block content %&#125; &#123;% endblock %&#125; &lt;/div&gt; &lt;footer class="footer"&gt; &lt;p&gt;&amp;copy; xxx.com 2017&lt;/p&gt; &lt;/footer&gt; &lt;/div&gt; &lt;!-- /container --&gt;&lt;/body&gt;&lt;/html&gt;&#123;% endraw %&#125; index页面 表单的csrf_token 表单的error信息，form.errors.content datetime时间对象格式化输出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&#123;% raw %&#125;&#123;% extends "base.html" %&#125;&#123;% block content %&#125; &lt;form class="input-group" action="/add" method="post"&gt; &#123;&#123; form.hidden_tag() &#125;&#125; &#123;&#123; form.content(class="form-control") &#125;&#125; &lt;span class="input-group-btn"&gt; &lt;button class="btn btn-default" type="submit"&gt;Add&lt;/button&gt; &lt;/span&gt; &lt;/form&gt; &#123;% for error in form.errors.content %&#125; &lt;div&gt;&#123;&#123; error &#125;&#125;&lt;/div&gt; &#123;% endfor %&#125; &lt;div&gt; &lt;h2&gt;Todo List&lt;/h2&gt; &#123;% if todos %&#125; &lt;table class="table"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;content&lt;/th&gt; &lt;th&gt;status&lt;/th&gt; &lt;th&gt;time&lt;/th&gt; &lt;th&gt;operate&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &#123;% for todo in todos %&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123; todo.content &#125;&#125;&lt;/td&gt; &lt;td&gt; &#123;% if todo.status == 1 %&#125; 已完成 &#123;% else %&#125; 未完成 &#123;% endif %&#125; &lt;/td&gt; &lt;td&gt;&#123;&#123; todo.time.strftime('%H:%M %d-%m-%Y') &#125;&#125;&lt;/td&gt; &#123;% if todo.status == 1 %&#125; &lt;td&gt;&lt;a href="/undone/&#123;&#123; todo.id &#125;&#125;" class="btn btn-primary"&gt;Undone&lt;/a&gt;&lt;/td&gt; &#123;% else %&#125; &lt;td&gt;&lt;a href="/done/&#123;&#123; todo.id &#125;&#125;" class="btn btn-primary"&gt;Done&lt;/a&gt;&lt;/td&gt; &#123;% endif %&#125; &lt;td&gt;&lt;a href="/delete/&#123;&#123; todo.id &#125;&#125;" class="btn btn-danger"&gt;Delete&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/tbody&gt; &lt;/table&gt; &#123;% else %&#125; &lt;h3 class="text-info"&gt;No todos,please add&lt;/h3&gt; &#123;% endif %&#125; &lt;/div&gt;&#123;% endblock %&#125;&#123;% endraw %&#125; 404页面 123456&#123;% raw %&#125; &#123;% extends "base.html" %&#125; &#123;% block content %&#125; &lt;h2 class="label-warning"&gt;Not Found&lt;/h2&gt; &#123;% endblock %&#125;&#123;% endraw %&#125; app配置和初始化 配置文件config.py 123SECRET_KEY = "asdadawefda"MONGODB_SETTINGS = &#123;'DB': 'todo'&#125;WTF_CSRF_ENABLED = False # 单元测试post表单时，时取消csrf验证， ​ 在app的__init__.py里定义app对象和创建数据库连接，使用配置文件 12345678from flask import Flaskfrom flask.ext.mongoengine import MongoEngineapp = Flask(__name__)app.config.from_object('config')db = MongoEngine(app) from app import views,models 或者使用一个工厂方法注册所有APP的组件，避免全局变量 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# __init__.pyfrom os import pathfrom flask_bootstrap import Bootstrapfrom flask_sqlalchemy import SQLAlchemyfrom flask_login import LoginManager, current_userfrom flask_pagedown import PageDownfrom flask_gravatar import Gravatarfrom flask_babel import Babel, gettext as _from config import configbasedir = path.abspath(path.dirname(__file__))db = SQLAlchemy()babel = Babel()bootstrap = Bootstrap()pagedown = PageDown()login_manager = LoginManager()login_manager.session_protection = 'strong'login_manager.login_view = 'auth.login'def create_app(config_name='default'): app = Flask(__name__) app.config.from_object(config[config_name]) db.init_app(app) bootstrap.init_app(app) login_manager.init_app(app) pagedown.init_app(app) babel.init_app(app) Gravatar(app, size=64) from auth import auth as auth_blueprint from main import main as main_blueprint app.register_blueprint(auth_blueprint, url_prefix='/auth') app.register_blueprint(main_blueprint, static_folder='static') @app.template_test('current_link') def is_current_link(link): return link == request.path @babel.localeselector def get_locale(): return current_user.locale return app ​ 实现查询、保存、更新、删除功能 视图views.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546from app import appfrom flask import render_template,requestfrom models import Todo, TodoFormfrom datetime import datetime# 查询@app.route('/')def index(): form = TodoForm() todos = Todo.objects.order_by('-time') return render_template("index.html",todos=todos,form=form)# 增加@app.route('/add', methods=['POST',])def add(): form = TodoForm(request.form) if form.validate(): content = form.content.data todo = Todo(content=content,time=datetime.now()) todo.save() todos = Todo.objects.order_by('-time') return render_template("index.html",todos=todos,form=form) # 修改@app.route('/done/&lt;string:todo_id&gt;')def done(todo_id): form = TodoForm() todo = Todo.objects.get_or_404(id=todo_id) todo.update(status=1) todos = Todo.objects.order_by('-time') return render_template("index.html",todos=todos,form=form) # 删除@app.route('/delete/&lt;string:todo_id&gt;')def delete(todo_id): form = TodoForm() todo = Todo.objects.get_or_404(id=todo_id) todo.delete() todos = Todo.objects.order_by('-time') return render_template("index.html",todos=todos,form=form)# 404页面@app.errorhandler(404)def not_found(error): return render_template('404.html') 改进用户体验 时间降序排列list todos = Todo.objects.order_by(&#39;-time&#39;) 格式化时间 在模板中todo.time.strftime(&#39;%H:%M %d-%m-%Y&#39;) 404页面 在视图中使用装饰器@app.errorhandler(404) 应用测试单元测试 编写测试用例123456789101112131415161718192021222324import unittestfrom app import appfrom app.models import Todoclass TodoTestCase(unittest.TestCase): # 开始测试前执行 def setUp(self): self.app = app.test_client() # 测试结束后执行 def tearDown(self): todos = Todo.objects.all() for todo in todos: todo.delete() def test_index(self): rv = self.app.get('/') assert "Todo" in rv.data def test_todo(self): self.app.post('/add', data = dict(content="testtodo")) todo = Todo.objects.get_or_404(content="testtodo") assert todo is not None 开始测试前setUp方法先执行 测试结束后tearDown方法执行 测试方法以test_开头命名 测试POST时关闭csrf验证 执行测试用例 python -m unittest discover 测试覆盖率 安装coverage pip install coverage 使用命令coverage report windows下可以右键测试文件，选择run with coverage]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask数据库的修改和迁移]]></title>
    <url>%2F2017%2F09%2F15%2F%E6%8A%80%E6%9C%AF%2FFlask%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%BF%AE%E6%94%B9%E5%92%8C%E8%BF%81%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[Flask数据库的修改和迁移 类似django中的manage migrate命令，flask也有类似的插件 使用flask插件pip install flask-migrate 在manage中绑定数据库命令即可 1234567891011121314151617# manage.pyfrom model import dbfrom model import appfrom flask.ext.script import Managerfrom flask.ext.migrate import Migrate, MigrateCommand, upgrademigrate = Migrate(app,db)manager = Manager(app)manager.add_command('db',MigrateCommand)@manage.commanddef deploy(): upgrade() app.run()if __name__ == '__main__': manager.run() ​ 初始化数据库 python manage.py db init 检测数据库变化 python manage.py db migrate 更新数据库表 python manage.py db upgrade]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitbook生成PDF电子书]]></title>
    <url>%2F2017%2F09%2F14%2F%E6%8A%80%E6%9C%AF%2FGitbook%E7%94%9F%E6%88%90PDF%E7%94%B5%E5%AD%90%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[Gitbook生成PDF电子书 看到几个不错的开源书籍，发布在gitbook上，然而gitbook很卡，网页体验不好。。。 哇塞，在gitbook官网找书，部分有下载按钮，应该是作者编译提供的。 好吧，这次就不自己折腾了。 problem-solving-with-algorithms-and-data-structure-using-python 中文版 编程之法：面试和算法心得 程序员的自我修养 LeetCode题解 参考教程 安装nodejs 安装gitbook-cli 安装gitbook 下载phantomjs 下载安装calibre2 配置环境变量]]></content>
      <categories>
        <category>折腾</category>
        <category>电子书</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>gitbook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask Markdown支持]]></title>
    <url>%2F2017%2F09%2F14%2F%E6%8A%80%E6%9C%AF%2FMarkdown%20in%20Flask%2F</url>
    <content type="text"><![CDATA[Markdown in Flaskpip安装markdown，flask-pagedown,可以在编辑内容时实时预览markdown 需要在form对象中设置相应的field 需要在前端页面引入pagedown 的js pagedown Field对应的开关参数only_input或only_preview 在form中设置Field123456789101112131415# forms.pyfrom flask.ext.pagedown.fields import PageDownFieldfrom flask.ext.wtf import Formfrom wtforms import StringField, SubmitFieldfrom wtforms.validators import DataRequiredclass PostForm(Form): title = StringField(label=_(u"标题"), validators=[DataRequired()]) body = PageDownField(label=_(u"正文"), validators=[DataRequired()]) submit = SubmitField(_(u"发表"))class CommentForm(Form): body = PageDownField(label=_(u'评论'), validators=[DataRequired()]) submit = SubmitField(_(u'发表')) 在模板中使用123456789101112131415161718192021222324252627282930&#123;% raw %&#125;&#123;% extends 'base.html' %&#125;&#123;% import "bootstrap/wtf.html" as wtf %&#125;&#123;% block scripts %&#125; &#123;&#123; super() &#125;&#125; &#123;&#123; pagedown.include_pagedown() &#125;&#125;&#123;% endblock %&#125;&#123;% block page_body %&#125; &lt;div class="container"&gt; &lt;form method="POST"&gt; &#123;&#123; form.hidden_tag() &#125;&#125; &lt;div class="form-group"&gt; &#123;&#123; form.title(class="form-control", placeholder=_("请输入文章标题") ) &#125;&#125; &lt;/div&gt; &lt;div class="form-group"&gt; &#123;&#123; form.body(only_input=True,rows=10,class="form-control") &#125;&#125; &lt;/div&gt; &lt;div&gt; &#123;&#123; form.body(only_preview=True) &#125;&#125; &lt;/div&gt; &lt;div class="form-group"&gt; &#123;&#123; form.submit(class="btn btn-primary") &#125;&#125; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt;&#123;% endblock %&#125;&#123;% endraw %&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask-Gravatar用户头像]]></title>
    <url>%2F2017%2F09%2F13%2F%E6%8A%80%E6%9C%AF%2FFlask-Gravatar%2F</url>
    <content type="text"><![CDATA[Flask-Gravatar 关于Gravatar： 我们在很多博客或者网站留言，评论的时候会看到有的人头像很酷很个性化，但是这个博客和网站本身并没有提供设置头像的功能，感觉有点神奇，那么是怎么做到的呢？其实这是使用了Gravatar。 Gravatar的概念首先是在国外的独立WordPress博客中兴起的，当你到任何一个支持Gravatar的网站留言时，这个网站都会根据你所提供的Email地址为你显示出匹配的头像。当然，这个头像，是需要你事先到Gravatar的网站注册并上传的，否则，在这个网站上，就只会显示成一个默认的头像。 flask-gravatar扩展插件，官方文档here pip install Flask-Gravatar 初始化12345678910# app/__init__.py 或者flask app的工厂方法from flask_gravatar import Gravatargravatar = Gravatar(app, size=100, rating='g', default='retro', force_default=False, force_lower=False, use_ssl=False, base_url=None) 在模板中使用12345&#123;% raw %&#125; &lt;img class="media-object img-circle" src="&#123;&#123; comment.author.email | gravatar &#125;&#125;"&gt;&lt;!-- 可以加入参数 --&gt; &#123;&#123; 'zzz.sochi@gmail.com' | gravatar(size=200, rating='x') &#125;&#125;&#123;% endraw %&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 国际化语言支持]]></title>
    <url>%2F2017%2F09%2F12%2F%E6%8A%80%E6%9C%AF%2FFlask%20%E5%9B%BD%E9%99%85%E5%8C%96%E8%AF%AD%E8%A8%80%E6%94%AF%E6%8C%81%2F</url>
    <content type="text"><![CDATA[Flask 国际化语言支持 flask-babel扩展]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 分页]]></title>
    <url>%2F2017%2F09%2F11%2F%E6%8A%80%E6%9C%AF%2FFlask%20%E5%88%86%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[flask 分页数据伪装 使用 forgery_py, 安装 pip install forgerypy 生成大量符合条件的随机数据,用于开发和测试，此处是用于分页的数据 生成大量随机的符合条件的数据 123456789101112from forgery_py import basic, lorem_ipsum, name, internet, datefrom random import randintPost(title=lorem_ipsum.title(), body=lorem_ipsum.paragraphs(), created=date.date(), author=func_author())User(name=internet.user_name(), email=internet.email_address(), password=basic.text(6, at_least=6, spaces=False), role=guests) 分页的视图逻辑 要有page_index参数，即当前是第几页 12345678910111213@main.route('/')def index(): # posts=Post.query.all() page_index = request.args.get('page', 1, type=int) query = Post.query.order_by(Post.created.desc()) pagination = query.paginate(page_index, per_page=20, error_out=False) posts = pagination.items return render_template('index.html', title=_(u'欢迎来到Ray的博客'), posts=posts, pagination=pagination) 模板中使用分页 使用Bootstrap提供的pagination 默认的页面参数是?page=n 123456789101112131415161718192021222324&#123;% raw %&#125;&#123;% extends 'base.html' %&#125;&#123;% from "bootstrap/pagination.html" import render_pagination %&#125;&#123;% block page_body %&#125; &lt;div class="container"&gt; &lt;a href="&#123;&#123; url_for('main.edit') &#125;&#125;" class="btn btn-primary"&gt;发表新文章&lt;/a&gt; &lt;/div&gt; &lt;div class="container"&gt; &lt;!-- 展示items --&gt; &#123;% for post in posts %&#125; &lt;h2&gt;&lt;a href="&#123;&#123; url_for('main.post', id = post.id) &#125;&#125;"&gt;&#123;&#123; post.title &#125;&#125;&lt;/a&gt;&lt;/h2&gt; &lt;div&gt; &#123;&#123; post.body_html|safe &#125;&#125; &lt;/div&gt; &#123;% endfor %&#125; &lt;!-- 分页栏 --&gt; &#123;% if pagination %&#125; &#123;&#123; render_pagination(pagination) &#125;&#125; &#123;% endif %&#125; &lt;/div&gt;&#123;% endblock %&#125;&#123;% endraw%&#125; ​]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask 应用测试]]></title>
    <url>%2F2017%2F09%2F10%2F%E6%8A%80%E6%9C%AF%2FFlask%20%E4%BB%A3%E7%A0%81%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[Flask 应用测试测试内容 模型测试 逻辑测试 view测试 unittest 测试文件以test_开头命名 每个测试文件都要实现一个测试用例 测试用例内的方法命名也是test_开头命名 测试用例有setUp和tearDown方法 目录结构– tests —-__init__.py —-test_models.py 为测试单独提供config参数123456789101112131415161718192021222324252627282930313233343536373839404142434445# config.pyimport osbasedir = os.path.abspath(os.path.dirname(__file__))class Config: SECRET_KEY = os.environ.get('SECRET_KEY') or '\x03d\xf4\x95J\x15\xa4B\xfb\xc0\xaf \xd1A[j$&#125;\x18\x16a\xe7\xd0\xec' SSL_DISABLE = False SQLALCHEMY_COMMIT_ON_TEARDOWN = True SQLALCHEMY_RECORD_QUERIES = True BABEL_DEFAULT_LOCALE = 'zh' @staticmethod def init_app(app): passclass DevelopmentConfig(Config): DEBUG = True SQLALCHEMY_DATABASE_URI = os.environ.get('DEV_DATABASE_URL') or \ 'sqlite:///' + os.path.join(basedir, 'data-dev.sqlite')class TestingConfig(Config): TESTING = True SERVER_NAME = 'localhost:5000' SQLALCHEMY_DATABASE_URI = os.environ.get('TEST_DATABASE_URL') or \ 'sqlite:///' + os.path.join(basedir, 'data-test.sqlite') WTF_CSRF_ENABLED = Falseclass Production(Config): DEBUG=True SQLALCHEMY_DATABASE_URI = os.environ.get('DEV_DATABASE_URL') or \ 'postgresql://ray:?@localhost/blog-db'config = &#123; 'development': DevelopmentConfig, 'testing': TestingConfig, 'production': Production, 'default': DevelopmentConfig&#125; 在flask app的工厂方法中使用参数来选择不同的配置 123456# app/__init__.pyfrom config import configdef create_app(config_name='default'): app = Flask(__name__) app.config.from_object(config[config_name]) 测试代码 Flask提供了测试客户端 测试models对象增删查改 开始测试方法前连接数据库，清空，重建表 测试结束后关闭数据库连接 12345678910111213141516171819202122232425262728293031323334# test_models.pyimport unittestfrom app import create_app, dbfrom app.models import User, Rolefrom forgery_py import internet, basicfrom flask import url_forclass ModelTest(unittest.TestCase): def setUp(self): self.app = create_app('testing') self.app_ctx = self.app.app_context() self.app_ctx.push() self.client = self.app.test_client() db.drop_all() db.create_all() def tearDown(self): self.app_ctx.pop() def test_user_role_set(self): user = User(name=internet.user_name(), email=internet.email_address(), password=basic.text()) db.session.add(user) db.session.commit() self.assertEqual(user.role.name, 'Guests') def test_index_page(self): rep = self.client.get(url_for('main.index')) self.assertEqual(rep.status_code, 200) nose nose extends unittest to make testing easier. web ui 测试 安装selenium，chrom driver chrome， Firefox 在views里实现一个关闭flask进程的功能，当测试结束后，访问该url后flask退出 123456789101112from flask import current_app@main.route('/shoutdown')def shutdown(): if not current_app.testing: abort(404) shoutdown = request.environ.get('werkzeug.server.shutdown') if not shoutdown: abort(500) shoutdown() return u'正在关闭服务端进程...' 将关于同一个页面的selenium操作封装到一个对象里，以方便复用 123456789101112131415161718192021222324from selenium import webdriverclass LoginPage(object): client = None def __init__(self, c): self.client = c @property def title(self): return self.client.title def set_user_name(self, name): user_input = self.client.find_element_by_name('username') user_input.send_keys(name) def set_pwd(self, pwd): pwd_input = self.client.find_element_by_name('password') pwd_input.send_keys(pwd) def submit(self): submit = self.client.find_element_by_name('submit') submit.click() 测试登录的脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# test_selenium.py# coding=utf-8import unittestimport threadingfrom selenium import webdriverfrom app import create_app, dbfrom app.models import Role, Userimport refrom forgery_py import internet, basicclass SeleniumTest(unittest.TestCase): client = None app_ctx = None @classmethod def setUpClass(cls): try: cls.client = webdriver.Firefox() except: pass if cls.client: cls.app = create_app('testing') cls.app_ctx = cls.app.app_context() cls.app_ctx.push() db.drop_all() db.create_all() Role.seed() threading.Thread(target=cls.app.run).start() @classmethod def tearDownClass(cls): # 在服务端关闭flask进程 cls.client.get('http://localhost:5000/shutdown') cls.client.close() db.session.remove() cls.app_ctx.pop() def setUp(self): if self.client is None: self.skipTest(u'略过测试') def tearDown(self): pass def test_user_login(self): from login_page import LoginPage new_user = User(name=internet.user_name(), email=internet.email_address(), password=basic.text()) db.session.add(new_user) db.session.commit() page = LoginPage(self.client) self.client.get('http://localhost:5000/auth/login') self.assertTrue(u'登录' in page.title) page.set_user_name(new_user.name) page.set_pwd(new_user.password) page.submit() # 返回注册结果 self.assertTrue(re.search(u'欢迎来到Ray的博客', self.client.page_source))]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask Web应用部署和运维]]></title>
    <url>%2F2017%2F09%2F09%2F%E6%8A%80%E6%9C%AF%2FFlask%20Web%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%E5%92%8C%E8%BF%90%E7%BB%B4%2F</url>
    <content type="text"><![CDATA[Flask Web应用部署和运维web应用发布服务器要求 云服务器 ssh登录到远程服务器 配置web服务器运行环境 上传数据 通过ssh的sftp协议 通过ssh的lrzsz命令 配置web应用 绑定公网ip，host= 0.0.0.0，允许公网访问 配置日志 配置缓存 WSGI WSGI简介 WSGI具有灵活性和扩展性 WSGI应用 WSGI应用是一个接受两个参数的可调用对象 WSGI服务器 为每个HTTP请求调用WSGI应用。 部署方案设计服务器系统的选择Linux服务器，CentOS或Ubuntu 常用的WSGI服务器 Gunicorn uWSGI CheryPy Tornado Gevent(基于协程，资源占用更少？) mod_wsgi(Apache) Web服务器 Nginx lighttpd Apache Nginx是面向性能设计的HTTP服务器，相比Apache，Lighttpd占用内存少，稳定性更高。 部署方案 Nginx web服务器 Gunicorn WSGI服务器 Virtualenv 管理Python运行环境 Supervisor进程监控管理 部署工作 可以选择将flask app设置为linux系统服务 ubuntu注册系统服务的配置为/etc/init/my_flask.conf 启动服务sudo service my_flask start 12345678910111213# /etc/init/my_flask.confdescription "My flask app service"start on runlevel [2345]stop on runlevel [!2345]respawnsetuid rootsetgid www-dataenv PATH=/usr/share/www/venv/binchdir /usr/share/www/#wsgi.py是flask app的入口执行文件，application是flask app对象实例exec gunicorn -w 4 -b 127.0.0.1:8000 wsgi:application 可以使用supervisor监控flask app进程 部署工具 virtualenv，串讲独立的python运行环境，pip install 解决版本稳题 依赖问题 权限问题 使用方法 创建虚拟环境 virtualenv flask_env 激活 source flask_env/bin/activate 退出 deactivate Supervisor 进程管理工具， apt-get install supervisor 应用进程控制 多应用进程管理 应用中断后快速重启 使用方法 主配置文件位于/etc/supervisor/supervisord.conf,其中有一行参数[include] files = /etc/supervisor/conf.d/*.conf表示我们自定义的进程管理配置文件的应存放位置 添加程序 123# //etc/supervisor/conf.d/app.conf[program:app]command python /home/ubuntu/new/app.py ​ 使用supervisorctl进行控制 reload stop help Flask应用部署Nginx Gunicorn部署flask应用 配置Python虚拟环境 pip install -r requirement.txt 123456# requirement.txtflaskflask-wtfflask-scriptflask_mongoenginegunicorn ​ 安装配置Nginx apt-get安装 配置文件/etc/nginx/nginx.conf，里面有指定错误日志记录位置，一般在var /etc/nginx/sites-available是可用的配置文件，在此处创建配置 nginx监听80端口，处理静态文件,转发所有请求到9000端口，9000端口由Gunicorn监听 /etc/nginx/sites-enabled是生效的配置文件，我们从available里链接文件过来 gunicorn转发gunicorn -b 0.0.0.0:9000 my_app:app 监听9000端口，my_app.py是flask 应用的入口文件，后面接:app 配置supervisor 轻量级运维方案设计与实现DevOps简介 优点 自动化 快速发布 快速恢复 Fabricpip install fabric 用法示例 编写fab脚本 12345# fabfile.pyfrom fabric import *def hello(): print "hello!" 执行fab命令 fab hello 简介通过SSH进行应用部署以及系统任务管理的命令行工具。 功能 本地或远程执行shell命令 上传和下载文件 提示用户输入 中断操作 轻量级运维方案Pycharm中使用Github 配置账户 首先settings，version control配置github账户。电脑本地要安装git 建立远程仓库并提交代码 菜单栏 VCS， import into version control， share on github commit 选中项目文件夹，右键选择git 或者快捷键 ctrl + k push ctrl + shift + k 从github仓库克隆项目、 VCS ，Check out from version control， github。 pycharm会登录你的github并拉去有仓库git地址，选择你要克隆的项目。 设计 实现 上传项目代码到git服务器 在远程服务器上git clone项目代码 部署应用，创建虚拟环境，安装项目依赖，配置数据库及flask参数 mongodb数据库安装，参考官网指导 Nginx配置 1234567891011server &#123; listen 80; location /static &#123; alias /home/ubuntu/new/todo/app/static; &#125; location / &#123; proxy_pass http://127.0.0.1:7000; &#125;&#125; ​ 使用supervisor监控管理应用 1234[program:todo]command = /home/ubuntu/flask_env/bin/gunicorn -b 0.0.0.0:7000 -w 4 run:appdirectory = /home/ubuntu/new/todo ​ 使用fabric实现自动更新部署脚本 登录服务器后，自动运行shell命令，实现项目更新部署 123456789101112from fabric.api import *# linux server的登录信息env.hosts = ['192.168.1.237']env.user = 'ubuntu'env.password = 'ubuntu'def deploy(): with cd('/home/ubuntu/new/todo'): run('git pull') sudo('supervisorctl restart todo') sudo('supervisorctl status') 本地执行 ：fab deploy]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask Bootstrap]]></title>
    <url>%2F2017%2F09%2F08%2F%E6%8A%80%E6%9C%AF%2FFlask%20Bootstrap%2F</url>
    <content type="text"><![CDATA[Flask Bootstrap 安装pip install flask-bootstrap flask-nav生成导航栏 在app中注册Bootstrap12from flask_bootstrap import BootstrapBootstrap(app) Flask-Bootstrap为我们提供了一些模板和宏 在模板中引入 直接在原来的base模板文件中继承bootstrap/base.html 123456789101112131415161718192021222324252627&#123;% raw %&#125;&#123;% extends 'bootstrap/base.html' %&#125;&#123;% block head %&#125; &#123;&#123; super() &#125;&#125;&#123;# &lt;link href="&#123;&#123; url_for('static',filename='bootstrap.min.css') &#125;&#125;" rel="stylesheet" type="text/css"/&gt;#&#125; &lt;link href="&#123;&#123; url_for('static',filename='index.css') &#125;&#125;" rel="stylesheet" type="text/css"/&gt;&#123;% endblock %&#125;&#123;% block body %&#125; &lt;div class="container"&gt; &lt;div class="header clearfix"&gt; &lt;h3 class="text-muted"&gt;Todo&lt;/h3&gt; &lt;/div&gt; &lt;div class="jumbotron"&gt; &#123;% block content %&#125; &#123;% endblock %&#125; &lt;/div&gt; &#123;% block footer %&#125; &lt;footer class="footer"&gt; &lt;p&gt;&amp;copy; yangshuai 2017&lt;/p&gt; &lt;/footer&gt; &#123;% endblock %&#125; &lt;/div&gt; &lt;!-- /container --&gt; &#123;% endblock %&#125;&#123;% endraw %&#125; Flask-Nav生成导航栏 注册Nav对象 注册navbar元素 在模板需要的地方引用 nav.top.render() top是nav对象的id 12345678from flask_nav import Navfrom flask_nav.elements import *nav = Nav(app)nav.register_element('top', Navbar(u'记事本', View(u'主页', 'index'), View(u'关于', 'index'), View(u'项目', 'index'))) Bootstrap CDN选择Bootstrap的样式，引入css文件 www.bootstrapcdn.com 123456789&#123;% raw %&#125;&#123;% block styles %&#125; &#123;&#123; super() &#125;&#125; &lt;link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/darkly/bootstrap.min.css" rel="stylesheet" integrity="sha384-S7YMK1xjUjSpEnF4P8hPUcgjXYLZKK3fQW1j5ObLSl787II9p8RO9XUGehRmKsxd" crossorigin="anonymous"&gt;&#123;% endblock %&#125;&#123;% endraw %&#125; 使用Bootstrap wtf宏渲染表单12345&#123;% raw %&#125;&lt;form action="/login" method="post"&gt; &#123;&#123; wtf.quick_form(form) &#125;&#125; &lt;/form&gt;&#123;% endraw %&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python Web框架]]></title>
    <url>%2F2017%2F09%2F07%2F%E6%8A%80%E6%9C%AF%2FPython%20Web%E6%A1%86%E6%9E%B6%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[Python Web框架简介Web开发框架Web框架简介框架 Web框架 Web框架中的概念 MVC (Model，View，Controller) ORM（Object-Relational Mapping） URL Route Template 常用Web框架种类 Django Flask]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python CGI编程]]></title>
    <url>%2F2017%2F09%2F06%2F%E6%8A%80%E6%9C%AF%2FPython%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84CGI%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[python CGI编程简介 CGI介绍cgi允许web服务器执行外部脚本或程序，并将执行结果通过web服务器发送给浏览器。 对一个 CGI 程序，做的工作其实只有：从环境变量(environment variables)和标准输入(standard input)中读取数据、处理数据、向标准输出(standard output)输出数据。 GET和POST 常见的web服务器Python内置的 ApacheNginxCGI hello world12345678#! /usr/bin/env python# cgi-bin/main.pyimport cgi, cgitbform = cgi.FieldStorage()name = form.getvalue('name')print "Content-type:text/html \n\n"print "&lt;h1&gt;Hello %s&lt;/h1&gt;" % name python -m &quot;CGIHTTPServer&quot; 8881,启动服务器。 访问 http://127.0.0.1:8881/cgi-bin/main.py?name=Susan,就会得到“Hello Susan”的输出。]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python web 数据库连接]]></title>
    <url>%2F2017%2F09%2F05%2F%E6%8A%80%E6%9C%AF%2FPython%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[Python数据库连接数据库基础数据库概念 数据库分类SQL和NoSQL SQL SQLite 单文件，小型数据库 MySQL 开源，性能优异，使用广泛 PostgreSQL 开源，性能优异，使用广泛 Oracle Microsoft SQL Server NoSQL MongoDB 性能好 neo4j elasticsearch 索引搜索功能强大 InfluxDB BigTable LevelDB 单机 分布式 单机：Mysql和PostgreSQL常用于单机 分布式：Apache HIVE 和 cloudera IMPALA 文件型和内存性 文件型，数据放在磁盘，索引放在内存 MySQL、MongoDB 内存性：数据存放在内存，多用于缓存系统 Redis(支持复杂数据类型)、Memcached 批处理和交互式 批处理：将SQL分解成MR(map &amp;&amp; reduce) Apache Hive 交互式：分级之后查询汇总 cloudera IMPALA、Apache Hbase、Amazon DynamoDB AWS Amazon web services，亚马逊云服务，提供了免运维的数据库服务，支持MySQL、PostgreSQL、Oracle、SQL Server，注册后有个免费一年的套餐。 安装数据库及管理工具 mysql server 管理工具 Navicat RoboMongo RedisDesktop ​ 数据库查询语言SQL 不同数据库之间的SQL语句不完全相同 增删查改 python进行SQL操作Mysqlpip install mysql-python 建立数据库连接 连接也可以使用URI，mysql:\\user:passs@host:port/db_name 创建游标 通过游标执行SQl语句 执行插入、删除、修改后，需要提交到数据库以保持数据一致性 最后关闭数据库 1234567891011121314151617181920212223242526import MySQLdb# connect to dbconn = MySQLdb.connect("db_host","user","passwd","db_name", charset='utf-8')# create cursorcur = conn.cursor()# sql sql ="select * from student"insert_sql="insert into student (name) values ('%s')" %('xxx')# executecur.execute(insert_sql)conn.commit() # 执行插入、提交# 执行查询，并遍历查询结果# get the resultcur.execute(sql)result=cur.fetchall()for row in result: print row[0] print row[1]# 关闭数据库conn.close() Mongodb 操作 使用pymongo 123456789101112import pymongo# 建立连接client = pymongo.MongoClient(host='127.0.0.1', port='27017')# 选择数据库db = client['test']# 选着collectionuser_collection = db['user']# 向collection插入一条文档user_collection.insert(&#123;'id': '1', 'name': 'Lisa'&#125;)# 文档查找all_user = user_collection.find() Flask中使用数据库 首先创建表 字段：id, user, password, 使用单独的py文件定义全部sql操作。 1234567891011121314151617# db.pyimport MySQLdbconn = MySQLdb.connect("localhost","root","","test")cur = conn.cursor()def insert(username,password): sql = "insert into user (username,password) values ('%s','%s')" %(username,password) cur.execute(sql) conn.commit() conn.close()def isExisted(username,password): sql="select * from user where username ='%s' and password ='%s'" %(username,password) cur.execute(sql) result = cur.fetchall() return True if result else False 视图函数中使用SQL操作 注册用户时，新建用户插入数据库表中 用户登陆时，检查登陆信息是否正确 12345678910111213141516171819from db import *@app.route("/register",methods=['GET','POST'])def register(): myForm=LoginForm(request.form) if request.method=='POST': insert(myForm.username.data,myForm.password.data) return redirect("http://www.jikexueyuan.com") return render_template('index.html',form=myForm) @app.route("/login",methods=['GET','POST'])def login(): myForm=LoginForm(request.form) if request.method =='POST': if (isExisted(myForm.username.data,myForm.password.data)): return redirect("http://www.jikexueyuan.com") else: return "Login Failed" return render_template('index.html',form=myForm) ORM 对象关系映射ORM概念数据库和对象之间的桥梁 SQLAlchemy 著名的Python ORM框架 建立连接和创建表 创建有外键关联的表对象 插入和查询数据 高级查询 与或逻辑，多表查询，多级查询 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899# coding:utf-8import sqlalchemyfrom sqlalchemy import create_enginefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy import Column, Integer, String, DateTime, TEXTfrom sqlalchemy.orm import sessionmakerfrom datetime import datetime# 创建数据库连接引擎, echo显示执行的sqlengine = create_engine('sqlite:///test.db', echo=False)# 创建数据库会话，用于事务提交Session = sessionmaker(bind=engine)session = Session()# 声明基类Base = declarative_base()class User(Base): __tablename__ = 'users' id = Column(Integer, primary_key=True) passwd = Column(Integer) name = Column(String, default='Noname') full_name = Column(String(50)) create_time = Column(DateTime, default= datetime.now) def __repr__(self): return str(self.id) + " &lt;User(name='%s', fullname='%s')&gt;" % ( self.name, self.full_name)# 包含外键的对象from sqlalchemy import ForeignKeyfrom sqlalchemy.orm import relationship, backrefclass Address(Base): __tablename__ = 'addresses' id = Column(Integer, primary_key=True) email_address = Column(String, nullable=False) user_id = Column(Integer, ForeignKey('users.id')) user = relationship("User", backref=backref('addresses', order_by=id)) def __repr__(self): return "&lt;Address(email_address='%s')&gt;" % self.email_address# 创建数据库表Base.metadata.create_all(engine)if __name__ == "__main__": u = User(name='sqwe', full_name='aassd', passwd=1) # 保存一条数据并提交 session.add(User(name='sqwe', full_name='aassd', passwd=1)) session.commit() # 保存多条数据并提交 session.add_all([ User(name='wendy1', full_name='aassd1', passwd=1), User(name='jack', full_name='aassd2', passwd=1), User(name='wendy3', full_name='aassd3', passwd=1), User(name='jack4', full_name='aassd4', passwd=1), ]) session.commit() # 查询操作，SELECT * FROM users WHERE name="ed" LIMIT 1; print session.query(User).filter_by(name='sqwe2').first() # 所有的User对象的list print(session.query(User).all()) # 按id排序，降序 for row in session.query(User).order_by(-User.id): print(row) # 精确查找，完全匹配给定值 for row in session.query(User).filter(User.name.in_(['sqwe', 'wendy', 'jack'])): print(row) # 模糊查找，子串匹配即可 for row in session.query(User).filter(~User.name.in_(['sqwe2', 'wendy', 'jack'])): print(row) # count计数 print(session.query(User).filter(User.name == 'sqwe').count()) # 高级查询条件，与或逻辑 from sqlalchemy import and_, or_ for row in session.query(User).filter(and_(User.name == 'ed', User.fullname == 'Ed Jones')): print(row) for row in session.query(User).filter(or_(User.name == 'ed', User.name == 'wendy')): print(row) jack = User(name='jack', full_name='Jack Bean', passwd='gjffdd') # 一对多的关系，一个用户可以有多个地址 jack.addresses = [ Address(email_address='jack@google.com'), Address(email_address='j25@yahoo.com')] session.add(jack) session.commit() # 多表条件查询 for u, a in session.query(User, Address).\ filter(User.id==Address.user_id).\ filter(Address.email_address=='jack@google.com').\ all(): print u, a Flask-SQLAlchemy ORM相关操作 ORM使用示例 使用ORM实现用户注册、登陆 db.create_all()命令可以生成所有的表 先创建一个SQLAlchemy对象 继承db.Model创建Model对象，实现对应的SQL操作 model对象要定义与数据库表的列名一致的属性 数据库的表可以用__tablename__定义 model.py 12345678910111213141516171819202122232425262728293031# model.pyfrom flask import Flaskfrom flask.ext.sqlalchemy import SQLAlchemyapp = Flask(__name__)app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql://root@localhost/test'db = SQLAlchemy(app)class User(db.Model): id = db.Column(db.Integer,primary_key=True) username = db.Column(db.String(32),unique=True) password = db.Column(db.String(32)) def __init__(self,username,password): self.username = username self.password = password def add(self): try: db.session.add(self) db.session.commit() return self.id except Exception,e: db.session.rollback() return e finally: return 0 def isExisted(self): temUser=User.query.filter_by(username=self.username,password=self.password).first() if temUser is None: return 0 else: return 1 在view中实例化Model对象，并调用其SQL操作方法 123456789101112131415161718192021from model import User@app.route("/register",methods=['GET','POST'])def register(): myForm=LoginForm(request.form) if request.method=='POST': u=User(myForm.username.data,myForm.password.data) u.add() return redirect("http://www.jikexueyuan.com") return render_template('index.html',form=myForm) @app.route("/login",methods=['GET','POST'])def login(): myForm=LoginForm(request.form) if request.method =='POST': u=User(myForm.username.data,myForm.password.data) if (u.isExisted()): return redirect("http://www.jikexueyuan.com") else: return "Login Failed" return render_template('index.html',form=myForm) 多表关联，主表中设置外键，foreignkey指向从表。从表中设置relationship指向主表 1234567891011121314151617181920db = SQLAlchemy(app)# 主表class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer,primary_key=True) username = db.Column(db.String(32),unique=True) password = db.Column(db.String(32)) address_id = db.Column(db.Integer, db.ForeignKey('address.id')) # 从表class Address(db.model): __tablename__ = 'address' id = db.Column(db.Integer,primary_key=True) address = db.Column(db.String(32),unique=True) users = db.relationship('User', backref='adress_x') # 相当于为User增加了一个属性address_x # 使用 User(id=1, name='xx', address_x=Address()) ​ 实现一个留言板 SQLAlchemy Model对象有query方法，实现了一系列SQL查询操作 1234567891011121314151617class Entry(db.Model): id = db.Column(db.Integer,primary_key=True) content = db.Column(db.Text) sender = db.Column(db.String(32)) def __init__(self,content,sender): self.content = content self.sender = sender def add(self): try: db.session.add(self) db.session.commit() return self.id except Exception,e: db.session.rollback() return e finally: return 0 Entry.query.filter_by().all()可以从数据库获取全部Entry对象的记录 每个表单都用wtform实现一个类 POST提交数据，GET展示数据 12345678910111213class PublishForm(Form): content = TextField("content",[validators.Required()]) sender = TextField("sender",[validators.Required()])@app.route("/show",methods=['GET','POST'])def show(): myEntryForm = PublishForm(request.form) l = Entry.query.filter_by().all() if request.method =='POST': e = Entry(myEntryForm.content.data,myEntryForm.sender.data) e.add() return render_template("show.html",entries=l,form=myEntryForm) return render_template("show.html",entries=l,form=myEntryForm) Flask应用的外部脚本 flask-script pip install flask-script ，类似Django中的manage命令 一个manage.py示例 不带参数的函数用manager.command装饰器 带参数的函数manager.option 使用livereload启动app，可以在开发时，修改代码，页面自动刷新。 12345678910111213141516171819202122from adder import app # flask appfrom flask_script import Managermanager = Manager(app)@manager.commanddef hello_world(): print 'hello world!'@manager.option('-n', '--name', dest='name', default='my friend')def hello(name): print 'hello &#123;&#125;!'.format(name) @manager.commanddef run(): from livereload import Server live_server = Server(app.wsgi_app) live_server.watch('**/*.*') live_server.serve(open_url=True) if __name__ == '__main__': manager.run() 执行 python manage hello -n Alice就会运行hello函数。 我们可以通过外部脚本与flask应用交互。 SQLlite3操作 model对象中定义SQL存储查询等操作 123456789101112131415161718192021222324252627282930313233import sqlite3def get_conn(): return sqlite3.Connection('test.db') class User(object): def __init__(self, id, name): self.id = id self.name = name def save(self): conn = get_conn() cursor = conn.cursor() sql = 'insert into user VALUES (?, ?)' cursor.execute(sql, (self.id, self.name)) conn.commit() cursor.close() conn.close() @staticmethod def query(): sql = 'select * from user' conn = get_conn() cursor = conn.cursor() cursor.execute(sql) rows = cursor.fetchall() users = [User(row[0], row[1]) for row in rows] cursor.close() conn.close() return users def __str__(self): return 'id:&#123;&#125; ----- name:&#123;&#125;'.format(self.id, self.name) ​ 在manage中可以执行SQL 12345678910111213141516171819@manager.commanddef init_db(): conn = sqlite3.Connection('test.db') cursor = conn.cursor() sql = 'create table user(id INT, NAME VARCHAR )' cursor.execute(sql) conn.commit() cursor.close() conn.close()@manager.commanddef all_user(): for x in User.query(): print x @manager.option('-i', dest='id')@manager.option('-n', dest='name', default='sss')def save_user(id, name): User(id, name).save() Mysql操作 model对象中定义SQL存储查询等操作 Mysqldb建立连接时无法使用URI格式，接收关键字参数 user passwd db host port 12345678910111213141516171819202122232425262728293031import MySQLdbdef get_conn(): return MySQLdb.Connection(user='root', passwd='123456', db='test' )# ''mysql://root:123456@localhost:3306/test''class User(object): def __init__(self, id, name): self.id = id self.name = name def save(self): conn = get_conn() cursor = conn.cursor() sql = 'insert into user(user_id, user_name) VALUES (%s, %s)' cursor.execute(sql, (self.id, self.name)) conn.commit() cursor.close() conn.close() @staticmethod def query(): sql = 'select * from user' conn = get_conn() cursor = conn.cursor() cursor.execute(sql) rows = cursor.fetchall() users = [User(row[0], row[1]) for row in rows] cursor.close() conn.close() return users 在manage中可以执行SQL 调用对象sql方法即可 Mysql ORM使用 使用 flask_sqlalchemy的Model对象定义Model 代码简洁，且无需自己实现SQL操作 会有一定的资源消耗 1234# your appapp = Flask(__name__)app.config['SQLALCHEMY_DATABASE_URI'] = 'mysql://root:123456@localhost:3306/test'db = SQLAlchemy(app) 数据库配置 app.config中配置数据库URI app.config[&#39;SQLALCHEMY_DATABASE_URI&#39;] = &#39;mysql://root:123456@localhost:3306/test&#39; 创建db对象 db = SQLAlchemy(app) 创建完APP后，就应该创建对应的db对象，然后在models.py中引用db 定义Model model的column属性名必须和数据表中字段一致 变量名一致 12345678910111213# model.pyfrom adder import dbclass User(db.Model): user_id = db.Column(db.Integer, primary_key=True) user_name = db.Column(db.String) def __init__(self, id, name): self.user_id = id self.user_name = name def __str__(self): return 'id:&#123;&#125; ----- name:&#123;&#125;'.format(self.id, self.name) Model相关操作 对于数据库的SQL操作都是使用的db对象 一个数据库的warning FSADeprecationWarning: SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future.解决办法， app.config[&#39;SQLALCHEMY_TRACK_MODIFICATIONS&#39;]=True 一个Mysql数据库的bug Warning: Incorrect string value: ‘\xD6\xD0\xB9\xFA\xB1\xEA…’ for column ‘VARIABLE_VALUE’ at row 480 ​ 1234567891011121314151617# manage.pyfrom models import Userfrom adder import app, dbfrom flask_script import Managermanager = Manager(app)@manager.commanddef all_user(): for x in User.query.all(): print x@manager.option('-i', dest='id')@manager.option('-n', dest='name', default='sss')def save_user(id, name): u = User(int(id), str(name)) db.session.add(u) db.session.commit() Mobgodb ORM使用Mongodb是文档型的，Document，准确的讲应该是Document-Relational Mapping. flask_mongoengine 事务要求高的系统不适合Mongodb 使用flask_Mongengine扩展来实现ORM app.config中配置数据库URI app.config[&#39;MONGODB_SETTINGS&#39;] = {&#39;db&#39;: &#39;test&#39;} 数据库配置三种方式可选 app.config[&#39;MONGODB_SETTINGS&#39;] = { &#39;db&#39;: &#39;project1&#39;, &#39;username&#39;:&#39;webapp&#39;, &#39;password&#39;:&#39;pwd123&#39;} 1234app.config['MONGODB_SETTINGS'] = &#123; 'db': 'project1', 'host': 'mongodb://localhost/database_name'&#125; 12345app.config['MONGODB_DB'] = 'project1'app.config['MONGODB_HOST'] = '192.168.1.35'app.config['MONGODB_PORT'] = 12345app.config['MONGODB_USERNAME'] = 'webapp'app.config['MONGODB_PASSWORD'] = 'pwd123' 创建db对象 db = MongoEngine(app) 123from flask_mongoengine import MongoEngineapp.config[&apos;MONGODB_SETTINGS&apos;] = &#123;&apos;db&apos;: &apos;test&apos;&#125;db = MongoEngine(app) 创建完APP后，就应该创建对应的db对象，然后在models.py中引用db 定义Document对象 document对象和mongodb中的数据结构要保持一致。 变量命名一致 不需要实现init 12345678910111213141516# model.pyfrom adder import dbclass User(db.Document): meta = &#123; 'collection': 'todo', 'ordering': ['-create_at'], 'strict': False, &#125; user_id = db.StringField() user_name = db.StringField() create_at = db.DateTimeField(default=datetime.now) is_completed = db.BooleanField(default=False) def __str__(self): return "id: &#123;&#125;---name:&#123;&#125;".format(self.user_id, self.user_name) Model相关操作 对于数据库的SQL操作都是使用的db对象 保存用document对象的save方法 查询所有用XXX.objects.all() ​ 12345678910111213141516# manage.pyfrom models import Userfrom adder import app, dbfrom flask_script import Managermanager = Manager(app)@manager.commanddef all_user(): for x in User.objects.all(): print x@manager.option('-i', dest='id')@manager.option('-n', dest='name', default='sss')def save_user(id, name): u = User(str(id), str(name)) u.save() 条件查询 123task = 'cooking'todo = Todo.objects(task=task).first() 排序 用Todo.objects().order_by(&#39;create_at&#39;) 更新、删除数据时，先找到，在更新 1234todo = Todo.objects(task='1').first() # 先查找if todo: todo.update(is_completed=True) # 再更新 todo.delete() 还可以实现分页 事件驱动 触发器1234567891011121314151617181920class Post(db.Model): __tablename__ = 'posts' id = db.Column(db.Integer, primary_key=True) title = db.Column(db.String) body = db.Column(db.String) body_html = db.Column(db.String) created = db.Column(db.DateTime, index=True, default=datetime.utcnow) comments = db.relationship('Comment', backref='post') author_id = db.Column(db.Integer, db.ForeignKey('users.id')) @staticmethod def on_body_changed(target, value, oldvalue, initiator): if value is None or (value is ''): target.body_html = '' else: target.body_html = markdown(value)db.event.listen(Post.body, 'set', Post.on_body_changed)]]></content>
      <categories>
        <category>技术</category>
        <category>数据库</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RESTful API]]></title>
    <url>%2F2017%2F09%2F04%2F%E6%8A%80%E6%9C%AF%2FRESTful%20API%20%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[RESTful API 设计Chrome开发工具 F12 审查元素，查看network，resource，element Console使用 postman插件 RESTful简介比如微博开发平台API接口 RESTful API 不会保存会话和cookie 验证身份可以服务器生成token，请求API时携带Token即为合法请求 表现层状态转化 表现层：html、纯文本、xml、或json格式的数据。资源呈现的具体形式即为表现层。 每一个URI代表一种资源； 客户端和服务器之间，传递这种资源的某种表现形式； 状态转移 客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化” 设计REST架构的6大原则 Uniform Interface Stateless Cacheable Client-Server Layered System 分层 Code on Demond 不限制编程语言 实例 restful api使用json或xml传递数据，为了方便生成json，定义一个jsonobject对象 123456789101112import jsonclass JsonObject(): def __init__(self): self.dic=&#123;&#125; def put(self,key,value): self.dic[key]=value def get(self,key): return self.dic[key] def getJson(self): return json.dumps(self.dic,ensure_ascii=False) def getDic(self): return self.dic 使用flask-restful扩展 定义API对象 reqparse.RequestParser对象， add_argument绑定要解析哪些参数，提交的参数不满足条件，可以给出提示 auth.parse_args 解析请求参数 可插拔视图机制 12345678910111213141516171819202122232425#coding:utf-8from flask.ext.restful import reqparse, Resourcefrom JsonObject import JsonObjectfrom models import Userauth=reqparse.RequestParser()class Authentication(Resource): def get(self): pass def post(self): auth.add_argument('username',required=True,help="Username is Required") auth.add_argument('password',required=True,help="Password is Required") args=auth.parse_args() username = args['username'] password = args['password'] u = User(username,password) jsobj = JsonObject() if u.isExisted(): jsobj.put("code",1) jsobj.put("desc","User Existed") else: jsobj.put("code",2) jsobj.put("desc","User Not Existed") return jsobj.getJson(),200 ​ 在app主文件内注册API 12345678910111213141516#coding:utf-8from flask import Flaskfrom flask.ext.restful import Apifrom userAPI import Authenticationapp = Flask(__name__)api = Api(app)import sysreload(sys)sys.setdefaultencoding('utf-8')api.add_resource(Authentication,'/auth')if __name__=='__main__': app.run(port=8080) ​]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>flask</tag>
        <tag>restful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy中使用BloomFilter优化URL去重]]></title>
    <url>%2F2017%2F09%2F03%2F%E6%8A%80%E6%9C%AF%2FScrapy%E4%BD%BF%E7%94%A8bloom%20filter%E4%BC%98%E5%8C%96URL%E5%8E%BB%E9%87%8D%2F</url>
    <content type="text"><![CDATA[scrapy使用BloomFilter优化URL去重 scrapy原有的url去重算法是sha1 Hash算法，去重队列存放在内存中,数据结构为set。 当URL记录上亿时，内存开销会非常大，因此需要更加节省内存的算法来实现URL过滤。 MD5输出128bit SHA1输出160bit SHA256输出256bit，对于100亿的去重对象，需要保存（128bit * 100亿 约150GB， 160bit的约187GB），使用bloomfilter的占用空间约为25Gb（在保证出错率不超过0.01%的情况下）。 参考文章 scrapy_redis去重优化 基于redis的BloomFilter实现 demo BloomFilter算法原理简介bloomfilter是基于bitmap数据结构的一种算法，用于精确（非100%准确）判断某个元素是否在集合中。使用场景为对空间、时间要求严格，但是能够容忍一定程度的失误率。 布隆过滤器的优点就是利用很少的空间就能实现很高的精确度。 黑名单系统 垃圾邮件过滤 爬虫网址去重系统 保存元素信息 共有n个对象 使用长度为m bit的bitarray记录对象信息。（m远大于n） 使用k个相互独立的哈希函数提取对象信息，标记bitarray中模m取余后的k个位置。 在存储元素的过程中，可能一个不在集合中的元素的k个哈希位，全部都被标记。因此容易产生误判，即不再集合中的元素被误判为已经存在于集合中，而已经在集合中的元素，是绝对不可能被误判为不再集合中的。 即使误差三千也不会漏掉一个。 判断元素是否在集合中 用k个哈希函数处理对象A 将k个哈希值模m，得到k个位置 如果bitarray中k个位置全部都为1，则A存在于集合中，否则A不存在于集合中。 精度控制和参数选择 假设样本数量n为100亿，容忍的失误率不超过0.01%， bitarray大小为m，样本数量为n，失误率为p 确定bitarray的大小m $$m=- \frac{n \times \ln p}{(\ln2)^2}$$ 当 $p=0.01\%$ 时， $m\approx19.19n$ ， m取20n，2000亿bit约为25G。 确定哈希函数的个数k $$k=\ln2\times\frac{m}{n}​$$ 可以求得k=14。 计算真实的失误率p 由于m越大失误率越低，在确定m时，一般会向上取整。实际的计算公式如下： $$p=(1-e^{-\frac{mk}{n}})^k$$ 当n=100亿， m=20n时，k=14，p=0.006%。 源码解读 当scrapy的scheduler将url request任务入队时，首先要判断URL是否重复 在scrapy_redis/scheduler下有一个enqueue_request方法 if not request.dont_filter and self.df.request_seen(request) 如果设置了不过滤url，或者url任务已执行过，则不入队。 12345678def enqueue_request(self, request): if not request.dont_filter and self.df.request_seen(request): self.df.log(request, self.spider) return False if self.stats: self.stats.inc_value('scheduler/enqueued/redis', spider=self.spider) self.queue.push(request) return True self.df = load_object(self.dupefilter_cls) df是dupefilter对象。 df.request_seen是去重函数 使用的是redis的集合添加操作sadd，如果存在sadd会返回0 redis中存放的是request的指纹，request_fingerprint(request) 12345def request_seen(self, request): fp = self.request_fingerprint(request) # This returns the number of values added, zero if already exists. added = self.server.sadd(self.key, fp) return added == 0 ​ 查看request_fingerprint(request)函数 fp是hashlib.sha1对象，也就是说存放在redis数据库中的是request的sha1摘要。 123456789101112131415161718def request_fingerprint(request, include_headers=None): if include_headers: include_headers = tuple(to_bytes(h.lower()) for h in sorted(include_headers)) cache = _fingerprint_cache.setdefault(request, &#123;&#125;) if include_headers not in cache: fp = hashlib.sha1() fp.update(to_bytes(request.method)) fp.update(to_bytes(canonicalize_url(request.url))) fp.update(request.body or b'') if include_headers: for hdr in include_headers: if hdr in request.headers: fp.update(hdr) for v in request.headers.getlist(hdr): fp.update(v) cache[include_headers] = fp.hexdigest() return cache[include_headers] 如果要改进去重机制实现节省内存的话，则需要修改request_fingerprint算法生成更小的指纹，或者改进redis存储查找指纹的算法，节省空间，而不损失太多性能。 如果改变指纹算法函数的话，那么之前爬取过得任务指纹都无法使用了，sha1算法不可逆。而且找到sha1的替代也很难。 使用BloomFilter算法，改进指纹的存储和检索算法。只需改动df.request_seen 1234567def request_seen(self, request): fp = request_fingerprint(request) if self.bf.isContains(fp): # 如果已经存在 return True else: self.bf.insert(fp) return False bf为BloomFilter对象，实现了插入和查找(判断是否存在) BloomFilter算法 123456789101112131415161718192021222324252627282930313233343536373839class BloomFilter(object): def __init__(self, host='localhost', port=6379, db=0, blockNum=1, key='bloomfilter'): """ :param host: the host of Redis :param port: the port of Redis :param db: witch db in Redis :param blockNum: one blockNum for about 90,000,000; if you have more strings for filtering, increase it. :param key: the key's name in Redis """ self.server = redis.Redis(host=host, port=port, db=db) self.bit_size = 1 &lt;&lt; 31 # Redis的String类型最大容量为512M，现使用256M self.seeds = [5, 7, 11, 13, 31, 37, 61] self.key = key self.blockNum = blockNum self.hashfunc = [] for seed in self.seeds: self.hashfunc.append(SimpleHash(self.bit_size, seed)) def isContains(self, str_input): if not str_input: return False m5 = md5() m5.update(str_input) str_input = m5.hexdigest() ret = True name = self.key + str(int(str_input[0:2], 16) % self.blockNum) for f in self.hashfunc: loc = f.hash(str_input) ret = ret &amp; self.server.getbit(name, loc) return ret def insert(self, str_input): m5 = md5() m5.update(str_input) str_input = m5.hexdigest() name = self.key + str(int(str_input[0:2], 16) % self.blockNum) for f in self.hashfunc: loc = f.hash(str_input) self.server.setbit(name, loc, 1) ​]]></content>
      <categories>
        <category>技术</category>
        <category>Scrapy</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[screen Cannot open your terminal]]></title>
    <url>%2F2017%2F09%2F02%2F%E6%8A%80%E6%9C%AF%2FScreen%20%E8%BF%9E%E6%8E%A5%E5%87%BA%E9%94%99%2F</url>
    <content type="text"><![CDATA[解决screen Cannot open your terminal ‘/dev/pts/1’问题 问题描述: userA首先登录系统，使用screen开启了一个session，然后detach这个窗口。 userB然后登录系统，通过su - userA 变成userA，然后使用screen -r 恢复之前detached窗口，这时系统报如下错误: Cannot open your terminal ‘/dev/pts/1’ - please check. 解决方法: userB在 su - userA以后，执行如下命令即可: script /dev/null 原理 注意: 有人提到 chmod 777 /dev/pts/1，这么干的人真是误人子弟，虽然这么做的确能解决这个问题，但是会带来极大的安全问题！！！ 为什么这条命令能解决问题? 一般人看到上面这里估计就马上回去试验了，但是，等等，你不想知道为什么这个命令会有作用吗？它是怎么起作用的呢？ 我们来过一遍整个的操作步骤: 首先，usera登录到系统中，我们使用tty命令查看一下分配给他的tty，然后看一下这个tty的权限，然后用户执行screen命令。 usera@localhost ~ $ ssh usera@remotehostusera@remotehost ~ $ tty/dev/pts/1usera@remotehost ~ $ ls -l /dev/pts/1crw–w—- 1 usera tty 136, 1 2011-01-09 20:14 /dev/pts/1usera@remotehost ~ $ screen 我们观察上边的输出，发现usera对于/dev/pts/1具有读写权限，它所在组成员对这个tty具有写权限，其他用户不能访问这个tty。 然后，userb也登录到系统中，同样我们使用tty命令查看一下分配给他的tty，然后看一下这个tty的权限 userb@localhost ~ $ ssh userb@remotehostuserb@remotehost ~ $ tty/dev/pts/2userb@remotehost ~ $ ls -l /dev/pts/2crw–w—- 1 userb tty 136, 2 2011-01-09 20:20 /dev/pts/2 观察输出，userb被分配了/dev/pts/2，也是对于/dev/pts/2具有读写权限，它所在组成员对这个tty具有写权限，其他用户不能访问这个tty。 然后userb通过su - usera命令变成usera，同样我们使用tty命令查看一下分配给他的tty，然后看一下这个tty的权限 userb@remotehost ~ $ sudo su - usera[sudo] password for userb:usera@remotehost ~ $ tty/dev/pts/2usera@remotehost ~ $ ls -l /dev/pts/2crw–w—- 1 userb tty 136, 2 2011-01-09 20:20 /dev/pts/2 AHA!! 注意了，我们看到虽然userb已经变成了usera，但是他所使用的tty并没有改变，仍然是/dev/pts/2。这就是为什么执行screen命令会报错的原因了，因为所有命令此时是使用usera帐户执行的，但是/dev/pts/2的读写权限属于userb，所以所有试图控制/dev/pts/2的访问都被拒绝了！ 那么我们接下来看一下 script /dev/null做了些什么，使得screen命令能执行呢？ usera@remotehost ~ $ script /dev/nullScript started, file is /dev/nullusera@remotehost ~ $ tty/dev/pts/3usera@remotehost ~ $ ls -l /dev/pts/3crw–w—- 1 usera tty 136, 3 2011-01-09 20:36 /dev/pts/3 AHA!!! 看到了吗？我们实际上是得到了一个新的tty —&gt; /dev/pts/3，因此screen命令能够执行了，因为 /dev/pts/3这个tty的所有者是usera！]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web开发基础]]></title>
    <url>%2F2017%2F09%2F01%2F%E6%8A%80%E6%9C%AF%2FWeb%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[python web开发基础 Web开发概述CS和BS架构QQ客户端属于C/S架构。 b/s浏览器服务器架构，不需要安装/升级客户端，只要浏览器，可以跨平台。 动态/静态网站区别：数据全部来自html还是有从数据库获取加工。 MVC设计web应用 CGI程序 HTML和JavaScripthtml页面结构和元素 head ，包含meta，title，js， css body 页面主体 footer 底部 img标签 form表单 input输入框 ​ 12345678910111213141516171819&lt;head&gt; &lt;title&gt;Calculator&lt;/title&gt; &lt;script src="add.js" type="text/javascript"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div align="center" style="margin-top:40px;"&gt; &lt;img src="add.png"&gt; &lt;/div&gt; &lt;div align="center" style="margin-top:60px;"&gt; &lt;form name="form1"&gt; &lt;input type="text" placeholder="adder" name="adder1"&gt;+ &lt;input type="text" placeholder="adder-2" name="adder2"&gt;= &lt;input type="text" readonly="readonly" placeholder="result" name="result"&gt; &lt;input type="button" value="计算" onclick="add()"&gt; &lt;/form&gt; &lt;/div&gt;&lt;/body&gt;&lt;footer&gt;&lt;/footer&gt; JavaScript document定位元素对象 数值转换 1234567function add()&#123; var adder1=Number(document.form1.adder1.value); var adder2=Number(document.form1.adder2.value); var result=adder1+adder2; document.form1.result.value=result;&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Web</tag>
        <tag>Html</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask基础 hello world]]></title>
    <url>%2F2017%2F08%2F30%2F%E6%8A%80%E6%9C%AF%2FFlask%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Hello World1234567891011from flask import Flaskapp = Flask(__name__)@app.route('/')def hello_world(): return 'Hello World!'if __name__ == '__main__': app.run() Flask路由 装饰器@app.route(&#39;/login&#39;, methods=[&#39;GET&#39;, &#39;POST&#39;]) 可以使用多个装饰器，同一视图绑定多个url路由 反向路由url_for(&#39;index&#39;)，参数为视图函数 从URL中获取参数 get参数request.args.get(&#39;key&#39;) 路由中的参数 /user/&lt;user_id&gt; 参数转化器/user/&lt;int：user_id&gt; 自定义参数转化器 from werkzeug.routing import BaseConverter /url/&lt;regex(&quot;[a-z0-9]{3}&quot;):user_id&gt; 12345678910111213141516171819202122232425262728from flask import Flask,request,url_for,request, session, g, redirect, url_for, abort, render_template, flashapp = Flask(__name__)# 指定请求方法，默认为GET@app.route('/login/', methods=['GET', 'POST'])def login(): error = None if request.method == 'POST': # 判断请求方法 # 从POST表单中提取数据 form = request.form if form.get('username') != app.config['USERNAME']: error = 'Invalid username' elif form.get('password') != app.config['PASSWORD']: error = 'Invalid password' else: session['logged_in'] = True flash('You were logged in') # 消息提示 重定向，反向路由 return redirect(url_for('index')) 渲染模板页面 return render_template('login.html', error=error)# 获取参数@app.route('/user/&lt;int: user_id&gt;')def show_user(user_id): pass /about/和/about的区别 访问/about/等同于访问/about/index.html, 在浏览器中不加最后的斜线也能正常访问 如果路由是/about，那么访问/about/会404出错。 request request上下文可以获取cookie、form(POST)、args(GET)参数等信息 request.cookie[‘token’] 设置cookie 1234from flask import make_responseresponse = make_response(render_template('index.html', **locals()))response.set_cookie('key', 'value')return response request.files[&#39;form-key&#39;]可以 获取post提交的文件 1from werkzeug.utils import secure_filename form表单必须指明enctype参数 模板语法 使用jinja2模板，块语句、表达式、变量赋值和with域、 赋值123456789&#123;% raw %&#125;&#123;% with %&#125;&#123;% set links=[ ('Hpme', url_for('.index')), ('About', url_for('.about')), ('Projects', url_for('.projects')),]%&#125;&#123;% endwith %&#125;&#123;% endraw %&#125; 条件语句if if elif else endif 123456789&#123;% raw %&#125;&#123;% if session.logged_in %&#125; xxx&#123;% elif session.user %&#125; ooo&#123;% else %&#125; xxx&#123;% endif %&#125;&#123;% endraw%&#125; 循环语句for语句支持else，当遍历对象为空时，进入else逻辑 1234567&#123;% raw %&#125; &#123;% for entry in entries %&#125; &lt;li&gt;&lt;h2&gt;&#123;&#123; entry.title &#125;&#125;&lt;/h2&gt;&#123;&#123; entry.text|safe &#125;&#125; &#123;% else %&#125; &lt;li&gt;&lt;em&gt;Unbelievable. No entries here so far&lt;/em&gt; &#123;% endfor %&#125;&#123;% endraw%&#125; 过滤器 {{ text | safe }} {% for comment in post.comments|sort(attribute='created',reverse=True ) %} 自定义过滤器 实现markdown渲染的例子 1234@app.template_filter('md')def markdown_to_html(text): from markdown import markdown return markdown(text) 可以调用服务器的函数 {{ read_mdfile('readme.md') | md | safe }} 12345678def read_mdfile(filename): with open(filename) as md: content = reduce(lambda x, y: x + y, md.readlines()) return content.decode('utf-8')@app.context_processordef inject_methods(): return dict(read_mdfile=read_mdfile) 模板继承 同一个block如何引用多次？ {{ self.title() }} 如果只是在父类block基础上部分增加内容，而不是覆盖，又不想重复写一遍代码？ {% block footer %} 增加内容{{ super() }} 增加内容{% endblock %} block内如何引用block外的变量 ？scoped参数 {% block title scoped %} {{ item }} {% endblock %} 模板继承，引入文件，重写覆盖block块 include参数可以是数组，一次引入多个文件 1234567&#123;% raw %&#125;&#123;% extend 'base.html' %&#125;&#123;% block body %&#125; &#123;% endblock body %&#125;重写base里的block&#123;% include 'footer.html' %&#125; //从html文档里导入代码&#123;% endraw%&#125; base.html 12345678910111213141516171819&#123;% raw %&#125;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang="en"&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&#123;&#123; title &#125;&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt; &#123;% block header %&#125;&#123;% endblock %&#125;&lt;/div&gt;&#123;% block content %&#125;&#123;% endblock %&#125;&lt;div&gt; &#123;% block footer %&#125; &#123;% endblock %&#125;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;&#123;% endraw %&#125; ​ extend_base.html 123456789101112&#123;% raw %&#125;&#123;% extend 'base.html' %&#125;&#123;% block header %&#125; &#123;% include 'header.html' %&#125;&#123;% endblock %&#125;&#123;% block content %&#125; &lt;h2&gt;这是页面内容&lt;/h2&gt;&#123;% endblock %&#125;&#123;% block footer %&#125; &#123;% include 'footer.html' %&#125;&#123;% endblock %&#125;&#123;% endraw %&#125; header.html 1234567891011121314151617181920&#123;% raw %&#125;&#123;% if session.logged_in %&#125; &lt;form action="&#123;&#123; url_for('add_entry') &#125;&#125;" method=post class=add-entry&gt; &lt;dl&gt; &lt;dt&gt;Title: &lt;dd&gt;&lt;input type=text size=30 name=title&gt; &lt;dt&gt;Text: &lt;dd&gt;&lt;textarea name=text rows=5 cols=40&gt;&lt;/textarea&gt; &lt;dd&gt;&lt;input type=submit value=Share&gt; &lt;/dl&gt; &lt;/form&gt; &#123;% endif %&#125; &lt;ul class=entries&gt; &#123;% for entry in entries %&#125; &lt;li&gt;&lt;h2&gt;&#123;&#123; entry.title &#125;&#125;&lt;/h2&gt;&#123;&#123; entry.text|safe &#125;&#125; &#123;% else %&#125; &lt;li&gt;&lt;em&gt;Unbelievable. No entries here so far&lt;/em&gt; &#123;% endfor %&#125; &lt;/ul&gt;&#123;% endraw %&#125; ​ 模板宏 宏类似于python的函数，引用 {{ input('password', type='password') }} 当宏很多时，可以写在单独的文件里，然后在需要的地方引用 {% import '_marcos.html' as ui %} 然后调用 {{ ui.input('password', type='password') }} 消息提示与异常处理消息提示 消息闪现 flash函数, 需要定义app.secret_key加密消息 在视图函数中使用flash(&quot;login success&quot;) 模板中使用get_flashed_messages 12345&#123;% raw %&#125; &#123;% for message in get_flashed_messages() %&#125; &lt;div class=flash&gt;&#123;&#123; message &#125;&#125;&lt;/div&gt; &#123;% endfor %&#125;&#123;% endraw %&#125; 异常处理 @app.httphandler(404)装饰器 abort(404) 主动抛出404异常 12345678910@app.errorhandler(404)def not_found(e): return render_template("404.html")@app.route('/find/&lt;user_id&gt;')def find(user_id): if int(user_id): return render_template("user.html") else: abort(404) # 抛出异常 视图蓝图可以根据功能将一个项目拆分成多个子app模块。 url_for]]></content>
      <categories>
        <category>技术</category>
        <category>flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip requirements]]></title>
    <url>%2F2017%2F05%2F03%2F%E6%8A%80%E6%9C%AF%2FPython-pip-requirement%2F</url>
    <content type="text"><![CDATA[requirements.txt的作用在很多Python项目中都包含一个requirements.txt文件，里面写的是一些包的名称和版本信息。 描述运行这个项目所需要的环境，包括一些库。 可以使用pip install -r requirements.txt安装这些库。 查找python项目依赖并生成requirements.txt 将整个python环境的依赖包list出来， pip freeze &gt; requirements.txt list某个项目用到的依赖包,使用工具pipreqs ，但有的时候结果会有偏差(源码分析的不准确) pip install pipreqs pipreqs ./]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海豚笔试]]></title>
    <url>%2F2017%2F04%2F13%2F%E6%8A%80%E6%9C%AF%2Fdolphin-exam%2F</url>
    <content type="text"><![CDATA[今天参加了一个实习生招聘的笔试，准备的不充分，错的惨不忍睹。整理一下遇到的题目。 1、Java部分试题有java和c++两种，以前上课学的C和Java早还给老师了，python的BIF用多了，发现连个排序算法都写不好了。 考察java的类继承和静态方法 通过类名来调用子类中的静态变量和静态方法，当父类与子类相同时是，子类会隐藏父类中与其相同的静态变量和静态方法，如果子类中没有与其父类相同的静态变量和静态方法，子类从其父类调用过来的静态变量和静态方法就会表现出来。 通过子类创建对象来用对象名调用子类中的静态变量和静态方法，除非是父类没有的静态变量和静态方法，会显示其子类的静态变量和静态方法。否则，最后显示一定是从父类哪里引用来的静态变量和静态方法。 考察Java String变量的比较及值比较 1234567891011121314151617181920//"=="操作符:用于基本数据类型的比较,判断引用是否指向同一内存块//如果String缓冲池内不存在与其指定值相同的String对象，那么此时虚拟机将为此创建新的String对象，并存放在String缓冲池内。import java.io.*;class test &#123; public static void main (String[] args) throws java.lang.Exception &#123; String s1 = "helloworld"; String s2 = "hello" + "world"; String s0 = "helloworld"; String s3 = new String("helloworld"); System.out.println(s1==s0); // true System.out.println(s2==s0); // true System.out.println(s1==s2); // true System.out.println(s1.equals(s0)); // true System.out.println(s1.equals(s3)); // true System.out.println(s1==s3); //false &#125;&#125;//如果String缓冲池内存在与其指定值相同的String对象，那么此时虚拟机将不为此创建新的String对象，而直接返回已存在的String对象的引用。 ​ 简单的算法，一个32位整数的数组，返回有序排列的2个相邻元素之差的最大值。整数是32位的，时间复杂度o(n)有加分。LeetCode 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115// 写了个最蠢的方法，冒泡排序，然后遍历数组，求最大的差值。时间复杂度在排序，o(n^2);// 数据结构书里只记得o(n*logn)的排序算法，快速排序，插入排序，堆排序，选择排序o(n^2);// 在整数取值范围有限的情况下，计数排序、基数排序和桶排序可以实现空间复杂度O(k),时间复杂度O(n)的排序/* 思路：使用桶排序的原理，但桶的取值设为n-1，而不是整数的取值范围。桶内数据无序，桶间，用后一个桶的min 减去 前一个桶的max即可。*/public class MaxGap&#123; public int maximumGap(int[] num) &#123; int maxGap = 0; // edge case if (num.length &lt; 2) &#123; return maxGap; &#125; // get maximum and minimum int min = num[0]; int max = num[0]; for (int i = 0; i &lt; num.length; i++) &#123; if (num[i] &lt; min) min = num[i]; if (num[i] &gt; max) max = num[i]; &#125; // divide into identical gaps Gap[] gaps = new Gap[num.length - 1]; boolean[] Engaged = new boolean[num.length - 1]; double gap = (double) (max - min) / (double) (num.length - 1); for (int i = 0; i &lt; gaps.length; i++) Engaged[Math.min((int) Math.floor((double) (num[i] - min) / gap), gaps.length - 1)] = true; // assign maximum and minimum for each gap for (int i = 0; i &lt; gaps.length; i++) gaps[i] = new Gap(); for (int i = 0; i &lt; num.length; i++) &#123; int index = (int) Math.floor((double) (num[i] - min) / gap); index = Math.min(index, gaps.length - 1); // lower bound if (gaps[index].low == -1) gaps[index].low = num[i]; else gaps[index].low = Math.min(gaps[index].low, num[i]); // upper bound if (gaps[index].high == -1) gaps[index].high = num[i]; else gaps[index].high = Math.max(gaps[index].high, num[i]); &#125; // find maximum gap for (int i = 0; i &lt; gaps.length; i++) &#123; if (Engaged[i]) &#123; // check its inner gap maxGap = Math.max(gaps[i].high - gaps[i].low, maxGap); // lower all the way int j = i; while (--j &gt;= 0) &#123; if (Engaged[j]) break; &#125; if (j &gt;= 0) maxGap = Math.max(gaps[i].low - gaps[j].high, maxGap); // upper all the way j = i; while (++j &lt; num.length - 2) &#123; if (Engaged[j]) break; &#125; if (j &lt; gaps.length) maxGap = Math.max(gaps[j].low - gaps[i].high, maxGap); &#125; &#125; return maxGap; &#125; class Gap &#123; int low; int high; boolean hasItem; Gap() &#123; low = -1; high = -1; &#125; Gap(int x, int y) &#123; low = x; high = y; &#125; &#125; public static void main(String[] args) &#123; int[] num = &#123;1, 2, 3, 5, 7, 9&#125;; System.out.println((new MaxGap()).maximumGap(num)); &#125;&#125; ​ 2、Python部分 下列不能创建字典的语句是 dict1 = {[1,2,3]: &#39;use&#39;} 12345678910a = &#123;[1,2 ,3]: "user"&#125;Traceback (most recent call last): Python Shell, prompt 6, line 1TypeError: unhashable type: 'list'a = &#123;4:5&#125; a = &#123;&#125;a = &#123;(1,2,3): 'use'&#125;print a&#123;(1, 2, 3): 'use'&#125; Numpy数组的切片操作 3、机器学习 研究发现，买尿布的顾客中80%的也会同时购买啤酒，这属于数据挖掘的哪种问题？关联规则。 为了防止过拟合可以采取的方法，正则化，early stopping，数据集扩增，Dropout(神经网络)。 分类和回归的区别，应用场景，常见的算法 分类和回归的区别在于输出变量的类型。 定量输出称为回归，或者说是连续变量预测；预测明天的气温是多少度，这是一个回归任务；定性输出称为分类，或者说是离散变量预测。预测明天是阴、晴还是雨，就是一个分类任务。 常见算法？好像很多算法思想都既能用于回归，也能用于分类。分类和回归应该有内在联系， 标记一下，以后深入学习后补充 逻辑回归中的常用激励函数 记得神经网络里有sigmod函数做激励函数，逻辑回归？ logistic回归此处留疑，后面再补充 描述你熟悉的神经网络和它们的特征 重要的人工神经网络算法包括：感知器神经网络（Perceptron Neural Network）, 反向传递（Back Propagation）， Hopfield网络，自组织映射（Self-Organizing Map, SOM）。学习矢量量化（Learning Vector Quantization， LVQ） 都不熟悉，先去看书了:cry: ​]]></content>
      <categories>
        <category>技术</category>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Exam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy-redis 分布式爬虫]]></title>
    <url>%2F2017%2F03%2F02%2F%E6%8A%80%E6%9C%AF%2FScrapy-redis%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[scrapy-redis 分布式爬虫简介安装和配置 安装redis数据库 pip install scrapy redis-py scrapy-redis 作用和特点 scrapy-redis是为Scrapy提供redis支持以实现分布式爬虫的组件 多个爬虫共享一个redis队列（分配request） 分布式的post处理。将爬到的items也放入redis队列，因而可以实现items的分布式处理。 scrapy-redis仅仅为scrapy提供了部分基于redis的组件，可以查看源码。 pipeline scheluder redis队列替换原有的scrapy队列 过滤器 Duplication 初步使用settings参数123456789101112131415161718192021222324252627282930313233343536# Enables scheduling storing requests queue in redis.SCHEDULER = "scrapy_redis.scheduler.Scheduler"# Ensure all spiders share same duplicates filter through redis.DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter"# Don't cleanup redis queues, allows to pause/resume crawls.SCHEDULER_PERSIST = True# Schedule requests using a priority queue. (default)SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.PriorityQueue'# Alternative queues.#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.FifoQueue'#SCHEDULER_QUEUE_CLASS = 'scrapy_redis.queue.LifoQueue'# Max idle time to prevent the spider from being closed when distributed crawling.# This only works if queue class is SpiderQueue or SpiderStack,# and may also block the same time when your spider start at the first time (because the queue is empty).#SCHEDULER_IDLE_BEFORE_CLOSE = 10# Store scraped item in redis for post-processing.ITEM_PIPELINES = &#123; 'scrapy_redis.pipelines.RedisPipeline': 300&#125;# Specify the host and port to use when connecting to Redis (optional).#REDIS_HOST = 'localhost'#REDIS_PORT = 6379# Specify the full Redis URL for connecting (optional).# If set, this takes precedence over the REDIS_HOST and REDIS_PORT settings.REDIS_URL = 'redis://user:pass@hostname:9001'# Use other encoding than utf-8 for redis.默认utf-8REDIS_ENCODING = 'latin1' scrapy-redis使用方法 首先用scrapy实现一个爬虫，然后在替换其中的组件为scrapy-redis setting里修改： 123456789101112131415# setting.pyBOT_NAME = 'moko1'SPIDER_MODULES = ['moko1.spiders']NEWSPIDER_MODULE = 'moko1.spiders'# 使用scrapy-redis的去重和调度器组件DUPEFILTER_CLASS = "scrapy_redis.dupefilter.RFPDupeFilter"SCHEDULER = "scrapy_redis.scheduler.Scheduler"SCHEDULER_PERSIST = TrueITEM_PIPELINES = &#123;# 会将items放入redis队列中'scrapy_redis.pipelines.RedisPipeline': 400,&#125; spiders里修改： spider类从scrapy_redis.spiders导入，有RedisSpider和RedisCrawlSpider，对应scrapy原来的Spider和CrawlSpider。 start_urls改为从redis中某个key获取，因此redis_key = ‘moko_spider:start_urls’，然后向该key push数据。 直接给出start_urls也是可行的，但是不太符合redis队列及分布式的逻辑，而且不能手动动态添加。 123456789101112131415161718192021# -*- coding: utf-8 -*-import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import Rulefrom ..items import Moko1Itemfrom scrapy_redis.spiders import RedisCrawlSpiderclass MokoSpiderSpider(RedisCrawlSpider): # 修改此处 name = 'moko_spider' allowed_domains = ['moko.cc'] start_urls = ['http://www.moko.cc/moko/post/1.html'] # 修改此处 # redis_key = 'moko_spider:start_urls' rules = ( Rule(LinkExtractor(allow=r'http://www\.moko\.cc/post/\d+\.html'), callback='parse_item', follow=True), ) def parse_item(self, response): item = Moko1Item() item['name'] = response.css("#workNickName::text").extract()[0] return item 确保redis数据库运行，清空数据库flushdb, “moko_spider:dupefilter”保存了我上次执行时已经爬取过的url信息。再次执行会被过滤掉，scrapy的去重机制。 然后启动scrapy爬虫，然后向redis_key = ‘moko_spider:start_urls’中push数据，在redis-cli客户端中执行lpush moko_spider:start_urls https://moko.cc/1.html 如果启用了scrapy_redis.pipelines.RedisPipeline，items会存储在moko_spider:items中。可以将items不断的pop出来，并进行其他处理，如存储等。(感觉这种活应该交给一个pipeline干) 分布式爬取直接运行多个爬虫 上面的单个爬虫默认从localhost的Redis数据库中存取request和爬到的items， 而实现分布式爬虫只需要为爬虫指定Redis数据库的网络位置，所有的爬虫都去redis队列里存取。 12345# settings.pyREDIS_URL = 'redis://user:mima@localhost:6379' # 或者不带密码的REDIS_HOST = 'localhost'REDIS_PORT = 6379 配置redis允许远程访问 修改配置文件/etc/redis.conf 12# bind 127.0.0.1requirepass mima # 设置密码 ​ 关于主从模式 分布式架构一般分为主从模式和P2P模式。有的人认为scrapy-redis中安装有redis数据库的节点就是master，错的！ scrapy-redis中的每只爬虫都是平级的，没有主从之分。每只爬虫都是主动请求任务，执行任务，爬到的数据也可以提交给redis。redis的request队列为空时，爬虫处于饥饿状态。 scrapy-redis仅仅是把scrapy原来得本地队列放入redis数据库中，从通信和数据传输的角度来看，redis像是一个master，而实际上redis对爬虫没做任何控制和操作，只是被动的为它们提供数据。 利用docker部署爬虫 创建一个docker镜像并配置scrapy环境，这样下次就能恢复环境直接使用了 首先在daocloud申请一台胶囊主机，然后ssh登录上去，配置scrapy环境 123456789101112# 使用ubuntu的docker镜像docker run -it daocloud.io/ubuntu:14.04 /bin/bashapt-get update apt-get install lrzszapt-get install python2.7 python-pip python-devapt-get install libxml2-dev libxslt-dev python-lxml # 安装lxmlapt-get install build-essential libssl-dev libffi-devpip install six --upgradepython -m pip install pyparsing appdirspip install cryptographypip install pymongo redis twisted scrapy scrapy-redisexit # 退出docker，记住id，docker id root@ea0d832b19bb 打包上传镜像 123456789101112131415161718# 打包镜像，docker容器的id ea0d832b19bb~$ docker commit -m "ubuntu with scrapy_redis" -a "author——info" ea0d832b19bb scrapy-redissha256:53a605ccc92ab29bba70f9f026c002a9c4afa43fb9b14a9819d5859f51b0d586~$ docker images # 查看镜像# 为镜像打上tagdocker tag scrapy-redis syy2358/scrapy-redis:latest# 上传至dockerhub托管docker login # 先注册并登录dockerhub，创建一个托管仓库scrapy-redisdocker push syy2358/scrapy-redis:lastest # 将镜像上传至dockerhub# 胶囊主机只有2小时，hub上传速度又慢，只好打包镜像文件下载到我的电脑上。docker save ea0d832b19bb &gt; /home/ubuntu/scrapy-redis.tar# 可以在有docker的电脑上恢复该容器，docker load &lt; scrapy-redis.tar# 或者直接拉dockerhub/daocloud上的镜像用就行了docker pull syy2358/scrapy-redisdocker run -it xx.xx# 导出 export 和save的区别- 导入 import# save保存了容器的运行状态，支持回滚，但是数据较大。 ​自己配置环境各种报错，主要是下载链接超时，用daocloud就很顺利 首先自己编译docker镜像容易遇到各种错误，而且dockerhub的镜像push、pull的速度巨慢，估计是被墙了，所以决定改用daocloud在线编译发布镜像，编译和pull的速度都很快。 镜像制作过程： 在自己 GitHub 创建新的 repository 。 将爬虫的代码，包含Dockerfile push 到自己刚创建的 repository。 到 https://dashboard.daocloud.io/build-flows/new ，项目名称 scrapy，选择自己刚在 GitHub 创建的 repository同步代码，开始创建，选择分支：master，手动执行。如果失败，可以先看下流程定义里的构建阶段，修改任务，选择云端Dockerfile。 到 https://dashboard.daocloud.io/packages 选择 scrapy，设置 -&gt; 镜像访问控制 -&gt; 公开,设置tag为latest。 https://dashboard.daocloud.io/packages/选择scrapy后，版本 -&gt; latest 。然后可以部署到已经接入的docker或者云测试环境(右上角打开控制台，能进入web版的终端，在里面执行scrapy crawl spider即可)。 或者在自己的docker环境下，使用docker run -it daocloud.io/blue_whale/scrapy,然后就能看到爬虫在运行了 镜像地址 daocloud.io/blue_whale/scrapy : daocloud上的，速度很快 syy2358/scrapy-redis: dockerhub上的，巨慢 ​ 运行爬虫 上传源码，并从Dockerfile build镜像，然后运行爬虫 1234567891011121314151617181920212223242526272829303132333435# 项目结构.├── docker-compose.yml├── Dockerfile├── moko1│ ├── __init__.py│ ├── items.py│ ├── pipelines.py│ ├── settings.py│ └── spiders│ ├── __init__.py│ ├── moko_spider.py├── requirements.txt└── scrapy.cfg---------------------------# docker-compose.ymlversion: '2'services: spider: build: . volumes: - .:/code------------------------# DockerfileFROM syy2358/scrapy-redisENV PATH /usr/local/bin:$PATHADD . /codeWORKDIR /codeRUN pip install -r requirements.txt# COPY spiders.py /usr/local/lib/python3.5/site-packages/scrapy_redisCMD scrapy crawl moko_spider 我的redis服务器是在腾讯云上的，没有使用docker。 如果redis在docker中运行的话，需要在docker-compose.yml中定义redis的container，将spider和redis link起来，同时redis需要映射端口6379，这样不同的container之间才能相互通信。 使用docker-compose创建container 12345pip install docker-compose rz -E # 上传爬虫源码 docker-compose up #从 docker-compose.yml 中创建 `container` docker-compose scale spider=4 #将 spider 这一个服务扩展到4个container # 会有4个scrapy爬虫运行，处于饥饿状态，因为刚开始start_urls为空，直到我们pushurl去feed爬虫，爬虫才会开始抓取工作。 ​ 方法二，使用已经build好的docker镜像(爬虫代码也已经copy进去了) 123456docker run -it daocloud.io/blue_whale/scrapy### 或者docker run -it syy2358/scrapy-redis### Ctrl+P+Q 将当前container放入后台，回到docker界面docker ps -a ## 查看正在运行的containerdocker attach id # 连接入正在执行的container 退出attach的docker container 用1执行爬虫时真惨，attach上container退不出去，scrapy不停地输出log内容，按啥键都不好使，只好退出ssh重连T.T，重连后发现原来的container仍在运行中。 正常attach上一个container，可以Ctrl+P+Q退出再后台执行，或exit终止运行并退出container。 使用Docker attach命名进入docker容器后： 【场景一】如果要正常退出不关闭容器，请按Ctrl+P+Q进行退出容器。 【场景二】如果使用exit退出，那么在退出容器后会关闭容器，如下图所示。 总结 只需要配置一次scrapy的docker运行环境，上传代码，然后将container打包成镜像，就可以在任何有docker的地方pull下镜像运行。 docker挺有意思的，项目部署非常方便，不过我这个新手对docker只是一知半解。 导出redis中的items linux下使用redis-dump redis-dump -u 127.0.0.1:6379 &gt; db_full.json 将数据导入mongodb中 123456789101112131415161718192021222324#!/usr/bin/env python# -*- coding: utf-8 -*-import jsonimport redisimport pymongodef main(): r = redis.Redis(host='192.168.1.112',port=6379,db=0) client = pymongo.MongoClient(host='localhost', port=27017) db = client['dmoz'] sheet = db['sheet'] while True: # 将队列里的数据逐条pop出来，并插入mongodb中 # process queue as FIFO, change `blpop` to `brpop` to process as LIFO source, data = r.blpop(["dmoz:items"]) item = json.loads(data) sheet.insert(item) try: print u"Processing: %(name)s &lt;%(link)s&gt;" % item except KeyError: print u"Error procesing: %r" % itemif __name__ == '__main__': main() ​]]></content>
      <categories>
        <category>技术</category>
        <category>Scrapy</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>Redis</tag>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis学习笔记]]></title>
    <url>%2F2017%2F03%2F01%2F%E6%8A%80%E6%9C%AF%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[redis学习笔记no sql：redis，mongodb，Memcached redis：Remote Directory Server，远程字典服务器。 键值数据类型支持： ●字符串String类型 set、get、getset。。。 ●散列Hash类型 类似python的字典 hset、hget、hdel、hgetall、hkeys、hvals ●列表List类型 lpush、rpush、lpop、rpop、llen ●集合Set类型 sadd、smembers、srem、spop、sdiff(差集)、sinter(交集)、sunion(并集)、scard(长度)、 ●有序集合Zset类型 ZADD key [NX|XX][CH] [INCR] score member [score member ...] zscore、zcard、zrank、 一个键最多存储512MB 官网 1、下载安装linux下安装apt-get install redis-server,启动service redis-server start redis-server ：服务器 redis-benchmark：性能测试工具 redis-cli：命令行客户端 redis-check-dump：RDB文件检测工具 redis-check-aof：AOF文件修复工具 启动命令 redis-server redis.windows.conf 设置Redis服务 由于上面虽然启动了redis，但是只要一关闭cmd窗口，redis就会消失。所以要把redis设置成windows下的服务。 redis-server --service-install redis.windows-service.conf --loglevel verbose 卸载服务：redis-server –service-uninstall 开启服务：redis-server –service-start 停止服务：redis-server –service-stop 测试： redis-cli -h 127.0.0.1 -p 6379 参数配置 启动参数 redis-server redis.windows.conf –port xxx –loglevel notice 命令行客户端中动态修改 127.0.0.1:6379&gt; CONFIG get loglevel1) “loglevel”2) “notice”127.0.0.1:6379&gt; CONFIG GET port1) “port”2) “6379”127.0.0.1:6379&gt; CONFIG SET loglevel warningOK127.0.0.1:6379&gt; CONFIG GET loglevel1) “loglevel”2) “warning” 配置文件redis.conf port 6379 默认端口 bind 127.0.0.1，默认绑定的主机地址 timeout 0，当客户端闲置多久之后关闭连接，0代表没有启动这个选项 loglevel notice，日志的记录级别 # debug：很详细的信息，适合开发和测试 # verbose ：包含很多不太有用的信息 # notice ：比较适合生产环境 # warning ：警告信息 logfile stdout代表日志的记录方式，默认为标准输出 databases 16代表默认数据库的数量16个,默认的数据库编号从0开始，select 1 选择数据库1 save 300 10 –300秒内将10个更改同步到磁盘 save 900 1 dbfilename dump.rdb，指定本地数据库文件名，默认为dump.rdb dir ./,指定本地数据库的存放目录，默认是当前目录 requirepass password 设置认证 ​ ​ 2、客户端命令行2.1、命令返回消息类型： 状态信息 127.0.0.1:6379&gt; set test “test_value” OK 127.0.0.1:6379&gt; ping PONG 错误回复 127.0.0.1:6379&gt; xx (error) ERR unknown command ‘xx’ 整数 127.0.0.1:6379&gt; DBSIZE (integer) 1 字符串 127.0.0.1:6379&gt; get a “1” 127.0.0.1:6379&gt; get test “test_value” 127.0.0.1:6379&gt; get aa (nil) nil表示空的结果 多行字符串 127.0.0.1:6379&gt; keys * 1) “b” 2) “test” 3) “a” 2.2、常用命令‘redis-cli -h 127.0.0.1 -p 6379 -a passwd’ select 0 选择0号数据库 exit quit 断开连接 shutdown 同时关闭服务器 参考文档http://doc.redisfans.com/ 2.3、使用python redis-py连接Redispip install redis redis-py没有实现select 1234r = redis.Redis(host='localhost', port=6379, db=0, password=None)print r.set('a', 'a_value', ex=None, px=None, nx=False, xx=False)print r.get('a')print r.config_get('loglevel') 使用pipeline提高执行效率 1234567r = redis.Redis(host='localhost', port=6379, db=1)p = r.pipeline()p.set('k1', 'v1')p.set('qqq', 2)p.incr('num1')p.execute()print r.keys('*') 3、事务事务可以理解为一些列操作的集合，或一个过程。要么成功（全部执行），要么失败（全部都不被执行）。 开启事务 EXEC 执行事务 事务的执行 监视key WATCH counter1 counter2 如果在执行事务之前key如果被其它命令改动，事务就被打断了，不会执行。 UNWATCH:取消WATCH命令对所有key的监视 取消事务 DISCARD 错误处理 语法错误 错误的语法不会被添加到队列中，自然也不会被执行。 运行出错 事务中QUEUED的语句，在运行中出错，其他的命令也会成功执行。Redis事务不支持回滚。 4、缓存和Redis生存时间redis的键值可以设置生存时间，到期后自动删除。 EXPIRE（设置过期的秒数）/EXPIREAT（在指定的时间戳进行删除） PEXPIRE（设置过期的微秒数）/PEXPIREAT（在指定的时间戳进行删除） PERSIST（永不过期，持久化） TTL （得到某个键的生存时间） PTTL （得到某个键的生存时间） 将近期访问过得数据保存到redis中。如果数据不在Redis中，再去数据库中取。 如果大量的使用这种缓存键而且生存时间设置的过长，Redis会占用大量内存。 如果缓存键的生存时间设置太短的话，可能会导致缓存的命中率过低，内存利用率低。 5、消息队列5.1、生产者-消费者模式123456789101112131415161718# coding: utf-8import redisclass Task: def __init__(self): self.rcon = redis.Redis(db=5) self.queue = 'task:prodcons:queue' def process_task(self): while True: task = self.rcon.blpop(self.queue, 0)[1] # blpop阻塞式的pop print 'Task: %s' % taskTask().process_task()# 向'task:prodcons:queue'里lpush数据后，会有数据打印出来 5.2、发布-订阅模式12345678910111213141516171819# coding: utf-8import redisclass Task: def __init__(self): self.rcon = redis.Redis(db=5) self.ps = self.rcon.pubsub() self.ps.subscribe('task:pubsub:channel') # 订阅频道 def process_task(self): for i in self.ps.listen(): # 是个生成器 if i['type'] == 'message': print 'Task: %s' % i['data']Task().process_task()# 向'task:pubsub:channel'里publish数据后，每个订阅该频道的程序都会会打印打印相同的消息出来]]></content>
      <categories>
        <category>技术</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy_redis源码阅读]]></title>
    <url>%2F2017%2F03%2F01%2F%E6%8A%80%E6%9C%AF%2FScapy-redis%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[scapy-redis 源码阅读connection.py 创建redis连接实例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788import sixfrom scrapy.utils.misc import load_object # 加载对象from . import defaults# Shortcut maps 'setting name' -&gt; 'parmater name'.SETTINGS_PARAMS_MAP = &#123; 'REDIS_URL': 'url', 'REDIS_HOST': 'host', 'REDIS_PORT': 'port', 'REDIS_ENCODING': 'encoding',&#125;def get_redis_from_settings(settings): """Returns a redis client instance from given Scrapy settings object. This function uses ``get_client`` to instantiate the client and uses ``defaults.REDIS_PARAMS`` global as defaults values for the parameters. You can override them using the ``REDIS_PARAMS`` setting. Parameters ---------- settings : Settings A scrapy settings object. See the supported settings below. Returns ------- server Redis client instance. Other Parameters ---------------- REDIS_URL : str, optional Server connection URL. REDIS_HOST : str, optional Server host. REDIS_PORT : str, optional Server port. REDIS_ENCODING : str, optional Data encoding. REDIS_PARAMS : dict, optional Additional client parameters. """ # 获取Redis的设置参数 params = defaults.REDIS_PARAMS.copy() params.update(settings.getdict('REDIS_PARAMS')) for source, dest in SETTINGS_PARAMS_MAP.items(): val = settings.get(source) if val: params[dest] = val # ``redis_cls``是redis类的路径 if isinstance(params.get('redis_cls'), six.string_types): params['redis_cls'] = load_object(params['redis_cls']) # 通过'redis_cls'得到redis对象，如果if为False，get_redis函数中会加载默认的redis类StrictRedis return get_redis(**params)# Backwards compatible alias.from_settings = get_redis_from_settingsdef get_redis(**kwargs): """Returns a redis client instance. Parameters ---------- redis_cls : class, optional Defaults to ``redis.StrictRedis``. url : str, optional If given, ``redis_cls.from_url`` is used to instantiate the class. **kwargs Extra parameters to be passed to the ``redis_cls`` class. Returns ------- server Redis client instance. """ redis_cls = kwargs.pop('redis_cls', defaults.REDIS_CLS) # defaults.REDIS_CLS 默认值redis.StrictRedis url = kwargs.pop('url', None) if url: return redis_cls.from_url(url, **kwargs) # url不为None，则通过url创建一个Redis连接客户端实例 else: return redis_cls(**kwargs) dupefilter.py 实现去重机制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131import loggingimport timefrom scrapy.dupefilters import BaseDupeFilterfrom scrapy.utils.request import request_fingerprint # 计算url的指纹from . import defaultsfrom .connection import get_redis_from_settingslogger = logging.getLogger(__name__)# TODO: Rename class to RedisDupeFilter.class RFPDupeFilter(BaseDupeFilter): """Redis-based request duplicates filter. This class can also be used with default Scrapy's scheduler. """ logger = logger def __init__(self, server, key, debug=False): """Initialize the duplicates filter. Parameters ---------- server : redis.StrictRedis The redis server instance. key : str Redis key Where to store fingerprints. debug : bool, optional Whether to log filtered requests. """ self.server = server self.key = key self.debug = debug self.logdupes = True @classmethod def from_settings(cls, settings): """Returns an instance from given settings. This uses by default the key ``dupefilter:&lt;timestamp&gt;``. When using the ``scrapy_redis.scheduler.Scheduler`` class, this method is not used as it needs to pass the spider name in the key. Parameters ---------- settings : scrapy.settings.Settings Returns ------- RFPDupeFilter A RFPDupeFilter instance. """ server = get_redis_from_settings(settings) # XXX: This creates one-time key. needed to support to use this # class as standalone dupefilter with scrapy's default scheduler # if scrapy passes spider on open() method this wouldn't be needed # TODO: Use SCRAPY_JOB env as default and fallback to timestamp. key = defaults.DUPEFILTER_KEY % &#123;'timestamp': int(time.time())&#125; debug = settings.getbool('DUPEFILTER_DEBUG') return cls(server, key=key, debug=debug) @classmethod def from_crawler(cls, crawler): """Returns instance from crawler. Parameters ---------- crawler : scrapy.crawler.Crawler Returns ------- RFPDupeFilter Instance of RFPDupeFilter. """ return cls.from_settings(crawler.settings) def request_seen(self, request): """ 去重判断 如果request已经请求过了，则返回false """ fp = self.request_fingerprint(request) # This returns the number of values added, zero if already exists. # redis客户端的sadd操作，即向集合里添加元素 added = self.server.sadd(self.key, fp) return added == 0 def request_fingerprint(self, request): return request_fingerprint(request) def close(self, reason=''): """Delete data on close. Called by Scrapy's scheduler. 退出时清除URL指纹数据 Parameters ---------- reason : str, optional """ self.clear() def clear(self): """Clears fingerprints data.""" self.server.delete(self.key) def log(self, request, spider): """Logs given request. Parameters ---------- request : scrapy.http.Request spider : scrapy.spiders.Spider """ if self.debug: msg = "Filtered duplicate request: %(request)s" self.logger.debug(msg, &#123;'request': request&#125;, extra=&#123;'spider': spider&#125;) elif self.logdupes: msg = ("Filtered duplicate request %(request)s" " - no more duplicates will be shown" " (see DUPEFILTER_DEBUG to show all duplicates)") self.logger.debug(msg, &#123;'request': request&#125;, extra=&#123;'spider': spider&#125;) self.logdupes = False picklecompat.py 实现序列化， 参考廖雪峰-序列化 12345678910111213141516"""A pickle wrapper module with protocol=-1 by default.redis数据格式有整数和字符串，其他的Python复杂的数据类型需要序列化成字符串后存入redis把变量从内存中变成可存储或传输的过程称之为序列化，"""try: import cPickle as pickle # PY2except ImportError: import pickledef loads(s): return pickle.loads(s)def dumps(obj): return pickle.dumps(obj, protocol=-1) pipelines.py&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869from scrapy.utils.misc import load_objectfrom scrapy.utils.serialize import ScrapyJSONEncoderfrom twisted.internet.threads import deferToThreadfrom . import connection, defaultsdefault_serialize = ScrapyJSONEncoder().encodeclass RedisPipeline(object): """Pushes serialized item into a redis list/queue Settings -------- REDIS_ITEMS_KEY : str Redis key where to store items. REDIS_ITEMS_SERIALIZER : str Object path to serializer function. """ def __init__(self, server, key=defaults.PIPELINE_KEY, serialize_func=default_serialize): """Initialize pipeline. ---------- server : StrictRedis,Redis client instance. key : str,Redis key where to store items. serialize_func : callable,Items serializer function. """ self.server = server self.key = key # defaults.PIPELINE_KEY = '%(spider)s:items',不同的爬虫用不同的key self.serialize = serialize_func @classmethod def from_settings(cls, settings): params = &#123; 'server': connection.from_settings(settings), &#125; if settings.get('REDIS_ITEMS_KEY'): params['key'] = settings['REDIS_ITEMS_KEY'] if settings.get('REDIS_ITEMS_SERIALIZER'): params['serialize_func'] = load_object( settings['REDIS_ITEMS_SERIALIZER'] ) return cls(**params) @classmethod def from_crawler(cls, crawler): return cls.from_settings(crawler.settings) def process_item(self, item, spider): return deferToThread(self._process_item, item, spider) def _process_item(self, item, spider): key = self.item_key(item, spider) data = self.serialize(item) self.server.rpush(key, data) return item def item_key(self, item, spider): """Returns redis key based on given spider. Override this function to use a different key depending on the item and/or spider. """ return self.key % &#123;'spider': spider.name&#125; Queue.py 实现消息队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139from scrapy.utils.reqser import request_to_dict, request_from_dictfrom . import picklecompatclass Base(object): """Per-spider base queue class""" def __init__(self, server, spider, key, serializer=None): """Initialize per-spider redis queue. ---------- server : StrictRedis,Redis client instance. spider : Spider,Scrapy spider instance. key: str, Redis key where to put and get messages. serializer : object, Serializer object with ``loads`` and ``dumps`` methods. """ if serializer is None: # Backward compatibility. # TODO: deprecate pickle. serializer = picklecompat if not hasattr(serializer, 'loads'): raise TypeError("serializer does not implement 'loads' function: %r" % serializer) if not hasattr(serializer, 'dumps'): raise TypeError("serializer '%s' does not implement 'dumps' function: %r" % serializer) self.server = server self.spider = spider self.key = key % &#123;'spider': spider.name&#125; self.serializer = serializer def _encode_request(self, request): """Encode a request object""" obj = request_to_dict(request, self.spider) return self.serializer.dumps(obj) def _decode_request(self, encoded_request): """Decode an request previously encoded""" obj = self.serializer.loads(encoded_request) return request_from_dict(obj, self.spider) def __len__(self): """Return the length of the queue""" raise NotImplementedError def push(self, request): """Push a request""" raise NotImplementedError def pop(self, timeout=0): """Pop a request""" raise NotImplementedError def clear(self): """Clear queue/stack""" self.server.delete(self.key)class FifoQueue(Base): """Per-spider FIFO queue""" def __len__(self): """Return the length of the queue""" return self.server.llen(self.key) def push(self, request): """Push a request""" self.server.lpush(self.key, self._encode_request(request)) def pop(self, timeout=0): """Pop a request""" if timeout &gt; 0: data = self.server.brpop(self.key, timeout) if isinstance(data, tuple): data = data[1] else: data = self.server.rpop(self.key) if data: return self._decode_request(data)class PriorityQueue(Base): """Per-spider priority queue abstraction using redis' sorted set""" def __len__(self): """Return the length of the queue""" return self.server.zcard(self.key) def push(self, request): """Push a request""" data = self._encode_request(request) score = -request.priority # We don't use zadd method as the order of arguments change depending on # whether the class is Redis or StrictRedis, and the option of using # kwargs only accepts strings, not bytes. self.server.execute_command('ZADD', self.key, score, data) def pop(self, timeout=0): """ Pop a request timeout not support in this queue class """ # use atomic range/remove using multi/exec pipe = self.server.pipeline() pipe.multi() pipe.zrange(self.key, 0, 0).zremrangebyrank(self.key, 0, 0) results, count = pipe.execute() if results: return self._decode_request(results[0])class LifoQueue(Base): """Per-spider LIFO queue.""" def __len__(self): """Return the length of the stack""" return self.server.llen(self.key) def push(self, request): """Push a request""" self.server.lpush(self.key, self._encode_request(request)) def pop(self, timeout=0): """Pop a request""" if timeout &gt; 0: data = self.server.blpop(self.key, timeout) if isinstance(data, tuple): data = data[1] else: data = self.server.lpop(self.key) if data: return self._decode_request(data)# TODO: Deprecate the use of these names.SpiderQueue = FifoQueue # 先进先出SpiderStack = LifoQueue # 后进先出SpiderPriorityQueue = PriorityQueue # 优先级队列 scheduler.py 调度，对request查重，为spider分配request任务。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180import importlibimport sixfrom scrapy.utils.misc import load_objectfrom . import connection, defaults# TODO: add SCRAPY_JOB support.class Scheduler(object): """Redis-based scheduler Settings -------- SCHEDULER_PERSIST : bool (default: False) Whether to persist or clear redis queue. SCHEDULER_FLUSH_ON_START : bool (default: False) Whether to flush redis queue on start. SCHEDULER_IDLE_BEFORE_CLOSE : int (default: 0) How many seconds to wait before closing if no message is received. SCHEDULER_QUEUE_KEY : str Scheduler redis key. SCHEDULER_QUEUE_CLASS : str Scheduler queue class. SCHEDULER_DUPEFILTER_KEY : str Scheduler dupefilter redis key. SCHEDULER_DUPEFILTER_CLASS : str Scheduler dupefilter class. SCHEDULER_SERIALIZER : str Scheduler serializer. """ def __init__(self, server, persist=False, flush_on_start=False, queue_key=defaults.SCHEDULER_QUEUE_KEY, queue_cls=defaults.SCHEDULER_QUEUE_CLASS, dupefilter_key=defaults.SCHEDULER_DUPEFILTER_KEY, dupefilter_cls=defaults.SCHEDULER_DUPEFILTER_CLASS, idle_before_close=0, serializer=None): """Initialize scheduler. Parameters ---------- server : Redis The redis server instance. persist : bool Whether to flush requests when closing. Default is False. flush_on_start : bool Whether to flush requests on start. Default is False. queue_key : str Requests queue key. queue_cls : str Importable path to the queue class. dupefilter_key : str Duplicates filter key. dupefilter_cls : str Importable path to the dupefilter class. idle_before_close : int Timeout before giving up. """ if idle_before_close &lt; 0: raise TypeError("idle_before_close cannot be negative") self.server = server self.persist = persist self.flush_on_start = flush_on_start self.queue_key = queue_key self.queue_cls = queue_cls self.dupefilter_cls = dupefilter_cls self.dupefilter_key = dupefilter_key self.idle_before_close = idle_before_close self.serializer = serializer self.stats = None def __len__(self): return len(self.queue) @classmethod def from_settings(cls, settings): kwargs = &#123; 'persist': settings.getbool('SCHEDULER_PERSIST'), 'flush_on_start': settings.getbool('SCHEDULER_FLUSH_ON_START'), 'idle_before_close': settings.getint('SCHEDULER_IDLE_BEFORE_CLOSE'), &#125; # If these values are missing, it means we want to use the defaults. optional = &#123; # TODO: Use custom prefixes for this settings to note that are # specific to scrapy-redis. 'queue_key': 'SCHEDULER_QUEUE_KEY', 'queue_cls': 'SCHEDULER_QUEUE_CLASS', 'dupefilter_key': 'SCHEDULER_DUPEFILTER_KEY', # We use the default setting name to keep compatibility. 'dupefilter_cls': 'DUPEFILTER_CLASS', 'serializer': 'SCHEDULER_SERIALIZER', &#125; for name, setting_name in optional.items(): val = settings.get(setting_name) if val: kwargs[name] = val # Support serializer as a path to a module. if isinstance(kwargs.get('serializer'), six.string_types): kwargs['serializer'] = importlib.import_module(kwargs['serializer']) server = connection.from_settings(settings) # Ensure the connection is working. server.ping() return cls(server=server, **kwargs) @classmethod def from_crawler(cls, crawler): instance = cls.from_settings(crawler.settings) # FIXME: for now, stats are only supported from this constructor instance.stats = crawler.stats return instance def open(self, spider): self.spider = spider try: # 根据对象名字创建一个对象 self.queue = load_object(self.queue_cls)( server=self.server, spider=spider, key=self.queue_key % &#123;'spider': spider.name&#125;, serializer=self.serializer, ) except TypeError as e: raise ValueError("Failed to instantiate queue class '%s': %s", self.queue_cls, e) try: self.df = load_object(self.dupefilter_cls)( server=self.server, key=self.dupefilter_key % &#123;'spider': spider.name&#125;, debug=spider.settings.getbool('DUPEFILTER_DEBUG'), ) except TypeError as e: raise ValueError("Failed to instantiate dupefilter class '%s': %s", self.dupefilter_cls, e) if self.flush_on_start: self.flush() # notice if there are requests already in the queue to resume the crawl if len(self.queue): spider.log("Resuming crawl (%d requests scheduled)" % len(self.queue)) def close(self, reason): if not self.persist: self.flush() def flush(self): self.df.clear() self.queue.clear() def enqueue_request(self, request): # 如果需要检测去重，且检测到有重复，返回False if not request.dont_filter and self.df.request_seen(request): self.df.log(request, self.spider) return False if self.stats: self.stats.inc_value('scheduler/enqueued/redis', spider=self.spider) # 将request入队，返回True self.queue.push(request) return True def next_request(self): block_pop_timeout = self.idle_before_close # 分发request request = self.queue.pop(block_pop_timeout) if request and self.stats: self.stats.inc_value('scheduler/dequeued/redis', spider=self.spider) return request def has_pending_requests(self): return len(self) &gt; 0 spiders.py 爬虫类， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188from scrapy import signalsfrom scrapy.exceptions import DontCloseSpiderfrom scrapy.spiders import Spider, CrawlSpiderfrom . import connection, defaultsfrom .utils import bytes_to_str# Mixin 混合类型，利用多重继承来简洁的实现组合模式class RedisMixin(object): """Mixin class to implement reading urls from a redis queue.""" redis_key = None redis_batch_size = None redis_encoding = None # Redis client placeholder. server = None def start_requests(self): """Returns a batch of start requests from redis.""" return self.next_requests() def setup_redis(self, crawler=None): """Setup redis connection and idle signal. This should be called after the spider has set its crawler object. """ if self.server is not None: return if crawler is None: # We allow optional crawler argument to keep backwards # compatibility. # XXX: Raise a deprecation warning. crawler = getattr(self, 'crawler', None) if crawler is None: raise ValueError("crawler is required") settings = crawler.settings if self.redis_key is None: self.redis_key = settings.get( 'REDIS_START_URLS_KEY', defaults.START_URLS_KEY, ) self.redis_key = self.redis_key % &#123;'name': self.name&#125; if not self.redis_key.strip(): raise ValueError("redis_key must not be empty") if self.redis_batch_size is None: # TODO: Deprecate this setting (REDIS_START_URLS_BATCH_SIZE). self.redis_batch_size = settings.getint( 'REDIS_START_URLS_BATCH_SIZE', settings.getint('CONCURRENT_REQUESTS'), ) try: self.redis_batch_size = int(self.redis_batch_size) except (TypeError, ValueError): raise ValueError("redis_batch_size must be an integer") if self.redis_encoding is None: self.redis_encoding = settings.get('REDIS_ENCODING', defaults.REDIS_ENCODING) self.logger.info("Reading start URLs from redis key '%(redis_key)s' " "(batch size: %(redis_batch_size)s, encoding: %(redis_encoding)s", self.__dict__) self.server = connection.from_settings(crawler.settings) # The idle signal is called when the spider has no requests left, # that's when we will schedule new requests from redis queue crawler.signals.connect(self.spider_idle, signal=signals.spider_idle) def next_requests(self): """Returns a request to be scheduled or none.""" use_set = self.settings.getbool('REDIS_START_URLS_AS_SET', defaults.START_URLS_AS_SET) fetch_one = self.server.spop if use_set else self.server.lpop # XXX: Do we need to use a timeout here? found = 0 # TODO: Use redis pipeline execution. while found &lt; self.redis_batch_size: data = fetch_one(self.redis_key) # 取出一条数据 if not data: # Queue empty. break req = self.make_request_from_data(data) if req: yield req found += 1 else: self.logger.debug("Request not made from data: %r", data) if found: self.logger.debug("Read %s requests from '%s'", found, self.redis_key) def make_request_from_data(self, data): """Returns a Request instance from data coming from Redis. By default, ``data`` is an encoded URL. You can override this method to provide your own message decoding. Parameters ---------- data : bytes Message from redis. """ url = bytes_to_str(data, self.redis_encoding) return self.make_requests_from_url(url) def schedule_next_requests(self): """Schedules a request if available""" # TODO: While there is capacity, schedule a batch of redis requests. for req in self.next_requests(): self.crawler.engine.crawl(req, spider=self) # 当爬虫空闲时 def spider_idle(self): """Schedules a request if available, otherwise waits.""" # XXX: Handle a sentinel to close the spider. self.schedule_next_requests() raise DontCloseSpiderclass RedisSpider(RedisMixin, Spider): """Spider that reads urls from redis queue when idle. Attributes ---------- redis_key : str (default: REDIS_START_URLS_KEY) Redis key where to fetch start URLs from.. redis_batch_size : int (default: CONCURRENT_REQUESTS) Number of messages to fetch from redis on each attempt. redis_encoding : str (default: REDIS_ENCODING) Encoding to use when decoding messages from redis queue. Settings -------- REDIS_START_URLS_KEY : str (default: "&lt;spider.name&gt;:start_urls") Default Redis key where to fetch start URLs from.. REDIS_START_URLS_BATCH_SIZE : int (deprecated by CONCURRENT_REQUESTS) Default number of messages to fetch from redis on each attempt. REDIS_START_URLS_AS_SET : bool (default: False) Use SET operations to retrieve messages from the redis queue. If False, the messages are retrieve using the LPOP command. REDIS_ENCODING : str (default: "utf-8") Default encoding to use when decoding messages from redis queue. """ @classmethod def from_crawler(self, crawler, *args, **kwargs): obj = super(RedisSpider, self).from_crawler(crawler, *args, **kwargs) obj.setup_redis(crawler) return objclass RedisCrawlSpider(RedisMixin, CrawlSpider): """Spider that reads urls from redis queue when idle. Attributes ---------- redis_key : str (default: REDIS_START_URLS_KEY) Redis key where to fetch start URLs from.. redis_batch_size : int (default: CONCURRENT_REQUESTS) Number of messages to fetch from redis on each attempt. redis_encoding : str (default: REDIS_ENCODING) Encoding to use when decoding messages from redis queue. Settings -------- REDIS_START_URLS_KEY : str (default: "&lt;spider.name&gt;:start_urls") Default Redis key where to fetch start URLs from.. REDIS_START_URLS_BATCH_SIZE : int (deprecated by CONCURRENT_REQUESTS) Default number of messages to fetch from redis on each attempt. REDIS_START_URLS_AS_SET : bool (default: True) Use SET operations to retrieve messages from the redis queue. REDIS_ENCODING : str (default: "utf-8") Default encoding to use when decoding messages from redis queue. """ @classmethod def from_crawler(self, crawler, *args, **kwargs): obj = super(RedisCrawlSpider, self).from_crawler(crawler, *args, **kwargs) obj.setup_redis(crawler) return obj]]></content>
      <categories>
        <category>技术</category>
        <category>Scrapy</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy线性运算]]></title>
    <url>%2F2017%2F02%2F28%2F%E6%8A%80%E6%9C%AF%2FNumpy-liner-skills%2F</url>
    <content type="text"><![CDATA[线性代数 解方程组 Numpy和Scipy模块 Numpy进行简单的描述性统计计算 Numpy进行线性代数运算 Numpy计算特征值和特征向量 Numpy随机数 创建掩码式Numpy数组 描述性统计计算12345678910# 计算numpy数组的平均值，中位数，最大值，最小值和标准差import numpy as npfrom scipy.stats import scoreatpercentile # 就算第N%的数值data = np.loadtxt('ex1.csv', delimiter=',', usecols=(1,), skiprows=1, unpack=True)print dataprint "Max:", data.max(), np.max(data)print "Min:", data.min(), np.min(data)print "Mean:", data.mean(), np.mean(data)print "Std方差:", data.std(), np.std(data)print "Median:", np.median(data), scoreatpercentile(data, 50) [ 2. 6. 10.] Max: 10.0 10.0 Min: 2.0 2.0 Mean: 6.0 6.0 Std方差: 3.26598632371 3.26598632371 Median: 6.0 6.0 线性代数运算 numpy.linalg 或 scipy.linalg 矩阵求逆运算，转置，计算特征值，求解线性方程组或计算行列式矩阵可用numpy.ndarray的一个子类表示。 1234567891011121314# 创建一个矩阵A = np.mat("2 4 6;4 2 6;10 -4 18")print A# 矩阵求逆A_inverse = np.linalg.inv(A)print A_inverseprint "如果矩阵是不可逆的，可以用pinv求伪逆矩阵"A_inverse = np.linalg.pinv(A)print A_inverse# A*A- = IX = A * A_inverseprint X# 计算误差print X - np.eye(3) [[ 2 4 6] [ 4 2 6] [10 -4 18]] [[-0.41666667 0.66666667 -0.08333333] [ 0.08333333 0.16666667 -0.08333333] [ 0.25 -0.33333333 0.08333333]] 如果矩阵是不可逆的，可以用pinv求伪逆矩阵 [[-0.41666667 0.66666667 -0.08333333] [ 0.08333333 0.16666667 -0.08333333] [ 0.25 -0.33333333 0.08333333]] [[ 1.00000000e+00 -1.66533454e-15 4.44089210e-16] [ 6.66133815e-16 1.00000000e+00 3.88578059e-16] [ 1.11022302e-15 -1.88737914e-15 1.00000000e+00]] [[ 8.88178420e-16 -1.66533454e-15 4.44089210e-16] [ 6.66133815e-16 -1.22124533e-15 3.88578059e-16] [ 1.11022302e-15 -1.88737914e-15 8.88178420e-16]] 求解线性方程组， solve() 和 dot() 12345678A = np.mat("1 -2 1;0 2 -8;-4 5 9")b = np.array([0, 8, 9])# Ax=b，求x，用np.linalg.solvex = np.linalg.solve(A, b)print x# Ax=b,求解b，用np.dotb1 = np.dot(A, x)print b1 [ 155. 88. 21.] [[ 0. 8. 9.]] 若存在常数λ及n维非零向量X，使得Ax=λx，则称λ是矩阵A的特征值，x是A属于特征值λ的特征向量.λ = np.linalg.eigvals(A)(λ, x) = np.linalg.eig(A) 12345678A = np.mat("3,-2;1,0")a, x = np.linalg.eig(A)b = np.linalg.eigvals(A)print a, b, x# 验证Ax=λxfor i in range(len(x)): print 'A*x&#123;&#125;'.format(i), np.dot(A, x[:, i]) print 'a*x&#123;&#125;'.format(i), a[i] * x[:, i] [ 2. 1.] [ 2. 1.] [[ 0.89442719 0.70710678] [ 0.4472136 0.70710678]] A*x0 [[ 1.78885438] [ 0.89442719]] a*x0 [[ 1.78885438] [ 0.89442719]] A*x1 [[ 0.70710678] [ 0.70710678]] a*x1 [[ 0.70710678] [ 0.70710678]] numpy随机数，随机相关函数位于np.random模块。连续分布：正态分布和对数正态分布离散分布：几何分布，超几何分布和二项分布 123456789101112131415161718192021222324# 用np.random.binomial()模拟二项分布,提供相同的种子，则产生的随机结果相同from matplotlib import pyplot as plt%matplotlib inline# B(0.5, 9) 生成执行10000次的博弈结果序列 outcome = np.random.binomial(9, 0.5, size=10000)plt.subplot(121)plt.plot(np.arange(10000), outcome)money = np.zeros(10000)my_money = 1000i = 0for x in outcome: if x &lt; 5: money[i] = my_money - 1 elif x &lt; 10: money[i] = my_money + 1 my_money = money[i] i = i + 1 print moneyplt.subplot(122)plt.plot(np.arange(10000), money)plt.show() [ 999. 1000. 999. ..., 972. 971. 970.] ​ 正态分布采样np.random模块提供了很多表示连续随机分布的函数 Draw random samples from a normal (Gaussian) distribution. np.random.normal(loc, scale, size)loc : float,Mean (“centre”) of the distribution.scale : float,Standard deviation (spread or “width”) of the distribution.size : int or tuple of ints, optional,Output shape. 12345678N = 10000normal_values = np.random.normal(size=N)dummy, bins, dummy = plt.hist(normal_values, np.sqrt(N), normed=True, lw=1) # dunmmy中文蠢货，假的；bins箱子，也就是直方图的条条sigma = 1mu = 0fx = 1/(sigma * np.sqrt(2 * np.pi)) * np.exp(- (bins - mu) ** 2 / (2 * sigma ** 2))plt.plot(bins, fx, lw=2) ## lw: linewidthplt.show() 正态检测：检查样本是否符合正态分布scipy.stats里实现了一些正态分布的检测方法。 创建掩码式数组掩码式数组可以忽略无效的、残缺的数据。如忽略负值和极值]]></content>
      <categories>
        <category>技术</category>
        <category>numpy</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib笔记]]></title>
    <url>%2F2017%2F02%2F26%2F%E6%8A%80%E6%9C%AF%2FMatplotlib-use%2F</url>
    <content type="text"><![CDATA[matplotlib matplotlib API pandas中绘图函数 1%pylab Using matplotlib backend: Qt5Agg Populating the interactive namespace from numpy and matplotlib 123import matplotlib.pyplot as pltimport numpy as npimport pandas as pd 1%matplotlib inline Figure 和Subplot创建一个figure后，还需要在上面添加子图，然后调用子图的绘图方法绘图。直接使用plot绘图，图像绘制在最后一次选定的子图 1234567891011from numpy.random import randnfig = plt.figure()sp1 = fig.add_subplot(2, 2, 1) # 2*2布局的第一个子图sp1.plot(randn(50).cumsum(), 'k--') # k--黑色虚线图sp2 = fig.add_subplot(2, 2, 2)sp2.hist(randn(100), bins=20, color='k', alpha=0.3) ## 直方图，20个箱子sp3 = fig.add_subplot(2, 2, 3)sp3.scatter(np.arange(30), np.arange(30) + randn(30) * 3, color = 'b')# sp4 = fig.add_subplot(2, 2, 4) 12345# 使用plt.subplot()创建子图fig, axes = plt.subplots(2, 2) ## 返回画布和子图对象的数组axes[0][0].plot(range(10), range(10))## 调整子图间的距离, wspace和hspace 子图间百分比fig.subplots_adjust(left=1, right=2, wspace=0, hspace=0) 颜色、标记、线型plot函数接受一组X和y坐标，还有格式字符串。表示颜色和线型的字符串,如“g–”,表示绿色的折线“go–”, 绿色O点折线，marker=’o’也可以在plot中指定参数 linestyle=’–’ color=’g’ color值可以用缩写词或RGB值，“#CECECE” 线形图的点可以加上标记marker，更容易看出点的位置 label 图线的label drawstyle 绘图方式 fig的方法 fig.xlabel(‘xxxx’) fig.ylabel(‘y’) fig.xlim() 1234567plt.plot(randn(30).cumsum(), 'go--', label='yyy')plt.plot(randn(30).cumsum(), color='b', marker='*', linestyle='--', label='xxx')plt.plot(randn(30).cumsum(), color='r', drawstyle='steps-post', label='zzz')plt.legend(loc='best') # 图例，label的位置为bestplt.xlabel('X')plt.ylabel('random')plt.show() 12plt.xlim() # 当前x轴的范围plt.xlim([-10,10]) # 调整x轴的范围 (-10, 10) 123456#### 注解以及在subplot上绘图ax = plt.subplot(1, 1, 1)ax.plot(range(10), range(3, 13), 'g*--', label='line')ax.legend('best')ax.text(2, 5, 'Here!', family='monospace', fontsize=10)ax.annotate('Look Here!', xy=(3, 6), arrowprops=dict(facecolor='black')) #,family='monospace', fontsize=10) pandas中的绘图函数线型图Series和Dataframe的plot方法默认生成的是线型图 柱状图添加参数kind=bar或barh，生成柱状图和水平方向的柱状图 直方图和密度图直方图是一种可以对值频率进行离散化显示的柱状图，plot.hist()密度图：计算“可能会产生观测数据的连续发布的估计”，一般是将该分布近似为一组核（如高斯正态分布）分布。 散布图观察两组一维数据之间关系的有效方法 123from pandas import Series, DataFrames = Series(randn(10).cumsum(), index=range(0, 100, 10))s.plot() 12345678fig, axes = plt.subplots(2, 2)s.plot(ax=axes[0][0])frame = DataFrame(randn(10, 4).cumsum(0), columns=list('ABCD'), index=range(0, 100, 10))frame.plot(ax=axes[0][1])frame.plot(ax=axes[0][1])### 柱状图s.plot(ax=axes[1][0], kind='barh')frame.plot(ax=axes[1][1], kind='bar') 123456fig, axes = plt.subplots(2, 2)## 堆积柱状图s.plot(ax=axes[0][0], kind='bar', stacked=True, alpha=0.3) frame.plot(ax=axes[0][1], kind='bar', stacked=True, alpha=0.5)s.value_counts().plot(ax=axes[1][0], kind='bar', stacked=True, alpha=0.3)frame.ix[:, 2:8].plot(ax=axes[1][1], kind='bar', stacked=True, alpha=0.5) 123456fig, axes = plt.subplots(1, 2)s = Series(randn(100).cumsum(), index=range(0, 1000, 10))# 直方图s.hist(ax=axes[0], bins=40)# 密度图s.plot(ax=axes[1], kind='kde', color='k') 12s.hist(bins=40, normed=True)s.plot(kind='kde', style='g--') 12### 散点图plt.scatter(frame['A'], frame['D']) 1pd.scatter_matrix(frame, diagonal='kde') array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021169438&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000213EB4A8&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000214B22B0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021559710&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021667208&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002174F978&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002181B5F8&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000218DDCC0&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021A2D9B0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021AA00B8&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021B9DE80&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021BBE278&gt;], [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021D61400&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021E70E10&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000021F677F0&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000022036240&gt;]], dtype=object)]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas学习笔记]]></title>
    <url>%2F2017%2F02%2F25%2F%E6%8A%80%E6%9C%AF%2FPandas-skills%2F</url>
    <content type="text"><![CDATA[Pandas数据结构基本功能汇总和计算描述统计处理缺失数据层次化索引其他 123from pandas import DataFrame, Seriesimport pandas as pdimport numpy as np Series12345678910# series类似一维数组，由一组数据和数据的标签（索引）组成s = Series([11, 32, -223, 114])print sprint s.indexprint s.values# 索引可以直接赋值修改s.index = ['a', 'b', 'c', 'd']print ss2 = Series([11, 32, -223, 114], index=['a', 'b', 'c', 'd'])print s2['a'], '\n', s2[['a', 'd']] 0 11 1 32 2 -223 3 114 dtype: int64 RangeIndex(start=0, stop=4, step=1) [ 11 32 -223 114] a 11 b 32 c -223 d 114 dtype: int64 11 a 11 d 114 dtype: int64 Numpy数组运算的结果会保留索引和值之间的链接 根据布尔型数组进行过滤，标量乘法，数学函数等 1234567891011121314print s2 &gt; 11 ## 得到布尔型数组print s2[s2 &gt; 11] ## 根据布尔型数组筛选对应为true的元素## 可以将series理解为定长字典，因为是key-value的对应关系，series也可以由字典对象创建d = &#123;'Alice': 98, 'Bob': 87, 'Cc': 67&#125;score1 = Series(d)print score1print 'Alice' in score1## 同时传入字典和index索引student = ['Alice', 'Cc', 'Sam', 'Wandou']score2 = Series(d, index=student) # 会根据index查找字典中相应的数据，找不到的对应index的值为NaN，表示缺失或非数字print score2print score2.isnull()print score2.notnull() a False b True c False d True dtype: bool b 32 d 114 dtype: int64 Alice 98 Bob 87 Cc 67 dtype: int64 True Alice 98.0 Cc 67.0 Sam NaN Wandou NaN dtype: float64 Alice False Cc False Sam True Wandou True dtype: bool Alice True Cc True Sam False Wandou False dtype: bool 12345678## 在算术运算中，会自动对其不同索引的数据print score1, score2print score1 + score2 ## 索引和数据都有一个name属性score2.name = 'score'score2.index.name = 'name'print score2 Alice 98 Bob 87 Cc 67 dtype: int64 Alice 98.0 Cc 67.0 Sam NaN Wandou NaN dtype: float64 Alice 196.0 Bob NaN Cc 134.0 Sam NaN Wandou NaN dtype: float64 name Alice 98.0 Cc 67.0 Sam NaN Wandou NaN Name: score, dtype: float64 DataFramedataframe是一种表格型的数据结构，含有一组有序的列，每列的数值类型可以不同。dataframe既有行索引，又有列索引，可以看做Series组成的字典。 1234567891011121314151617181920212223242526## 构建DataFrame，传入等长的列表或Numpy数组province = ['Beijing', 'Shandong', 'Shanghai', 'Hubei', 'Hunan']area = [50, 156, 300, 250, 260]pop = [5000, 16000, 9000, 10000, 8000]data = &#123;'province': province, 'people': pop, 'area': area&#125;frame1 = DataFrame(data)print frame1# 指定列的排列顺序frame2 = DataFrame(data, columns=['province', 'area', 'people'])print frame2# 加入自定义索引frame3 = DataFrame(data, columns=['province', 'area', 'people'], index=data['province'])print frame3# 获取列print frame3['area']print frame3.area# 获取行print frame3.ix['Shandong']# 添加一列或修改一列，frame3['GDP_Unit'] = '亿元' # 一列所有数据都改为该值frame3['GDP'] = [150, 160, 170, 180, 190] print frame3frame3.GDP = Series(&#123;'Beijing': 0, 'Shandong': -1, 'Shanghai': 2, 'hah': 90&#125;)print frame3# 如果值是列表，要等长。# 如果是Series，则严格按照Series的索引赋值该列，series中无相应index的，frame中该值改为Na area people province 0 50 5000 Beijing 1 156 16000 Shandong 2 300 9000 Shanghai 3 250 10000 Hubei 4 260 8000 Hunan province area people 0 Beijing 50 5000 1 Shandong 156 16000 2 Shanghai 300 9000 3 Hubei 250 10000 4 Hunan 260 8000 province area people Beijing Beijing 50 5000 Shandong Shandong 156 16000 Shanghai Shanghai 300 9000 Hubei Hubei 250 10000 Hunan Hunan 260 8000 Beijing 50 Shandong 156 Shanghai 300 Hubei 250 Hunan 260 Name: area, dtype: int64 Beijing 50 Shandong 156 Shanghai 300 Hubei 250 Hunan 260 Name: area, dtype: int64 province Shandong area 156 people 16000 Name: Shandong, dtype: object province area people GDP_Unit GDP Beijing Beijing 50 5000 亿元 150 Shandong Shandong 156 16000 亿元 160 Shanghai Shanghai 300 9000 亿元 170 Hubei Hubei 250 10000 亿元 180 Hunan Hunan 260 8000 亿元 190 province area people GDP_Unit GDP Beijing Beijing 50 5000 亿元 0.0 Shandong Shandong 156 16000 亿元 -1.0 Shanghai Shanghai 300 9000 亿元 2.0 Hubei Hubei 250 10000 亿元 NaN Hunan Hunan 260 8000 亿元 NaN 1frame3.GDP.isnull() Beijing False Shandong False Shanghai False Hubei True Hunan True Name: GDP, dtype: bool 123## 删除一列del frame3['GDP']print frame3.columns Index([u&apos;province&apos;, u&apos;area&apos;, u&apos;people&apos;, u&apos;GDP_Unit&apos;], dtype=&apos;object&apos;) ​ 使用嵌套字典创建dataframe 外层的字典key作为列索引，内层的字典key作为行索引。frame可以转置。内层的字典key会被合并、排序最终成为行索引，显示指定了index的除外 123456789data = &#123;'province': &#123;'Shandong': 'Shangdong', 'Beijing': 'Beijing', 'Hubei': 'Hubei'&#125;, 'GDP': &#123;'Shanghai': 15000, 'Shandong': 20000, 'Hubei': 7000&#125;, 'people': &#123;'Shandong': 100000, 'Hubei': 20000&#125; &#125;frame = DataFrame(data) ## 缺省的值设为NaNprint frameframe = DataFrame(data, index=['Guangzhou', 'Beijing', 'Shanghai', 'Shandong'])print frameprint frame.T GDP people province Beijing NaN NaN Beijing Hubei 7000.0 20000.0 Hubei Shandong 20000.0 100000.0 Shangdong Shanghai 15000.0 NaN NaN GDP people province Guangzhou NaN NaN NaN Beijing NaN NaN Beijing Shanghai 15000.0 NaN NaN Shandong 20000.0 100000.0 Shangdong Guangzhou Beijing Shanghai Shandong GDP NaN NaN 15000 20000 people NaN NaN NaN 100000 province NaN Beijing NaN Shangdong 可以用于构造DataFrame的数据 二维ndarray 值为数组，列表或元组的字典， 每个数据序列必须等长，作为dataframe的一列 值为Series的字典， 每个series成为frame的一列，如果没有指定index索引，则series内的索引会成为行索引 嵌套字典 。。。 1frame3.values ## frame的values是ndarray， ndarray的数据类型会选择能兼容各列数据的类型 array([[&apos;Beijing&apos;, 50L, 5000L, &apos;\xe4\xba\xbf\xe5\x85\x83&apos;], [&apos;Shandong&apos;, 156L, 16000L, &apos;\xe4\xba\xbf\xe5\x85\x83&apos;], [&apos;Shanghai&apos;, 300L, 9000L, &apos;\xe4\xba\xbf\xe5\x85\x83&apos;], [&apos;Hubei&apos;, 250L, 10000L, &apos;\xe4\xba\xbf\xe5\x85\x83&apos;], [&apos;Hunan&apos;, 260L, 8000L, &apos;\xe4\xba\xbf\xe5\x85\x83&apos;]], dtype=object) 索引对象Index对象的值是不能不被修改的包含的方法有 append 连接一个index对象 diff 计算差集，并得到一个index intersect 计算交集 union 计算并集 isin 计算index各值是否在给定的集合内，返回一个布尔型数组 delete 删除索引i处的元素，并得到新的index drop insert is_monotonic 是否单调 is_unique 是否有重复值 unique 计算index中唯一值得数组 123456## 重新索引对象, 生成新的series或frameprint s.indexq = s.reindex(['e', 'd', 'c', 'b', 'a']) # 另外一个可选参数，fill_value=0设置默认值或method='填充方法'，ffill、pad向前填充，bfill或backfill向后填充print qp = frame3.reindex(index=[], columns=[], method='ffill') # 可以同时重新index和column，值填充只能按行应用 Index([u&apos;a&apos;, u&apos;b&apos;, u&apos;c&apos;, u&apos;d&apos;], dtype=&apos;object&apos;) e NaN d 114.0 c -223.0 b 32.0 a 11.0 dtype: float64 索引、选取和过滤 行列索引 布尔型dataframe索引 1234print frame3['area']print frame3[:4] # 选取的列print frame3[frame3['area'] &gt; 160] # 根据布尔型选取frame3.ix[:2, ['area', 'people']] # 同时选取行和列 Beijing 50 Shandong 156 Shanghai 300 Hubei 250 Hunan 260 Name: area, dtype: int64 province area people GDP_Unit Beijing Beijing 50 5000 亿元 Shandong Shandong 156 16000 亿元 Shanghai Shanghai 300 9000 亿元 Hubei Hubei 250 10000 亿元 province area people GDP_Unit Shanghai Shanghai 300 9000 亿元 Hubei Hubei 250 10000 亿元 Hunan Hunan 260 8000 亿元 area people Beijing 50 5000 Shandong 156 16000 12print frame3.iloc[1,:2] # 根据位置整数选取print frame3.loc[:, ['area', 'people']] # 同时根据行列lable选取 province Shandong area 156 Name: Shandong, dtype: object area people Beijing 50 5000 Shandong 156 16000 Shanghai 300 9000 Hubei 250 10000 Hunan 260 8000 算数运算和数据对齐计算是在两个对象索引的并集上运算，相同索引的值进行运算，不重叠的索引处引入NaN值。缺省值NaN在运算中会传播。在运算add、sub、div、mul中传入参数fill_value=0可以指定一个填充值。DataFrame和Series进行运算时，会产生广播。 函数应用和映射Numpy的元素级函数可用于操作Pandas对象 np.abs(frame) 和其他函数 frame.apply(funcs) frame.applymap(funcs) series.map() 123456789101112131415frame = DataFrame(np.random.randn(4, 3), columns=list('abc'), index=range(1, 5))frame2 = np.abs(frame)print frameprint frame2f1 = lambda x: x.max()print frame.apply(f1) # 将函数应用到frame的列print frame.max() ## 很多统计函数已被实现，没必要用applyprint frame.apply(f1, axis=1) # 将函数应用于frame的行## apply的函数除了返回值外，也可返回多个值组成的series，framef2 = lambda x: Series([x.min(), x.max()], index=['min', 'max'])print frame.apply(f2)## 如果要在元素级上应用函数，frame使用applymap(),series使用map()f3 = lambda x: '%.2f' %xprint frame.applymap(f3)print frame.a.map(f3) a b c 1 0.811815 0.501822 0.225176 2 0.171434 -1.446678 0.148284 3 -0.187686 -1.017413 1.145296 4 -0.596069 -0.376504 -0.298326 a b c 1 0.811815 0.501822 0.225176 2 0.171434 1.446678 0.148284 3 0.187686 1.017413 1.145296 4 0.596069 0.376504 0.298326 a 0.811815 b 0.501822 c 1.145296 dtype: float64 a 0.811815 b 0.501822 c 1.145296 dtype: float64 1 0.811815 2 0.171434 3 1.145296 4 -0.298326 dtype: float64 a b c min -0.596069 -1.446678 -0.298326 max 0.811815 0.501822 1.145296 a b c 1 0.81 0.50 0.23 2 0.17 -1.45 0.15 3 -0.19 -1.02 1.15 4 -0.60 -0.38 -0.30 1 0.81 2 0.17 3 -0.19 4 -0.60 Name: a, dtype: object 排序和排名123456s = Series(range(5), index=list('qwert'))print s.sort_index(ascending=False)print s.sort_values(ascending=False) # 缺省值会排序放到最后print frame.sort_index(axis=1, ascending=False)print frame.sort_values('a')print frame.rank(method='first') w 1 t 4 r 3 q 0 e 2 dtype: int64 t 4 r 3 e 2 w 1 q 0 dtype: int64 c b a 1 0.225176 0.501822 0.811815 2 0.148284 -1.446678 0.171434 3 1.145296 -1.017413 -0.187686 4 -0.298326 -0.376504 -0.596069 a b c 4 -0.596069 -0.376504 -0.298326 3 -0.187686 -1.017413 1.145296 2 0.171434 -1.446678 0.148284 1 0.811815 0.501822 0.225176 a b c 1 4.0 4.0 3.0 2 3.0 1.0 2.0 3 2.0 2.0 4.0 4 1.0 3.0 1.0 Index索引可以是重复的 选取了重复index的数据，返回的时series，非重复的直接返回其值frame的index也是可以重复的 123s = Series(range(5), index=list('qaqaz'))print s.aprint s.z a 1 a 3 dtype: int64 4]]></content>
      <categories>
        <category>技术</category>
        <category>Pandas</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy ImagePipeline下载gif图片和自定义图片文件名称]]></title>
    <url>%2F2017%2F02%2F16%2F%E6%8A%80%E6%9C%AF%2FScrapy-image-download%2F</url>
    <content type="text"><![CDATA[scrapy图片下载保留gif格式和自定义图片名称继承ImagesPipeline并重写部分函数 get_media_requests 返回下载图片的Request file_path 返回文件名，文件名是sha1哈希image url生成的image_guid convert_image 该函数将图片转化成rgb 模式的jpg格式，避免重新下载近期下载过的图片 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130######################## pipelines.py ######################################## -*- coding: utf-8 -*-# Define your item pipelines here## Don't forget to add your pipeline to the ITEM_PIPELINES setting# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.htmlimport pymongofrom scrapy.pipelines.images import ImagesPipelinefrom scrapy.http import Request# from scrapy.exceptions import DropItemfrom PIL import Imagetry: from cStringIO import StringIO as BytesIOexcept ImportError: from io import BytesIOclass JokerPipeline(object): collection_name = 'joke' def __init__(self, mongo_uri, mongo_db): self.mongo_uri = mongo_uri self.mongo_db = mongo_db @classmethod def from_crawler(cls, crawler): return cls( mongo_uri=crawler.settings.get('MONGO_URI'), mongo_db=crawler.settings.get("MONGO_DATABASE", "items") ) def open_spider(self, spider): self.client = pymongo.MongoClient(self.mongo_uri) self.db = self.client[self.mongo_db] def close_spider(self, spider): self.client.close() def process_item(self, item, spider): # data = self.db[self.collection_name].find(&#123;&#125;, &#123;'_id': 0, 'url': 1&#125;) # url_finished = set(x['url'] for x in data) # if item['pic-url']: # # raise DropItem("%s has been crawled!" % item) # pic_name = item['data-id'] + '.' + item['pic-url'].plite('.')[-1] # else: self.db[self.collection_name].insert(dict(item)) return item class ImageDownloadPipeline(ImagesPipeline): default_headers = &#123; 'accept': 'image/webp,image/*,*/*;q=0.8', 'accept-encoding': 'gzip, deflate, sdch, br', 'accept-language': 'zh-CN,zh;q=0.8,en;q=0.6', 'cookie': 'bid=yQdC/AzTaCw', 'referer': 'https://www.douban.com/photos/photo/2370443040/', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36', &#125; def get_media_requests(self, item, info): # 下载图片 for image_url in item['pic_url']: self.default_headers['referer'] = image_url yield Request(image_url, headers=self.default_headers, meta=&#123;'item': item&#125;) # # 使用meta是我想用item里的某个字段做图片的名字， def file_path(self, request, response=None, info=None): item = request.meta['item'] # 通过上面的meta传递过来item # 图片文件名，request.url.split('/')[-1].split('.')[-1]得到图片后缀jpg,png,gif image_guid = item['data-id'] + '-' + request.url.split('/')[-1] # 使用有中文的item字段做目录时，用path=''.join(item['no1']),否则路径会变成\u97e9\u56fd\u6c7d\u8f66\u6807\u5fd7\xxx.jpg filename = u'full/&#123;0&#125;'.format(image_guid) return filename # 图片格式转换，如果是gif，则不转换，可能会出问题 def convert_image(self, image, size=None): # 自己添加的 if image.format == 'GIF': buf = BytesIO() image.save(buf, 'GIF') return image, buf # 原始代码 if image.format == 'PNG' and image.mode == 'RGBA': background = Image.new('RGBA', image.size, (255, 255, 255)) background.paste(image, image) image = background.convert('RGB') elif image.mode != 'RGB': image = image.convert('RGB') if size: image = image.copy() image.thumbnail(size, Image.ANTIALIAS) buf = BytesIO() image.save(buf, 'JPEG') return image, buf # 重写下载完图片的处理方法image_downloaded def check_gif(self, image): if image.format == 'GIF': return True # The library reads GIF87a and GIF89a versions of the GIF file format. return image.info.get('version') in ['GIF89a', 'GIF87a'] def persist_gif(self, key, data, info): root, ext = os.path.splitext(key) if not key.endswith(('.gif', '.GIF')): key = key + '.gif' absolute_path = self.store._get_filesystem_path(key) self.store._mkdir(os.path.dirname(absolute_path), info) f = open(absolute_path, 'wb') # use 'b' to write binary data. f.write(data) def image_downloaded(self, response, request, info): checksum = None for key, image, buf in self.get_images(response, request, info): if checksum is None: buf.seek(0) checksum = md5sum(buf) if key.startswith('full') and self.check_gif(image): # Save gif from response directly. self.persist_gif(key, response.body, info) else: width, height = image.size self.store.persist_file( key, buf, info, meta=&#123;'width': width, 'height': height&#125;, headers=&#123;'Content-Type': 'image/jpeg'&#125;) # self.store.persist_image(key, image, buf, info) return checksum]]></content>
      <categories>
        <category>技术</category>
        <category>Scrapy</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅的使用Linux]]></title>
    <url>%2F2017%2F02%2F12%2F%E6%8A%80%E6%9C%AF%2FLinux-how-to-use%2F</url>
    <content type="text"><![CDATA[如何优雅的使用Linux 作为学习/开发环境使用，而不是娱乐。写这边文章是为了下次重装系统快速恢复，系统使用以为简洁、优雅、高效为目标。 1、选择 发行版选择Debian 之前一直使用Ubuntu，大概过那么一两个月就会出现啥问题，然后不得不重装系统，我严重Ubuntu16.04的桌面有bug，开2个软件窗口就卡的爹妈不认了。现在决定再也不用Ubuntu了，改用Debian8后稳定多了，图形桌面很少崩溃。关于centos和openSUSE，只在搭建服务器使用过，个人使用还是更习惯Debian系的。 桌面选择 Ubuntu的unity真tm丑，紫色的主题我也是忍了好久才适应下来。现在改用gnome3。 2、卸载liboffice事实上我连wps也没装，以前是装机必备，最后发现一共使用的次数不超过10次，office那套还是交给windows吧。文档记录使用txt和markdown。 完全卸载sudo apt-get purge libreoffice? 然后安装Typora markdown工具。参考官网, 1234567sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE# 添加密钥和源在 /etc/apt/sources.list中添加一条'deb https://typora.io ./linux/'sudo apt-get update# 安装 typorasudo apt-get install typora 3、更改主目录文件夹名为英文打开终端，在终端中输入命令: $ export LANG=en_US $ xdg-user-dirs-gtk-update 在弹出的窗口中询问是否将目录转化为英文路径,勾上不再提示并同意更改， $ export LANG=zh_CN $ xdg-user-dirs-gtk-update 关闭终端,并注销或重启.下次进入系统.主目录的中文转英文就完成了~ 4、美化Debian刚装上以后真是丑啊，尤其是白底黑字的shell终端，让人抓狂。 这里美化仅仅是设置gtk主题，gnome-shell主题，改变terminal的颜色等，以美观实用为主，花里胡哨的东西请去windows娱乐。相关文件下载 安装gnome-tweak-tool apt-get install gnome-tweak-tool 这个工具不能用root运行。按下win，搜索tweak，点优化工具打开。 在扩展中启用user-themes，然后gnome shell主题才可用。下面几个插件推荐安装 安装gnome主题 主题可以去网上下载，我直接从Kali Linux上copy出来的。将themes文件夹内容放入/usr/share/themes/下即可，操作之前先备份。 安装gnome-shell主题 备份替换/usr/share/gnome-shell/内容。 字体 备份替换 /usr/share/fonts 内容。如果使用主题后，登陆桌面崩溃，则很有可能缺少字体。 改变壁纸和锁屏、登陆背景 壁纸锁屏可以在设置中修改。 登陆背景，替换gnome-shell主题内的图片，位置 /usr/share/gnome-shell/theme/KaliLogin.png 安装配置terminator 修改终端内的文字高亮，自动代码补全。shell环境变量配置文件有 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110# /etc/profile 用户登陆时加载，全局配置，# /etc/bash.bashrc 打开shell时配置shell变量，如果~/.bashrc文件存在则会使用其配置，# ~/.bashrc，仅对该用户有效，user和root下的建议都改# .bashrc文件修改# If not running interactively, don't do anythingcase $- in *i*) ;; *) return;;esac# don't put duplicate lines or lines starting with space in the history.# See bash(1) for more optionsHISTCONTROL=ignoreboth# append to the history file, don't overwrite itshopt -s histappend# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)HISTSIZE=1000HISTFILESIZE=2000# check the window size after each command and, if necessary,# update the values of LINES and COLUMNS.shopt -s checkwinsize# If set, the pattern "**" used in a pathname expansion context will# match all files and zero or more directories and subdirectories.#shopt -s globstar# make less more friendly for non-text input files, see lesspipe(1)#[ -x /usr/bin/lesspipe ] &amp;&amp; eval "$(SHELL=/bin/sh lesspipe)"# set variable identifying the chroot you work in (used in the prompt below)if [ -z "$&#123;debian_chroot:-&#125;" ] &amp;&amp; [ -r /etc/debian_chroot ]; then debian_chroot=$(cat /etc/debian_chroot)fi# set a fancy prompt (non-color, unless we know we "want" color)case "$TERM" in xterm-color) color_prompt=yes;;esac# uncomment for a colored prompt, if the terminal has the capability; turned# off by default to not distract the user: the focus in a terminal window# should be on the output of commands, not on the promptforce_color_prompt=yesif [ -n "$force_color_prompt" ]; then if [ -x /usr/bin/tput ] &amp;&amp; tput setaf 1 &gt;&amp;/dev/null; then # We have color support; assume it's compliant with Ecma-48 # (ISO/IEC-6429). (Lack of such support is extremely rare, and such # a case would tend to support setf rather than setaf.) color_prompt=yes else color_prompt= fifiif [ "$color_prompt" = yes ]; then PS1='$&#123;debian_chroot:+($debian_chroot)&#125;\[\033[01;31m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$ 'else PS1='$&#123;debian_chroot:+($debian_chroot)&#125;\u@\h:\w\$ 'fiunset color_prompt force_color_prompt# If this is an xterm set the title to user@host:dircase "$TERM" inxterm*|rxvt*) PS1="\[\e]0;$&#123;debian_chroot:+($debian_chroot)&#125;\u@\h: \w\a\]$PS1" ;;*) ;;esac# enable color support of ls and also add handy aliasesif [ -x /usr/bin/dircolors ]; then test -r ~/.dircolors &amp;&amp; eval "$(dircolors -b ~/.dircolors)" || eval "$(dircolors -b)" alias ls='ls --color=auto' #alias dir='dir --color=auto' #alias vdir='vdir --color=auto' #alias grep='grep --color=auto' #alias fgrep='fgrep --color=auto' #alias egrep='egrep --color=auto'fi# some more ls aliases#alias ll='ls -l'#alias la='ls -A'#alias l='ls -CF'# Alias definitions.# You may want to put all your additions into a separate file like# ~/.bash_aliases, instead of adding them here directly.# See /usr/share/doc/bash-doc/examples in the bash-doc package.if [ -f ~/.bash_aliases ]; then . ~/.bash_aliasesfi# enable programmable completion features (you don't need to enable# this, if it's already enabled in /etc/bash.bashrc and /etc/profile# sources /etc/bash.bashrc).if ! shopt -oq posix; then if [ -f /usr/share/bash-completion/bash_completion ]; then . /usr/share/bash-completion/bash_completion elif [ -f /etc/bash_completion ]; then . /etc/bash_completion fifi 然后右键终端，修改配置文件中背景为透明。背景透明简直太爽了，可以在敲命令时，透过终端看文档或浏览器，而不用将终端窗口挪来挪去。 ​ 5、python开发环境 安装pyenv 自动安装,不推荐 12$ curl -L https://raw.githubusercontent.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash$ pyenv update 手动git 123456789101112# 安装依赖# sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utilsgit clone git://github.com/yyuu/pyenv.git ~/.pyenv# 用户和root的我都改了,使用了绝对路径，没用$HOMEvim ~/.bashrcexport PYENV_ROOT="/home/syy/.pyenv"export PATH="/home/syy/.pyenv/bin:$PATH"eval "$(pyenv init -)"eval "$(pyenv virtualenv-init -)"source ~/.bashrc# exec $SHELL 安装virtualenv插件 1git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv 使用 12345678910# 安装# pyenv install --list# pyenv install -v XXX 安装位置/home/syy/.pyenv/versions/# 卸载# pyenv uninstall XXX# pyenv versions (查看所有版本)# pyenv global 3.3.5 切换版本# pyenv virtualenv 2.7.1 newvir 创建虚拟环境# pyenv activate newvir 切换进入newvir# pyenv deactivate 退出当前虚拟环境]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy笔记]]></title>
    <url>%2F2017%2F02%2F11%2F%E6%8A%80%E6%9C%AF%2FNumpy-use%2F</url>
    <content type="text"><![CDATA[Numpy数组入门1 Numpy数组对象Numpy数组 数组中的元素类型必须一致 数组的空间大小可以确定，可以运用向量化运算，底层c实现，速度快 数组下标0开始 1234567import numpy as npa = np.arange(5) # 创建0-4的一维数组b = np.array([0, 1, 2, 3, 4])print aprint a.dtype # a 的数据类型print a.dtype.itemsize # 对象数据类型占的字节数a.shape # a的形状，输出元组为每一维的长度 [0 1 2 3 4] int32 4 (5L,) 2 创建多维数组1234m = np.array([a, a, a]) # array的参数为list或list的嵌套listprint mprint m.dtypem.shape [[0 1 2 3 4] [0 1 2 3 4] [0 1 2 3 4]] int32 (3L, 5L) 3 选择numpy数组元素1print m[2, 4], m[0, 0], m[1] # a[m, n]确定第m行n列的元素 4 0 [0 1 2 3 4] 4 Numpy的数值类型123456print m.dtype.typen = np.array(m, dtype='uint32') # 定义数据类型为无符号32位print n.dtypeprint float(62) # 数据类型转换print np.sctypeDict.keys()[-10:] # 部分dtype的字符码print n.dtype.char # n的类型的字符码 &lt;type &apos;numpy.int32&apos;&gt; uint32 62.0 [&apos;a&apos;, &apos;short&apos;, &apos;e&apos;, &apos;i&apos;, &apos;clongfloat&apos;, &apos;m&apos;, &apos;Object0&apos;, &apos;int64&apos;, &apos;i2&apos;, &apos;int0&apos;] L 5 一维数组的切片与索引1print a[1:3], a[2::2], a[::-1] [1 2] [2 4] [4 3 2 1 0] 6 处理数组型状 x.shape x.shape = (m, n) x.rashape(s, m, n) x.resize(s, m, n) x.ravel() x.flatten() x.transpose() 1234567891011121314c = np.arange(24)print c.shapeb = c.reshape(2, 3, 4) # 生成2个3x4的新数组， c不变b.resize(2, 3, 4) # b会改变print be.shape = (3, 8) # 1维数组变成形状为3x8的数组print e, type(e)e = b.ravel() # 将多维数组变为一维数组，返回的是原数组的视图d = b.flatten() # 将多维数组变为一维数组，生成真实的数组，分配存储内存print b, d, eprint b.shape, d.shape, c.shape# 数组转置t = b.transpose()print t (24L,) [[[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[12 13 14 15] [16 17 18 19] [20 21 22 23]]] [[ 0 1 2 3 4 5 6 7] [ 8 9 10 11 12 13 14 15] [16 17 18 19 20 21 22 23]] &lt;type &apos;numpy.ndarray&apos;&gt; [[[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[12 13 14 15] [16 17 18 19] [20 21 22 23]]] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] (2L, 3L, 4L) (24L,) (24L,) [[[ 0 12] [ 4 16] [ 8 20]] [[ 1 13] [ 5 17] [ 9 21]] [[ 2 14] [ 6 18] [10 22]] [[ 3 15] [ 7 19] [11 23]]] 数组堆叠 x.vstack() x.dstack() x.hstack() x.column_stack() x.row_stack() x.concatenate() 12345678910111213141516171819202122232425262728a = np.arange(9).reshape(3, 3)b = a * 2print a, b# 水平叠加x1 = np.hstack((a, b))x2 = np.concatenate((a, b), axis=1) # axis=1,水平连接；axis=0，垂直连接;默认为0print x1print x2# 垂直叠加x3 = np.vstack((a, b))x4 = np.concatenate((a, b), axis=0)print x3, x4# 深度叠加， 沿着第三个坐标轴方向叠加一组数据x5 = np.dstack((a, b))print x5# 列式堆叠 堆叠一维数组时，按列码处理进行水平叠加，处理二维数组同水平叠加hstack()one1 = np.arange(3)one2 = one1 * 2x6 = np.column_stack((one1, one2))x7 = np.column_stack((a, b))print x6, x7# 行式堆叠 堆叠一维数组时，按行码进行垂直叠加，处理二维数组时同垂直叠加vstack()x8 = np.row_stack((one1, one2))x9 = np.row_stack((a, b))print x8, x9 [[0 1 2] [3 4 5] [6 7 8]] [[ 0 2 4] [ 6 8 10] [12 14 16]] [[ 0 1 2 0 2 4] [ 3 4 5 6 8 10] [ 6 7 8 12 14 16]] [[ 0 1 2 0 2 4] [ 3 4 5 6 8 10] [ 6 7 8 12 14 16]] [[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 0 2 4] [ 6 8 10] [12 14 16]] [[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 0 2 4] [ 6 8 10] [12 14 16]] [[[ 0 0] [ 1 2] [ 2 4]] [[ 3 6] [ 4 8] [ 5 10]] [[ 6 12] [ 7 14] [ 8 16]]] [[0 0] [1 2] [2 4]] [[ 0 1 2 0 2 4] [ 3 4 5 6 8 10] [ 6 7 8 12 14 16]] [[0 1 2] [0 2 4]] [[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 0 2 4] [ 6 8 10] [12 14 16]] 数组拆分，横向，纵向，深度方向 hsplit() vsplit() dsplit() split() 123456789101112a = np.arange(9).reshape(3,3)print a# 沿着横向拆分成三个部分，也就是3列b = np.hsplit(a, 3)print bprint np.split(a,3, axis=1) # axis=1沿着横向拆分，axis=0，沿着纵向拆分，默认为0# 沿着纵向拆分print np.vsplit(a, 3)print np.split(a, 3, axis=0)# 沿着深度方向分割，要有一个三维数组,可以理解为面包片叠一起切条c = np.arange(36).reshape(3, 2, 6)print np.dsplit(c, 6) [[0 1 2] [3 4 5] [6 7 8]] [array([[0], [3], [6]]), array([[1], [4], [7]]), array([[2], [5], [8]])] [array([[0], [3], [6]]), array([[1], [4], [7]]), array([[2], [5], [8]])] [array([[0, 1, 2]]), array([[3, 4, 5]]), array([[6, 7, 8]])] [array([[0, 1, 2]]), array([[3, 4, 5]]), array([[6, 7, 8]])] [array([[[ 0], [ 6]], [[12], [18]], [[24], [30]]]), array([[[ 1], [ 7]], [[13], [19]], [[25], [31]]]), array([[[ 2], [ 8]], [[14], [20]], [[26], [32]]]), array([[[ 3], [ 9]], [[15], [21]], [[27], [33]]]), array([[[ 4], [10]], [[16], [22]], [[28], [34]]]), array([[[ 5], [11]], [[17], [23]], [[29], [35]]])] Numpy的属性 1234567891011print a.ndim, a.size, a.itemsize, a.nbytes, a.size * a.itemsize# 维度，元素个数，元素占字节数，数组占字节数print a.shape, a.dtypeprint a.T # a的转置数组，如果数组是一维，那么得到的是一个数组的视图b = np.array([1+2j, 3-4j])print b.dtype, b.real, b.imag # 复数的实部和虚部,数组的数据类型为复数a.flat # 把a转成一维数组的一个迭代器对象，可以用for遍历print a.flat[2:5]a.flat = 0 # a中所有数据都变成0print a 2 9 4 36 36 (3L, 3L) int32 [[0 0 0] [0 0 0] [0 0 0]] complex128 [ 1. 3.] [ 2. -4.] [0 0 0] [[0 0 0] [0 0 0] [0 0 0]] 数组的转换 tolist() astype() 12print a.tolist() # 把np数组转化为py的列表print a.astype('float') # 改变a的元素类型 [[0, 1, 2], [3, 4, 5], [6, 7, 8]] [[ 0. 1. 2.] [ 3. 4. 5.] [ 6. 7. 8.]] 7 创建数组的视图和拷贝 copy() view() 1234567891011121314151617import scipy.miscimport matplotlib.pyplot as plt%matplotlib inline# 显示图片face = scipy.misc.face()acopy = face.copy()aview = face.view()plt.subplot(221)plt.imshow(face)plt.subplot(222)plt.imshow(acopy)plt.subplot(223)plt.imshow(aview)aview.flat = 0plt.subplot(224)plt.imshow(aview)# 改变view视图后，原数组同样被改变，copy不受影响 8 花式索引花式索引，通过坐标x y的迭代器序列，索引一系列的元素 1234567face = scipy.misc.face()xmax = face.shape[0] ymax = face.shape[1]print xmax, ymaxface[range(xmax), range(xmax)] = 0 # 对角线上的像素点值改为0，sorry，非n*n方阵face[range(xmax-1, -1, -1), range(xmax)] = 0 # range(start, stop, step) 不包含stop，因此是n-1，-1plt.imshow(face) 768 1024 9 基于位置变量的索引方法1234567# 通过位置列表索引x = np.arange(xmax)y = np.arange(ymax)np.random.shuffle(x)np.random.shuffle(y)plt.imshow(face[np.ix_(x, y)]) # np.ix_() 输入n个1维数组，返回n个n维数组 # a[np.ix_([1,3],[2,5])] 的结果 [[a[1,2] a[1,5]], [a[3,2] a[3,5]]] 10 用bool型变量索引Numpy数组用布尔型变量索引数组 123456789x = (np.arange(xmax)%4 == 0)face = scipy.misc.face()f2 = face.copy()face[x, x] = 0 # 对角线上索引整除4的元素值设为0plt.subplot(121)plt.imshow(face)plt.subplot(122)f2[(face &gt; face.max()/4) &amp; (face &lt; 3*face.max()/4)] = 0 # 数组中值大于最大值1/4小于3/4的置为0plt.imshow(f2) 11 numpy数组的广播数组要和标量相乘的话，标量要根据数组的形状进行相应的扩展]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Numpy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ipython使用技巧]]></title>
    <url>%2F2017%2F02%2F10%2F%E6%8A%80%E6%9C%AF%2FIpython-noteboke-use%2F</url>
    <content type="text"><![CDATA[ipython使用技巧 ipython –pylab pylab开关，ipython启动时自动导入np，sci，和matplotlib ipython –pylab inline 进入pylab模式，且图片内嵌到网页中 %logstart 保存会话，记录日志； %logstop关闭日志记录功能 !date !+shell命令，执行系统shell命令 c = !date %hist 显示历史命令 %hist -g print 在输入的历史命令中搜索print % xx magic function，单独一行时可以省略% jupyter notebook使用技巧 jupyter notebook 启动nootbook jupyter nbconvert –to markdown xxxx.ipynb ​ 快捷键命令模式 (按键 Esc 开启) Enter : 转入编辑模式 Shift-Enter : 运行本单元，选中下个单元 Ctrl-Enter : 运行本单元 Alt-Enter : 运行本单元，在其下插入新单元 Y : 单元转入代码状态 M :单元转入markdown状态 R : 单元转入raw状态 1 : 设定 1 级标题 2 : 设定 2 级标题 3 : 设定 3 级标题 4 : 设定 4 级标题 5 : 设定 5 级标题 6 : 设定 6 级标题 Up : 选中上方单元 K : 选中上方单元 Down : 选中下方单元 J : 选中下方单元 Shift-K : 扩大选中上方单元 Shift-J : 扩大选中下方单元 A : 在上方插入新单元 B : 在下方插入新单元 X : 剪切选中的单元 C : 复制选中的单元 Shift-V : 粘贴到上方单元 V : 粘贴到下方单元 Z : 恢复删除的最后一个单元 D,D : 删除选中的单元 Shift-M : 合并选中的单元 Ctrl-S : 文件存盘 S : 文件存盘 L : 转换行号 O : 转换输出 Shift-O : 转换输出滚动 Esc : 关闭页面 Q : 关闭页面 H : 显示快捷键帮助 I,I : 中断Notebook内核 0,0 : 重启Notebook内核 Shift : 忽略 Shift-Space : 向上滚动 Space : 向下滚动 编辑模式 ( Enter 键启动) Tab : 代码补全或缩进 Shift-Tab : 提示 Ctrl-] : 缩进 Ctrl-[ : 解除缩进 Ctrl-A : 全选 Ctrl-Z : 复原 Ctrl-Shift-Z : 再做 Ctrl-Y : 再做 Ctrl-Home : 跳到单元开头 Ctrl-Up : 跳到单元开头 Ctrl-End : 跳到单元末尾 Ctrl-Down : 跳到单元末尾 Ctrl-Left : 跳到左边一个字首 Ctrl-Right : 跳到右边一个字首 Ctrl-Backspace : 删除前面一个字 Ctrl-Delete : 删除后面一个字 Esc : 进入命令模式 Ctrl-M : 进入命令模式 Shift-Enter : 运行本单元，选中下一单元 Ctrl-Enter : 运行本单元 Alt-Enter : 运行本单元，在下面插入一单元 Ctrl-Shift– : 分割单元 Ctrl-Shift-Subtract : 分割单元 Ctrl-S : 文件存盘 Shift : 忽略 Up : 光标上移或转入上一单元 Down :光标下移或转入下一单元 ​]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Notebook</tag>
        <tag>Ipython</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrapy 入门学习]]></title>
    <url>%2F2016%2F12%2F19%2F%E6%8A%80%E6%9C%AF%2FScrapy%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Scrapy学习笔记1、安装scrapy windows下安装 如果按照网上的方法自行安装scrapy，会出现各种错误，折腾很长时间。这里安装Anaconda2程序，会自带scrapy；如果默认没带的话，打开Anaconda Prompt，执行命令：conda listconda install scrapy安装完后，使用scrapy时如果提示openssl错误，去下载对应的openssl，安装即可。 Linux下安装 比较简单，# apt-get install python-dev# pip install scrapy 2、初步使用2.1、命令行工具scrapy12345678910111213141516171819202122232425# scrapy startproject my_spider # 创建scrapy项目.目录结构├── scrapy.cfg # 项目配置文件└── my_spider # 项目python模块, 之后将在此加入代码 ├── __init__.py ├── items.py ├── pipelines.py ├── settings.py └── spiders # 放置spider的目录 └── __init__.py# cd my_spider# scrapy genspider [-t template] &lt;name&gt; &lt;domain&gt; # 使用模板生成spider文件，位于spiders文件夹下,默认使用basic模板# scrapy genspider -l 列出所有模板# scrapy genspider -d basic 查看basic模板# scrapy list 列出所有的爬虫# scrapy 显示scrapy可用的命令# scrapy &lt;command&gt; -h 查看command命令的详细信息# scrapy version -v Scrapy : 1.1.1 lxml : 3.6.0.0 libxml2 : 2.9.3 Twisted : 16.5.0 ...# scrapy bench 运行基准测试,可以测试scrapy是否正常# scrapy runspider spider_file.py 2.2、基本流程 startproject和genspider 首先分析要抓取的目标网站，在items.py中定义要抓取的数据对象 123456789101112import scrapyclass DmozItem(scrapy.Item): title = scrapy.Field() link = scrapy.Field() desc = scrapy.Field() def __init__(self): # ？如果想初始化某些字段 scrapy.Item.__init__(self) self.title = '' def __str__(self): # ？默认控制台会输出所有的数据，包括抓取的页面源码 return 'crawling %s' % self.title 编写spider，解析网页(xpath/css/re)，提取数据到item对象 12345678910111213141516171819import scrapyfrom tutorial.items import DmozItemclass DmozSpider(scrapy.spider.Spider): name = "dmoz" #唯一标识，启动spider时即指定该名称 allowed_domains = ["dmoz.org"] start_urls = [ "http://www.dmoz.org/Computers/Programming/Languages/Python/Books/", "http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/" ] # 包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一。 后续的URL则从初始的URL获取到的数据中提取。 def parse(self, response): for sel in response.xpath('//ul/li'): # 使用response.selector的css或xpath解析网页 item = DmozItem() # 类字典对象 item['title'] = sel.xpath('a/text()').extract() item['link'] = sel.xpath('a/@href').extract() item['desc'] = sel.xpath('text()').extract() yield item ## 返回item数据对象 ''' 每个初始URL完成下载后生成的 Response 对象将会作为唯一的参数传递给parse()函数。 该方法负责解析返回的数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象。 ''' 保存数据 在执行scrapy crawl 命令时加入-o xxx.csv参数可以将item保存到csv文件中。也可在settings中设置FEED_URI和FEED_FORMAT 12FEED_URI = 'file:///tmp/export.csv'FEED_FORMAT = 'CSV' 将spider爬取到的item进一步处理并存储到数据库，需要在pipelines.py中实现自己的pipeline对象。 process_item(item, spider) # 数据经过pipeline时，都要调用该方法，最后返回一个item。 open_spider(spider) #当spider被开启时，这个方法被调用。 close_spider(spider) #当spider被关闭时，这个方法被调用，可以再爬虫关闭后进行相应的数据处理。 下面是存储数据到mongodb的一个实例： 12345678910111213141516171819202122232425class GushiciPipeline(object): collection_name = 'gushi' def __init__(self, mongo_uri, mongo_db): self.mongo_uri = mongo_uri self.mongo_db = mongo_db @classmethod def from_crawler(cls, crawler): return cls( mongo_uri=crawler.settings.get('MONGO_URI'), mongo_db=crawler.settings.get("MONGO_DATABASE", "items") ) # 在settings.py中定义 MONGO_URI = 'mongodb://localhost:27017' MONGO_DATABASE = 'test2' def open_spider(self, spider): self.client = pymongo.MongoClient(self.mongo_uri) self.db = self.client[self.mongo_db] def close_spider(self, spider): self.client.close() def process_item(self, item, spider): self.db[self.collection_name].insert(dict(item)) return item ​ 最后在settings.py中添加我们定义的pipeline：ITEM_PIPELINES = {&#39;blog_crawl.pipelines.SQLiteStorePipeline&#39;: 1} 1为优先级，越小级别越高 执行爬虫任务 12# scrapy list 查看所有的spider# scrapy crawl dmoz [-o xxx.csv|json|xml] 执行dmoz爬虫,-o指定结果输出到文件 通过python调用cmd命令执行爬虫 123# main.py 根目录下from scrapy import cmdlinecmdline.execute("scrapy crawl mindjet_muban".split()) 这样方便用ide调试 3、如何解析网页 scrapy.Selector有四个基本的方法： xpath()：参数是xpath表达式 css()：输入css表达式 extract()：序列化该节点为unicode字符串并返回list列表； re()：输入正则表达式，返回unicode字符串list列表；注意 正则效率低，可读性差 这四个方法返回的都是包含所有匹配节点的list列表，可嵌套使用css和xpath 3.1、xpathxpath w3school 12345678910111213141516171819202122/html/head/title: 选择HTML文档中 &lt;head&gt; 标签内的 &lt;title&gt; 元素/html/head/title/text(): 选择上面提到的 &lt;title&gt; 元素的文字//td: 选择所有的 &lt;td&gt; 元素//div[@class="mine"]: 选择所有具有 class="mine" 属性的 div 元素/x 是选取子节点x，//x 是递归选取全部的x.//x 从当前节点开始匹配，@是选择属性----- 路径表达式 -----/div/p[1] #选择第一个p元素/div/p[last()] #选择最后一个p元素/div/p[last()-2] #选择倒数第三个p元素/div/p[position()&lt;3] #选择前2个元素/div/p[x&gt;35.00]/name #选择x属性大于35.00的p元素下的name元素/div/p[x&gt;35.00]/@aaa #匹配所有属性aaa的值/div[@class] #选择含有class属性的div//div[@class="wp-pagenavi"]/a[not(@title)] #不含title属性的a标签/div[@class='lang'] #选择class值为lang的div/node() #根元素下所有的节点（包括文本节点，注释节点等）/text() #查找文档根节点下的所有文本节点----- 通配符 -----* #匹配任意元素@* #匹配任意属性exp1 | exp2 #返回2个表达式匹配结果的合集 3.2、css123456.con1 #选择class为con1的全部标签div.con1 #选择class为con1的全部div标签div p #递归选择div下的全部p标签div &gt; p #选择div的全部子标签pa::text #选择a标签的文本img::attr(href) #选择img标签的href属性的值 3.3、re返回unicode字符串的list，该对象无法继续使用css或xpath 3.4、extractresponse.xpath(&quot;//div[@class=&#39;son5&#39;]/p/a&quot;).css(&quot;::attr(href)&quot;).extract()[0] 该语句执行后得到的结果是字符串‘/view_12390.aspx’ 4、多级页面的爬取 主要是spider中的回调函数，下面分析爬古诗词网站为例，爬取诗文的标题、作者、朝代、url、原文，翻译注释 4.1、爬取前分析 [a] start_url：http://so.gushiwen.org/type.aspx [b] 不同朝代的诗文列表url：http://so.gushiwen.org/type.aspx?p=1&amp;c=先秦 ，参数p是页码，c是朝代，一共12个朝代，页码最多的有200页 [c] 诗文url：http://so.gushiwen.org/view_1.aspx [d] 翻译和注释url：http://so.gushiwen.org/fanyi_1.aspx 最后，abcd是递进关系，我们需要的item在bcd中都能找到一部分信息。注意b有很多页要抓，思路是“下一页”url。 4.2、代码示例 basic爬虫继承scrapy.Spider, crawl爬虫继承scrapy.CrawlSpider 基于basic模板的爬虫 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677# -*- coding: utf-8 -*-import scrapyfrom gushici.items import GushiciItemclass TangsiSpider(scrapy.Spider): name = "tangsi" allowed_domains = ["gushiwen.org"] start_urls = ( 'http://so.gushiwen.org/type.aspx', ) def parse(self, response): # 获取不同朝代诗词的列表入口,利用meta字典传参到下一个回调函数，并调用get_lists函数 destinies = response.css("div.cont&gt;a") for destiny in destinies: # item = GushiciItem() # item['destiny'] = destiny.css("::text").extract() url = destiny.css("::attr(href)").extract()[0] destiny_url = response.urljoin(url) # 此处是分类列表的url # item['url'] = full_url destiny_text = destiny.css("::text").extract()[0] yield scrapy.Request(destiny_url, meta=&#123;"destiny": destiny_text&#125;, callback=self.get_lists) def get_lists(self, response): # 爬当前页的所有诗词的url，title，作者，并进入下一级调爬诗文内容；爬到“下一页”url后交给get_lists处理 destiny = response.meta['destiny'] divs = response.css("div.sons") for div in divs: title = div.css('p &gt; a[target]::text').extract()[0] full_url = response.urljoin(div.css('p &gt; a[target]::attr(href)').extract()[0]) author = div.xpath("p[2]/text()").extract()[0] # score = response.re(u'(\d+\.\d+)')[0] yield scrapy.Request(full_url, meta=&#123;'title': title, 'url': full_url, 'author': author, 'destiny': destiny&#125;, callback=self.get_contents) # 递归爬下一页的诗词url，入口是网页中的下一页标签url next_urls = response.xpath('//a[@style="width:60px;"]').css("::attr(href)").extract() for next_url in next_urls: next_page = response.urljoin(next_url) yield scrapy.Request(next_page, meta=&#123;"destiny": destiny&#125;, callback=self.get_lists) # 获取诗词的评分，文本，翻译页的url，接收父级页面解析出来的标题，作者，朝代，创建item def get_contents(self, response): item = GushiciItem() item['title'] = response.meta['title'] item['url'] = response.meta['url'] item['destiny'] = response.meta['destiny'] item['author'] = response.meta['author'] try: item['score'] = response.xpath('//div[@class="pingfen"]//div[@class="line1"]/span/text()').extract()[0] except Exception: item['score'] = u'评分不足10人' ps = response.xpath("//div[@class='son2']/p") text = "" if len(ps) &gt; 3: for p in ps[3:]: text += ''.join(p.css("::text").extract()) + '\n' else: text += ''.join(response.xpath("//div[@class='son2']/text()").extract()).replace('\n', '') item['text'] = text try: fanyi_url = response.xpath("//div[@class='son5']/p/a").css("::attr(href)").extract()[0] fanyi_url = response.urljoin(fanyi_url) yield scrapy.Request(fanyi_url, callback=self.get_fanyi, meta=&#123;'item': item&#125;) except Exception: item['translate'] = '' yield item # 获取翻译文本 def get_fanyi(self, response): # 前面是利用meta字典传递已抓到的内容，这里是将item对象装入meta传递 item = response.meta['item'] ps = response.xpath('//div[@class="shangxicont"]/p') fanyi = '' for p in ps[:-1]: fanyi += ''.join(p.css("::text").extract()) + '\n' item['translate'] = fanyi yield item ​ 网站没有反扒措施，但这个爬虫最终抓到7795条文章，像宋词至少有1万+，但在该分类下200页后的内容就是空的，也就是说web只给我们提供了200页的宋词。 基于crawl模板的爬虫 crawl类的爬虫更强大一点，Rule方法可以根据正则匹配所有满足条件的url，并调用相应回调函数处理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# -*- coding: utf-8 -*-import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Rulefrom gushici.items import GushiciItemclass SongciSpider(CrawlSpider): name = 'songci' allowed_domains = ['so.gushiwen.org'] start_urls = ['http://so.gushiwen.org/type.aspx'] rules = ( # 这是分类页的url，全部加入到抓取列表中 Rule(LinkExtractor(allow=r"http://so\.gushiwen\.org/type\.aspx\?p=\d+&amp;c=.+?")), # 这是诗文详情页url，全部调用parse_item解析 Rule(LinkExtractor(allow=r'http://so\.gushiwen\.org/view_\d+\.aspx'), callback='parse_item', follow=True), ) def parse_item(self, response): item = GushiciItem() try: item['title'] = response.xpath('//h1/text()').extract()[0] item['url'] = response.url item['destiny'] = response.xpath('//div[@class="son2"]/p[1]//text()').extract()[-1] item['author'] = response.xpath('//div[@class="son2"]/p[2]//text()').extract()[-1] except Exception: pass try: item['score'] = response.xpath('//div[@class="pingfen"]//div[@class="line1"]/span/text()').extract()[0] except Exception: item['score'] = u'评分不足10人' ps = response.xpath("//div[@class='son2']/p") text = "" if len(ps) &gt; 3: for p in ps[3:]: text += ''.join(p.css("::text").extract()) + '\n' else: text += ''.join(response.xpath("//div[@class='son2']/text()").extract()).replace('\n', '') item['text'] = text try: fanyi_url = response.xpath("//div[@class='son5']/p/a").css("::attr(href)").extract()[0] fanyi_url = response.urljoin(fanyi_url) yield scrapy.Request(fanyi_url, callback=self.get_fanyi, meta=&#123;'item': item&#125;) except Exception: item['translate'] = '' yield item # 获取翻译文本 def get_fanyi(self, response): item = response.meta['item'] ps = response.xpath('//div[@class="shangxicont"]/p') fanyi = '' for p in ps[:-1]: fanyi += ''.join(p.css("::text").extract()) + '\n' item['translate'] = fanyi yield item basic爬虫是循环查找下一页的url来抓取，这里crawl爬虫我们直接用正则匹配列表页url和诗文详情页url，另外“标题文本朝代作者”也都改为在详情页获取了，“翻译”仍需从下一级网页获取。crawl爬了8700条数据，我在settings设置了download_delay为0.5秒，爬取效果是100秒约90条数据，一共用了2h48m。 pipelines的Dropitem 我先把basic抓到的放入mongodb了，再用crawl爬虫时，我改写了pipelines，如果item在数据库中，就丢弃，否则存入monggodb，避免数据重复。 123456789from scrapy.exceptions import DropItemdef process_item(self, item, spider): data = self.db[self.collection_name].find(&#123;&#125;, &#123;'_id': 0, 'url': 1&#125;) url_finished = set(x['url'] for x in data) # 获取已爬url的集合 if item['url'] in url_finished: raise DropItem("%s has been crawled!" % item) else: self.db[self.collection_name].insert(dict(item)) return item ​ 5、Scrapy框架解读 Scrapy基于Twisted异步网络库处理网络通信 5.1、整体框架 各组件及功能： Scrapy Engine: 用来处理整个系统的数据流处理, 触发事务(框架核心) Scheduler: 调度器，接收引擎发过来的Request, 压入队列中, 由引擎调度，将Request发送给Downloader。 可以理解为要爬取URL的优先队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址 Downloader: 根据Scheduler给出的Request，去下载网页内容, 并将网页内容返回给Spiders解析。Scrapy下载器是基于twisted的异步模型，因此网页下载的结果并不是有序的。 Spiders: 爬虫有2个作用：从网页中提取自己需要的信息实体(Item)，并将item发送到item pipeline进行后续处理；从中网页提取出进一步爬取的URL,并发送给Scheduler。 Pipeline: 负责处理爬虫从网页中抽取的实体：数据清洗(整理、查重、验证有效性)、数据保存等。 Downloader Middlewares: 位于Scrapy引擎和下载器之间的中间件，主要是处理Scrapy引擎与下载器之间的请求及响应。可以在此处设置请求的代理、cookie？ Spider Middlewares: 介于Scrapy引擎和爬虫之间的框架，主要工作是处理蜘蛛的响应输入和请求输出。 Scheduler Middewares: 介于Scrapy引擎和调度之间的中间件，从Scrapy引擎发送到调度的请求和响应。 ​ 5.2、主要对象 Spider Selector Items &amp; Item Pipeline &amp; Feed exports Requests Responses Logging 日志模块，使用python内置的logging模块，logging.log(logging.WARNING, &quot;This is a warning&quot;),可以在setting中配置logging属性。 同时Spider对象含有logger对象，spider内也可使用self.logger.info(&#39;msg&#39;) self.logger.warning(&#39;msg&#39;) setting中提供的logging全局变量可以参考这里 设置 LOG_FILE = &quot;mySpider.log&quot; 后，日志写入文件，终端就没有日志输出了。 statscollectors MailSender 12345678910111213141516from scrapy.mail import MailSenderfrom xxx import settings#------ spider文件，在spider对象close时发邮件，重写close方法 def close(self, spider, reason): mailer = MailSender.from_settings(settings) mailer.send(to=['xx@xx.com'], subject=u'爬虫结束', body='test!'+str(reason))#-----settings文件# 下面是在settings文件中配置邮件服务器# 发送邮件MAIL_FROM = 'xxx@xxx.com' #邮件中的fromMAIL_HOST = 'smtp.xxx.com' #邮件服务器地址，端口MAIL_PORT = 25MAIL_USER = '登录名'MAIL_PASS = '密码'MAIL_TLS = False # 默认邮件服务器不开启TLS SSL安全连接MAIL_SSL = False 6、下载图片和文件6.1、激活Media pipeline在settings中设置如下： 1234567891011121314# 启用pipelineITEM_PIPELINES = &#123;'scrapy.pipelines.images.ImagesPipeline': 1, 'scrapy.pipelines.files.FilesPipeline': 1&#125;# 1.2版默认存放在./full，路径是相对.cfg配置文件# 即使指定存储位置，也会在该目录下生成full子文件夹IMAGES_STORE = '/path/to/valid/dir'# 定义图片url的item域IMAGES_URLS_FIELD = 'field_name_for_your_images_urls'# 定义图片下载结果存放的item域IMAGES_RESULT_FIELD = 'field_name_for_your_processed_images'# 文件和图片定义类似FILES_STORE = '/path/to/valid/dir'FILES_URLS_FIELD = 'field_name_for_your_files_urls'FILES_RESULT_FIELD = 'field_name_for_your_processed_files' 6.2、items中定义123import scrapyimage_url = scrapy.Field()download_success = scrapy.Field() 注意：image_url 的接收对象是image url的列表。 download_success:包含字典的列表，由ImagePipeline自动填充，包含image的url，本地存储位置，文件校验值： [{&#39;url&#39;: &#39;http://img.tupianzj.com/uploads/allimg/161226/9-161226154443.jpg&#39;, &#39;path&#39;: &#39;full/46ae5ec4f4c0905e48a41d569abe8e1aaa832f29.jpg&#39;, &#39;checksum&#39;: &#39;c35693197b1217ac8cafd7f7f318ef33&#39;}] 6.3、spiders编写 只需要给item[‘image_url’]传url的列表，并将item返回 这是爬图片之家QQ表情图的一个例子。 123456789101112131415161718192021222324252627282930313233# -*- coding: utf-8 -*-import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Rulefrom gaoxiao_pic.items import GaoxiaoPicItemclass FunPicSpider(CrawlSpider): name = 'fun_pic' allowed_domains = ['tupianzj.com'] start_urls = ['http://www.tupianzj.com/gaoxiao/biaoqing/', ] rules = ( Rule(LinkExtractor(allow=r'http://www\.tupianzj\.com/gaoxiao/gx/biaoqing\.html')), Rule(LinkExtractor(allow=r'http://www\.tupianzj\.com/gaoxiao/biaoqing/list[_\d]+\.html')), Rule(LinkExtractor(allow=r'http://img\.tupianzj\.com/uploads/allimg/\d+/.+\.(?:gif|jpg|png|bmp)'), callback='parse_item'), Rule(LinkExtractor(allow=r'http://www\.tupianzj\.com/gaoxiao/biaoqing/\d+/[_\d]+.html'), callback='parse_item', follow=True), ) def parse_item(self, response): i = GaoxiaoPicItem() if str(response.url).split('.')[-1].lower() in ['jpg', 'gif', 'png', 'jpeg', 'bmp']: i['image_url'] = [response.url] else: try: url = response.xpath("//div[@id='bigpic']/a/img/@src").extract()[0] i['image_url'] = [response.urljoin(url)] # 这里每个页面只有一张图片, print i['image_url'] except Exception, e: print e.message return i items.py: 123class GaoxiaoPicItem(scrapy.Item): image_url = scrapy.Field() download_success = scrapy.Field() settings.py: 12345678910# 启用pipelineITEM_PIPELINES = &#123;'scrapy.pipelines.images.ImagesPipeline': 1, # 'scrapy.pipelines.files.FilesPipeline': 1 &#125;# 定义图片存储位置（必须）IMAGES_STORE = '.'# 定义图片url的item域IMAGES_URLS_FIELD = 'image_url'# 存储下载结果IMAGES_RESULT_FIELD = 'download_success' 7、设置headers7.1、设置默认headers1234567891011# settings中可以设置浏览器默认headers，DEFAULT_REQUEST_HEADERS = &#123; 'accept': 'image/webp,/;q=0.8', 'accept-language': 'zh-CN,zh;q=0.8', 'referer': 'https://www.baidu.com/', 'user-agent': 'Mozilla/5.0 (Windows NT 6.3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/31.0.1650.63 Safari/537.36',&#125; 7.2、为每个download 分配随机UA和代理 UA 1234567891011121314# --------------settings.py--------------------DOWNLOADER_MIDDLEWARES = &#123; 'xxx.middlewares.RandomUserAgentMiddleware': 400, 'scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware': None,&#125;# ------创建middlewares.py ----------------------import fakerf = faker.Factory().create()# user_agent = f.user_agent() # 随机生成的浏览器UA，都次调用返回结果都不同class RandomUserAgentMiddleware(object): def process_request(self, request, spider): request.headers.setdefault('User-Agent', f.user_agent()) #log.msg('&gt;&gt;&gt;&gt; UA %s'%request.headers) 代理 123456789101112131415161718192021222324252627282930# -------------------settings.py--------# 启用代理DOWNLOADER_MIDDLEWARES = &#123; 'scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware': 110, 'xxx.middlewares.ProxyMiddleware': 100,&#125;# 在setting中写死了代理列表，实际环境在需要代理时可以从数据库代理池获取PROXY_LIST = [ &#123;'ip_port': '111.11.228.75:80', 'user_pass': ''&#125;, &#123;'ip_port': '120.198.243.22:80', 'user_pass': ''&#125;, &#123;'ip_port': '111.8.60.9:8123', 'user_pass': ''&#125;, &#123;'ip_port': '101.71.27.120:80', 'user_pass': ''&#125;, &#123;'ip_port': '122.96.59.104:80', 'user_pass': ''&#125;, &#123;'ip_port': '122.224.249.122:8088', 'user_pass': ''&#125;,]# -----创建middlewares.py, 配置代理-----------------from xxx.settings import PROXY_LISTimport randomimport base64class ProxyMiddleware(object): def process_request(self, request, spider): proxy = random.choice(PROXIES_LIST) if proxy['user_pass'] is not None: request.meta['proxy'] = "http://%s" % proxy['ip_port'] encoded_user_pass = base64.encodestring(proxy['user_pass']) request.headers['Proxy-Authorization'] = 'Basic ' + encoded_user_pass else: request.meta['proxy'] = "http://%s" % proxy['ip_port'] 8、登陆Post和Cookiecookie保存和传递 8.1、POST表单登陆豆瓣登陆页面有验证码比无验证时post表单提交的数据多了captcha-id和captcha-solution。有验证码时下载图片，手动输入。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100# -*- coding: utf-8 -*-import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Rulefrom scrapy.http import Request, FormRequest, HtmlResponsefrom douban.items import DoubanItemimport faker, requests, osfrom PIL import Imageclass DoubanSpiderSpider(CrawlSpider): def _requests_to_follow(self, response): """重写加入cookiejar的更新""" if not isinstance(response, HtmlResponse): return seen = set() for n, rule in enumerate(self._rules): links = [l for l in rule.link_extractor.extract_links(response) if l not in seen] if links and rule.process_links: links = rule.process_links(links) for link in links: seen.add(link) r = Request(url=link.url, callback=self._response_downloaded) # 下面这句是我重写的 r.meta.update(rule=n, link_text=link.text, cookiejar=response.meta['cookiejar']) yield rule.process_request(r) name = 'douban_spider' allowed_domains = ['douban.com'] start_urls = ['https://www.douban.com/'] rules = ( Rule(LinkExtractor(allow=r'Items/'), callback='parse_item', follow=True), ) f = faker.Factory().create() user_agent = f.user_agent() # 随机生成的浏览器UA，都次调用返回结果都不同 headers = &#123;'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', 'Cache-Control': 'max-age=0', 'Referer': 'https://www.douban.com', 'User-Agent': user_agent, # 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.87 Safari/537.36', 'Accept-Encoding': 'gzip, deflate, sdch, br', 'Accept-Language': 'zh-CN,zh;q=0.8', 'Host': 'accounts.douban.com', 'Connection': 'keep-alive' &#125; your_email = '1XXX' your_password = 'XXXX' postdata = &#123;'source': 'None', 'redir': 'https://www.douban.com/', 'form_email': your_email, 'form_password': your_password, # 'captcha-solution': vcode, # 'captcha-id': captcha, 'login': '登录' &#125; def start_requests(self): # 访问登录页面 # Scrapy通过使用meta['cookiejar']来支持单spider追踪多cookie session。默认情况下其使用一个cookie jar(session)，不过可以传递一个标示符来使用多个。如meta=&#123;'cookiejar': 1&#125;这句，后面那个1就是标示符。 return [Request(url='https://www.douban.com/accounts/login', headers=self.headers, meta=&#123;'cookiejar': 1&#125;, callback=self.post_login)] def post_login(self, response): print 'Preparing login====', response.url # 如果登陆要验证码，则post数据中加入验证码的id和值 if response.body.find('captcha_image') &gt; 0: captcha_url = response.xpath('//img[@id="captcha_image"]/@src').extract()[0] print u'验证码的URL：%s' % captcha_url with open('v.jpg', 'wb') as f: f.write(requests.get(captcha_url, verify=False).content) with open('v.jpg', 'rb') as f: image = Image.open(f) image.show() self.postdata['captcha-solution'] = raw_input('请输入图片验证码:\n') os.remove('v.jpg') self.postdata['captcha-id'] = response.xpath('//input[@name="captcha-id"]/@value').extract()[0] print self.postdata return [FormRequest.from_response(response, headers=self.headers, meta=&#123;'cookiejar': response.meta['cookiejar']&#125;, formdata=self.postdata, callback=self.after_login, )] def after_login(self, response): # 登陆之后,访问的网页内容应该会包含用户信息 self.headers['Host'] = 'www.douban.com' print response.body with open('a.txt', 'w') as f: f.write(response.body) item = DoubanItem() item['main_page'] = response.body return Request('https://www.douban.com/doumail/', headers=self.headers, meta=&#123;'cookiejar': response.meta['cookiejar'], 'item': item&#125;, callback=self.openfile) def openfile(self, response): item['doumail_page'] = response.body return item 8.2、使用Cookie登陆豆瓣使用浏览器或requests模拟登陆，然后将cookie传进scrapy的spider。 由于每次从浏览器复制出来的cookies或headers都是字符串形式，手工改成字典太累了，写个小程序： 1234567891011121314151617181920212223242526272829# 从chrome浏览器的Request Header中，点击view source，然后复制header字符串headers_str = '''Host: www.douban.comConnection: keep-aliveCache-Control: max-age=0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8Upgrade-Insecure-Requests: 1User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.87 Safari/537.36Referer: https://www.douban.com/people/108243932/Accept-Encoding: gzip, deflate, sdch, brAccept-Language: zh-CN,zh;q=0.8Cookie: viewed="1770782"; bid=SrGB-eJRKEE; gr_user_id=a37ff9ef-33cc-4de7-971b-c161f747a77b; ll="118254"; ps=y; dbcl2="108243932:kVKKGRcAZVg"; _ga=GA1.2.1495924407.1465701053; ck=LRet; _pk_ref.100001.8cb4=%5B%22%22%2C%22%22%2C1483063011%2C%22https%3A%2F%2Faccounts.douban.com%2Fregister%22%5D; __utmt=1; ap=1; push_noty_num=0; push_doumail_num=0; _pk_id.100001.8cb4=438cca0c1cd12666.1482926660.4.1483063910.1483060769.; _pk_ses.100001.8cb4=*; __utma=30149280.1495924407.1465701053.1483060678.1483063011.6; __utmb=30149280.24.9.1483063909873; __utmc=30149280; __utmz=30149280.1483021458.4.3.utmcsr=accounts.douban.com|utmccn=(referral)|utmcmd=referral|utmcct=/register; __utmv=30149280.10824; _vwo_uuid_v2=02A1FB5802A3379A6C48F734CB328D35|33e02434e1d90a57e4c63094703cde0f'''headers = &#123;&#125;for i in headers_str.split('\n'): j = i.replace(': ', ':', 1).split(':', 1) headers[j[0]] = j[1]if 'Cookie' in headers: cookies_str = headers['Cookie']else: # 把cookie字符串从浏览器copy进来 cookies_str = ''' '''cookies = &#123;&#125;for i in cookies_str.split(';'): q = i.split('=') key = q[0].replace(' ', '', 1) value = q[1].replace(' ', '', 1) cookies[key] = value# print cookiesprint headers.pop('Cookie')print headers 使用cookie登陆豆瓣： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# -*- coding: utf-8 -*-import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Ruleclass DoubanCookieSpider(CrawlSpider): name = 'douban_cookie' allowed_domains = ['douban.com'] start_urls = ['https://www.douban.com/mine/', 'https://www.douban.com/doumail/', 'https://www.douban.com/people/108243932/', 'https://www.douban.com/mine/orders/' ] cookies = &#123;'ck': 'LRet', 'ps': 'y', '__utmz': '30149280.1483021458.4.3.utmcsr', '__utmv': '30149280.10824', 'push_doumail_num': '0', '__utmt': '1', 'bid': 'SrGB-eJRKEE', 'push_noty_num': '0', '_ga': 'GA1.2.1495924407.1465701053', '_pk_ref.100001.8cb4': '%5B%22%22%2C%22%22%2C1483063011%2C%22https%3A%2F%2Faccounts.douban.com%2Fregister%22%5D', '_vwo_uuid_v2': '02A1FB5802A3379A6C48F734CB328D35|33e02434e1d90a57e4c63094703cde0f', 'ap': '1', 'dbcl2': '"108243932:kVKKGRcAZVg"', '_pk_id.100001.8cb4': '438cca0c1cd12666.1482926660.4.1483063910.1483060769.', '_pk_ses.100001.8cb4': '*', 'gr_user_id': 'a37ff9ef-33cc-4de7-971b-c161f747a77b', '__utma': '30149280.1495924407.1465701053.1483060678.1483063011.6', '__utmb': '30149280.24.9.1483063909873', '__utmc': '30149280', 'll': '"118254"', 'viewed': '"1770782"'&#125; headers = &#123;'Accept-Language': 'zh-CN,zh;q=0.8', 'Accept-Encoding': 'gzip, deflate, sdch, br', 'Connection': 'keep-alive', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.87 Safari/537.36', 'Host': 'www.douban.com', 'Referer': 'https://www.douban.com/', 'Cache-Control': 'max-age=0', 'Upgrade-Insecure-Requests': '1'&#125; def start_requests(self): return [scrapy.Request('https://www.douban.com/', headers=self.headers, cookies=self.cookies, meta=&#123;'cookiejar': 1&#125;, callback=self.after_set_cookie)] def after_set_cookie(self, response): req = [] self.headers['Referer'] = response.url for url in self.start_urls: req.append(scrapy.Request(url=url, headers=self.headers, meta=&#123;'cookiejar': response.meta['cookiejar']&#125;, callback=self.parse_item)) return req def parse_item(self, response): print response.url filename = response.url.split('/')[-2] + '.html' with open(filename, 'w') as f: f.write(response.body) # 保存的网页中应该有登陆账号后的个人信息 9、JS 、XHR分析 主要是分析js请求的url。挖个坑，暂时不打算填。 不好解决的话，还是用selenium + phantomjs吧 10、Scrapy Redis分布式爬虫10.1、安装redis windows 下载地址：https://github.com/rgl/redis/downloads 安装完成后， 运行redis服务器的命令：安装目录下的redis-server.exe 运行redis客户端的命令：安装目录下的redis-cli.exe Linux 1234567$sudo apt-get install redis-server# 启动 Redis$ redis-server &amp;# 或者$ service redis-server start# 查看 redis 是否启动？$ redis-cli 12345# vi /etc/redis/redis.conf#注释bind#bind 127.0.0.1# 如果要设置密码，取消注释requirepassrequirepass mypasswd 修改配置文件后，要重启服务生效。有密码的连接方式，redis-cli -a mypasswd -h 172.16.28.24 -p 6379 还是单开一篇笔记来写吧！ 11、记录一些error11.1、url相关 ValueError: Missing scheme in request url: h 这种问题一般是url出错了，要以http开头，如果是从网页解析的url，可以用 response.urljoin(relative_url) 生成绝对路径。 如果在下载图片中出错，是因为image_field必须是图片url的列表，只存了一个url字符串的话，scrapy遍历url时取出的第一个对象是http url的第一个字符h，故报错h是非法url。 太坑了，花了半个小时才发现原因。 注意twisted库的版本，在conda中先装twisted再装scrapy]]></content>
      <categories>
        <category>技术</category>
        <category>Scrapy</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 配置SNMP服务]]></title>
    <url>%2F2016%2F12%2F14%2F%E6%8A%80%E6%9C%AF%2FLinux-snmp-server%2F</url>
    <content type="text"><![CDATA[Linux服务器配置snmp服务安装snmp server 安装snmp 1apt-get install snmp snmpd 安装mib库 1apt-get install snmp-mibs-downloader 参考debian-wiki-snmp 查看默认配置文件 12cat /etc/snmp/snmpd.conf cat /etc/snmp/snmp.conf 启动SNMP 12# service snmpd start# snmpd -C -c /etc/snmp/myconfig.conf ### -C不适用默认配置文件 -c指定自定义配置文件 如有需要，安装net-snmp 源码下载地址 编译 12345# tar -zxvf net-snmp-5.7.3.tar.gz ### 解压源码# ./configure --help ### 查看编译配置# ./configure ### 开始编译# make# make install 如果编译报错lperl，使用 apt-get install libperl-dev 使用net-snmp工具 查询到主机CPU空闲率为99% # snmpwalk -v 2c -c public localhost 1.3.6.1.4.1.2021.11.11.0 UCD-SNMP-MIB::ssCpuIdle.0 = INTEGER: 99 修改snmp配置文件/etc/snmp/snmpd.conf 配置允许网络访问,找到【AGENT BEHAVIOUR】，注释掉`agentAddress udp:127.0.0.1：161`,添加一行`agentAddress udp:161` 选择SNMPv2C协议版本,找到【ACTIVE MONITORING】，注释掉`trapsink localhost public`，添加`trap2sink localhost public` 设置访问权限,找到【ACCESS CONTROL】,注释掉`rocommunity public default -V systemonly`，添加`rocommunity public default `,允许所有访问请求。 /etc/snmp/snmp.conf 注释掉开头第一行 开启防火墙161端口 查看防火墙规则 iptables –L –n 添加规则 iptables -I INPUT -p udp --dport 161 -j ACCEPT 保存生效 iptables-save Debian iptables -save ubuntu iptables-save 重启后会失效，应使用service iptables save 常用Linux监控OID 系统信息 网络接口 CPU及负载 内存及磁盘 System Group sysDescr 1.3.6.1.2.1.1.1 sysObjectID 1.3.6.1.2.1.1.2 sysUpTime 1.3.6.1.2.1.1.3 sysContact 1.3.6.1.2.1.1.4 sysName 1.3.6.1.2.1.1.5 sysLocation 1.3.6.1.2.1.1.6 sysServices 1.3.6.1.2.1.1.7 Interfaces Group ifNumber 1.3.6.1.2.1.2.1 ifTable 1.3.6.1.2.1.2.2 ifEntry 1.3.6.1.2.1.2.2.1 ifIndex 1.3.6.1.2.1.2.2.1.1 ifDescr 1.3.6.1.2.1.2.2.1.2 ifType 1.3.6.1.2.1.2.2.1.3 ifMtu 1.3.6.1.2.1.2.2.1.4 ifSpeed 1.3.6.1.2.1.2.2.1.5 ifPhysAddress 1.3.6.1.2.1.2.2.1.6 ifAdminStatus 1.3.6.1.2.1.2.2.1.7 ifOperStatus 1.3.6.1.2.1.2.2.1.8 ifLastChange 1.3.6.1.2.1.2.2.1.9 ifInOctets 1.3.6.1.2.1.2.2.1.10 ifInUcastPkts 1.3.6.1.2.1.2.2.1.11 ifInNUcastPkts 1.3.6.1.2.1.2.2.1.12 ifInDiscards 1.3.6.1.2.1.2.2.1.13 ifInErrors 1.3.6.1.2.1.2.2.1.14 ifInUnknownProtos 1.3.6.1.2.1.2.2.1.15 ifOutOctets 1.3.6.1.2.1.2.2.1.16 ifOutUcastPkts 1.3.6.1.2.1.2.2.1.17 ifOutNUcastPkts 1.3.6.1.2.1.2.2.1.18 ifOutDiscards 1.3.6.1.2.1.2.2.1.19 ifOutErrors 1.3.6.1.2.1.2.2.1.20 ifOutQLen 1.3.6.1.2.1.2.2.1.21 ifSpecific 1.3.6.1.2.1.2.2.1.22 IP Group ipForwarding 1.3.6.1.2.1.4.1 ipDefaultTTL 1.3.6.1.2.1.4.2 ipInReceives 1.3.6.1.2.1.4.3 ipInHdrErrors 1.3.6.1.2.1.4.4 ipInAddrErrors 1.3.6.1.2.1.4.5 ipForwDatagrams 1.3.6.1.2.1.4.6 ipInUnknownProtos 1.3.6.1.2.1.4.7 ipInDiscards 1.3.6.1.2.1.4.8 ipInDelivers 1.3.6.1.2.1.4.9 ipOutRequests 1.3.6.1.2.1.4.10 ipOutDiscards 1.3.6.1.2.1.4.11 ipOutNoRoutes 1.3.6.1.2.1.4.12 ipReasmTimeout 1.3.6.1.2.1.4.13 ipReasmReqds 1.3.6.1.2.1.4.14 ipReasmOKs 1.3.6.1.2.1.4.15 ipReasmFails 1.3.6.1.2.1.4.16 ipFragsOKs 1.3.6.1.2.1.4.17 ipFragsFails 1.3.6.1.2.1.4.18 ipFragCreates 1.3.6.1.2.1.4.19 ipAddrTable 1.3.6.1.2.1.4.20 ipAddrEntry 1.3.6.1.2.1.4.20.1 ipAdEntAddr 1.3.6.1.2.1.4.20.1.1 ipAdEntIfIndex 1.3.6.1.2.1.4.20.1.2 ipAdEntNetMask 1.3.6.1.2.1.4.20.1.3 ipAdEntBcastAddr 1.3.6.1.2.1.4.20.1.4 ipAdEntReasmMaxSize 1.3.6.1.2.1.4.20.1.5 ICMP Group icmpInMsgs 1.3.6.1.2.1.5.1 icmpInErrors 1.3.6.1.2.1.5.2 icmpInDestUnreachs 1.3.6.1.2.1.5.3 icmpInTimeExcds 1.3.6.1.2.1.5.4 icmpInParmProbs 1.3.6.1.2.1.5.5 icmpInSrcQuenchs 1.3.6.1.2.1.5.6 icmpInRedirects 1.3.6.1.2.1.5.7 icmpInEchos 1.3.6.1.2.1.5.8 icmpInEchoReps 1.3.6.1.2.1.5.9 icmpInTimestamps 1.3.6.1.2.1.5.10 icmpInTimestampReps 1.3.6.1.2.1.5.11 icmpInAddrMasks 1.3.6.1.2.1.5.12 icmpInAddrMaskReps 1.3.6.1.2.1.5.13 icmpOutMsgs 1.3.6.1.2.1.5.14 icmpOutErrors 1.3.6.1.2.1.5.15 icmpOutDestUnreachs 1.3.6.1.2.1.5.16 icmpOutTimeExcds 1.3.6.1.2.1.5.17 icmpOutParmProbs 1.3.6.1.2.1.5.18 icmpOutSrcQuenchs 1.3.6.1.2.1.5.19 icmpOutRedirects 1.3.6.1.2.1.5.20 icmpOutEchos 1.3.6.1.2.1.5.21 icmpOutEchoReps 1.3.6.1.2.1.5.22 icmpOutTimestamps 1.3.6.1.2.1.5.23 icmpOutTimestampReps 1.3.6.1.2.1.5.24 icmpOutAddrMasks 1.3.6.1.2.1.5.25 icmpOutAddrMaskReps 1.3.6.1.2.1.5.26 TCP Group tcpRtoAlgorithm 1.3.6.1.2.1.6.1 tcpRtoMin 1.3.6.1.2.1.6.2 tcpRtoMax 1.3.6.1.2.1.6.3 tcpMaxConn 1.3.6.1.2.1.6.4 tcpActiveOpens 1.3.6.1.2.1.6.5 tcpPassiveOpens 1.3.6.1.2.1.6.6 tcpAttemptFails 1.3.6.1.2.1.6.7 tcpEstabResets 1.3.6.1.2.1.6.8 tcpCurrEstab 1.3.6.1.2.1.6.9 tcpInSegs 1.3.6.1.2.1.6.10 tcpOutSegs 1.3.6.1.2.1.6.11 tcpRetransSegs 1.3.6.1.2.1.6.12 tcpConnTable 1.3.6.1.2.1.6.13 tcpConnEntry 1.3.6.1.2.1.6.13.1 tcpConnState 1.3.6.1.2.1.6.13.1.1 tcpConnLocalAddress 1.3.6.1.2.1.6.13.1.2 tcpConnLocalPort 1.3.6.1.2.1.6.13.1.3 tcpConnRemAddress 1.3.6.1.2.1.6.13.1.4 tcpConnRemPort 1.3.6.1.2.1.6.13.1.5 tcpInErrs 1.3.6.1.2.1.6.14 tcpOutRsts 1.3.6.1.2.1.6.15 UDP Group udpInDatagrams 1.3.6.1.2.1.7.1 udpNoPorts 1.3.6.1.2.1.7.2 udpInErrors 1.3.6.1.2.1.7.3 udpOutDatagrams 1.3.6.1.2.1.7.4 udpTable 1.3.6.1.2.1.7.5 udpEntry 1.3.6.1.2.1.7.5.1 udpLocalAddress 1.3.6.1.2.1.7.5.1.1 udpLocalPort 1.3.6.1.2.1.7.5.1.2 SNMP Group snmpInPkts 1.3.6.1.2.1.11.1 snmpOutPkts 1.3.6.1.2.1.11.2 snmpInBadVersions 1.3.6.1.2.1.11.3 snmpInBadCommunityNames 1.3.6.1.2.1.11.4 snmpInBadCommunityUses 1.3.6.1.2.1.11.5 snmpInASNParseErrs 1.3.6.1.2.1.11.6 NOT USED 1.3.6.1.2.1.11.7 snmpInTooBigs 1.3.6.1.2.1.11.8 snmpInNoSuchNames 1.3.6.1.2.1.11.9 snmpInBadValues 1.3.6.1.2.1.11.10 snmpInReadOnlys 1.3.6.1.2.1.11.11 snmpInGenErrs 1.3.6.1.2.1.11.12 snmpInTotalReqVars 1.3.6.1.2.1.11.13 snmpInTotalSetVars 1.3.6.1.2.1.11.14 snmpInGetRequests 1.3.6.1.2.1.11.15 snmpInGetNexts 1.3.6.1.2.1.11.16 snmpInSetRequests 1.3.6.1.2.1.11.17 snmpInGetResponses 1.3.6.1.2.1.11.18 snmpInTraps 1.3.6.1.2.1.11.19 snmpOutTooBigs 1.3.6.1.2.1.11.20 snmpOutNoSuchNames 1.3.6.1.2.1.11.21 snmpOutBadValues 1.3.6.1.2.1.11.22 NOT USED 1.3.6.1.2.1.11.23 snmpOutGenErrs 1.3.6.1.2.1.11.24 snmpOutGetRequests 1.3.6.1.2.1.11.25 snmpOutGetNexts 1.3.6.1.2.1.11.26 snmpOutSetRequests 1.3.6.1.2.1.11.27 snmpOutGetResponses 1.3.6.1.2.1.11.28 snmpOutTraps 1.3.6.1.2.1.11.29 snmpEnableAuthenTraps 1.3.6.1.2.1.11.30]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML语法基础]]></title>
    <url>%2F2016%2F12%2F13%2F%E6%8A%80%E6%9C%AF%2FHTML-basic-grammar%2F</url>
    <content type="text"><![CDATA[HTML语法基础 学习django的时候发现还是要懂点html语法的 语法 html是一种展示网页的标记语言 由标签和被其标记的内容组成，标签的属性控制着显示的方式 &lt;tag key=&quot;value&quot;&gt;被标记的内容&lt;/tag&gt; 语法不区分大小写，默认使用小写 语法不区分回车、空格和缩进，为了代码可读和逻辑清晰，应该保持严格的缩进风格，必要时添加注释 注释内容&lt;!-- XXXXX --!&gt;，不会被显示 字符字体：保留字符无法直接使用，如&lt; &gt; 会和标签符号产生歧义，可以使用&amp;lt 或 &amp;#60表示小于号 HTML基本结构123456789101112131415161718&lt;html lang="en"&gt;&lt;!--html标签是文档开始和结束的标志--&gt;&lt;head&gt; &lt;!--HTML文件头标记，用来包含文件的基本信息，比如网页的标题、关键字，在 可以放&lt;title&gt;&lt;/title&gt;、&lt;meta&gt;&lt;/meta&gt;、&lt;style&gt;&lt;/style&gt;等等标记--&gt; &lt;!--注意:在&lt;head&gt;&lt;/head&gt;标记内的内容不会在浏览器中显示--&gt; &lt;meta charset="UTF-8"&gt; &lt;!--&lt;meta&gt; 元素可提供有关某个 HTML 元素的元信息 (meta-information)，比如描述、针对搜索引擎的关键词以及刷新频率。--&gt; &lt;title&gt;这是网页的标题&lt;/title&gt; &lt;!--网页的“主题”，显示在浏览器的标题栏，网页的标题不能太长，要短小精悍，能具体反应页面的内容，&lt;title&gt;&lt;/title&gt;标记中不能包含其他标记--&gt;&lt;/head&gt;&lt;body&gt;&lt;!--HTML文档的主体标记--&gt;&lt;!--功能：&lt;body&gt;...&lt;/body&gt;是网页的主体部分，在此标记之间可以包含如&lt;p&gt;&lt;/p&gt;、&lt;h1&gt;&lt;/h1&gt;、&lt;br&gt;、&lt;hr&gt;等等标记，这些内容组成了我们所看见的网页--&gt;&lt;!--body的属性有：背景颜色 bgcolor="red",文本颜色text="green",链接颜色 link="blue"，--&gt;&lt;!-- 已访问过链接的颜色vlink="yellow",正在被点击连接的颜色 alink="red"--&gt;&lt;/body&gt;&lt;/html&gt; 格式标记12345678910&lt;br&gt; 强制换行，后面的内容会显示在下一行&lt;p&gt;...&lt;/p&gt; 段落标记&lt;center&gt;...&lt;/center&gt; 居中对齐标记：让段落或者是文字相对于父标记居中显示&lt;pre&gt;...&lt;/pre&gt; 预格式化标记：保留预先编排好的格式&lt;li&gt;第一个&lt;/li&gt; 列表项目,默认无序&lt;ul&gt;...&lt;/ul&gt; 声明无序列表，内嵌套&lt;li&gt;&lt;ol&gt;...&lt;/ol&gt; 声明列表有序内嵌套&lt;li&gt;,属性type=&quot;[1|A|a|I|i]&quot; value=&quot;序列起始值&quot;&lt;dl&gt; &lt;dt&gt; &lt;dd&gt; 定义性列表，对列表条目进行简短的说明&lt;hr&gt; 水平分割线&lt;div&gt;...&lt;/div&gt; 分区显示/层标记，可以多层嵌套，用来编排一大段HTML代码 文本标记12345678910111213&lt;h1&gt;...&lt;/h1&gt; h1~6 1级标题文本最大，6级标题文本最小&lt;font size=&apos;3&apos; color=&apos;green&apos; face=&quot;微软雅黑&quot;&gt;有字体格式的文字&lt;/font&gt;&lt;b&gt;粗体字&lt;/b&gt;&lt;i&gt;斜体字&lt;/i&gt;&lt;sub&gt;下标字体&lt;/sub&gt;&lt;sup&gt;上标字体&lt;/sup&gt;&lt;tt&gt;打印机字体&lt;/tt&gt;&lt;cite&gt;引用方式的字体，通常是斜体&lt;/cite&gt;&lt;em&gt;强调字体，通常是斜体&lt;/em&gt;&lt;strong&gt;强调字体，通常是粗体&lt;/strong&gt;&lt;small&gt;小型字体&lt;/small&gt;&lt;big&gt;大型字体&lt;/big&gt;&lt;u&gt;带下划线的字&lt;/u&gt; 图像标签123456789&lt;img src=&quot;路径/文件名.图片格式&quot; width=&quot;属性值&quot; height=&quot;属性值&quot; border=&quot;属性值&quot; alt=&quot;属性值&quot;&gt;属性： 作用src 指定加载文件的路径width 指定图片的宽度，单位px、em、cm、mmheight 指定图片的高度，单位px、em、cm、mmborder 指定图标的边框宽度，单位px、em、cm、mmalt 当网页上的图片被加载完成后，鼠标移动到上面去，会显示这个图片指定的属性文字 如果图像没有下载或者加载失败，会用文字来代替图像显示 搜索引擎可以通过这个属性的文字来抓取图片 超链接1234567891011&lt;a href=&quot;&quot; target=&quot;打开方式&quot; name=&quot;页面锚点名称&quot; &gt;链接文字或者图片&lt;/a&gt;href 链接的地址，可以是网页或视频、图片、音乐等等target 定义超链接的打开方式target取值 _blank:在一个新的窗口中打开链接 _seif(默认值):在当前窗口中打开链接 _parent:在父窗口中打开页面（框架中使用较多） _top:在顶层窗口中打开文件（框架中使用较多）name 指定页面的锚点名称使用a标签实现页内跳转&lt;a href=&quot;#id1&quot;&gt;点击后跳到本页id值为id1的tag位置&lt;/a&gt; HTML表格12345678910111213141516171819202122232425262728293031&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt;&lt;/head&gt;&lt;body&gt;&lt;div&gt;&lt;table width="80%" border="1" height="100" align="center"&gt; &lt;!-- width 和 height的值可以是px或父级的%值， border是表格外框的宽度，默认值是0； align是表格的显示位置，left默认，right，center--&gt; &lt;!-- cellspacing，单元格之间的间距，默认是2px；cellpadding 单元格内容与单元格边框的显示距离，单位像素 --&gt; &lt;!-- frame 控制表格边框最外层的四条线框；rules 控制是否显示以及如何显示单元格之间的分割线；--&gt; &lt;caption align="bottom"&gt;表格的标题&lt;/caption&gt; &lt;!--caption位于table之后，tr表格行之前,其align属性取值 top、bottom、left、right，指定标题的位置--&gt; &lt;tr&gt; &lt;!-- 对于每一个表格行，都是由一对&lt;tr&gt;...&lt;/tr&gt;标记表示，每一行&lt;tr&gt;标记内可以嵌套多个&lt;td&gt;或者&lt;th&gt;标记 --&gt; &lt;th&gt;班级&lt;/th&gt; &lt;!--td 和th标签，必须在tr内，th是表头的单元格标记，即表格的首行 --&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;th&gt;成绩&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;四年级一班&lt;/td&gt; &lt;!--td 表格的数据单元格标记--&gt; &lt;td&gt;张三&lt;/td&gt; &lt;td&gt;16&lt;/td&gt; &lt;td&gt;80&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; HTML表单 form表单 1234567891011121314151617181920212223242526&lt;div&gt; &lt;form action="." method="post" name="login"&gt; &lt;!--&lt;form action="服务器端地址（接受表单内容的地址）" name="表单名称" method="post|get"&gt;...&lt;/form&gt;--&gt; &lt;!--get方式提交时，会将表单的内容附加在URL地址的后面，所以限制了提交的内容的长度，不超过8192个字符，且不具备保密性--&gt; &lt;!--post方式提交时，将表单中的数据一并包含在表单主体中，一起传送到服务器中处理，没有数据大小限制--&gt; &lt;!-- action=表单数据的处理程序的URL地址,为空则使用当前文档的URL地址，如果不需要使用,action="no"--&gt; &lt;!-- enctype,设置表单的资料的编码方式; target,和超链接的属于类似，用来指定目标窗口--&gt; &lt;p&gt;用户名 &lt;input type="text" name="login_name" value="QQ or Email" maxlength="20" size="10"&gt;&lt;/p&gt; &lt;p&gt;密码 &lt;input type="password" name="login_passwd" value="" size="10"&gt;&lt;/p&gt; &lt;p&gt;性别：&lt;input type="radio" name="sex" checked="checked"&gt;男&lt;input type="radio" name="sex"&gt;女&lt;/p&gt; &lt;p&gt;&lt;input type="hidden" value="隐藏的内容" name="mihiddenma" size="10"&gt;&lt;/p&gt; &lt;p&gt;爱好：&lt;input type="checkbox" name="tiyu" checked="checked"&gt;体育&lt;input type="checkbox" name="changge"&gt;唱歌&lt;br&gt;&lt;/p&gt; &lt;p&gt;&lt;br&gt; 地址： &lt;select name="dizhi"&gt; &lt;option value="sichuan"&gt;四川&lt;/option&gt; &lt;option value="beijing"&gt;北京&lt;/option&gt; &lt;option value="shanghai"&gt;上海&lt;/option&gt; &lt;/select&gt; &lt;/p&gt; &lt;p&gt;自我介绍 &lt;br&gt; &lt;textarea cols="35" rows="10" name="自我介绍"&gt;介绍一下你自己呗！&lt;/textarea&gt; &lt;/p&gt; &lt;p&gt;&lt;input type="submit" value="提交注册"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="reset" value="重置"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="button" value="一个按钮"&gt;&lt;/p&gt; &lt;/form&gt;&lt;/div&gt; input标签 12345678910111、文本域/密码框： &lt;input type=&quot;text/password&quot; name=&quot;&quot; value=&quot;框内初始化值&quot; size=&quot;框长&quot; maxlength=&quot;最大字符数&quot;&gt;2、提交，重置和普通按钮 &lt;input type=&quot;submit/reser/button&quot;&gt;3、单选框和复选框 &lt;input type=&quot;radio/checkbox&quot; checked=&quot;checked&quot;&gt; checked=&quot;checked&quot; 会默认该项被选中4、隐藏域 &lt;input type=&quot;hidden&quot; value=&quot;&quot; name=&quot;&quot;&gt; 一般用来提交验证信息5 多行文本 &lt;textarea name=&quot;name&quot; rows=&quot;value&quot; cols=&quot;value&quot; value=&quot;value&quot;&gt; ... ... &lt;/textarea&gt; rows和 cols指定行数和列数6、下拉菜单&lt;select name=&quot;&quot; size=&quot;列表高度&quot; multiple&gt; ### 如果使用mutiple关键字，则是一个下拉列表，不使用时是下拉框 &lt;option value=&quot;value&quot; selected&gt;选项1&lt;/option&gt; ### 指定了selected关键字是默认选中项，value的值是要发送给服务器上的数据 &lt;option value=&quot;value&quot;&gt;选项2&lt;/option&gt; &lt;option value=&quot;value&quot;&gt;选项3&lt;/option&gt;&lt;/select&gt;]]></content>
      <categories>
        <category>技术</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>Html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mongodb 学习笔记]]></title>
    <url>%2F2016%2F12%2F01%2F%E6%8A%80%E6%9C%AF%2FMongodb%20%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[ubuntu安装 mongodb32位的mongodb的数据库只能保存2G数据，32bit内存最大寻址长度。所以要用64位系统和mongodb。 apt-get install mongodb 安装好之后，服务自动运行，service mongodb stop停止服务，找到数据库存储位置/var/lib/mongodb/和日志文件位置/var/log/mongodb/mongodb.log,然后手动运行服务mongod --dbpath /var/lib/mongodb/ --logpath /var/log/mongodb/mongodb.log --logappend &amp; 如果想作为服务一直运行 修改/etc/mongodb.conf参数，允许远程登录和身份认证， 123456789101112131415161718192021# mongodb.conf# Where to store the data.dbpath=/var/lib/mongodb#where to loglogpath=/var/log/mongodb/mongodb.loglogappend=true# 允许远程注释掉此处bind_ip = 127.0.0.1# 修改端口在此处port = 27017# Enable journaling, http://www.mongodb.org/display/DOCS/Journalingjournal=true# 默认是关闭认证的，开启账号密码认证改此处# Turn on/off security. Off is currently the default#noauth = trueauth = true# Verbose logging output.verbose = true 然后运行服务service mongodb restart，本地连接mongodb后，给某个数据库添加用户，然后重启service。给admin添加的用户有数据库管理员权限。 admin里可以保存其他数据库的用户，普通数据库里只能保存自己的用户。 在哪个数据库下保存的用户，认证时要连接相应的数据库 123456789101112131415161718192021222324252627282930313233343536MongoDB shell version: 2.4.9connecting to: test&gt; show dbsadmin (empty)local 0.078125GB&gt; use adminswitched to db admin&gt; db.addUser('mongo','mongo123')&#123; "user" : "mongo", "readOnly" : false, "pwd" : "6a524e081c761e95c4d0b0096840d87c", "_id" : ObjectId("591078d7a129373b2f059bb3")&#125;# createUserdb.createUser( &#123; user:"DBadmin", pwd:"secret", roles:[&#123;role:"root",db:"admin"&#125;] # 超级管理员，admin数据库 &#125; )db.createUser( &#123; user:"kickstart", pwd:"kickstart", roles:[&#123;role:"read",db:"kickstart"&#125;] # 只读，kickstart数据库 &#125; ) db.createUser( &#123; user:"kickwrite", pwd:"kickstart", roles:[&#123;role:"readWrite",db:"kickstart"&#125;] # 读写权限，kickstart数据库 &#125; ) 连接mongodb 指定数据库及身份信息 mongo ip/dbname -u username -p password 先连接，后认证 123mongo use dbnamedb.auth('username', 'password') URI MONGO_URI = &#39;mongodb://localhost:27017&#39; MONGO_URI = &#39;mongodb://user:pass@localhost:27017&#39; mongodb基本命令12345678910111213141516171819&gt; help db.help() help on db methods db.mycoll.help() help on collection methods rs.help() help on replica set methods help connect connecting to a db help help admin administrative help help misc misc things to know help mr mapreduce help show dbs show database names show collections show collections in current database show users show users in current database show profile show most recent system.profile entries with time &gt;= 1ms use &lt;db_name&gt; set current database db.foo.find() list objects in collection foo db.foo.find( &#123; a : 1 &#125; ) list objects in foo where a == 1 it result of the last line evaluated; use to further iterate DBQuery.shellBatchSize = x set default number of items to display on shell exit quit the mongo shell 基本命令 db.help() 查看当前db的可用命令 db.mycoll.help() 查看集合的可用命令 show dbs 显示当前数据库服务器上的数据库 use xxx 切换到指定数据库xxx的上下文，可以在此上下文中管理xxx数据库以及其中的集合等 show collections 显示数据库中所有的集合（collection） db.serverStatus() 查看数据库的状态，如 version， mem， uptime db.stats() 查询指定数据库统计信息 db.getCollectionNames() 查询指定数据库包含的集合名称列表 基本数据操作 use new_db 切换上下文的过程后，插入一条数据时会自动创建新数据库 db.dropDatabase() 删除指定的数据库 db.createCollection(‘Colletion_name’, {‘capped’:true, ‘size’:10240, ‘max’:17855200}) 创建集合 db.mycoll.drop() 删除集合 db.mycoll.save({‘version’:’3.5’, ‘segment’:’e3ol6’}) 插入、更新记录 findOne() 查询满足条件的一条记录， find() 满足条件的所有记录，find().count()统计结果 db.mycoll.remove({‘version’:’3.5’}) 删除满足条件的所有记录 db.mycoll.ensureIndex(keypattern[,options]) 创建索引 db.system.indexes.find() 查询数据库中所有索引 db.mycoll.getIndexes() 查看集合上的所有索引 删除索引 db.mycoll.dropIndex(name)db.mycoll.dropIndexes() 索引重建 db.mycoll.reIndex() 查询存储空间 db.mycoll.storageSize() 集合可用存储空间， db.baseSe.totalSize() 集合已分配的存储空间 启动和停止mongod --auth --dbpath /usr/mongo/data --logfile /var/mongo.log 启动 mongod -f /etc/mongodb.conf --repair 以修复模式启动 db.shutdownServer() 停止数据库，或者kill掉mongod进程 锁操作加写数据锁，一般在执行数据库备份时使用，不允许写数据操作。 db.runCommand({fsync:1,lock:1}) 查看当前的锁状态 db.currentOp() 解锁 db.$cmd.sys.unlock.findOne() mongodb用户与权限mongodb 的权限: 数据库用户角色：read、readWrite; 数据库管理角色：dbAdmin、dbOwner、userAdmin； 集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManager； 备份恢复角色：backup、restore； 所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、dbAdminAnyDatabase 超级用户角色：root // 这里还有几个角色间接或直接提供了系统超级用户的访问（dbOwner 、userAdmin、userAdminAnyDatabase） 内部角色：__system12345678 read:允许用户读取指定数据库readWrite:允许用户读写指定数据库dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profileuserAdmin：允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户clusterAdmin：只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。root：只在admin数据库中可用。超级账号，超级权限 mongodb 使用技巧findfind({条件}, {指定Field}).skip(n).limit(m) 查询满足条件的记录，跳过n条，总共取m条，只取指定Field数据。 db.getCollection(&#39;finished&#39;).find({}, {&#39;_id&#39;: 0, &#39;name&#39;:1}, limits=2, skip=2) 查询key的值是否非空 db.mycollection.find({&quot;pic_url&quot;:{$ne:null}}); 查询key是否存在 db.course.find( { &quot;lectures.lectures_count&quot;: { $exists: true } } ) 查询某个key的值 db.mycollection.find({&quot;IMAGE URL&quot;:{$ne:&#39;&#39;}}); 数值比较，in查询， all多值匹配 1234567891011db.collection.find(&#123; "field" : &#123; $gt: value &#125; &#125; ); // greater than : field &gt; valuedb.collection.find(&#123; "field" : &#123; $lt: value &#125; &#125; ); // less than : field &lt; valuedb.collection.find(&#123; "field" : &#123; $gte: value &#125; &#125; ); // greater than or equal to : field &gt;= valuedb.collection.find(&#123; "field" : &#123; $lte: value &#125; &#125; ); // less than or equal to : field &lt;= valuedb.collection.find(&#123; "field" : &#123; $gt: value1, $lt: value2 &#125; &#125; ); // value1 &lt; field &lt; valuedb.things.find( &#123; 'field' : &#123; $ne : 3 &#125; &#125; );# indb.things.find(&#123;j:&#123;$in: [2,4,6]&#125;&#125;);db.things.find(&#123;j:&#123;$nin: [2,4,6]&#125;&#125;);# alldb.things.find( &#123; a: &#123; $all: [ 2, 3 ] &#125; &#125; ); // 可以匹配到&#123; a: [ 1, 2, 3 ] &#125; 数组长度 $size 嵌套对象查询 db.postings.find( { &quot;author.name&quot; : &quot;joe&quot; } ) 对于记录{&quot;author&quot; : {&quot;name&quot; : &quot;Jane&quot;, &quot;id&quot; : 1}} 这种查询会失败db.blog.findOne({&quot;author&quot; : {&quot;name&quot; : &quot;Jane&quot;}}), 因为{&quot;name&quot; : &quot;Jane&quot;}是key的value，必须精确匹配。 内嵌文档的完全匹配查询和数组的完全匹配查询一样，内嵌文档内键值对的数量，顺序都必须一致才会匹配: update如果不存在则创建，upsert操作。 db.xxx.update({条件}，{操作}，upsert=true) 集合重命名db.runCommand( { renameCollection: &quot;kickstart.project_name&quot;, to: &quot;kickstart.project_data&quot; }) 集合建立索引测试集合内有35万条记录，没建立索引前执行500次查询约耗时5分钟。在id字段建立索引后，执行124371次查找，耗时不到1分钟。 db.test.ensureIndex({&quot;userid&quot;:1},{&quot;unique&quot;:true}) 唯一索引，如果有重复的会报错 db.test.ensureIndex({&quot;id&quot;:1},{&quot;unique&quot;:true,&quot;dropDups&quot;:true}) 唯一索引，删除重复记录 db.test.reIndex() 重建索引 数据备份和恢复mongoexport -h：数据库宿主机IP -u：数据库用户名 -p：数据库密码 -d：数据库名字 -c：集合名字 -f：指明列 –csv 导出csv格式，默认导出json格式 mongoexport -h IP --port 端口 -u 用户名 -p 密码 -d 数据库 -c 表名 -f 字段1，字段2 -q ‘{条件导出}’ -o data.json mongoimportmongoimport -d kickstart -c finished finish.json mongodumpmongodump --host mongodb1.example.net --port 37017 --username user --password &quot;pass&quot; --out /opt/backup/mongodump-2011-10-24 mongorestoremongorestore -h 182.254.229.194 -u kickwrite -p &quot;kickstart&quot; -d kickstart -c project_data --authenticationDatabase admin mongodump-2018-01-12/newkick/project_data.bson 1.65GB数据恢复到腾讯云上用了10分钟左右，1C1G1M低配云。 db.copyDatabase这个方法必须要在要写入的mongod上登陆，并且有写入权限，数据源必须要有公网IP。 比如从腾讯云(有公网ip)上复制数据库到本地电脑（局域网），则在本地登陆mongo client，执行copyDatabase。 参考官方文档 pymongo使用技巧 建立连接 增删改查，参考集合操作 错误解决内存不足，重启失败12345var/lib/mongodb/kickstart.4 open/create failed in createPrivateMap (look in log for more information)warning database /var/lib/mongodb kickstart could not be opened2018-01-11T20:29:57.778+0800 [initandlisten] DBException 13636: file /var/lib/mongodb/kickstart.4 open/create failed in createPrivateMap (look in log for more information)2018-01-11T20:29:57.778+0800 [initandlisten] exception in initAndListen: 13636 file /var/lib/mongodb/kickstart.4 open/create failed in createPrivateMap (look in log for more information), terminating2018-01-11T20:29:57.778+0800 [initandlisten] dbexit: 原因： 32位mongodb写满了2G数据，重启数据库后，发现启动失败，我还开启了journal功能。 解决： 我没敢删除数据库里的其他文件，值把数据库data文件复制出来， 然后 mongodb --dbpath /path/to/newdir --auth=true mmap failed with out of memory64位系统下，可能是虚拟内存不足导致的 取消虚拟内存限制的方法：修改etc/profile文件，在文件最后加入一行 ulimit -v unlimited 然后# source /etc/profile，使配置生效。]]></content>
      <categories>
        <category>技术</category>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>Mongodb</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python cookbook 笔记1]]></title>
    <url>%2F2016%2F11%2F16%2F%E6%8A%80%E6%9C%AF%2FPython-cookbook-note1%2F</url>
    <content type="text"><![CDATA[数据结构和算法 多变量同时赋值 12345678910111213141516171819202122# 左右两边必须数目一致，右边为列表或任意可迭代对象l = [&apos;a&apos;, 1, 345]a, b, c = lprint(a, b, c)a, b, c = &apos;qwe&apos;print(a, b, c)# 变量数小于赋值数，使用*args表达式a, *others1 = l*others2, b = lprint(a, b, others1, others2) #others是列表类型# 处理字符串分割时，或变长元组的序列时，使用*args变量来占位，很方便line = &apos;nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false&apos;uname, *fields, homedir, sh = line.split(&apos;:&apos;)records = [(&apos;foo&apos;, 1, 2),(&apos;bar&apos;, &apos;hello&apos;),(&apos;foo&apos;, 3, 4),(&apos;a&apos;, 4, 5, 6),]for tag, *args in records:if tag == &apos;foo&apos;: 保存一个迭代对象的最后N个元素使用大小为N的队列实现，队列 123456from collections import dequeq = deque(maxlen=3)q.append(1)q.appendleft(0)q.pop()q.popleft() 获得最大或最小的N个元素 123456789101112131415161718heapq模块有两个函数：nlargest()和nsmallest()可以完美解决这个问题。import heapqnums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]print(heapq.nlargest(3, nums)) # Prints [42, 37, 23]print(heapq.nsmallest(3, nums)) # Prints [-4, 1, 2]两个函数都能接受一个关键字参数，用于更复杂的数据结构中：portfolio = [&#123;&apos;name&apos;: &apos;IBM&apos;, &apos;shares&apos;: 100, &apos;price&apos;: 91.1&#125;,&#123;&apos;name&apos;: &apos;AAPL&apos;, &apos;shares&apos;: 50, &apos;price&apos;: 543.22&#125;,&#123;&apos;name&apos;: &apos;FB&apos;, &apos;shares&apos;: 200, &apos;price&apos;: 21.09&#125;,&#123;&apos;name&apos;: &apos;HPQ&apos;, &apos;shares&apos;: 35, &apos;price&apos;: 31.75&#125;,&#123;&apos;name&apos;: &apos;YHOO&apos;, &apos;shares&apos;: 45, &apos;price&apos;: 16.35&#125;,&#123;&apos;name&apos;: &apos;ACME&apos;, &apos;shares&apos;: 75, &apos;price&apos;: 115.65&#125;]cheap = heapq.nsmallest(3, portfolio, key=lambda s: s[&apos;price&apos;])expensive = heapq.nlargest(3, portfolio, key=lambda s: s[&apos;price&apos;])译者注：上面代码在对每个元素进行对比的时候，会以price的值进行比较。heapq.heapify(nums) //生成堆 字典一个键映射多个值将字典对应的多个值放到列表或集合里,集合元素是无序且不重复的 123456789from collections import defaultdictd = defaultdict(list)d[&apos;a&apos;].append(1)d[&apos;a&apos;].append(2)d[&apos;b&apos;].append(4)d = defaultdict(set)d[&apos;a&apos;].add(1)d[&apos;a&apos;].add(2)d[&apos;b&apos;].add(4) 有序字典在迭代或序列化时，希望字典是有序的，有序dict是普通dict内存的2倍 123456789101112131415from collections import OrderedDictdef ordered_dict():d = OrderedDict()d[&apos;foo&apos;] = 1d[&apos;bar&apos;] = 2d[&apos;spam&apos;] = 3d[&apos;grok&apos;] = 4# Outputs &quot;foo 1&quot;, &quot;bar 2&quot;, &quot;spam 3&quot;, &quot;grok 4&quot;for key in d:print(key, d[key])# 输出有序的json编码&gt;&gt;&gt; import json&gt;&gt;&gt; json.dumps(d)&apos;&#123;&quot;foo&quot;: 1, &quot;bar&quot;: 2, &quot;spam&quot;: 3, &quot;grok&quot;: 4&#125;&apos;&gt;&gt;&gt; 字典运算查找最大值和最小值，zip函数，将dict的值和value转置，直接使用max，min处理dict，计算的值是dict的key，得到的结果也是key。也可以配合sort 1234567891011121314151617181920prices = &#123;&apos;ACME&apos;: 45.23,&apos;AAPL&apos;: 612.78,&apos;IBM&apos;: 205.55,&apos;HPQ&apos;: 37.20,&apos;FB&apos;: 10.75, &apos;qw&apos;: 10.75&#125;b = zip(prices.values(), prices.keys())for i in b: print(i)//b是一个只能迭代一次的对象(205.55, &apos;IBM&apos;)(10.75, &apos;qw&apos;)(10.75, &apos;FB&apos;)(45.23, &apos;ACME&apos;)(612.78, &apos;AAPL&apos;)(37.2, &apos;HPQ&apos;)b = zip(prices.values(), prices.keys())print(min(b)) //如果有多个相同值的key存在，会再根据key的大小返回结果(10.75, &apos;FB&apos;) 寻找2个字典的相同之处 集合操作，&amp; - + 12345678910111213141516171819202122a = &#123;&apos;x&apos; : 1,&apos;y&apos; : 2,&apos;z&apos; : 3&#125;b = &#123;&apos;w&apos; : 10,&apos;x&apos; : 11,&apos;y&apos; : 2&#125;print(a.keys() &amp; b.keys())&#123;&apos;y&apos;, &apos;x&apos;&#125;print(a.items() &amp; b.items())&#123;(&apos;y&apos;, 2)&#125;print(a.items() - b.items())&#123;(&apos;z&apos;, 3), (&apos;x&apos;, 1)&#125;print(a.items() | b.items())&#123;(&apos;y&apos;, 2), (&apos;w&apos;, 10), (&apos;z&apos;, 3), (&apos;x&apos;, 11), (&apos;x&apos;, 1)&#125;# dict.values()不支持集合操作，因为不能保证值无重复，可以先转为set。# 排除字典里某些元素，构建新的字典c = &#123;key:a[key] for key in a.keys() - &#123;&apos;z&apos;, &apos;w&apos;&#125;&#125; 保持序列原有的序列顺序，同时删除重复的值 12345678910111213# 利用集合或者生成器，直接使用set会打乱原有顺序def dedupe(items): seen = set() for item in items: if item not in seen: yield item seen.add(item)a = [1, 5, 2, 1, 9, 1, 5, 10]print(list(deque(a)))# 用来去除文件里重复的行也可以with open(&apos;a.txt&apos;) as f: for line in deque(f): print(line) 命名切片 使用可读的变量名定义slice对象，增加代码可维护可读性 12345record = &apos;....................100 .......513.25 ..........&apos;# s.start, s.stop, s.step 分片对象属性，s.indices(len(record)),根据record长度重新映射分片的边界PRICE = slice(31,37)NUMBERS = slice(20,23)cost = int(record[NUMBERS]) * float(record[PRICE]) 统计序列中元素出现的次数 常规方法我们会用字典计数实现，key保存元素，value用来计数，count[&#39;s&#39;] += 1 。collections.Counter类更方便，还有most_common方法,更重要的是两个counter对象实例可以进行数学运算+，- 1234567891011121314words = [&apos;look&apos;, &apos;into&apos;, &apos;my&apos;, &apos;eyes&apos;, &apos;look&apos;, &apos;into&apos;, &apos;my&apos;, &apos;eyes&apos;,&apos;the&apos;, &apos;eyes&apos;, &apos;the&apos;, &apos;eyes&apos;, &apos;the&apos;, &apos;eyes&apos;, &apos;not&apos;, &apos;around&apos;, &apos;the&apos;,&apos;eyes&apos;, &quot;don&apos;t&quot;, &apos;look&apos;, &apos;around&apos;, &apos;the&apos;, &apos;eyes&apos;, &apos;look&apos;, &apos;into&apos;,&apos;my&apos;, &apos;eyes&apos;, &quot;you&apos;re&quot;, &apos;under&apos;]from collections import Counterword_counts = Counter(words)# 出现频率最高的3 个单词top_three = word_counts.most_common(3)print(top_three)# Outputs [(&apos;eyes&apos;, 8), (&apos;the&apos;, 5), (&apos;look&apos;, 4)]print(word_counts)Counter(&#123;&apos;eyes&apos;: 8, &apos;the&apos;: 5, &apos;look&apos;: 4, &apos;my&apos;: 3, &apos;into&apos;: 3, &apos;around&apos;: 2, &quot;don&apos;t&quot;: 1, &apos;not&apos;: 1, &apos;under&apos;: 1, &quot;you&apos;re&quot;: 1&#125;) 通过某几个字典关键字段排序字典列表 operator的itemgetter，支持多个key 123456789from operator import itemgetterrows_by_uid = sorted(rows, key=itemgetter(&apos;uid&apos;))# output[&#123;&apos;uid&apos;: 1001, &apos;lname&apos;: &apos;Cleese&apos;, &apos;fname&apos;: &apos;John&apos;&#125;, &#123;&apos;uid&apos;: 1002, &apos;lname&apos;: &apos;Beazley&apos;, &apos;fname&apos;: &apos;David&apos;&#125;, &#123;&apos;uid&apos;: 1003, &apos;lname&apos;: &apos;Jones&apos;, &apos;fname&apos;: &apos;Brian&apos;&#125;, &#123;&apos;uid&apos;: 1004, &apos;lname&apos;: &apos;Jones&apos;, &apos;fname&apos;: &apos;Big&apos;&#125;]rows_by_lfname = sorted(rows, key=itemgetter(&apos;lname&apos;,&apos;fname&apos;))# itemgetter()有时候也可以用lambda表达式代替，lambda比较慢，比如：rows_by_fname = sorted(rows, key=lambda r: r[&apos;fname&apos;])rows_by_lfname = sorted(rows, key=lambda r: (r[&apos;lname&apos;],r[&apos;fname&apos;]))# itemgetter同样适用于min、max的key关键字参数 排序不支持比较的对象 sorted方法的key参数接收一个callable对象，该对象作用于每个排序的个体，根据其返回的值作为排序比较的依据，同理max，min函数。加入比较的是一类对象，key的接收函数可以定义为lambda函数，也可以使用operator.attrgetter(‘user_id’） 12345sorted(users, key=lambda u: u.user_id) ### 二者均可，但是attrgetter运行速度更快，而且支持多个变量&gt;&gt;&gt; from operator import attrgetter&gt;&gt;&gt; sorted(users, key=attrgetter(&apos;user_id&apos;))[User(3), User(23), User(99)] 根据某个字段将数据分组 先将数据排序，然后使用itertools.groupby(&#39;key_field&#39;)，或者使用 collections.defaultdict（list）, dict_a[row[&#39;key_field&#39;]].append(row) 1234567891011121314151617181920212223242526272829303132from operator import itemgetterfrom itertools import groupbyrows = [&#123;&apos;address&apos;: &apos;5412 N CLARK&apos;, &apos;date&apos;: &apos;07/01/2012&apos;&#125;,&#123;&apos;address&apos;: &apos;5148 N CLARK&apos;, &apos;date&apos;: &apos;07/04/2012&apos;&#125;,&#123;&apos;address&apos;: &apos;5800 E 58TH&apos;, &apos;date&apos;: &apos;07/02/2012&apos;&#125;,&#123;&apos;address&apos;: &apos;2122 N CLARK&apos;, &apos;date&apos;: &apos;07/03/2012&apos;&#125;,&#123;&apos;address&apos;: &apos;5645 N RAVENSWOOD&apos;, &apos;date&apos;: &apos;07/02/2012&apos;&#125;,&#123;&apos;address&apos;: &apos;1060 W ADDISON&apos;, &apos;date&apos;: &apos;07/02/2012&apos;&#125;,&#123;&apos;address&apos;: &apos;4801 N BROADWAY&apos;, &apos;date&apos;: &apos;07/01/2012&apos;&#125;,]l = groupby(rows, key=itemgetter(&apos;date&apos;)) //l值能被迭代一次for i, j in l: print(i) for z in j: print(z)# 输出结果07/01/2012&#123;&apos;date&apos;: &apos;07/01/2012&apos;, &apos;address&apos;: &apos;5412 N CLARK&apos;&#125;&#123;&apos;date&apos;: &apos;07/01/2012&apos;, &apos;address&apos;: &apos;4801 N BROADWAY&apos;&#125;07/02/2012&#123;&apos;date&apos;: &apos;07/02/2012&apos;, &apos;address&apos;: &apos;5800 E 58TH&apos;&#125;&#123;&apos;date&apos;: &apos;07/02/2012&apos;, &apos;address&apos;: &apos;5645 N RAVENSWOOD&apos;&#125;&#123;&apos;date&apos;: &apos;07/02/2012&apos;, &apos;address&apos;: &apos;1060 W ADDISON&apos;&#125;07/03/2012&#123;&apos;date&apos;: &apos;07/03/2012&apos;, &apos;address&apos;: &apos;2122 N CLARK&apos;&#125;07/04/2012&#123;&apos;date&apos;: &apos;07/04/2012&apos;, &apos;address&apos;: &apos;5148 N CLARK&apos;&#125;### 使用defaultdictfrom collections import defaultdictrows_by_date = defaultdict(list)for row in rows: rows_by_date[row[&apos;date&apos;]].append(row) 过滤序列元素 最简单的方法，当过滤规则简单时，使用列表推导式或生成器表达式；当过滤规则负责时，编写一个过滤规则函数(对每个元素返回True或False)，然后使用内建的filter()函数，filter(func, list_a)得到的是生成器，想要得到列表，可以使用list()函数。 1234567891011121314151617mylist = [1, 4, -5, 10, -7, 2, 3, -1]l = [n for n in mylist if n &gt; 0]# 上述的列表推导式会占用大量的内存，使用生成器表达式迭代产生要过滤的元素pos = (n for n in mylist if n &gt; 0)for i in pos: print(i)def is_int(i): try: x = int(i) return True except ValueError: return Falsel = list(filter(is_int, &apos;123wertsdfg&apos;))print(l)# 输出 [&apos;1&apos;, &apos;2&apos;, &apos;3&apos;] 使用列表推导式，可以同时转换(处理)符合条件的数据；也可以替换(处理)不符合条件的结果，而不是直接丢弃。 123import mathl1 = [math.sqrt(n) for n in mylist if n &gt; 0]l2 = [n if n &gt; 0 else 0 for n in mylist] 另外一个值得关注的过滤工具就是itertools.compress()，它以一个iterable对象和一个相对应的Boolean选择器序列作为输入参数。然后输出iterable对象中对应选择器为True的元素,是个生成器。当你需要用另外一个相关联的序列来过滤某个序列的时候，这个函数是非常有用的. 12345678910# 关键点在于先创建一个Boolean序列，指示哪些元素复合条件。然后compress()函数根据这个序列去选择输出对应位置为True的元素。from itertools import compresss = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;]count = [99, 20, 16, 71, 56]big50 = [n &gt; 50 for n in count]l = list(compress(s, big50))print(l)# 输出 [&apos;a&apos;, &apos;d&apos;, &apos;e&apos;] 从字典中提取子集 首先考虑字典推导,dict()函数传入元组的推导式也可以实现，但比字典推到速度慢1倍： 1234567891011121314prices = &#123;&apos;ACME&apos;: 45.23,&apos;AAPL&apos;: 612.78,&apos;IBM&apos;: 205.55,&apos;HPQ&apos;: 37.20,&apos;FB&apos;: 10.75&#125;# Make a dictionary of all prices over 200p1 = &#123;key: value for key, value in prices.items() if value &gt; 200&#125;# Make a dictionary of tech stockstech_names = &#123;&apos;AAPL&apos;, &apos;IBM&apos;, &apos;HPQ&apos;, &apos;MSFT&apos;&#125;p2 = &#123;key: value for key, value in prices.items() if key in tech_names&#125;# dict()方式慢p1 = dict((key, value) for key, value in prices.items() if value &gt; 200) 映射名称到序列， 命名元组替代不可读的下标，或作为有大量字典元素的替代，节省空间，但命名元组的元素是不可修改的，（可以_replace()方法更新，如果需要大量更新，则不适合使用nametuple） 12345678910111213141516171819202122232425from collections import namedtuplenamedtuple(typename,field_names,verbose=False,rename=False)# 返回一个类，但该类支持元组操作，是元组类的一个子类Subscriber = namedtuple(&apos;Subscriber&apos;, [&apos;addr&apos;, &apos;joined&apos;])sub = Subscriber(&apos;jonesy@example.com&apos;, &apos;2012-10-19&apos;)print(sub.addr, sub.joined)a, b = sublen(sub)# 使用命名元组增加可读性的一个例子from collections import namedtupleStock = namedtuple(&apos;Stock&apos;, [&apos;name&apos;, &apos;shares&apos;, &apos;price&apos;])def compute_cost(records): //records [[price, nums],] total = 0.0 for rec in records: s = Stock(*rec) total += s.shares * s.price return total## 如果非要改变命名元组的属性，可以使用_replace()方法。该方法常用于填充数据，返回一个新的元组实例# 比如我们命名了一个具有缺省值的默认元组，用该方法创建实例stock_prototype = Stock(&apos;&apos;, 0, 0.0, None, None)def dict_to_stock(s): return stock_prototype._replace(**s) 转换并同时处理数据 处理函数与生成器参数结合 123456s = sum(x*x for x in nums)import os if any(name.endswith(&apos;.py&apos;) for name in os.listdir(&apos;.&apos;)): print(1)s = (&apos;ACME&apos;, 50, 123.45)print(&apos;,&apos;.join(str(x) for x in s)) 合并多个字典或映射使用collections.ChainMap()或dict的update方法，update会改变原有的字典结构，或创建新的字典对象，（当原字典更新时，update无法反应这种改变） 12345678910a = &#123;&apos;x&apos;: 1, &apos;z&apos;: 3 &#125;b = &#123;&apos;y&apos;: 2, &apos;z&apos;: 4 &#125;# 现在假设你必须在两个字典中执行查找操作(比如先从a中找，如果找不到再在b中找)from collections import ChainMapc = ChainMap(a,b) //字典的列表容器，仍支持大部分字典的方法print(c[&apos;x&apos;]) # (from a)print(c[&apos;y&apos;]) # (from b)print(c[&apos;z&apos;]) # (from a)，永远只输出第一个匹配字典的结果# 对于字典的更新或删除操作总是影响的是列表中第一个字典。del c[&apos;z&apos;] 字符串和文本日期和时间迭代器和生成器文件和IO数据编码和处理函数类和对象元编程模块和包网络和web编程并发编程脚本和系统管理异常、调试、测试]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix部署]]></title>
    <url>%2F2016%2F10%2F30%2F%E6%8A%80%E6%9C%AF%2FZabbix%2F</url>
    <content type="text"><![CDATA[zabbix appliance 部署 登陆 appliance：zabbix 修改中文支持修改你的 locales . inc . php 这个文件，/usr/share/zabbix/include/ 下‘zhCN’ =&gt; [‘name’ =&gt; (‘Chinese (zh_CN)’), ‘display’ =&gt; true], #也就是把false改为true，在web页面点击用户信息头像，选择语言。 解决图形字体乱码修改你的defines.inc.php 这个文件 1234#修改第93行define(&apos;ZBX_FONT_NAME&apos;, &apos;msyh&apos;); #修改第45行改为 define(&apos;ZBX_GRAPH_FONT_NAME&apos;, &apos;msyh&apos;) 然后下载微软雅黑字体，传入zabbix/fonts下，架设服务器，python -m SimpleHTTPServer 8080 配置snmp server]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[魅蓝3s移动版刷机+修改串号]]></title>
    <url>%2F2016%2F10%2F24%2F%E6%8A%98%E8%85%BE%2F2016-10-24-meizu-mobile-meilan3s-imei-change%2F</url>
    <content type="text"><![CDATA[最近魅蓝3s移动版，但是移动定制版，开机logo，系统软件，功能限制，网络限制，很恶心，果断刷机。 刷机教程刷机教程魅族论坛有。 移动定制版的系统recovery会验证固件，因此直接刷全网通版的固件会提示固件损坏，无法写入固件。 使用flashfire刷入全网通的update.zip， 首先获取root权限，安装superSU，并重启。 然后flashfire写入，等待系统自动重启。这时的系统并不是clean的，会有各种问题，相当于只是从移动版升级到全网通，绕过系统的rom检测。 开机后，使用系统自带的recovery再刷一次全网通的固件，刷时选择清除数据。这是最后一步，然后就是全网通版的魅蓝3s啦。如果还是有相机图库无法使用的情况，恢复出厂设置，或再刷一次全网通固件，记得选清除数据。 修改串号 在拔号按##3646633##–&gt; 进入connectivity 选 cds information –&gt; radioinformation 选 phone1(SIM1) 在command (有A+的位置)列按入”AT +EGMR = 1,7,”你的IMEI””(在输入sim2时改为”AT +EGMR = 1,10, “你的IMEI”) 按 “SEND ATCOMMAND” 完成后重启手机 注意：步骤4中AT和+加个空格（AT +EGMR=1,7,””像这样，+号前加个空格） 这个不用root 我试过可以改魅族note2 以下是网上找到的参考 系统必须降价到Flyme 4.5，因为Flyme5.1工程模式(拨号界面输入*#*#3646633#*#*)没有cds information 选项，无法进行下一步操作； 选 cds information --&gt; radioinformation之后，选择phone1(SIM1) or phone2(SIM2)时候，最好把2个都搞一下，因为我才开始选择phone1(SIM1)，但是输入*#06#后，还是原来的串号，但是工程模式下却是我要修改的串号，但是再改phone2(SIM2)时候，两个就一样了； 在输入AT + EGMR = 1,7,”你的IMEI”这一串代码时候，请注意，把原来的AT+删掉，直接输入这一串代码-----AT + EGMR = 1,7,&quot;你的IMEI&quot;（AT和+之间有空格，一定要有）； 改完之后英文显示ok，要重启，然后再看是不是已经改成功了 用工具侠或者移动叔叔 应该也是要在Flyme4.5下进行，昨天我是在Flyme5.1下弄的，始终不行 使用工具侠查看iemi，更改成功。]]></content>
      <categories>
        <category>折腾</category>
        <category>手机</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Git服务器]]></title>
    <url>%2F2016%2F09%2F22%2F%E6%8A%80%E6%9C%AF%2FGit-server-on-centos%2F</url>
    <content type="text"><![CDATA[cent os 搭建git server + gitolite 爬了很久的坑，终于爬出来了，真累。说说走的弯路，最初打算配置gitlab（有和github一样漂亮的web界面），然后下源码编译，失败。后来发现gitlab有中文站，提供二进制包，可能是centos32位的原因，为了少浪费生命，果断放弃，转而采用git-core + gitolite。后来，git服务器搭好了，但是没人用，实验室还是在用SVN。估计是迁移和学习成本吧，不愿意改变。 1、安装git1.1、创建git用户12345678# yum update# yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-devel# mkdir -p /home/git //创建git用户的目录# groupadd git //创建git用户组# useradd -g git -d /home/git -s /bin/bash git // 添加linux用户git# passwd git //设置git用户密码# passwd -d git //在所有工作完成后禁用git用户的密码，这样git无法ssh远程登录主机 1.2、更改git目录权限12# chown -R git:git /home/git# chmod -R 2755 /home/git 1.3、源码安装git先从官网 http://git-scm.com/download 上下载 git源码，然后解压，tar -zxvf git-xxx.xxx.tar.gz 1234567891011121314系统默认版本为1.8.3，版本太老，删除并通过源代码安装删除安装的gityum -y remove git安装git依赖包$ sudo yum install curl-devel expat-devel gettext-devel openssl-devel perl-devel zlib-devel下载源码并编译安装 mkdir /tmp/git &amp;&amp; cd /tmp/git curl --progress https://www.kernel.org/pub/software/scm/git/git-2.8.2.tar.gz | tar xz cd git-2.8.2/ ./configure make make prefix=/usr/local install为确保$PATH环境变量生效，需要重新连接后执行git --versionctrl + d 关闭ssh会话，然后重新ssh登录。 2、安装gitolite 参照官方的quick install，只需3行命令 12345678910111213# su – git //切换到git用户下安装$ pwd /home/git$ mkdir bin// 获取源码$ git clone https://github.com/sitaramc/gitolite.git或者git clone git://github.com/ossxp-com/gitolite.git $ ls bin gitolite// 安装$ ./gitolite/install --to /home/git/bin/$ ls bin/commands gitolite gitolite-shell lib syntactic-sugar triggers VERSION VREF 3、配置gitolite管理员首先生成rsa key,然后用管理员的public key初始化gitolite 1234567891011121314// Windows安装git for windows2.6.2，安装完后打开Git Bash$ ssh-keygen –f admin –C 20151030@qq.com$ scp admin.pub git@serverIP:/tmp/admin.pub// 切换到git用户，为gitolite配置管理员$ su - git$ bin/gitolite setup -pk /tmp/admin.pub Initialized empty Git repository in /home/git/repositories/gitolite-admin.git/Initialized empty Git repository in /home/git/repositories/testing.git/WARNING: /home/git/.ssh missing; creating a new one (this is normal on a brand new install)WARNING: /home/git/.ssh/authorized_keys missing; creating a new one (this is normal on a brand new install)$ ls bin gitolite projects.list repositories 4、ssh配置服务端 123456789su -// vim /etc/ssh/sshd_config，将下面几句前面的#号去掉RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keysAuthorizedKeysCommand noneAuthorizedKeysCommandRunAs nobody// 重启sshservice sshd restart 客户端的git bash， 1234在 ~/.ssh/config 添加以下内容，以便连接到服务器Host 192.168.1.254Compression yesIdentityFile ~/.ssh/id_rsa 5、gitolite添加用户、库，设置用户管理权限12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455561. windows安装TortoiseGit2. 新建git文件夹，进入，右键Git Clone…URL: git@serverIP:gitolite-admin.git 勾选Load Putty Key，选择你的私钥（此处需使用ppk格式私钥，可以使用puttygen将私钥admin转换成admin.ppk） 点击OK即可clone服务器上的gitolite-admin文件夹到本地3. 添加用户管理员将其他用户的公钥(如dong.pub)复制到gitolite-admin/keydir/下4. 添加库进入gitolite-admin/conf/，右键Git Bash Here，$ vim gitolite.conf (此文件用于添加库和配置用户对库的权限)repo gitolite-admin RW+ = adminrepo testing RW+ = @all repo git-dong #新建库git-dong RW+ = admin dong #设置用户admin dong有读写权限 将修改push到服务器，即可添加库和用户。:wq$ cd ..$ git status #查看git库状态$ git add keydir/dong.pub conf/gitolite.conf 或者git add .$ git commit –m “add repo git-admin;add user dong”进入gitolite-admin文件夹，右键TortoiseGitPush点击OK即可。5. 用户权限管理在客户端clone gitolite-admin.git,编辑gitolite-admin/conf/gitolite.conf配置各用户权限。1 @team1 = zc2 @team2 = aws zc3 repo gitolite-admin4 RW+ = admin56 repo ossxp/.+7 C = admin8 RW = @all910 repo testing11 RW+ = admin12 RW master = junio13 RW+ pu = junio14 RW cogito$ = pasky15 RW bw/ = linus16 - = somebody17 RW tmp/ = @all18 RW refs/tags/v[0-9] = junio在上面的示例中，我们演示了很多授权指令。• 第1行，定义了用户组 @admin，包含两个用户 jiangxin 和 wangsheng。• 第3-4行，定义了版本库 gitolite-admin。并指定只有用户 jiangxin 才能够访问，并拥有读(R)写(W)和强制更新(+)的权限。• 第6行，通过正则表达式定义了一组版本库，即在 ossxp/ 目录下的所有版本库。• 第7行，用户组 @admin 中的用户，可以在 ossxp/ 目录下创建版本库。创建版本库的用户，具有对版本库操作的所有权限。• 第8行，所有用户都可以读写 ossxp 目录下的版本库，但不能强制更新。• 第9行开始，定义的 testing 版本库授权使用了引用授权语法。• 第11行，用户组 @admin 对所有的分支和里程碑拥有读写、重置、添加和删除的授权。• 第12行，用户 junio 可以读写 master 分支。（还包括名字以 master 开头的其他分支，如果有的话）。• 第13行，用户 junio 可以读写、强制更新、创建以及删除 pu 开头的分支。第14行，用户 pasky 可以读写 cogito 分支。 (仅此分支，精确匹配）。 以下是通过修改gitolite-admin库，管理git用户和权限。添加新用户wuxiaohui的公钥，赋予其读写testing.git库的权限。 123456789## 对权限文件配置gitolite.conf的修改repo gitolite-admin RW+ = adminrepo testing RW+ = @allrepo new-source RW+ = wuxiaohui Chenchuneng maning 修改完成后push到git server。 12345678910111213141516171819202122232425262728293031shuaiyy@shuaiyy-PC MINGW64 /g/git/gitolite-admin (master)$ git statusOn branch masterYour branch is up-to-date with &apos;origin/master&apos;.Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: conf/gitolite.confUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) keydir/wuxiaohui.pubno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)shuaiyy@shuaiyy-PC MINGW64 /g/git/gitolite-admin (master)$ git add keydir/wuxiaohui.pub conf/gitolite.confwarning: LF will be replaced by CRLF in keydir/wuxiaohui.pub.The file will have its original line endings in your working directory.shuaiyy@shuaiyy-PC MINGW64 /g/git/gitolite-admin (master)shuaiyy@shuaiyy-PC MINGW64 /g/git/gitolite-admin (master)$ git commit -m &quot;add repo new-source;add user wuxiaohui&quot;[master bf3f6fe] add repo new-source;add user wuxiaohuiwarning: LF will be replaced by CRLF in keydir/wuxiaohui.pub.The file will have its original line endings in your working directory. 2 files changed, 4 insertions(+) create mode 100644 keydir/wuxiaohui.pub 6、git基础教程6.1、基本操作 git init要想使用git进行版本管理，必须先初试化仓库。新建一个文件夹，在该文件夹下执行 git init 命令，就可以将该文件夹初始化为git仓库，其下会生成.git的文件夹，记录git的版本追踪管理，千万不要删除或更改。 git status显示当前仓库的状态，，如 处于master分支，没有修改内容。 git add我们创建的文件不会被自动加入git仓库的管理文件中，必须使用git add filename或git add .使其加入本地的Index暂存区。然后git status 查看改变。 git commit -m “First Commit !”将git add的内容提交，保存到版本管理的历史记录中。git status 查看状态。 git log查看日志，其中 commit ID是版本号，如果想要改变到某个版本，需要指定版本号。git log file/dir 查看指定文件或文件夹的日志 git diff 查看当前状态和最新提交，历史版本的不同之处。其中+代表新增，-代表删除； 6.2、分支操作 git branch 显示分支一览表 git checkout -b 创建、切换分支 git merge 合并分支 git log –graph 以图表形式查看分支 6.3、更改提交 git reset 回溯历史版本 git commit –amend 修改提交信息 git rebase -i 压缩历史 6.4、推送至远程仓库 git remote add 添加远程仓库 git push 推送至远程仓库 6.5、从远程仓库获取 git clone 获取远程仓库到本地 git pull 获取最新的远程仓库分支 6.6、在线git命令练习 LearnGitBranching 提供在线的git命令学习与实践 Try Git 6.7、git命令备忘录master: 默认开发分支 origin: 默认远程版本库 Head: 默认开发分支 Head^: Head的父提交 创建版本库12$ git clone &lt;url&gt; #克隆远程版本库$ git init #初始化本地版本库 修改和提交123456789$ git status #查看状态$ git diff #查看变更内容$ git add . #跟踪所有改动过的文件$ git add &lt;file&gt; #跟踪指定的文件$ git mv &lt;old&gt;&lt;new&gt; #文件改名$ git rm&lt;file&gt; #删除文件$ git rm --cached&lt;file&gt; #停止跟踪文件但不删除$ git commit -m &quot;commit messages&quot; #提交所有更新过的文件$ git commit --amend #修改最后一次改动 查看提交历史123$ git log #查看提交历史$ git log -p &lt;file&gt; #查看指定文件的提交历史$ git blame &lt;file&gt; #以列表方式查看指定文件的提交历史 撤销1234$ git reset --hard HEAD #撤销工作目录中所有未提交文件的修改内容$ git checkout HEAD &lt;file&gt; #撤销指定的未提交文件的修改内容$ git revert &lt;commit&gt; #撤销指定的提交$ git log --before=&quot;1 days&quot; #退回到之前1天的版本 分支与标签1234567$ git branch #显示所有本地分支$ git checkout &lt;branch/tag&gt; #切换到指定分支和标签$ git branch &lt;new-branch&gt; #创建新分支$ git branch -d &lt;branch&gt; #删除本地分支$ git tag #列出所有本地标签$ git tag &lt;tagname&gt; #基于最新提交创建标签$ git tag -d &lt;tagname&gt; #删除标签 合并与衍合12$ git merge &lt;branch&gt; #合并指定分支到当前分支$ git rebase &lt;branch&gt; #衍合指定分支到当前分支 远程操作12345678$ git remote -v #查看远程版本库信息$ git remote show &lt;remote&gt; #查看指定远程版本库信息$ git remote add &lt;remote&gt; &lt;url&gt; #添加远程版本库$ git fetch &lt;remote&gt; #从远程库获取代码$ git pull &lt;remote&gt; &lt;branch&gt; #下载代码及快速合并$ git push &lt;remote&gt; &lt;branch&gt; #上传代码及快速合并$ git push &lt;remote&gt; :&lt;branch/tag-name&gt; #删除远程分支或标签$ git push --tags #上传所有标签 7、githubGitHub 除了 Git 代码仓库托管及基本的 Web 管理界面以外，还提供了订阅、讨论组、文本渲染、在线文件编辑器、协作图谱（报表）、代码片段分享（Gist）等功能。 Github的三个精彩功能 fork，star，watch 1.想拷贝别人项目到自己帐号下就fork一下。2.持续关注别人项目更新就star一下3.watch是设置接收邮件提醒的。 7.1、开始 创建账户 完善个人信息 设置Key 添加公钥 7.2、使用 创建仓库 连接仓库 提交开源代码 Github Desktop 7.3、GitHUb Flow ————以部署为中心的开发模式GitHub Flow 保持master分支始终是可部署使用的 新的开发要从master分支创建新的分支，分支名要有描述性意义 在本地仓库的新建分支提交 PUSH本地分支作业到github服务器端的同名分支 审查测试push的新分支，确认无误后与master合并 合并后的master分支可以立即投入使用，如果有bug，和回退到提交状态之前 8、Git server 使用指导8.1、将自己的代码上传到远程仓库我在 project 目录下创建了4个用户对应的仓库 Chenchuneng.git Maning.git Wuxiaohui.git Wangba.git因此对应的git仓库地址为： git@121.41.15.6:project/Wangba.git使用git clone 克隆到本地： 假如我的workspace目录下有2个项目源码，project1，project2，想上传project1到远程仓库 Wangba.git。 在workspace下打开git bash here，执行 git init 初试化本地仓库 git add project1,添加需要git log的文件，git add .可以添加所有变更的文件，省事。 git commit -m &quot; 备注&quot;，提交变化到本地仓库 git remote add mywork git@121.41.15.6:project/Yangshuai.git,为本地仓库添加远程仓库，命令中的mywork 是我们为远程仓库起的别名（可以自己任取），然后push的时候使用别名 mywork 就可以少打很多字了。 将本地仓库push到服务器上的远程仓库，右键workspace，选择Tortogit小乌龟里的push命令： 以后修改添加的代码想要上传至git服务器，重复 2 3 5步骤，即 add commit push。其他目录下的代码想要上传的话，重复步骤 1-6 。 注意：git clone 和git push 我们都是用的程序而不是命令行，是因为在git bash 下如何配置git服务器认证所需的ssh-key暂时没找到解决方法，而GUI工具可以”load ssh key”。]]></content>
      <categories>
        <category>技术</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 模板语法]]></title>
    <url>%2F2016%2F08%2F19%2F%E6%8A%80%E6%9C%AF%2FDjango%E6%A8%A1%E6%9D%BF%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Django模板语法模板变量 {{var_name}} ,view视图传入参数可以为 Context({'name':'vale',}) {{dict.key}},view视图传入参数为dict字典 {{object_name.attribute 或 method}} ,view视图传入一个对象object。 {{list_name.N}},view视图出入一个list，可以取出list的第N个元素。 条件分支 {% if user.age < 18 %} 未成年{% else %} XXX {% endif %} 条件中的逻辑关系词 and or not，其中and与or不能同时使用。 循环 for 123456789101112&#123;% raw %&#125;&#123;% for book in booklist reversed %&#125; &#123;&#123;book&#125;&#125;&#123;&#123;% empty %&#125;&#125; &lt;li&gt;&#123;&#123;forloop.counter&#125;&#125;&lt;/li&gt; &lt;li&gt;&#123;&#123;forloop.revcounter&#125;&#125;&lt;/li&gt; &lt;li&gt;&#123;&#123;foorloop.counter0&#125;&#125;&lt;/li&gt; &lt;li&gt;&#123;&#123;forloop.revcounter0&#125;&#125;&lt;/li&gt;&#123;% endfor %&#125;&#123;% for key in dict %&#125; &#123;&#123;key&#125;&#125; &#123;% endfor %&#125;&#123;% endraw %&#125; reversed 是逆序输出,{{% empty %}}判断循环体是否为空，for 没有continue和break； forloop变量forloop.counter 从1计数的当前循环次数，forloop.revcounter，剩余的循环次数forloop.counter0，从0开始计数的循序。forloop.first和forloop.last,是否为第一次和最后一次循环，True 或False。 过滤器 filter |{{book | upper | lower | capfisrt}},将变量book先变大写在变小写在变首字母大写|过滤器标识，类似于linux的管道，{{today | date:"Y-m-d"}},today变量为datetime.datetime.now()。 自定义过滤器模板自定义的过滤器位于 templatetags文件夹下，这是一个python包，里面要有一个空的__init__文件，一般一个过滤器函数为一个单独的py文件 12345from django import templateregister = template.Library()def percent(value): return value + '%'register.filter('percent',percent) 过滤器必须用register对象注册，有2个参数，name和func，也可以在func处使用装饰器，如下： 1234567from django import templateregister = template.Library()@register.filter(name='percent')def percent(value): return value + '%' #register.filter('percent',percent) 使用自定义过滤器时必须在模板中先load py文件，{% load percent %} 需要重启服务器使过滤器生效]]></content>
      <categories>
        <category>技术</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 学习笔记(二)]]></title>
    <url>%2F2016%2F08%2F16%2F%E6%8A%80%E6%9C%AF%2FDjango%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%2F</url>
    <content type="text"><![CDATA[Django进阶1、用户信息扩展1.1、使用profile扩展在models定义一个profile表，使用外键关联 1.2、继承AbstractUser在models创建继承AbstractUser的User类，为其增加新的字段，比如QQ号，手机号。在setting里设置字段 AUTH_USER_MODEL = &#39;blog.User&#39;在admin注册自己的User。 2、自定义认证2.1、自定义认证方式2.2、session保持3、权限设计和使用3.1、用户注册4、自定义模板库base文件和base.html 123456\&#123;\% block head_css \%\&#125; &lt;继承扩展此处部分&gt;\&#123;\% endblock \%\&#125;\&#123;\% block head_css \%\&#125; &lt;继承扩展此处部分&gt;\&#123;\% endblock \%\&#125; 模板文件中引用base.html,重载里面需要定制的block，其他的继承base里默认的。 1234\&#123;\% extend "base/base.html" \%\&#125;\&#123;\% block container \%\&#125;实现部分\&#123;\% endblock \%\&#125; 5、自定义标签在app目录下建立templatetags文件夹， 12345678910111213141516from django import templateregister = template.Library()class UpperNode(template.Node): def __init__(self,nodelist): self.nodelist = nodelist def render(self,context): content = self.nodelist.render(context) return content.lower()@register.tagdef upper(parse,token): nodelist = parse.parse("endupper") parse.delete_first_token() return UpperNode(nodelist) 在模板中加载使用自定义标签： 1234\&#123;\% load upper \%\&#125; \&#123;\% upper \%\&#125; upper标签将作用于此块的内容 \&#123;\% endupper \%\&#125; 6、自定义过滤器在templatetags下创建 assets.py,实现区分开发环境的assets资源定位 123456789from django import templateregister = template.Library()from blog.settings import is_Debug@register.filterdef assets(value): if is_debug: return '/static/'+value return '/static/assets/' +value 在模板中使用过滤器： 1234&#123;% raw %&#125;&#123;% load assets %&#125; &lt;link src="&#123;&#123;'1.css' | assets&#125;&#125;"/&gt;&#123;% endraw %&#125; 7、model的定义和同步，增删改在models.py中导入django.db 的models,数据类定义：在models.py中定义一个评论类123456789101112class review(models.Model): user = models.ForeignKey(User) new = models. content = models.TextField creat_time = models.DateTimeField() is_dele = models.BoolenField(default = 0) def __str__(self): return self.content class Meta: permission = () 同步数据库: 增加数据：在视图views中导入数据类，比如user类，然后创建user对象的实例，然后调用save方法。修改：先get实例，然后赋值修改，最后save 删除： 1、修改is_dele标志字段 2、删除数据实例，先获取实例。然后调用delete()方法 8、django单表查询和多表查询ORM查询 多表查询用到外键 9、聚合查询Q协助查询，实现与或非。12from django.db.models import Qres_list = news.objects.filter(Q(title = 'today')|Q(body = 'new')) 10、ORM无法满足查询需求时，直接使用SQL语句查询10.1、raw() XXX.objects.raw(‘SQL 语句’)，但raw的SQL语句里，必须包含主键；对复杂语句支持不好 12res_list = user.objects.raw('select * from blog_user where id = 1 or sex = "女" ') 10.2、cursor()12345from django.db import connection,transactioncursor = connection.cursor()sql = 'select * from user'cursor.execute(sql)res_list = cursor.fetchall() #每条记录是一个元组 11、querysets和惰性机制querysets查询结果集，可以遍历，也可以继续执行查询筛选，res_list = news.objects.filter(Q(title = &#39;today&#39;)|Q(body = &#39;new&#39;)) 惰性机制：只有querysets被使用到，其数据查询才被执行，并返回结果。 1234res_list = news.objects.filter(Q(title = 'today')|Q(body = 'new')) res_list.order_by('age')res_dict = res_list.value('id','name') 12、自定义manager管理器当ORM的方法无法满足我们的需求时， 新增manager方法类似article.objects.all()就是一个manager，用来获取数据的方法，我们可以定义自己的manager，在models.py中新建类，继承models.Manager， 12345678910111213141516class PollManager(models.Manager): def with_counts(self): from django.db import connection with connection.cursor() as cursor: cursor.execute(""" SELECT p.id, p.question,p.poll_date, COUNT(*) FROM polls_opinionpoll p, polls_response r WHERE p.id = r.poll_id GROUP BY p.id, p.question, p.poll_date ORDER BY p.poll_date DESC""") result_list = [] for row in cursor.fetchall(): p = self.model(id=row[0], question=row[1],poll_date=row[2]) p.num_responses = row[3] result_list.append(p) return result_listclass OpinionPoll(models.Model): question = models.CharField(max_length=200) poll_date = models.DateField() objects = PollManager() 然后就可以使用OpinionPoll.objects.with_count()方法 改变原有的querySet方法覆盖重写原有方法。 13、Form表单在views.py中定义form类：1234567891011from django import formsclass LoginForm(forms.Form) email = forms.CharField(label = 'email',max_length =100) pwd = forms.CharField(label ='password',widget = forms.PasswordInput)#添加验证 def clean_email(self): pass def clean(self): if len(self.cleaned_data["email"].split('@'))&lt;2: raise forms.ValidationError('email is wrong!') return email django开发实践技巧：1、从setting.py中读取配置信息为全局使用settings中： 123456789101112131415161718192021222324252627#网站的基本信息配置SITE_URL = 'http://localhost:8000/'SITE_NAME = '个人博客'SITE_DESC = '专注Python开发，欢迎和大家交流'WEIBO = 'http://weibo.com/holdhiitfitness/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo&amp;is_all=1'WEIBO_TENCENT = 'http://weibo.com/holdhiitfitness/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo&amp;is_all=1'PRO_RSS = 'http://www.abroadrecommend.com'PRO_EMAIL = 'johnson_hugh@163.com'# 在templates中配置处理器TEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [ os.path.join(BASE_DIR,'templates'), ], 'APP_DIRS': True, 'OPTIONS': &#123; 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', 'blog.views.global_setting' # 注意此处 ], &#125;, &#125;,] 在 views中定义templates处理器的方法12345from django.conf import settingsdef globe_setting(request): return &#123;'SITE_URL':settings.SITE_URL, 'SITE_NAME':settings.SITE_NAME &#125; 在模板文件中，可直接引用变量{{SITE_URL}} 2、数据库模型设计技巧使用工具 PowerDesign、ERWin、Visio、Navicat Data MOdeler 分析可能存在的数据库表 分析可能会有的数据列，以及对应的数据类型和约束。 设计数据模型图 在modles.py中定义模型： 1234567891011class Tag(models.Model): name = models.CharField(max_length =30,verbose_name ='标签名称') class Meta: # 在admin管理界面可以看到 verbose_name = '标签' verbose_name_plural = verbose_name def __unicode__(self): #print 对象时的输出 return self.name# 自定义User modelclass User(AbstactUser): avatar = models.ImageField(upload_to ='url',default ='avatar/default.png',max_length =200,) QQ = models.CharField() 自定义user model需要在setting中添加参数：AUTH_USER_MODEL= &#39;blog.User&#39;，可以继承abstactUser，或关联外键扩展。 mysql配置 settings: 123456789101112DATABASES = &#123; 'default': &#123; #配置别忘了用逗号，否则不被识别为元组 'ENGINE': 'django.db.backends.mysql', 'NAME': 'blogdb', #开发环境可用，生产环境不要用 'USER': 'root', 'PASSWORD': '123456', 'HOST': '', 'PORT': '',#默认3306 &#125;&#125; 在mysql中创建blogdb数据库，utf-8编码。 富文本编辑框：使用kindeditor，下载kindeditor，解压文件放到/static/js/kindeditor 下面。定义媒体文件 1234class Media： js = ('/static/js/kindeditor-4.10/kindeditor-min.js', '/static/js/kindeditor-4.10/lang/zh-CN.js', '/static/js/kindeditor-4.10/config.js',) 注意新建配置文件config.js，参考官方文档：K.create(‘#id’),#id 是对应html页面中需要富文本编辑器的网页元素 12345678KindEditor.ready(function(K) &#123; K.create('textarea[name=content]',&#123; width:'800px', height:'200px', //配置上传地址，这个地址在url.py中已经配置好了，要和它对应 uploadJson: '/admin/upload/kindeditor', &#125;); &#125;); 需要自己定义文件上传接口。配置: 根目录下创建uploads，在settings中配置MEDIA_URL和MEDIA_ROOT 配置文件上传 123#上传图片设置MEDIA_URL = '/uploads/'MEDIA_ROOT = os.path.join(BASE_DIR,'uploads') 路由设置： 123456#配置用于处理图片上传的url映射url(r"^uploads/(?P&lt;path&gt;.*)$", \ #django.views.static.serve专门用于处理静态文件 "django.views.static.serve", \ #这里用到了settings中配置好的路径MEDIA_ROOT &#123;"document_root": settings.MEDIA_ROOT,&#125;), 配置富文本编辑器的文件上传 12345from blog.upload import upload_image#用于映射富文本编辑器的图片上传url(r'^admin/upload/(?P&lt;dir_name&gt;[^/]+)$', upload_image,\ name='upload_image'), 自己实现上传处理函数： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# -*- coding: utf-8 -*-from django.http import HttpResponsefrom django.conf import settingsfrom django.views.decorators.csrf import csrf_exemptimport osimport uuidimport jsonimport datetime as dt#这个装饰器用于不再进行表单验证提交@csrf_exemptdef upload_image(request, dir_name): ################## # 这是kindeditor想要的格式 # kindeditor图片上传返回数据格式说明： # &#123;"error": 1, "message": "出错信息"&#125; # &#123;"error": 0, "url": "图片地址"&#125; ################## result = &#123;"error": 1, "message": "上传出错"&#125; #imgFile来自于富文本编辑器查看源码之后找到的它定义的文件名字 files = request.FILES.get("imgFile", None) if files: result =image_upload(files, dir_name) return HttpResponse(json.dumps(result), content_type="application/json")#目录创建def upload_generation_dir(dir_name): today = dt.datetime.today() dir_name = dir_name + '/%d/%d/' %(today.year,today.month) if not os.path.exists(settings.MEDIA_ROOT + dir_name): os.makedirs(settings.MEDIA_ROOT + dir_name) return dir_name# 图片上传def image_upload(files, dir_name): #允许上传文件类型 allow_suffix =['jpg', 'png', 'jpeg', 'gif', 'bmp'] file_suffix = files.name.split(".")[-1] if file_suffix not in allow_suffix: return &#123;"error": 1, "message": "图片格式不正确"&#125; relative_path_file = upload_generation_dir(dir_name) path=os.path.join(settings.MEDIA_ROOT, relative_path_file) if not os.path.exists(path): #如果目录不存在创建目录 os.makedirs(path) file_name=str(uuid.uuid1())+"."+file_suffix path_file=os.path.join(path, file_name) file_url = settings.MEDIA_URL + relative_path_file + file_name #写入操作，二进制形式，最终完成上传，真正保存图片 open(path_file, 'wb').write(files.file.read()) return &#123;"error": 0, "url": file_url&#125; 配置好路由，在kindeditor的config js中配置上传路径： 12345678KindEditor.ready(function(K) &#123; K.create('textarea[name=content]',&#123; width:'800px', height:'200px', //配置上传地址，这个地址在url.py中已经配置好了，要和它对应 uploadJson: '/admin/upload/kindeditor', &#125;); &#125;); ​ 3、模板设计base.html保留不变的内容，变化的部分以\{\% block XXX \%\} \{\% endblock \%\}代替，子模板继承 base.html,\{\% extends &#39;base.html&#39;},然后重写\{\% block XXX \%\} \{\% endblock \%\}，在{\% block XXX \%} 中间添加变化的内容 {\% endblock \%}。也可将变化的部分单独放入一个文件中，使用 \{\% include &#39;XXX.html&#39; \%\} 4 、导航栏数据获取假如以category模型设计导航栏，先获取对象列表，传递变量给模板，然后在模板中展示123456# views 中from models import *class index(request)： ca_list = category.objects.all() return render(request,'base.html',&#123;'ca_list':ca_list&#125;) 在模板中 12345&#123;% raw %&#125;&#123;% for ca in ca_list %&#125;&lt;a herf =''&gt;&#123;&#123;ca.name&#125;&#125; &lt;/a&gt;&#123;% endfor %&#125;&#123;% endraw %&#125; 5、其他 locals() 将所有变量封装传递进模板，render(&#39;index.html&#39;,locals()) 代码重构：使用模板处理器，上面的global_setting的例子，将每个视图都用到的模板变量数据定义到模板处理器中。 聚合查询 annotate 异常捕获 1234try ： get_article()except Artical.NotExist: xxx 标签过滤器 {{update_date|date:'Y-m-d'}}safe 不转义变量文本里的html便签，确定变量安全的可以用该过滤器。 csrf表单验证 模板页面表单处需要 \{\% csrf_token \%\},防止跨站提交的安全手段。 不使用csrf(不推荐)，post方法使用csrf_exmp装饰器。]]></content>
      <categories>
        <category>技术</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django 学习笔记(一)]]></title>
    <url>%2F2016%2F08%2F13%2F%E6%8A%80%E6%9C%AF%2FDjango%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01%2F</url>
    <content type="text"><![CDATA[Django 学习笔记1 基于python2.7和django1.10 django工作流程： 1、快速开始1.1、创建项目 django-admin.py startproject website manage.py startapp blog 修改webisite下的setting.py urls.py 1234567891011# setting 修改# installed_apps 添加你的app#To include the app in our project, we need to add a reference to its configuration class in the INSTALLED_APPS setting. The PollsConfigclass is in the polls/apps.pyfile, so its dotted pathis ’blog.apps.PollsConfig’. Edit the mysite/settings.pyfile and add that dotted path to the INSTALLED_APPSsetting.INSTALLED_APPS = [...XXX..., ’blog.apps.PollsConfig’, ]language zh-HANStime-zone Asia/Shanghai# 数据库连接配置 1234567# website/urls.py修改from django.conf.urls import include, url # 注意导入includefrom django.contrib import adminurlpatterns = [ url(r'^blog/', include('blog.urls')), # include app的urls规则 url(r'^admin/', admin.site.urls), # 只有admin例外，可以不用include] ​ 1.2、创建应用 manage.py startapp blog 创建视图 1234# 编辑文件 blog/views.pyfrom django.http import HttpResponsedef index(request):return HttpResponse("Hello, world. You're at the polls index.") views可以获取url中的参数作为变量使用：url(r&#39;^(?P&lt;question_id&gt;[0-9]+)/vote/$&#39;, views.vote, name=&#39;vote&#39;),通过urls中的正则表达式匹配的命名变量: %question_id view视图模板 模板文件存放在 app/templates/app/下。在settings中设置模板文件夹的路径，静态文件的路径 123456789101112131415161718# 静态文件STATICFILES_DIRS = ( os.path.join(BASE_DIR, "static"), )# django 1.8TEMPLATE_DIRS = ( os.path.join(os.path.dirname(__file__), '../templates').replace('\\','/'), )# django 1.9 TEMPLATES = [ &#123; 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': ( os.path.join(BASE_DIR, 'templates'), os.path.join(BASE_DIR, '../templates'), ), 'APP_DIRS': True, &#125; 在view文件中加载渲染的模板： 12345678910from django.http import HttpResponsefrom django.template import loaderfrom .models import Questiondef index(request):latest_question_list = Question.objects.order_by('-pub_date')[:5]template = loader.get_template('polls/index.html')context = &#123;'latest_question_list': latest_question_list,&#125;return HttpResponse(template.render(context, request)) 或直接使用render()函数渲染,这样就不用Httpresponse和loader了。 123456from django.shortcuts import renderfrom .models import Questiondef index(request):latest_question_list = Question.objects.order_by('-pub_date')[:5]context = &#123;'latest_question_list': latest_question_list&#125;return render(request, 'blog/index.html', context) 模板中的url软编码在urls.py中每个url匹配规则可以指定一个name参数。在模板中使用{% url 'name' %}引用URL， e.g. {{ question.question_text }} 这样，当url映射改变时，无需修改模板文件。当app很多时，在urls.py中指定url命名空间，即app_name=’XXX’,然后模板引用url时，使用{% url 'blog:detail' question_id %} 模板中的表单和view中对表单数据的处理 404视图使用try catch或get_XXX_or_404方法，推荐后者 123456789try: question = Question.objects.get(pk = question_id) except Question.DoesNotExist: raise Http404("Questin does not exist!") return render(request, 'blog/detail.html', context=&#123;'question':question&#125;) ### 或者 no use try ,we can do this : question = get_object_or_404(Question, pk=question_id) return render(request, 'polls/detail.html', &#123;'question': question&#125;) 使用generic views 12345678from django.views import genericclass IndexView(generic.ListView): template_name = 'blog/index.html' context_object_name = 'latest_question_list' def get_queryset(self): """Return the last five published questions.""" return Question.objects.order_by('-pub_date')[:5] url映射规则 123456789#编辑 blog/urls.pyfrom django.conf.urls import urlfrom . import viewsurlpatterns = [url(r'^$', views.index, name='index'),# 如果index写成'^/$',则所有的url都会被路由到index]# name参数可以在模板文件中以&#123;% raw %&#125;&#123;% url name %&#125;&#123;% endraw %&#125; 引用。# 然后将其include到website下的urls.py内 数据库设置 123#修改settings.py，配置数据库连接# 然后执行命令创建数据库manage.py migrate 创建模式 编辑 blog/models.py 123456789from django.db import modelsclass Question(models.Model): question_text = models.CharField(max_length=200) pub_date = models.DateTimeField('date published')class Choice(models.Model): question = models.ForeignKey(Question,on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) 激活models，执行manage.py makemigrations blog，最后应用到数据库，manage migrate。 总结：• Change your models (in models.py).• Run python manage.py makemigrations to create migrations for those changes• Run python manage.py migrate to apply those changes to the database. views中引用数据库中的数据 获得全部对象： 12345678910from .models import Questionquestion_list = Question.object.all()l1=Question.objects.filter(question_text = u'what 你好') # 对象数据过滤器，等于Question.objects.filter( age__gt = 16) # 属性age &gt; 16Question.objects.filter( age__gte = 16) # 属性age &gt;= 16Question.objects.filter( name__contains = '张') # 属性name中含有张。# 批量更新,无需调用saveQuestion.objects.filter( age__gt = 16).update(name = 'zhang')# 删除调用.delete()方法 filter过滤表达式 123456ques = Question.object.get(id = 2)ques.name = 'a'ques.date = todayques.save() #同步修改# 删除调用.delete()方法ques.delete() 获得单个对象 添加一个新对象数据 12newQ = Question(name = 'new',age =16)newQ.save() 实现实体对应关系一对一和多对多 待补充 1.3、 Django Admin create admin user 1234python manage.py createsuperusername:adminmail:password:**** ​启动server,访问 http://127.0.0.1:8000/admin/ 在admin界面注册app 的object 打开的admin管理界面默认是没有blog app数据的编辑 blog/admin.py 1234from django.contrib import admin# Register your models here.from .models import Questionadmin.site.register(Question) 个性化 app static文件夹，blog\static\blog\ 下存放css文件，模板文件中引用css和图片使用相对路径。 blog\static\blog\images\下存放图片文件，css中和模板中引用图片使用相对路径。 django favicon.ico 处理：https://pypi.python.org/pypi/django-favicon 从url传值 get 12id = request.GET['id']passwd = request.POST['password'] /argv1/argv2/… 123456views.pydef wanda(request,wanda): return HttpResponse(r' `&lt;h4&gt; %s &lt;/h4&gt;`' % wanda)urls.pyurl(r'wanda/(?P&lt;wanda&gt;\d&#123;4&#125;)/$',views.wanda), 其中变量wanda是在url正则表达式中定义的分组变量名称。如果不定义?P&lt;name&gt;,则在view视图函数中可以传入任意变量名，按对应顺序从URL匹配中取值。 2、记录踩过的坑 object has no attribute ‘_state’： django不使用init方法，参考文档creating-objects部分。 IOError: No translation files found for default language zh-CN. 经确认是新版本的django包版本中只有zh_Hans目录，没有zh_CN,把zh_Hans目录复制一个zh_CN就Ok了或者在settings里面直接改成zh-Hans，这样就不用升级完Django，还去改目录了。 debug=False后，网站无法访问静态资源图片等 需要在启动参数中添加insecure manage runserver 0.0.0.0:8080 --insecure]]></content>
      <categories>
        <category>技术</category>
        <category>django</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PhantomJS + Selenium实现登陆网站签到]]></title>
    <url>%2F2016%2F08%2F10%2F%E6%8A%80%E6%9C%AF%2FPhantomJS%20%2B%20Selenium%E5%AE%9E%E7%8E%B0%E7%99%BB%E9%99%86%E7%BD%91%E7%AB%99%E7%AD%BE%E5%88%B0%2F</url>
    <content type="text"><![CDATA[PhantomJS + Selenium实现登陆网站签到 js脚本是由浏览器前端加载执行的，因此爬虫要想渲染js，就要实现js引擎，或者我们分析出js发送的请求后，自己构造(很难，复杂)。 另外一种，就是使用selenium调用浏览器自动化处理。phantomjs是一个无头浏览器，没有界面，因此运行速度要比chrome快一点，没有弹窗干扰。 requests，urllib之类的http库，只能将http资源请求下来，其中的img link js标签都不会自动加载。而浏览器会请求所有的资源。 目标网站分析 网站yrw.com,登陆后签到页面是一个js脚本控制的插件,ipinyou.com估计是显示签到效果的 1234567891011121314151617181920 &lt;script type="text/javascript"&gt; var _py = _py || []; var _userId = "0"; var _source = "0"; var _pv = "0"; _py.push(['a', 'qJ..OIEiS_boFsG_SD2lEUB5nX']); _py.push(['domain', 'stats.ipinyou.com']); _py.push(['e', "&#123;\"userId\":\"" + _userId + "\",\"source\":\"" + _source + "\"&#125;"]); _py.push(['pv', _pv]); -function (d) &#123; var s = d.createElement('script'), e = document.body.getElementsByTagName('script')[0]; e.parentNode.insertBefore(s, e), f = 'https:' == location.protocol; s.src = (f ? 'https' : 'http') + '://' + (f ? 'fm.ipinyou.com' : 'fm.p0y.cn') + '/j/adv.js'; &#125;(document);&lt;/script&gt;&lt;noscript&gt; &lt;img src="//stats.ipinyou.com/adv.gif?a=qJ..OIEiS_boFsG_SD2lEUB5nX&amp;e=" style="display:none;"/&gt;&lt;/noscript&gt; 最初用fiddler抓包，发现请求的链接很复杂，不好构造，于是决定用selenium操作浏览器。后来用Chrome的XHR发现了请求链接，囧。 1234567891011121314151617Request-Headers:GET /member/check/?_=1482648421735 HTTP/1.1Host: www.yrw.comConnection: keep-aliveAccept: application/json, text/javascript, */*; q=0.01X-Requested-With: XMLHttpRequestUser-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.87 Safari/537.36Referer: https://www.yrw.com/member/homeAccept-Encoding: gzip, deflate, sdch, brAccept-Language: zh-CN,zh;q=0.8Cookie: JSESSIONID=99ED09E3560F9F944EEAE855532F8684; CNZZDATA1253600367=1638558785-1463053615-%7C1482644670Request-url:https://www.yrw.com/member/check/?_=1482648421735Response-json:&#123;&quot;error&quot;:false,&quot;page&quot;:null,&quot;result&quot;:&#123;&quot;checkDate&quot;:1482648441429,&quot;checkSource&quot;:0,&quot;createTime&quot;:null,&quot;gainPopularity&quot;:2,&quot;id&quot;:null,&quot;memberId&quot;:110850411330,&quot;popularityDouble&quot;:1&#125;,&quot;resultCode&quot;:null,&quot;resultCodeEum&quot;:null,&quot;resultCodeList&quot;:[],&quot;resultList&quot;:null,&quot;success&quot;:true&#125; 签到脚本12345678910111213141516171819202122232425# coding:utf-8from selenium import webdriverimport time # 要注意等待浏览器加载页面完成browser = webdriver.PhantomJS(executable_path=r"E:\C\python\py\pantomjs_selenuim\bin\phantomjs.exe")url = r'http://www.yrw.com/'a = browser.get(url)login_url = r'http://www.yrw.com/security/login/'browser.get(login_url)username= browser.find_elements_by_id('j-cpn2') # find_elements方法返回的列表， find_element返回找到的第一个passwd=browser.find_elements_by_name('password')submit = browser.find_elements_by_id('j-login-submit')username[0].send_keys('username') # 填用户名passwd[0].send_keys('password') # 填密码submit[0].click() # 点击登陆按钮time.sleep(5)page1 = browser.page_sourcebrowser.save_screenshot('login.jpg')browser.find_element_by_id("j-checkin-btn").click()time.sleep(5)page2 = browser.page_source # 打印网页源码browser.save_screenshot('sign.jpg')browser.quit() # 关闭phantom浏览器print 1 使用requests模拟签到 找到了js请求的url：https://www.yrw.com/member/check/?_=1482648421735 12345678910111213141516171819202122232425# 主要是想验证签到的url是否正确，登陆部分直接用的cookie，模拟登陆也很简单，post登陆表单即可，无验证码import requestssign_url = r'https://www.yrw.com/member/check/?_=1482648421735' # 数字含义应该是时间戳，不影响url访问cookie_string = r'JSESSIONID=6F98E86EBE571D3233EE14B986320E86; CNZZDATA1253600367=1638558785-1463053615-%7C1482717076'headers = &#123; 'Host': 'www.yrw.com', 'Connection': 'keep-alive', 'Accept': 'application/json, text/javascript, */*; q=0.01', 'X-Requested-With': 'XMLHttpRequest', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.87 Safari/537.36', 'Referer': 'https://www.yrw.com/member/home', 'Accept-Encoding': 'gzip, deflate, sdch, br', 'Accept-Language': 'zh-CN,zh;q=0.8', 'Cookie': cookie_string&#125;s = requests.Session()s.headers = headersresponse = s.get(sign_url)q = response.json()if q['success']: print u'签到成功,获得积分%d点' % q['result']['gainPopularity']else: print u'签到失败']]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
        <category>Python 爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>Selenium</tag>
        <tag>Phantomjs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫笔记(基于python2)]]></title>
    <url>%2F2016%2F08%2F09%2F%E6%8A%80%E6%9C%AF%2FPython2%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基于python2.7 urllib2库的用法基础用法 urlopen方法打开网页 传入3个参数，data和timeout不是必须的；返回网页的源码可用read方法读出。 123response = urlopen(url,data,timeout)content = response.read() urlopen()本质上接收一个request对象，返回response对象。构建request对象：request = urllib2.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False) 12345import urllib2request = urllib2.Request(&quot;http://www.baidu.com&quot;)response = urllib2.urlopen(request)print response.read() post方式请求数据 post提交的数据不会在网址中显示 123456789import urllibimport urllib2values = &#123;&quot;username&quot;:&quot;xxxx@qq.com&quot;,&quot;password&quot;:&quot;XXXX&quot;&#125;data = urllib.urlencode(values) url = &quot;https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn&quot;request = urllib2.Request(url,data)response = urllib2.urlopen(request)print response.read() get方式请求数据 get方式提高的数据直接包含在网址当中 12345678910111213import urllibimport urllib2values=&#123;&#125;values[&apos;username&apos;] = &quot;1016903103@qq.com&quot;values[&apos;password&apos;]=&quot;XXXX&quot;data = urllib.urlencode(values) url = &quot;http://passport.csdn.net/account/login&quot; ### 数据拼接到url中geturl = url + &quot;?&quot;+data request = urllib2.Request(geturl)response = urllib2.urlopen(request)print response.read() 高级用法 下面来说一说urllib2中的两个重要概念：Openers和Handlers。1.Openers：当你获取一个URL你使用一个opener(一个urllib2.OpenerDirector的实例)。正常情况下，我们使用默认opener：通过urlopen。但你能够创建个性的openers。2.Handles：Openers使用处理器handlers，所有的“繁重”工作由handlers处理。每个handlers知道如何通过特定协议打开URLs，或者如何处理URL打开时的各个方面。例如HTTP重定向或者HTTP cookies headers属性模拟浏览器身份 User-Agent : 通常会通过该值来判断是否是浏览器发出的请求Content-Type : 在使用 REST 接口时，服务器会检查该值，用来确定 HTTP Body 中的内容该怎样解析。application/xml ： 在 XML RPC，如 RESTful/SOAP 调用时使用application/json ： 在 JSON RPC 调用时使用application/x-www-form-urlencoded ： 浏览器提交 Web 表单时使用在使用服务器提供的 RESTful 或 SOAP 服务时， Content-Type 设置错误会导致服务器拒绝服务referer：有些网站会检测该值是否为自身，防盗链。 在构建request对象时设置headers 12345headers = &#123; &apos;User-Agent&apos; : &apos;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&apos; , &apos;Referer&apos;:&apos;http://www.zhihu.com/articles&apos; &#125;request = urllib2.Request(url, data, headers) response = urllib2.urlopen(request) page = response.read() 用自建的opener()中addheaders属性加入headers参数： 1234567891011121314user_agents = [ &apos;Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11&apos;, &apos;Opera/9.25 (Windows NT 5.1; U; en)&apos;, &apos;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)&apos;, &apos;Mozilla/5.0 (compatible; Konqueror/3.5; Linux) KHTML/3.5.5 (like Gecko) (Kubuntu)&apos;, &apos;Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.12) Gecko/20070731 Ubuntu/dapper-security Firefox/1.5.0.12&apos;, &apos;Lynx/2.8.5rel.1 libwww-FM/2.14 SSL-MM/1.4.1 GNUTLS/1.2.9&apos;, &quot;Mozilla/5.0 (X11; Linux i686) AppleWebKit/535.7 (KHTML, like Gecko) Ubuntu/11.04 Chromium/16.0.912.77 Chrome/16.0.912.77 Safari/535.7&quot;, &quot;Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:10.0) Gecko/20100101 Firefox/10.0 &quot;, ] agent = random.choice(user_agents) opener.addheaders = [(&quot;User-agent&quot;,agent),(&quot;Accept&quot;,&quot;*/*&quot;),(&apos;Referer&apos;,&apos;http://www.google.com&apos;)] Proxy代理设置 在创建opner时传入Proxy handler ，urllib2.build_opener(proxy_handler)或在一个opener实例中调用opener.add_handler(proxy_handler)方法传入 创建proxy handler对象 1proxy_handler = urllib2.ProxyHandler(&#123;&quot;http&quot; : &apos;http://some-proxy.com:8080&apos;&#125;) 超时设置timeout 可以设置等待多少秒无响应即为超时，在urlopen(url,data,timeout=10)中设置 http的put和delete方法 http协议有6种请求数据的方法，除了最常用get和post，还有head，put，delete，options；PUT：这个方法比较少见。HTML表单也不支持这个。本质上来讲， PUT和POST极为相似，都是向服务器发送数据，但它们之间有一个重要区别，PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定。DELETE：删除某一个资源。基本上这个也很少见，不过还是有一些地方比如amazon的S3云服务里面就用的这个方法来删除资源。 123# 在创建request对象时指定put或delete方法request = urllib2.Request(url,data,headers=&#123;&#125;)request.get_method = lambda: &apos;PUT&apos; # or &apos;DELETE&apos; 使用DebugLog 该功能可以将收发包的内容打印出来，不常用。 123httpHandler = urllib2.HTTPHandler(debuglevel=1)httpsHandler = urllib2.HTTPSHandler(debuglevel=1)opener = urllib2.build_opener(httpHandler, httpsHandler) cookie保持登陆在opener中绑定处理cookie对象的handler，即可捕获cookie并在后续的请求中使用。 cookielib模块 cookielib模块提供可存储的cookie对象，配合urllib2使用。cookielib提供的主要对象有CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar。 保存cookie到变量中，使用cookiejar()对象 12345678910import urllib2import cookielibcookie = cookielib.CookieJar()cookie_handler = urllib2.HTTPCookieProcessor(cookiejar=cookie)opener = urllib2.build_opener(cookie_handler)opener.open(url) # ...for item in cookie : print item.name + item.value 保存cookie到文件中， 使用FileCookieJar()对象及其子类 MozillaCookieJar和LWPCookiejar。 123456789import urllib2import cookielibcookie_file = &apos;cookie.txt&apos;cookie_jar=cookielib.MozillaCookieJar(filename=cookie_file)cookie_handler = urllib2.HTTPCookieProcessor(cookiejar=cookie_jar)opener = urllib2.build_opener(cookie_handler)opener.open(&apos;http:\\www.baidu.com&apos;)cookie_jar.save(ignore_discard=True, ignore_expires=True) # 即使将废弃的cookie也保存，覆盖cookie文件内容 从文件中加载cookie cookiejar对象的load方法 1234567891011import urllib2import cookielibcookie_file = &apos;cookie.txt&apos;cookie_jar=cookielib.MozillaCookieJar()### load()方法cookie_jar.load(filename=cookie_file, ignore_discard=True, ignore_expires=True)cookie_handler = urllib2.HTTPCookieProcessor(cookiejar=cookie_jar)opener = urllib2.build_opener(cookie_handler)resp=opener.open(&apos;http:\\www.baidu.com&apos;)print resp.read() 实例 登陆小说网站 166zw.com 12345678910111213141516171819202122232425262728293031323334353637383940import urllib2import urllibimport cookielib########################################################################class Browser(object): &quot;&quot;&quot; 创建一个有cookie和headers的opener对象,带有异常处理 &quot;&quot;&quot; #---------------------------------------------------------------------- def __init__(self): &quot;&quot;&quot;Constructor&quot;&quot;&quot; cookie_handler = urllib2.HTTPCookieProcessor(cookiejar=cookielib.CookieJar( )) self.opener = urllib2.build_opener(cookie_handler) self.opener.addheaders = [(&quot;User-agent&quot;, &apos;Opera/9.25 (Windows NT 5.1; U; en)&apos;,),(&quot;Accept&quot;,&quot;*/*&quot;),(&apos;Referer&apos;,&apos;http://www.google.com&apos;)] def openurl(self,url,data=None,timeout=10): try: response = self.opener.open(url,data,timeout) except urllib2.URLError, e: print e.code,&apos;\n&apos;,e.reason return response postData=urllib.urlencode(&#123;&apos;username&apos;:&apos;wocaonima&apos;,\ &apos;password&apos;:&apos;******&apos;,\ &apos;usecookie&apos;:&apos;1&apos;,\ &apos;submit.x&apos;:&apos;25&apos;,\ &apos;submit.y&apos;:&apos;5&apos;,\ &apos;action&apos;:&apos;login&apos;&#125;)loginUrl=r&apos;http://www.166zw.com/loginframe.php&apos;html=Browser().openurl(loginUrl,postData)print html.code,html.msg,html.infocontent= html.read()print content ### 打印的页面含有用户名信息，表明登陆成功 URLError异常处理 http协议状态码 服务器返回的响应请求，包含一个状态码。urllib2.HTTPError可以捕获 100：继续 客户端应当继续发送请求。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。101： 转换协议 在发送完这个响应最后的空行后，服务器将会切换到在Upgrade 消息头中定义的那些协议。只有在切换新的协议更有好处的时候才应该采取类似措施。102：继续处理 由WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。200：请求成功 处理方式：获得响应的内容，进行处理201：请求完成，结果是创建了新资源。新创建资源的URI可在响应的实体中得到 处理方式：爬虫中不会遇到202：请求被接受，但处理尚未完成 处理方式：阻塞等待204：服务器端已经实现了请求，但是没有返回新的信 息。如果客户是用户代理，则无须为此更新自身的文档视图。 处理方式：丢弃300：该状态码不被HTTP/1.0的应用程序直接使用， 只是作为3XX类型回应的默认解释。存在多个可用的被请求资源。 处理方式：若程序中能够处理，则进行进一步处理，如果程序中不能处理，则丢弃301：请求到的资源都会分配一个永久的URL，这样就可以在将来通过该URL来访问此资源 处理方式：重定向到分配的URL302：请求到的资源在一个不同的URL处临时保存 处理方式：重定向到临时的URL304：请求的资源未更新 处理方式：丢弃400：非法请求 处理方式：丢弃401：未授权 处理方式：丢弃403：禁止 处理方式：丢弃404：没有找到 处理方式：丢弃500：服务器内部错误 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器端的源代码出现错误时出现。501：服务器无法识别 服务器不支持当前请求所需要的某个功能。当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。502：错误网关 作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。503：服务出错 由于临时的服务器维护或者过载，服务器当前无法处理请求。这个状况是临时的，并且将在一段时间以后恢复。 URLError HTTPError是URLError的子类,所以try… except…时应先捕获子类，子类捕获不到再捕获父类错误。 1234567891011import urllib2req = urllib2.Request(&apos;http://blog.csdn.net/cqcre&apos;)try: urllib2.urlopen(req)except urllib2.HTTPError, e: print e.codeexcept urllib2.URLError, e: print e.reasonelse: print &quot;OK&quot; 直接捕获一个URLError，如果含有code和reason属性，则说明是一个HTTPError。 123456789101112import urllib2req = urllib2.Request(&apos;http://blog.csdn.net/cqcre&apos;)try: urllib2.urlopen(req)except urllib2.URLError, e: if hasattr(e,&quot;code&quot;): print e.code,e.reason else: print eelse: print ok 正则表达式 和 bs4正则表达式 正则表达式用来匹配符合特定规则的字符串，类似于数学表达式是一种逻辑公式，实现对字符串的过滤匹配。 正则表达式的语法规则 贪婪模式和转义字符 python默认使用贪婪模式匹配查找字符串，即总是尝试匹配尽可能多的字符，非贪婪模式则相反。举例：模式ab 在abbbc字符串中将匹配到3个b，即abbb;非贪婪模式ab? 在abbbc字符串中将匹配到0个b，即a; 转义字符为\，很多编程语言也用\做转义字符，那么编程语言里的正则表达式想要匹配“\”就得使用4个‘\’,即“\\”。先在编程语言环境中转义得到“\”,然后提供给正则表达式。好在python有原生字符串的表示方法，即不转义任何’\’,而将其作为字符’\’,比如 print r’\s\%\‘ 执行后得到的结果就是 \s\%\ 。 re模块 re模块提供正则表达式引擎 pattern 是re 匹配模式的对象，由正则表达式字符串预编译得到。 12import repattern = re.compile(r&apos;\d&apos;) re主要的方法如下： 12345678910#返回pattern对象,该对象包含match，findall等方法p = re.compile(string[,flag]) #以下为匹配所用函数，也可传入pattern字符串，re会先执行compile编译正则表达式字符串生成pattern对象re.match(pattern, string[, flags])re.search(pattern, string[, flags])re.split(pattern, string[, maxsplit])re.findall(pattern, string[, flags])re.finditer(pattern, string[, flags])re.sub(pattern, repl, string[, count])re.subn(pattern, repl, string[, count]) flag参数可选值如下： 123456• re.I(全拼：IGNORECASE): 忽略大小写（括号内是完整写法，下同）• re.M(全拼：MULTILINE): 多行模式，改变&apos;^&apos;和&apos;$&apos;的行为（参见上图）• re.S(全拼：DOTALL): 点任意匹配模式，改变&apos;.&apos;的行为• re.L(全拼：LOCALE): 使预定字符类 \w \W \b \B \s \S 取决于当前区域设定• re.U(全拼：UNICODE): 使预定字符类 \w \W \b \B \s \S \d \D 取决于unicode定义的字符属性• re.X(全拼：VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释。 re方法 re.match(pattern,string,flag)match返回第一次匹配成功的结果（match对象）或None。注意match是从字符串开头的第一个字符开始匹配。hello模式match 字符串say hello就会失败返回None。 1234567891011121314151617 import re# 匹配如下内容：单词+空格+单词+任意字符m = re.match(r&apos;(\w+) (\w+)(?P&lt;sign&gt;.*)&apos;, &apos;hello world!&apos;)print &quot;m.string:&quot;, m.stringprint &quot;m.re:&quot;, m.reprint &quot;m.pos:&quot;, m.posprint &quot;m.endpos:&quot;, m.endposprint &quot;m.lastindex:&quot;, m.lastindexprint &quot;m.lastgroup:&quot;, m.lastgroupprint &quot;m.group():&quot;, m.group() # 默认返回group(0),即整个匹配结果，group(n)可以输出第n个元组匹配的结果。print &quot;m.group(1,2):&quot;, m.group(1, 2)print &quot;m.groups():&quot;, m.groups()print &quot;m.groupdict():&quot;, m.groupdict()print &quot;m.start(2):&quot;, m.start(2)print &quot;m.end(2):&quot;, m.end(2)print &quot;m.span(2):&quot;, m.span(2)print r&quot;m.expand(r&apos;\g \g\g&apos;):&quot;, m.expand(r&apos;\2 \1\3&apos;) re.search(pattern, string[, flags])search()同match()方法相似，区别是match()仅从字符串的开头匹配，如果0位置失败，则匹配以失败结束。search同match有相同的属性和方法。 123456789101112 #导入re模块 import re# 将正则表达式编译成Pattern对象pattern = re.compile(r&apos;world&apos;)# 使用search()查找匹配的子串，不存在能匹配的子串时将返回None# 这个例子中使用match()无法成功匹配res = re.search(pattern,&apos;hello world!&apos;)if res: # 使用Match获得分组信息 print res.group()### 输出 #### world re.split(pattern, string[, maxsplit]) 按照能够匹配的子串将string分割后返回列表。maxsplit用于指定最大分割次数，不指定将全部分割。 123456 import re pattern = re.compile(r&apos;\d+&apos;) print re.split(pattern,&apos;one1two2three3four4&apos;) ### 输出 #### [&apos;one&apos;, &apos;two&apos;, &apos;three&apos;, &apos;four&apos;, &apos;&apos;] re.findall(pattern, string[, flags]) 搜索string，以列表形式返回全部能匹配的子串 re.finditer(pattern, string[, flags]) 搜索string，返回一个顺序访问每一个匹配结果（Match对象）的迭代器.迭代器使用for进行遍历。 re.sub(pattern, repl, string[, count]) 使用repl替换string中每一个匹配的子串后返回替换后的字符串。当repl是一个字符串时，可以使用\id或\g、\g引用分组，但不能使用编号0。当repl是一个方法时，这个方法应当只接受一个参数（Match对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。count用于指定最多替换次数，不指定时全部替换。 123456789101112131415import repattern = re.compile(r&apos;(\w+) (\w+)&apos;)s = &apos;i say, hello world!&apos;print re.sub(pattern,r&apos;\2 \1&apos;, s)def func(m): return m.group(1).title() + &apos; &apos; + m.group(2).title()print re.sub(pattern,func, s)### output #### say i, world hello!# I Say, Hello World! re.subn(pattern, repl, string[, count]) 返回 (sub(repl, string[, count]), 替换次数)。 使用pattern对象调用上述方法则不必传入pattern对象 常用匹配 ip 文件后缀 r&#39;http://img\.tupianzj\.com/uploads/allimg/\d+/.+\.(?:gif|jpg|png|bmp)&#39; BeautifulSoup BeautifulSoup是python的一个第三方库，用于解析网页并从中提取数据。 安装 pip install beautifulsoup4,或去官网下载安装包。 BeautifulSoup使用Python标准库中默认的HTML解析器，想要使用其他可选的第三方html解析器需要提前安装好。 lxml或html5lib。lxml解析器更强大速度更快。html5lib是纯python实现的，解析方式与浏览器相同。 pip install lxml 和 pip install html5lib windows下直接pip安装lxml失败，可以先pip install wheel ,然后去Python Extension Packages for Windows - Christoph Gohlke上下载对应系统的安装包，然后pip install c:\lxml-3.6.4-cp27-cp27m-win_amd64.whl其他pip无法直接安装的模块也可用这种方法。 官方文档 Beautiful Soup 4.4.0 文档 — beautifulsoup 4.4.0 文档 使用 1234567from bs4 import BeautifulSoupimport urllib2URL = r&quot;http://www.baidu.com&quot;content = urllib2.urlopen(URL).read()bsobj = BeautifulSoup(content) #传入html格式的字符串print bsobj.prettify() #打印出html文档树，格式化输出 bs将html文档转换为树形结构，每个节点都是一个对象，对象分为4种：Tag，NavigableString，BeautifulSoup，Comment。 Tag 即HTML中的标签，由&lt;&gt; &lt;/&gt;闭合。比如 News Today 获取标签方法如下，找不到返回None，这种方法只能查找符合条件的第一个标签。tag常用的属性有name，attrs，string。 12345678910111213print bsobj.title# &lt;title&gt;百度一下，你就知道&lt;/title&gt;print bsobj.title.string# 百度一下，你就知道print bsobj.div.attrs# &#123;&apos;id&apos;: &apos;wrapper&apos;&#125; 输出的是标签的属性print bsobj.div.name# div 标签的名字为对象本身的名字，bsobj对象的名字为`[document]`#获取某个属性的值print bsobj.div[&apos;id&apos;]wrapperprint bsobj.div.get(&apos;id&apos;)wrapper NavgableString 可以遍历的字符串，即标签闭合的内容：print bsobj.title.string #输出 百度一下，你就知道 BeautifulSoup BeautifulSoup对象表示一个文档的全部内容，也可以当做tag对象，只不过是包含很多子tag的特殊的tag Comment Comment 对象是一个特殊类型的 NavigableString 对象，但是使用ob.string输出的内容仍然不包括注释符号。 有必要时可进行类型判断 12 if type(soup.a.string)==bs4.element.Comment:print soup.a.string 遍历文档树 tag.contens 属性 bsobj.tag.contents 可以将tag的子节点以列表的形式输出。 tag.children 属性 bsobj.tag.children 是一个子节点的list生成器，可以用for循环遍历 tag.descendants 属性 bsobj.tag.descendants 是tag的子孙节点的list生成器，用for遍历。而contents和children只包含孩子节点（一级子节点），不包含孩子的孩子及后续孙子节点。 tag.string 属性，节点内容 如果tag只含有唯一的一个子tag，那么tag.string输出的是子tag的内容，不含子tag，则直接输出tag的内容；如果有多个子tag，则输出none。 tag.strings 和 tag.stripped_strings 获取多个内容 都需要用for循环遍历，.stripped_strings去除了多余空白内容。 tag.parent 属性 父节点 tag.parents 属性 全部父辈节点 通过递归得到tag全部的父辈节点，用for循环遍历 tag.next_sibling 和 tag.previous_sibling 兄弟节点 获取与tag同一级的节点，.next_sibling 属性获取了该节点的下一个兄弟节点，.previous_sibling 则与之相反，如果节点不存在，则返回 None注意：实际文档中的tag的 .next_sibling 和 .previous_sibling 属性通常是字符串或空白，因为空白或者换行也可以被视作一个节点，所以得到的结果可能是空白或者换行 .next_siblings .previous_siblings 属性 全部兄弟节点 .next_element .previous_element 属性 tag节点的前后节点，与兄弟节点不同，前后节点没有层级关系，可以是父子也可以是兄弟节点。 .next_elements .previous_elements 属性 搜索文档树 bsobj.find_all(name=None, attrs={}, recursive=True, text=None, limit=None)搜索当前tag的所有子tag，返回符合条件的结果 name 参数 查找所有名字满足name条件的tag。 1&gt;如果传入字符串，则搜索完全匹配该字符串的tag : 标签; 2&gt; 传正则表达式，搜索名字匹配正则的tag标签 3&gt; 传入name列表，返回所有与列表元素匹配的tag 4&gt; 传True，返回全部的任意tag，除字符串节点。 5&gt; 传方法，该方法只接收一个参数，根据判断条件返回True 或False。find_all()返回的是满足True的全部节点 attrs 和 keyword 参数 attrs={‘id’:’123’,’color’:’red’},attrs接收一个字典，用来搜索含有指定属性的tag。也可以指定关键字参数，如 id=’today’,class_=’nostyle’,注意class是python保留字，所以bs使用class来做区别。注意 html5中的类似 data-*的参数不能用作关键字搜索，会报错。 text参数 可以匹配文档中的字符串内容，与name参数的可选值一样，接收 字符串，正则表达式，列表，True limit参数 limit = n ，限制返回的数量为n，即找到n个节点就停止。 recursive参数 递归参数默认为true，即搜索子孙节点。如果只搜索子节点怎改为false。 find( name , attrs , recursive , text , **kwargs )它与 find_all() 方法唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果 find_parents() 和 find_parent()find_all() 和 find() 只搜索当前节点的所有子节点,孙子节点等. find_parents() 和 find_parent() 用来搜索当前节点的父辈节点,搜索方法与普通tag的搜索方法相同,搜索文档搜索文档包含的内容 find_next_siblings() find_next_sibling()迭代对象为tag.next_siblings ，对tag 的所有后面解析的兄弟 tag 节点进行迭代, find_next_siblings() 方法返回所有符合条件的后面的兄弟节点,find_next_sibling() 只返回符合条件的后面的第一个tag节点 find_previous_siblings() 和 find_previous_sibling()迭代对象为.previous_siblings ，对当前 tag 的前面解析的兄弟 tag 节点进行迭代, find_previous_siblings() 方法返回所有符合条件的前面的兄弟节点, find_previous_sibling() 方法返回第一个符合条件的前面的兄弟节点 find_all_next() find_next()迭代对象为tag.next_elements，find_all_next() 方法返回所有符合条件的节点, find_next() 方法返回第一个符合条件的节点 find_all_previous() 和 find_previous()迭代对象为.previous_elements,find_all_previous() 方法返回所有符合条件的节点, find_previous()方法返回第一个符合条件的节点 Requests库的用法 Requests是第三方库，比urllib库更高级、抽象。也就是说使用更方便。 文档 Requests: HTTP for Humans — Requests 2.11.1 documentation 安装 pip install requests 初次相见html= requests.get(url),返回的是对象，具有以下属性或方法：’apparent_encoding’, ‘close’, ‘connection’, ‘content’, ‘cookies’, ‘elapsed’, ‘encoding’, ‘headers’, ‘history’, ‘is_permanent_redirect’, ‘is_redirect’, ‘iter_content’, ‘iter_lines’,‘json()’：解析json格式内容,‘links’, ‘ok’, ‘raise_for_status’,‘raw’：获得原始套接字,要在初始的请求中设置stream=True‘reason’, ‘request’, ‘status_code’ ：http响应状态码,‘text’:直接输出内容,‘url’ 基本http请求 requests实现了http的6种请求，get、post、delete、put、options、head。 GET请求方式requests.get(url, params=None),参数传入字典，比如{‘k1’:’v1’ , ‘k2’:’v2’}，则请求url自动编码为url?k1=v1&amp;k2=v2在请求中添加headers， 123456import requestspayload = &#123;&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;&#125;headers = &#123;&apos;content-type&apos;: &apos;application/json&apos;&#125;r = requests.get(&quot;http://httpbin.org/get&quot;, params=payload, headers=headers)print r.url post请求 12345678910import jsonpost_data =&#123;'key1': 'value1', 'key2': 'value2'&#125; res = requests.post(url, data=post_data, json=None)# 如果提交的信息不是表单形式，而是json格式的数据，可用json.dumps()把表单数据序列化,或使用json参数res = requests.post(url, data=json.dumps(post_data), json=None)res = requests.post(url, data=None, json=post_data)# 以上2者等效# 支持流式上传数据，只需传入一个file-like对象,不用file.read()加载内容至内存with open('test.file','r') as f : res = requests.post(url, data=f) Cookies 如果服务器返回的响应包含cookie，则我们得到的response对象就会保存该cookie，可以利用.cookies属性查看。使用cookie发送请求时只需在get/post方法中指定cookies参数要想使用cookie保持登陆，则需要一个session会话对象 123456789# 查看cookiesimport requestsurl1 = 'http://xxx.com'r = requests.get(url1)print r.cookies# 构造cookies并用来发送请求url2 = 'http://ooo.com'cookies = &#123;'id':'1234'&#125;r = requests.get(url2，cookies=cookies) 超时设置 timeout在get/post方法中传入timeout参数，仅对连接建立有效，与返回response全部数据的时间无关。 会话对象 session 每次直接调用requests.get/post方法都相当与建立了一个新的请求会话，相当于用不同的浏览器发起请求。因而无法使用cookie保持登陆状态。 123456s = requests.session()s.headers.update(&#123;(&quot;User-agent&quot;,&quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11&quot;),(&quot;Accept&quot;,&quot;*/*&quot;),(&apos;Referer&apos;,&apos;http://www.google.com &apos;)&#125;) # 此处设置的headers是全局变量，post/get方法传入的headers参数的同名变量会覆盖此处headers的变量，不使用某个参数可将其值设为None。# 不同名的参数会一块加入到请求的headers中生效.res = s.get(url)# 通过会话发起请求 SSL证书验证Requests可以为HTTPS请求验证SSL证书，就像web浏览器一样。要想检查某个主机的SSL证书，你可以在get/post方法中使用 verify 参数，默认为True，是检查的。如直接requests.get(‘https://www.12306.cn&#39;),就会出现证书无效的错误：requests.exceptions.SSLError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:590)。使用requests.get(url=&apos;https://www.12306.cn&apos;,verify=False)取消证书检查。 代理在post/get方法中传入参数proxies： 1234proxies = &#123; &quot;https&quot;: &quot;http://41.118.132.69:4433&quot;&#125;r = requests.post(&quot;http://httpbin.org/post&quot;, proxies=proxies) 也可以设置环境变量HTTP_PROXY和HTTPS_PROXY来配置代理。 12export HTTP_PROXY=&quot;http://10.10.1.10:3128&quot;export HTTPS_PROXY=&quot;http://10.10.1.10:1080&quot; 参考：官方API文档 xpath语法与lxml库 lxml解析库使用xpath语法，beautifulSoup的内部实现是RExpath语法参考lxml官方文档 - Processing XML and HTML with Python xpath语法 XPath 是一门在 XML 文档中查找信息的语言。XPath 可用来在 XML 文档中对元素和属性进行遍历。XPath 是 W3C XSLT 标准的主要元素，并且 XQuery 和 XPointer 都构建于 XPath 表达之上。 xpath使用路径表达在xml中选取节点。节点的逻辑关系有：父节点Parent、先辈节点Ancestor、子节点Children、后代节点Descendant、兄弟/同胞节点sibling。 路径表达式：nodename: 选择nodename节点的所有子节点,/:从根路径选取,绝对路径，//:从当前路径下选取全部,不考虑位置，相对路径，.:选取当前节点,..:选取当前节点的父节点,@:选取属性. 谓语：用来查找某个特定的节点或者包含某个特定的值的节点。谓语嵌在方括号[]中。 | 路径表达式 | 结果 || /bookstore/book[1] | 选取属于 bookstore 子元素的第一个 book 元素。 || /bookstore/book[last()] | 选取属于 bookstore 子元素的最后一个 book 元素。 || /bookstore/book[last()-1] | 选取属于 bookstore 子元素的倒数第二个 book 元素。 || /bookstore/book[position()35.00] | 选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。 || /bookstore/book[price&gt;35.00]/title | 选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。 | 选取未知节点： *:匹配任何节点; @*:匹配任何属性的节点; node():匹配任何类型的节点; 选取多个路径：|运算符，//book/title | //book/price xpath表达式运算符|:找到满足2个路径表达式之一的节点集合；+:加法-:减法*:乘法div:除法，取整 ; mod:取余数=:等于，比较，相等返回true，否则返回false！=:不等于，比较&lt;:小于 ； &lt;=:小于或等于&gt;:大于 ； &gt;=:大于或等于or: 或，连接2个布尔表达式，有一个为真返回trueand: 与，都为真才返回true lxml用法PhantomJS的用法Selenium的用法PyQuery的用法 PySpider框架]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
        <category>Python 爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python编程技巧]]></title>
    <url>%2F2016%2F08%2F07%2F%E6%8A%80%E6%9C%AF%2FPython%E7%BC%96%E7%A8%8B%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[python编程技巧 x的n次方求解 ： x ** n 22]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 字符串技巧]]></title>
    <url>%2F2016%2F07%2F29%2F%E6%8A%80%E6%9C%AF%2FPython-str%2F</url>
    <content type="text"><![CDATA[将 \u3232\u6674转换成unicode字符 运用str对象的decode方法 1234567#任何字符，都可以在：#http://unicodelookup.com/#中，查找到对应的unicode的值s=&apos;\u6210\u529f&apos;print s.decode(&apos;unicode-escape&apos;)...成功 写入unicode报错‘ascii’ codec can’t encode character in position 0-3。py2如果开头指定了utf-8，Python的解释器根据 “#encoding:utf-8” 来按utf-8的编码规则来理解这些字符码•当你把字符串写到文件中去时，因为你的字符串是 unicode，所以Python会（自动）先调用encode方法来编码unicode字符串，然后再写入文件•当调用encode方法时，因为没有指定编码格式，所以采用默认值 ascii，ascii并不能解释定义的utf-8中翻译的字符码，所以报错 今天遇到一个错误： UnicodeEncodeError: ‘ascii’ codec can’t encode characters in position 0-3 搜索网上找到一个解决办法（转载自 http://blog.sina.com.cn/s/blog_727b603701019pyl.html） 异常: ‘ascii’ codec can’t encode characters 字符集的问题，在文件前加两句话： reload(sys) sys.setdefaultencoding( “utf-8” ) 完美解决，]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python字典键值转置]]></title>
    <url>%2F2016%2F07%2F29%2F%E6%8A%80%E6%9C%AF%2FPython-dict-reverse%2F</url>
    <content type="text"><![CDATA[dict的key与value转置 如果value1值唯一，则直接交换key1与value1的位置 1234from collections import OrderedDict as od_dict #生成有序的dictd= od_dict((v,k) for k,v in OID_FS_lst.items()) print d 如果value1不唯一，直接交换，则作为key2插入的value1值，会被相同的key2覆盖。也就说会丢失部分值。]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python创建项目]]></title>
    <url>%2F2016%2F07%2F28%2F%E6%8A%80%E6%9C%AF%2FSomething-with-python-project%2F</url>
    <content type="text"><![CDATA[使用Cookiecutter模板创建Python项目样式 首先安装cookiecutter pip install -U cookiecutter 在github上找一个模板 在某个目录下执行 cookiecutter https://github.com/audreyr/cookiecutter-pypackage.git，使用找到的模板创建项目，输入相关参数 是否开源发布看个人 import自己的模块 首先.py文件和主文件在一个目录下 import name ,不要加.py,否则报错 Fatal error in launcher: Unable to create process using ‘“‘Windows新装的python3自带了easy_install和pip，但执行时会出错Fatal error in launcher: Unable to create process using &#39;&quot;&#39; ,1、确保环境变量中没空格。2、如果不是环境变量问题，则重装\升级easy_install和pip，python3 -m pip install -U pip,python3 -m pip install -U setuptools。问题解决。 pip安装模块失败的解决办法windows下直接pip安装lxml失败，可以先pip install wheel ,然后去Python Extension Packages for Windows - Christoph Gohlke上下载对应系统的安装包，然后pip install c:\lxml-3.6.4-cp27-cp27m-win_amd64.whl其他pip无法直接安装的模块也可用这种方法。 python2 Unicode和普通字符串之间转换问题描述：You need to deal with data that doesn’t fit inthe ASCII character set.解决： 将Unicode转换成普通的Python字符串:”编码(encode)” 12u_string = u&quot;你好&quot;utf8_s = u_string.encode(&apos;utf-8&apos;) ascii_s ,iso_s,utf16_s 对应的编码集分别为”ascii” “ISO-8859-1” “utf-16”将普通的Python字符串转换成Unicode: “解码(decode)” 1234plainstring1 = unicode(utf8string, &quot;utf-8&quot;) plainstring2 = unicode(asciistring, &quot;ascii&quot;) plainstring3 = unicode(isostring, &quot;ISO-8859-1&quot;)plainstring4 = unicode(utf16string, &quot;utf-16&quot;)]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统服务配置]]></title>
    <url>%2F2016%2F07%2F26%2F%E6%8A%80%E6%9C%AF%2FConfig-of-Linux%2F</url>
    <content type="text"><![CDATA[查看内核版本1uname -r 稳定版本的偶数版，如2.6.x，适合于商业与家用环境使用；开发中版本，如2.5.x，适合开发特殊功能的环境。 安装内核文件：apt-get install linux-headers-$(uname -r) 修改源vim /etc/apt/sources.list deb http://http.kali.org/kali kali-rolling main contrib non-free ssh远程登陆设置允许root登陆ssh新装的系统可能需要要修改root密码gedit /etc/ssh/sshd_config修改 PermitRootLogin yes PermitRootLogin yesPermitEmptyPasswords no注意重启ssh service 设置系统开机启动sshd服务chkconfig sshd on 即可but debian8不行， 如果是debian 8，直接使用systemd，比如：sudo systemctl enable xxx.servicesudo systemctl disable xxx.service Mac：（若以root身份登陆，将username改为root） 登陆 1ssh root@IPaddress Linux：(若以root身份登陆，将username删掉）Linux默认root的提示符为#,而一般身份用户的提示符为$。 1su - username 使用ssh上传下载文件 很多系统初始不带这工具，但感觉比起ftp，sftp传输文件，还是方便很多的。 首先安装sz，rz命令行工具，apt-get install lrzsz。然后使用xshell或secureRT登陆服务器，putty好像不行。 上传 rz -E输入rz -E会自动弹出打开文件窗口，选择要上传的文件。 下载 sz file-path输入sz file，会弹出窗口选择file文件下载存放的位置。 FTP 服务配置参考链接:proftp 安装配置FTP服务器 切换root 安装proftpd，在确认安装中选Y，并选择《Standalone》安装apt-get install proftpd 安装完以后将实现先停掉，以方便改配置/etc/init.d/proftpd stop 或service proftpd stop 编辑proftpd的配置文件nano /etc/proftpd/proftpd.conf更改FTP根目录, 默认为: DefaultRoot ~，比如说改为:DefaultRoot /var/www允许匿名用户访问,找到配置文件中的 ““ 和 ““ 之间的部分，将注释移除即可。 保存配置文件 “/etc/proftpd.conf”,重启proftpd服务/etc/init.d/proftpd restart 为FTP服务器添加用户名、密码和读写权限 FTP服务的用户名密码其实就是拥有特定目录权限的linux用户及其密码，所以添加一个FTP用户并设置密码，用户信息即可adduser tester -home /var/www 还要为此用户添加FTP共享目录的读写权限，[直接改变所有权]chown tester /var/www [可选] 当用户非常多时，可以添加一个用户组，统一配置权限addgroup ftpuser并将tester添加进ftpuser组adduser tester ftpuser注* 删除用户和用户组deluser testerdelgroup tester安装VMware tools 修改防火墙端口 开启防火墙 UDP161端口 for snmp 查看防火墙配置：iptables –L –n 添加一条规则记录：iptables -I INPUT -p udp --dport 161 -j ACCEPT 保存规则使防火墙生效iptables-save(debian linux),ubuntu下的保存iptables命令iptables -save。 iptables-save 重启后会失效，应使用service iptables save 常用端口 21是指FTP默认端口、80是指web服务器端口、3306是指MySQL数据库链接端口，22是指SSH远程管理端口，9000到9045是FTP被动模式端口范围 修改DNS永久修改网卡DNSsudo –icd /etc/resolvconf/resolv.conf.dvim base添加如下内容nameserver 8.8.8.8nameserver 8.8.4.4 Linux下python2 与3共存 安装Python3后，建立ln，使用Python（Python2），Python3 来区分两个版本，使用sudo apt-get install python3-setuptools 安装Easy_install，再使用sudo easy_install3 pip 安装Pip，Pip 对应Python2，Pip3 对应Python3。Easy_Install 对应Python2，Easy_Install3 对应Python3. python使用virtualenv创建隔离环境 注销Linux注销Linux并不意味着关机，只是用户离开系统。 1exit 基础命令的操作1command [-options] parameter1 parameter2 ··· 123456echo $LANG #显示目前支持的语言LANG=en_US #将语言改为英文系date #显示日期与实践cal 10 2014 #显示日历bc #计算器quit #退出 重要的热键[tab]：连按两次，具有“命令补全”和“文件补齐”的作用。[control]+c：中断目前程序。[control]+d：键盘输入结束；直接离开文字界面（相当于`exit）。 在线求助 man page1man command #command是要查询的命令名称 进入man命令后，可按空格往下翻页，按q键离开。在man page中，可以在任何时候输入/keyword来查询关键字，比如/date. 正确的关机方法123who #查看目前有谁在线netstat -a #查看网络的联机状态ps -aux #查看后台执行的程序 数据同步写入磁盘：为了防止不正常关机导致的内存数据没有来得及写入磁盘，在文字界面输入 1sync 惯用的关机命令： 123456shutdown -h now #立刻关机shutdown -h 20:25 #晚上8点25分关机shutdown -h +10 #过十分钟后关机shutdown -r now #立刻重启shutdown -r +30 ‘The system will be reboot’ #再过30分钟关机，并显示后面的消息给所有在线用户shutdown -k now ‘The system will be reboot’ #仅发出警告，系统并不会真正关机 重启、关机：reboot，halt，poweroff。务必用man去查询一下。 压缩解压unrar x a.rar ./a/ 使用screen12345678910111213141516171819screen -S myjobSessionscreen -r sessionname/ID 恢复sessionscreen -lsexit 退出screen session，终止任务，ctrl+a+d 暂时离开/后台运行session，先按住ctrl，然后按一下a，按一下d远程演示首先演示者先在服务器上执行 screen -S test 创建一个screen会话，观众可以链接到远程服务器上执行screen -x test 观众屏幕上就会出现和演示者同步其它命令Ctrl + a，d #暂离当前会话Ctrl + a，c #在当前screen会话中创建一个子会话 Ctrl + a，w #子会话列表 Ctrl + a，p #上一个子会话 Ctrl + a，n #下一个子会话 Ctrl + a，0-9 #在第0窗口至第9子会话间切换有时在恢复screen时会出现There is no screen to be resumed matching ****，遇到这种情况咋办呢？输入命令screen -d ****]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 目录 文件 权限]]></title>
    <url>%2F2016%2F07%2F25%2F%E6%8A%80%E6%9C%AF%2FFile-and-dir-of-Linux%2F</url>
    <content type="text"><![CDATA[Linux目录操作12345. # 代表此层目录.. # 代表上一层目录- # 代表前一个工作目录~ # 代表『目前使用者身份』所在的家目录~account # 代表 account 这个使用者的家目录(account是个帐号名称) 在所有目录底下都会存在的两个目录，分别是.与.. 根目录的上一层(..)与根目录自己(.)是同一个目录 几个常见的处理目录的命令 cd：变换目录，cd是Change Directory的缩写 pwd：显示目前的目录，pwd是Print Working Directory的缩写 mkdir：创建一个新的目录 rmdir：删除一个空的目录 mv：移动文件 1234pwd -P # -P：代表显示正确的完整路径，而不是连接路径mkdir -m xxx # -m：直接配置文件的权限mkdir -p test1/test2 # -p：直接将所需要的目录(包含上一级目录)递回创建起来！PATH=&quot;$PATH&quot;:/root # 将/root路径加入PATH环境变量中 文件与目录管理 文件与目录的检视： ls 复制、删除与移动： cp, rm, mv 1234567cp -a # 将文件的所有特性都一起复制过来cp -p # 连同文件的属性一起复制过去，而非使用默认属性(备份常用)cp -r # 可以复制目录，但是，文件与目录的权限可能会被改变rm -i # 互动模式，在删除前会询问使用者是否动作rm -r # 连目录下的东西一起删掉，并且不会询问，慎用mv -f # force强制移动，如果目标文件已经存在，不会询问而直接覆盖mv -i # 若目标文件 (destination) 已经存在时，就会询问是否覆盖 文件内容查询 直接检视文件内容： cat, tac, nl （常用） 可翻页检视： more, less （常用） 数据撷取： head, tail 非纯文字档： od 修改文件时间与建置新档： touch 12345678cat [-AbEnTv] filename # 由第一行开始显示文件内容。-b列出非空白行行号；-n列出所有行号。tac # 从最后一行开始显示文件内容，tac就是cat倒着写！nl # 显示文件内容，顺便输出行号more # 一页一页地显示文件内容less # 与more类似，但可以往前翻页head [-n number] # 只看文件头几行，默认是10行，number是自定义行数tail # 只看文件尾几行，文件很大的时候常用od # 以二进制方式读取文件内容 文件与目录的默认权限与隐藏权限 文件默认权限：umask 文件隐藏属性： chattr, lsattr 文件特殊权限：SUID, SGID, SBIT, 权限配置 观察文件类型：file 123umask # 后三位数是被拿走的权限分数，比如0022，u没有被拿走权限，g和o被拿走了w权限umask -S # 以符号类型来显示权限umask number # 配置自己需要的权限 在默认的情况中，root的umask会拿掉比较多的属性，root的umask默认是022， 这是基於安全的考量啦～至於一般身份使用者，通常他们的 umask 为002 ，亦即保留同群组的写入权力。 特殊权限s和t Set UID，简称SUID，当s标志在文件拥有者的x项目为SUID，对目录无效 Set GID，简称SGID，当s标志在群组的x项目为SGID，对目录有效 Sticky Bit, 简称SBIT，目前只针对目录有效，对於文件已经没有效果了 配置SUID,SGID,SBIT权限在原有的权限数字前面加上需要配置的权限数字。比如755-&gt;4755 ，就意味着-rwxr-xr-x变为了-rwsr-xr-x。 4 为 SUID 2 为 SGID 1 为 SBIT 123chmod 4755 filenamechmod u=rwxs,go=x test; ls -l test # 配置权限为-rws--x--x的模样chmod g+s,o+t test; ls -l test # 配置权限为-rws--s--t，即加入SGID,SBIT权限 ###命令与文件的搜寻 命令档名的搜寻：which 文件档名的搜寻：whereis, locate, find 权限与命令的关系一、让使用者能进入某目录成为『可工作目录』的基本权限为何： 可使用的命令：例如 cd 等变换工作目录的命令； 目录所需权限：使用者对这个目录至少需要具有 x 的权限 额外需求：如果使用者想要在这个目录内利用 ls 查阅档名，则使用者对此目录还需要 r 的权限。 二、使用者在某个目录内读取一个文件的基本权限为何？ 可使用的命令：例如本章谈到的 cat, more, less等等 目录所需权限：使用者对这个目录至少需要具有 x 权限； 文件所需权限：使用者对文件至少需要具有 r 的权限才行！ 三、让使用者可以修改一个文件的基本权限为何？ 可使用的命令：例如 nano 或未来要介绍的 vi 编辑器等； 目录所需权限：使用者在该文件所在的目录至少要有 x 权限； 文件所需权限：使用者对该文件至少要有 r, w 权限 四、让一个使用者可以创建一个文件的基本权限为何？ 目录所需权限：使用者在该目录要具有 w,x 的权限，重点在 w 啦！ 五、让使用者进入某目录并运行该目录下的某个命令之基本权限为何？ 目录所需权限：使用者在该目录至少要有 x 的权限； 文件所需权限：使用者在该文件至少需要有 x 的权限]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-磁盘与文件系统管理]]></title>
    <url>%2F2016%2F07%2F24%2F%E6%8A%80%E6%9C%AF%2FDisk-and-fileSystem-management-of-Linux%2F</url>
    <content type="text"><![CDATA[认识EXT2文件系统每种操作系统能够使用的文件系统并不相同。 举例来说，windows 98以前的微软操作系统主要利用的文件系统是FAT(或FAT16)，windows 2000以后的版本有所谓的NTFS文件系统，至于Linux的正统文件系统则为Ext2(Linux second extended file system, ext2fs)这一个。此外，在默认的情况下，windows操作系统是不会认识Linux的Ext2的。 那么文件系统是如何运行的呢？这与操作系统的文件数据有关。较新的操作系统的文件数据除了文件实际内容外，通常含有非常多的属性，例如Linux操作系统的文件权限(rwx)与文件属性(拥有者、群组、时间参数等)。 文件系统通常会将这两部份的数据分别存放在不同的区块，权限与属性放置到inode中，至于实际数据则放置到data block区块中。 另外，还有一个超级区块(superblock)会记录整个文件系统的整体信息，包括inode与block的总量、使用量、剩余量等。 文件系统的简单操作磁盘的分割、格式化、检验与挂载 磁盘分区： fdisk, partprobe 磁盘格式化： mkfs, mke2fs 磁盘检验： fsck, badblocks 磁盘挂载与卸除： mount, umount 磁盘参数修订： mknod, e2label, tune2fs, hdparm 配置启动挂载 启动挂载 /etc/fstab 及 /etc/mtab 特殊装置 loop 挂载(映象档不刻录就挂载使用) 内存置换空间(swap)之建置 使用实体分割槽建置swap 使用文件建置swap swap使用上的限制 文件系统的特殊观察与操作 boot sector 与 superblock 的关系 磁盘空间之浪费问题 利用 GNU 的 parted 进行分割行为 重点回顾 基本上 Linux 的正统文件系统为 Ext2 ，该文件系统内的信息主要有： superblock：记录此 filesystem 的整体信息，包括inode/block的总量、使用量、剩余量， 以及文件系统的格式与相关信息等； inode：记录文件的属性，一个文件占用一个inode，同时记录此文件的数据所在的 block 号码； block：实际记录文件的内容，若文件太大时，会占用多个 block 。 Ext2 文件系统的数据存取为索引式文件系统(indexed allocation) 需要碎片整理的原因就是文件写入的 block 太过于离散了，此时文件读取的效能将会变的很差所致。 这个时候可以透过碎片整理将同一个文件所属的 blocks 汇整在一起。 Ext2文件系统主要有：boot sector, superblock, inode bitmap, block bitmap, inode table, data block 等六大部分。 data block 是用来放置文件内容数据地方，在 Ext2 文件系统中所支持的 block 大小有 1K, 2K 及 4K 三种而已 inode 记录文件的属性/权限等数据，其他重要项目为： 每个 inode 大小均固定为 128 bytes； 每个文件都仅会占用一个 inode 而已； 因此文件系统能够创建的文件数量与 inode 的数量有关； 文件的 block 在记录文件的实际数据，目录的 block 则在记录该目录底下文件名与其 inode 号码的对照表； 日志式文件系统 (journal) 会多出一块记录区，随时记载文件系统的主要活动，可加快系统复原时间； Linux 文件系统为添加效能，会让主存储器作为大量的磁盘高速缓存； 实体链接只是多了一个文件名对该 inode 号码的链接而已； 符号链接就类似Windows的快捷方式功能。 磁盘的使用必需要经过：分割、格式化与挂载，分别惯用的命令为：fdisk, mkfs, mount三个命令 启动自动挂载可参考/etc/fstab之配置，配置完毕务必使用 mount -a 测试语法正确否； 参考资料 鸟哥的Linux私房菜 第八章]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的装机必备软件]]></title>
    <url>%2F2016%2F07%2F20%2F%E6%8A%98%E8%85%BE%2F2016-07-20-software-tools-on-mylaptop%2F</url>
    <content type="text"><![CDATA[windows美化 RocketDock 实现mac上的Dock栏 TrueLancherBar 目录式的任务栏快捷操作入口 Q-Dir 1分4的资源管理器 Fliqlo 极客感十足的时钟屏保 fences2.01 桌面整理，提高效率 win10安装破解后，如出现桌面图标无法移动，需要安装破解补丁 破解补丁 实用工具 QQ Internet 国际版QQ，功能少，无广告，消息多时不卡顿 魔影工厂 音视频格式转换工具 镜像工具 DAEMON 虚拟光驱 V-Disk 虚拟光驱 UltraIso 光驱加载刻录 win32diskImager 镜像刻录 编辑器 MarkdownPad2 notepad++ 替换系统的记事本，打开大文件不卡死，语法高亮，可辅助编程 sublime text 3 同上，作为Python编辑器很方便 ultra edit 对二进制支持友好 虚拟机与镜像 VMware VirtualBox 客户机系统镜像下载，解压直接使用 360隔离沙箱 ：用来运行从网下二进制小程序， docker 翻墙工具 lantern ：自己编译生成的exe是免安装，无流量限制的 xx-net ：基于GoAgent实现的，第一次部署比较麻烦，流量每天1G*n（GAE apps） ss：配合ss服务器食用 安卓软件 微博国际版 日事清 Newton 邮件客户端 JuiceSSh 双开助手 BusyBox + 终端模拟器]]></content>
      <categories>
        <category>资源</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux 下配置sublime text]]></title>
    <url>%2F2016%2F07%2F11%2F%E6%8A%80%E6%9C%AF%2FSublime-Text3-On-Linux%2F</url>
    <content type="text"><![CDATA[Linux下配置sublime text Sublime Text是个跨平台的编辑器，支持Windows、Linux、Mac系统平台，支持各种语言的代码编辑，配合上对应的插件，话上点时间学习，你将会对它爱不释手，大大的提高你的编码效率。本文将讲解在Ubuntu 14.04系统中安装SublimeText 3，并配置SublimeClang插件来配置C/C++开发环境。 1. Sublime Text 3的下载安装 到官方网站上http://www.sublimetext.com/3下载64位（系统位64位）的.deb安装包（http://c758482.r82.cf2.rackcdn.com/sublime-text_build-3059_amd64.deb），下载后双击安装即可。安装好之后，通过命令subl即可打开程序，此时已经可以编写代码了。在开始之前建议先记下一些常用的快捷键，可参考：http://blog.csdn.net/cywosp/article/details/31791881 2. 安装Package ControlPackage Control是一个用于管理插件的好工具，可以用于安装、删除、禁用相应的插件，常用的插件都能在上面找到。其源码地址在https://github.com/wbond/package_control_channel上，安装非常方便，使用git将该代码先克隆下来即可，然后拷贝到~/.config/sublime-text-3/Packages/目录下并命名为Package Control即可。（也可以直接在github上打包下载，然后解压复制到~/.config/sublime-text-3/Packages/目录下并命名为Package Control）。 cd ~/.config/sublime-text-3/Packages/git clone https://github.com/wbond/package_control_channel.git Package\ Control 或者打开sublime_text然后按快捷键ctrl+`(Esc下面那个键)，在弹出的命令输入窗口输入下面信息回车即可： 12[python] view plain copyimport urllib.request,os,hashlib; h = &apos;2915d1851351e5ee549c20394736b442&apos; + &apos;8bc59f460fa1548d1514676163dafc88&apos;; pf = &apos;Package Control.sublime-package&apos;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( &apos;http://packagecontrol.io/&apos; + pf.replace(&apos; &apos;, &apos;%20&apos;)).read(); dh = hashlib.sha256(by).hexdigest(); print(&apos;Error validating download (got %s instead of %s), please try manual install&apos; % (dh, h)) if dh != h else open(os.path.join( ipp, pf), &apos;wb&apos; ).write(by) 重新启动SublimeText 3，然后使用快捷键Ctrl + Shift + p，在弹出的输入框中输入Package Control则可以看到Install Package的选项，选择它后一会儿（看左下角的状态）会弹出插件查询及安装窗口，输入想用的插件，选中回车即可。如果用于C/C++开发建议安装C++ snipptes，ConvertToUTF8，SublimeAStyleFormatter插件，具体代表什么意思baidu一下就清楚了。 3. 安装强大的SublimeClang插件 SublimeClang是Sublime Text中唯一的C/C++自动补全插件，功能强大，自带语法检查功能，不过最近作者已经停止更新了，目前只能在Sublime Text 2的Package Control中可以找到并自动安装，在SublimeText 3中只能手动通过源码安装，其代码线在https://github.com/quarnster/SublimeClang中。具体安装步骤如下：安装相关软件 12345678910sudo apt-get install cmake build-essential clang gitcd ~/.config/sublime-text-3/Packagesgit clone --recursive https://github.com/quarnster/SublimeClang SublimeClangcd SublimeClangcp /usr/lib/x86_64-linux-gnu/libclang-3.4.so.1 internals/libclang.so #这一步很重要，如果你的clang库不是3.4版本的话，请将对应版本的库拷贝到internals中cd srcmkdir buildcd buildcmake ..make 一切成功的话将会在SublimeClang/internals目录中生成libcache.so库文件。重启Sublime Text，然后按快捷键Ctrl + ~ (Esc下面那个键)打开自带的控制输出，看看有没有错误，如果没有错误就说明一切OK了。接下来就是配置自己的文件了，按下ctrl + shift + p快捷键，在弹出的输入框中输入 sublimeclang settings ，然后选择带User那一行，在打开的文件中输入如下信息： 123456789101112131415161718&#123; &quot;show_output_panel&quot;: false, &quot;dont_prepend_clang_includes&quot;: true, &quot;inhibit_sublime_completions&quot;: false, &quot;options&quot;: [ &quot;-std=gnu++11&quot;, &quot;-isystem&quot;, &quot;/usr/include&quot;, &quot;-isystem&quot;, &quot;/usr/include/c++/*&quot;, &quot;-isystem&quot;, &quot;/usr/include/c++/4.8&quot;, &quot;-isystem&quot;, &quot;/usr/include/c++/4.8/*&quot;, &quot;-isystem&quot;, &quot;/usr/include/boost&quot;, &quot;-isystem&quot;, &quot;/usr/include/boost/**&quot;, &quot;-isystem&quot;, &quot;/usr/lib/gcc/x86_64-linux-gnu/4.8/include&quot;, &quot;-isystem&quot;, &quot;/usr/lib/gcc/x86_64-linux-gnu/4.8/include/*&quot; ]&#125; 注释：我的gcc版本为4.8，如果你的不是请替换对应的版本，在#include相应的头文件后保存当前文件，在接下来的操作中将更快的提示所包含在头文件的函数或者变量。 4. 工程实例通过菜单栏中的Project -&gt; Add Folder To Project…把你已有的原代码目录加入到Sublime Text中，然后通过Project -&gt; Save Project As…来保存你的项目，这样就创建好了项目。例如我的机器在/media/WinE/WorkStation/Swift中有个C++项目，代码分别放在了Swift下的swift/base和swift/disruptor两个目录下，现在想要把这两个目录中的内容在写代码时能够自动提示则需要相应的配置修改。Project -&gt; Edit Project，在所打开的配置文件中我更改如下： 12345678910111213141516171819&#123; &quot;folders&quot;: [ &#123; &quot;follow_symlinks&quot;: true, &quot;path&quot;: &quot;/media/WinE/WorkStation/Swift&quot; &#125; ], &quot;settings&quot;: &#123; &quot;sublimeclang_options&quot;: [ &quot;-I/media/WinE/WorkStation/Swift&quot;, &quot;-I/media/WinE/WorkStation/Swift/swift/base&quot;, &quot;-I/media/WinE/WorkStation/Swift/swift/disruptor&quot;, ] &#125;&#125;]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习笔记-3]]></title>
    <url>%2F2016%2F07%2F06%2F%E6%8A%80%E6%9C%AF%2FPython3-study%2F</url>
    <content type="text"><![CDATA[正则表达式 通过正则表达式匹配字符串，\w+\@\w+.\w+ 匹配一个邮箱地址，\w可以匹配一个数字或字母，\d \D \s \S,[a-z,A-Z,0-9,_] 取值范围；[P|p]ython 匹配Python或python；^\d 必须以数字开头； \d$ 必须以数字结尾； re模块 判断字符串是否匹配re.match() 12345test = &apos;用户输入的字符串&apos;if re.match(r&apos;正则表达式&apos;, test): print &apos;ok&apos;else: print &apos;failed&apos; 切分字符串，用正则表达式试试： 12&gt;&gt;&gt; re.split(r&apos;\s+\,\;&apos;, &apos;a b c&apos;)[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;] 分组正则表达式还有提取子串的强大功能。用()表示的就是要提取的分组（Group） 1234567891011121314&gt;&gt;&gt; m = re.match(r&apos;^(\d&#123;3&#125;)-(\d&#123;3,8&#125;)$&apos;, &apos;010-12345&apos;)&gt;&gt;&gt; m&lt;_sre.SRE_Match object at 0x1026fb3e8&gt;&gt;&gt;&gt; m.group(0) # `group(0)`永远是原始字符串&apos;010-12345&apos;&gt;&gt;&gt; m.group(1)&apos;010&apos;&gt;&gt;&gt; m.group(2)&apos;12345&apos;&gt;&gt;&gt; t = &apos;19:05:30&apos;&gt;&gt;&gt; m = re.match(r&apos;^(0[0-9]|1[0-9]|2[0-3]|[0-9])\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9]|[0-9])\:(0[0-9]|1[0-9]|2[0-9]|3[0-9]|4[0-9]|5[0-9]|[0-9])$&apos;, t)&gt;&gt;&gt; m.groups()(&apos;19&apos;, &apos;05&apos;, &apos;30&apos;) 预编译一个匹配模式被多次用到，可以先预编译，re.compile(‘string’) 贪婪模式 常用内建模块collections namedtuple 12345678&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; Point = namedtuple(&apos;Point&apos;, [&apos;x&apos;, &apos;y&apos;]) #定义一个点&gt;&gt;&gt; Circle = namedtuple(&apos;Circle&apos;, [&apos;x&apos;, &apos;y&apos;, &apos;r&apos;])#定义一个圆&gt;&gt;&gt; p = Point(1, 2)&gt;&gt;&gt; p.x #按属性访问&gt;&gt;&gt; 1&gt;&gt;&gt; p.y&gt;&gt;&gt; 2 deque 双向列表，deque是为了高效实现插入和删除操作的双向列表，适合用于队列和栈 123456&gt;&gt;&gt; from collections import deque&gt;&gt;&gt; q = deque([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;])&gt;&gt;&gt; q.append(&apos;x&apos;)&gt;&gt;&gt; q.appendleft(&apos;y&apos;)&gt;&gt;&gt; q&gt;&gt;&gt; deque([&apos;y&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;x&apos;]) deque除了实现list的append()和pop()外，还支持appendleft()和popleft()，这样就可以非常高效地往头部添加或删除元素。 defaultdict 使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict： 1234567&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt; dd = defaultdict(lambda: &apos;N/A&apos;)&gt;&gt;&gt; dd[&apos;key1&apos;] = &apos;abc&apos;&gt;&gt;&gt; dd[&apos;key1&apos;] # key1存在&gt;&gt;&gt; &apos;abc&apos;&gt;&gt;&gt; dd[&apos;key2&apos;] # key2不存在，返回默认值&gt;&gt;&gt; &apos;N/A&apos; 注意默认值是调用函数返回的，而函数在创建defaultdict对象时传入。 除了在Key不存在时返回默认值，defaultdict的其他行为跟dict是完全一样的。 OrderedDict 使用dict时，Key是无序的。在对dict做迭代时，我们无法确定Key的顺序。如果要保持Key的顺序，可以用OrderedDict： 1234567&gt;&gt;&gt; from collections import OrderedDict&gt;&gt;&gt; d = dict([(&apos;a&apos;, 1), (&apos;b&apos;, 2), (&apos;c&apos;, 3)])&gt;&gt;&gt; d # dict的Key是无序的&gt;&gt;&gt; &#123;&apos;a&apos;: 1, &apos;c&apos;: 3, &apos;b&apos;: 2&#125;&gt;&gt;&gt; od = OrderedDict([(&apos;a&apos;, 1), (&apos;b&apos;, 2), (&apos;c&apos;, 3)])&gt;&gt;&gt; od # OrderedDict的Key是有序的&gt;&gt;&gt; OrderedDict([(&apos;a&apos;, 1), (&apos;b&apos;, 2), (&apos;c&apos;, 3)]) 注意，OrderedDict的Key会按照插入的顺序排列，不是Key本身排序： 123456&gt;&gt;&gt; od = OrderedDict()&gt;&gt;&gt; od[&apos;z&apos;] = 1&gt;&gt;&gt; od[&apos;y&apos;] = 2&gt;&gt;&gt; od[&apos;x&apos;] = 3&gt;&gt;&gt; od.keys() # 按照插入的Key的顺序返回&gt;&gt;&gt; [&apos;z&apos;, &apos;y&apos;, &apos;x&apos;] OrderedDict可以实现一个FIFO（先进先出）的dict，当容量超出限制时，先删除最早添加的Key： 12345678910111213141516171819from collections import OrderedDictclass LastUpdatedOrderedDict(OrderedDict): def __init__(self, capacity): super(LastUpdatedOrderedDict, self).__init__() self._capacity = capacity def __setitem__(self, key, value): containsKey = 1 if key in self else 0 if len(self) - containsKey &gt;= self._capacity: last = self.popitem(last=False) print 'remove:', last if containsKey: del self[key] print 'set:', (key, value) else: print 'add:', (key, value) OrderedDict.__setitem__(self, key, value) Counter Counter是一个简单的计数器，例如，统计字符出现的个数： 1234567&gt;&gt;&gt; from collections import Counter&gt;&gt;&gt; c = Counter()&gt;&gt;&gt; for ch in &apos;programming&apos;:&gt;&gt;&gt; ... c[ch] = c[ch] + 1&gt;&gt;&gt; ...&gt;&gt;&gt; c&gt;&gt;&gt; Counter(&#123;&apos;g&apos;: 2, &apos;m&apos;: 2, &apos;r&apos;: 2, &apos;a&apos;: 1, &apos;i&apos;: 1, &apos;o&apos;: 1, &apos;n&apos;: 1, &apos;p&apos;: 1&#125;) Counter实际上也是dict的一个子类，统计的元素作为key，出现次数是key的值。 base64对二进制数据进行处理，每3个字节一组，一共是3x8=24bit，划为4组，每组正好6个bit，对应编码规则里定义的64个字符。二进制字节不是3的倍数，Base64用\x00字节在末尾补足后，再在编码的末尾加上1个或2个=号。解码的=。urlsafe编码，把字符+和/分别变成-和_。字符+和/，在URL中就不能直接作为参数。 123456&gt;&gt;&gt; base64.b64encode('i\xb7\x1d\xfb\xef\xff')'abcd++//'&gt;&gt;&gt; base64.urlsafe_b64encode('i\xb7\x1d\xfb\xef\xff')'abcd--__'&gt;&gt;&gt; base64.urlsafe_b64decode('abcd--__')'i\xb7\x1d\xfb\xef\xff' struct Python提供了一个struct模块来解决str和其他二进制数据类型的转换。 struct的pack函数把任意数据类型变成字符串： 123&gt;&gt;&gt; struct.unpack(&apos;&gt;IH&apos;, &apos;\xf0\xf0\xf0\xf0\x80\x80&apos;)(4042322160, 32896)### &gt;IH的说明，后面的str依次变为I：4字节无符号整数和H：2字节无符号整数,&gt;表示大端存储方式 struct模块定义的数据类型可以参考： Python官方文档 hashlib用户名如果不可变可以作为salt与passwd一起hash 12345678910import hashlibmd5 = hashlib.md5()md5.update('how to use md5 in python hashlib?')print md5.hexdigest() import hashlibsha1 = hashlib.sha1()sha1.update('how to use sha1 in ')sha1.update('python hashlib?') #多次update和一次做完结果一样print sha1.hexdigest() itertools count() cycle() repeat() chain() groupby() imap() imap()可以作用于无穷序列，并且，如果两个序列的长度不一致，以短的那个为准。 12for x in itertools.imap(lambda x, y: x * y, [10, 20, 30], itertools.count(1)): print x 注意imap()返回一个迭代对象，而map()返回list。当你调用map()时，已经计算完毕.当你调用imap()时，并没有进行任何计算,必须用for循环迭代，每次计算出一个元素。 ifliter() XMLHTMLParser###第三方模块 PILNumpy图形界面网络编程TCP/IPTCP编程UDP编程电子邮件SMTP发送邮件pop3接收邮件访问数据库使用SQLite使用MySQL使用SQLAlchemyWeb开发HTTP协议HTMLWSGI接口使用Web框架使用模板协程12]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux基础学习笔记]]></title>
    <url>%2F2016%2F07%2F05%2F%E6%8A%80%E6%9C%AF%2FLinux%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Linux简介系统安装与grub引导 系统运行级别6级，0：关机；1：单用户模式，进行系统维护；2：多用户，无网络连接；3：完全多用户模式，默认不用图形化；4：保留；5：窗口模式，多用户；6：重启。 安装linux grub系统引导 登陆系统有图形登陆、终端登陆、远程终端登陆。 linux默认提供6个终端，使用ctrl + alt + F1~F6切换。 使用ctrl + alt + F7切回桌面图形登陆。 在字符终端中使用startx可以启动图形桌面。 终端用户退出登陆exit. 常用命令 lsls -al 查看详细信息，ls -lh 文件的大小自适应显示(GB,MB,KB),使用参数--block-size=m 指定文件大小的单位。 pwd cd cat ps ifconfig netstat -ano 查看命令帮助文档 man 和 info在查看结果中 使用 /keyword进行关键字搜索，n向下查找，N向上查找。空格向下翻页，pageup/pagedown翻页，q退出查看。 123$ man -f reboot man -f 查看命令位于哪些man文件里$ man 2 reboot 查看2号文档里的reboot命令$ info ls 获取ls命令的说明文档 用户管理用户和用户组 UIDUID为0的是root超级用户，1~500是系统用户，500以后是普通用户。 GID一个用户可以属于多个组 12345$ id 查看自己的uid$ group 查看自己的gid$ whoami 查看用户自己的信息$ who 查看当前已登录的用户信息$ w 查看更详细的用户信息 /etc/passwd /etc/shadow两个文件记录了用户的用户名和密码。 账号管理和用户切换 增加删除用户 1234# useradd -u 555 - g group1 -d /home/john -s /bin/bash john 指定uid，加入的组，家目录，shell路径，组必须是已经存在的# useradd -G group1,group2 john -G加入一系列的组# userdel john 删除了john用户，从shadow中清除记录，用户文件还在# userdel -r john 删除john的home目录和邮件 修改密码和删除密码 1234567# passwd 不加参数则是修改当前用户的密码# passwd user1 修改user1的密码，新建的用户必须修改密码后才能登陆# passwd -d user1 删除密码，即密码为空# passwd -l user1 禁用user1的密码，实际在shadow文件的记录前加了`!`# passwd -u user1 解锁账号# usermod -L user1 # usermod -U user1 原理同上 修改用户# usermod 增加删除组 12# groupadd group1 新增group1# groupdel group1 删除用户组，如果组内有用户，则删除失败 切换用户 123456$ su 直接切换到root用户，当前用户环境不变，工作目录，shell等# exit 退出root，切回普通用户$ su - 切换到root用户，同时使用root用户环境# su - john 切换为john用户，root切换为任何user无需密码， 普通user相互切换要知道user密码$ sudo command 普通用户以root身份执行某条命令，输入自己的密码即可 用户能否使用sudo命令，在/etc/sudoers中配置。使用visudo命令进行配置。123456789# User privilege specificationroot ALL=(ALL:ALL) ALLjohn ALL=(ALL:ALL) ALLluna ALL=(ALL:ALL) NOPASSWD:/sbin/shutdown# 在此处添加，允许john 从任何地方登陆后，执行任何人的，任何命令,对应3个all# 允许luna 不用输密码即可执行 sudo shutdown 命令。# Members of the admin group may gain root privileges%admin ALL=(ALL) ALL# 允许admin组的所有成员，......执行sudo 文件管理文件和目录管理和权限 目录结构 123456789101112131415161718/├── bin 常见用户指令├── boot 内核和启动文件├── cdrom 光驱挂载位置├── dev 设备文件├── etc 系统和服务配置├── home 用户主目录├── lib 系统函数库├── lib64├── lost+found ext3 文件系统用于磁盘检查├── media 挂载u盘等临时文件系统├── mnt 系统加载文件系统的挂载点├── opt 第三方软件安装目录├── root root用户主目录├── sbin 系统管理命令├── tmp 临时文件存放目录├── usr 存放和用户直接相关的文件├── var 路径和特殊目录绝对路径，从/根路径开始，比如/root/abc;当前路径，pwd命令可以查看。shell命令执行默认基于当前路径；特殊目录.和..，分别表示当前目录和当前目录的父目录。相对路径，从当前路径开始计算,通常配合.和..使用。 文件操作 1234567891011121314151617181920212223### 文件创建$ touch a.txt touch一个已存在的文件，会更新其时间戳属性$ vi a.txt$ echo &apos;XXX&apos; &gt; a.txt### 删除文件$ rm -f a.txt 直接删除，不用确认### 复制、移动文件$ cp a.txt /home/test/$ cp a.txt /path/to/b.txt 可以实现重命名$ mv a.txt /path/to/filename$ mv a.txt /path/to/### 文件查看$ cat readme.txt$ cat -n readme.txt 查看文件时显示行号$ head readme.txt 默认显示前10行内容$ head -n 20 readme.txt 查看前20行内容$ tail readme.txt 查看最后10行内容，-n 指定显示的行数目$ tail -f error.log 文件不断写入时，可以动态查看文件末尾的内容### 改变属主# chown john a.txt 改变a的所有者为john用户# chown :john a.txt 改变a的所有组为john组# chown -R john:john dir_a 递归改变dir_a下所有文件的所有组为john，所有者为john# chgrp -R john dir_b 递归改变所有组 目录操作 123$ cd /home/ 进入到指定目录$ mkdir dir_a 创建目录$ rm -rf dir_a 删除目录及其包含的全部内容，无需确认 权限和属性 1234567891011# ls -al总用量 1712drwx------ 27 root root 4096 10月 31 12:54 .-rw------- 1 root root 16213 10月 30 22:25 .bash_history#第一个字符的含义：d目录，-普通文件，l链接文件，b块文件， c字符文件，s socket文件，p管道文件#接下来的3组 X 3个字符，表示文件所有者，文件所有组和其他用户对该文件的权限# rwx为可读、可写、可执行，-表示不拥有该位置的权限 # 第二列的数字为连接数，文件为1，目录为其包含的目录数（包括特殊目录.和..）# 第三四列 为文件的所有人和所有组# 第五列文件大写，第六列文件最近修改时间 文件隐藏属性a和i123456# lsattr run_dedicated_servers.sh -------------e-- run_dedicated_servers.sh## 有13个短横，# chattr +a a.ttx append,a属性的文件即使root也不能删除，可以追加的方式写文件# chattr +i b.txt i属性确保文件无法删除写入和改名，常用于关键配置文件# man chattr 查看更多 文件特殊属性SUID/SGID/Sticky1234567891011# ll /usr/bin/passwd -rwsr-xr-x 1 root root 54256 3月 29 2016 /usr/bin/passwd*### 原本的执行权限x变成了s，表示其他用户可以以文件的所有者身份来执行该文件### SGID与SUID类似，都只能用于可执行文件# chmod u+s ‘可执行文件’ 设置SUID# chmod g+s ‘可执行文件’ 设置SGID，用的较少### Sticky属性用于目录# ll -d /tmpdrwxrwxrwt 26 root root 4096 10月 31 14:24 /tmp/### 最后一个t表示，任何人都能在此创建修改文件，但只有owner和root可以删除文件。# chmod o+t ‘目录’ 添加t属性 默认权限和umask，用户或系统创建的文件有默认的权限设置，root和普通用户创建文件，权限为644，root的目录为755，普通用户的为775. 文件查找 findfind PATH -name FILENAME locatelocate查找依赖一个数据库，因此使用之前一般先执行updatedb。 which/whereis 查找可执行文件which command可以找到命令所在位置，which在path路径中查找。whereis同时给出相关man文件。 文件压缩解压1234567# gzip a.txt 压缩成gz格式压缩包# gunzip a.txt.gz 解压# tar -zcvf a.tar.gz /home/a 创建压缩文件### 参数z，使用gzip压缩；参数c，创建压缩文件；参数f，使用文件名；参数v，详情模式；# tar -zxvf a.tar.gz -C /tmp -C 指定解压到的目录# bzip2 -z a 压缩得到bz2格式的压缩包# bzip2 -d a.bz2 解压文件 文件系统磁盘分区，文件系统的挂载和卸载1234# fdisk -l 查看磁盘设备和分区# mount DEVICE MOUNT_POINT 将设备挂载到指定位置### 设备自动挂载，在/etc/fstab中配置# df -h 查看磁盘使用情况 linux逻辑卷硬链接和软链接硬链接：多个文件名指向同一个文件的inode索引节点，使得一个文件拥有多个合法的路径。删除一个硬链接不会影响其他的硬链接和文件本身。目录无法创建硬链接，不同文件系统/分区之间不能建立硬链接。ln &#39;源文件&#39; &#39;新建硬链接文件&#39;软连接：包含指向另一个文件的路径，类似windows的快捷方式。ln -s &#39;源文件&#39; &#39;新建软连接&#39; 字符处理管道和grep管道连接符command1 | command2，将command1的输出作为command2的输入。grep文本搜索123$ cat a.txt | grep &apos;name&apos; 打印含有name的行$ grep [-ivnc] &apos;search_str&apos; CONTENT/FILE### i忽略大小写，v反向选择，n同时输出行号，c统计匹配的行数 sort排序和uniq去重1234567891011### sort参数，-t指定分割符，k排序的列，n以数字排序，默认是字符排序，r反向排序，即降序# sort -t &apos;:&apos; -k 3 -n /etc/passwd daemon:*:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:*:2:2:bin:/bin:/usr/sbin/nologinsys:*:3:3:sys:/dev:/usr/sbin/nologinsync:*:4:65534:sync:/bin:/bin/syncgames:*:5:60:games:/usr/games:/usr/sbin/nologinman:*:6:12:man:/var/cache/man:/usr/sbin/nologinlp:*:7:7:lp:/var/spool/lpd:/usr/sbin/nologin### uniq只能去除连续重复的行，因此一般配合sort使用# uniq -ic CONTENT 忽略大小写，输出该行重复的次数 cut、tr、paste、split网络管理网络配置和dns配置1234567891011121314151617181920$ ifconfig 查看网卡信息eth0 Link encap:以太网 硬件地址 f4:8e:38:b8:1e:fd inet 地址:172.16.27.118 广播:172.16.27.255 掩码:255.255.252.0 inet6 地址: fe80::ec5d:eb79:5e03:112/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 跃点数:1 接收数据包:1002 错误:0 丢弃:3 过载:0 帧数:0 发送数据包:147 错误:0 丢弃:0 过载:0 载波:0 碰撞:0 发送队列长度:1000 接收字节:107932 (107.9 KB) 发送字节:18302 (18.3 KB)eth1 ***lo ***wlan ***$ ifconfig eth0 查看指定网卡### ifconfig动态修改网卡的配置，重启后失效# ifconfig eth0 192.168.159.130 netmask 255.255.255.0# ifconfig eth0 192.168.159.130/24 指定eth0的ip和子网# ifconfig eth0 down 停用网卡# ifconfig eth0 up 启用网卡# ifdown/ifup eth0 效果同上# route add/del default gw 192.168.8.1 修改网关 修改网卡配置文件1234567891011121314/etc/network/interfaces文件默认的内容如下： auto lo iface lo inet loopback 在后面添加内容 1、获取动态配置： auto eth0 iface eth0 inet dhcp 2、获取静态配置： auto eth0 iface eth0 inet static address 192.168.0.1 netmask 255.255.255.0 gateway 192.168.0.1 重启networking服务 修改DNS配置1234567永久修改网卡DNSsudo –icd /etc/resolvconf/resolv.conf.dvim base添加如下内容nameserver 8.8.8.8nameserver 8.8.4.4 网络测试 ping发icmp echo请求，判断主机是否可达 hosthost命令查询DNS记录 traceroute追溯数据包所经过的路由 网络故障排查1、ping 127.0.0.1 判断网卡工作是否正常，tcp/ip协议栈出问题2、ping 本机ip 判断本地设备驱动/物理端口3、ping 同网段其他主机 看交换机是否正常4、ping 网关ip5、ping 公网ip ，本地路由，nat6、ping 公网域名 dns设置是否正确 进程管理查看进程1234567# ps aux 显示所有包含其他使用者的有效进程USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.1 119732 5812 ? Ss 16:49 0:01 /sbin/init splashroot 2 0.0 0.0 0 0 ? S 16:49 0:00 [kthreadd]# top 查看结果是实时动态变化的# 按下O，大写的，进入排序过滤器，然后... 杀死进程12345678910#### 先查看要杀死进程的PID# ps -ef | grep &apos;ssh&apos;root 975 1 0 16:49 ? 00:00:00 /usr/sbin/sshd -Droot 3291 975 0 16:50 ? 00:00:00 sshd: root@pts/8root 4873 3782 0 20:05 pts/8 00:00:00 grep --color=auto ssh# pidof sshd3291 975# kill 3291 停止pid = 3291的进程# kill -1 pid 1重启，9强制退出，15正常退出（默认）# killall sshd 停止进程，跟进程名 查询进程打开的文件1234567891011# lsof -i:22 查询打开22端口的进程COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 975 root 3u IPv4 19938 0t0 TCP *:ssh (LISTEN)sshd 975 root 4u IPv6 19940 0t0 TCP *:ssh (LISTEN)# lsof -c sshd 显示COMMAND中包含指定字符串的进程所打开的全部文件COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 975 root cwd DIR 8,2 4096 2 /sshd 975 root rtd DIR 8,2 4096 2 /sshd 975 root txt REG 8,2 799216 12328642 /usr/sbin/# lsof FILENAME 显示所有打开FILENAME文件的进程 进程优先级调整：nice、renice使用top时，可以看到进程的NI、PR字段。NI表示进程优先级，取值-20~19，默认为0。普通用户可以设置进程NI值0~19.PR是动态优先级，系统进程调用采取的’动态优先级‘调度算法。最终程序的优先级是NI+PR，定义和修改进程优先级nice和renice12345# topPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 119732 5812 3904 S 0.0 0.1 0:01.58 systemd# nice -n -12 ./job.sh 设定程序运行时的优先级为-12# renice -10 -p 5555 将优先级调整为-10 编译、安装软件安装包管理器编译安装执行定时任务 at crontab screen crontabcrontab用于配置定时任务，并交由cond进程调度。 定时任务的脚本文件应具有可执行权限，并且使用绝对路径。 12#!/bin/shcd /home/ubuntu/kickstarter/ &amp;&amp; scrapy crawl new_project_spider crontab -e 编辑任务 crontab -l 查看任务 添加任务后， crontab 会自动的帮我们每分钟重新读取一次/etc/crontab的例行工作事项，但是某些原因或者是其他的 Unix 系统中，由于 crontab 是读到内存当中的，所以在你修改完/etc/crontab 之后，可能并不会马上运行， 这个时候请重新启动 crond 这个服务吧！/etc/init.d/crondrestart 或 service crond restart crontab任务格式 分 时 日 月 周 任务命令 * 表示任意时刻都接受 比如每天12点，0 12 * * * /path/to/run.sh&amp; ,分隔，表示或，比如12点或0点，0 0,12 * * * /path/to/run.sh -表示一段时间内，比如0点到8点每个小时都执行一次， 0 0-8 * * * /path/to/run.sh /n 每间隔n执行一次， 比如每五分钟执行一次， */5 * * * * /path/to/run.sh 周几和日月是互斥的，只能二选一 crontab执行日志 tail -100 /var/log/cron 在ubuntu下安装crontab后，系统默认的是不开启crontab的日志记录的，启用crontab的日志的办法：修改rsyslog文件，将/etc/rsyslog.d/50-default.conf 文件中的#cron.*前的#删掉；重启rsyslog服务service rsyslog restart；重启cron服务service cron restart；代码如下:more /var/log/cron.log；就可以查看运行时的日志文件，如果在日志文件中出现：代码如下:No MTA installed, discarding output那么就是说，crontab执行脚本时是不会直接错误的信息输出，而是会以邮件的形式发送到你的邮箱里，这时候就需要邮件服务器了，如果你没有安装邮件服务器，它就会报这个错。如果是测试，可以用下面的办法来解决：在每条定时脚本后面加入：代码如下: /dev/null 2&gt;&amp;1 后台执行&amp; 和 输出重定向&gt; /path/to/run.sh &amp; 表示后台运行命令 0 2 * * * /u01/test.sh &gt;/dev/null 2&gt;&amp;1 &amp; 后台运行，错误输出重定向到1，标准输出清空，即输入到null。 0 键盘输入 1 标准输出 2 错误输出 screen 和 nohub nohup sh 22.sh将任务放到后台，关闭标准输入，前台不再能够接收任何输入（标准输入），重定向标准输出和标准错误到当前目录下的nohup.out文件，即使关闭xshell退出当前session依然继续运行。 nohup sh 22.sh &amp;将任务放到后台，但是依然可以使用标准输入，前台能够接收任何输入，重定向标准输出和标准错误到当前目录下的nohup.out文件，即使关闭xshell退出当前session依然继续运行。 supervisor正则表达式与sed、awkvi和vim# TODO shell编程# TODO]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习笔记-2]]></title>
    <url>%2F2016%2F07%2F04%2F%E6%8A%80%E6%9C%AF%2Fpython2-study%2F</url>
    <content type="text"><![CDATA[错误、调试、测试 try机制 12345678910 try: print 'try...' r = 10 / 0 #此处出现异常直接跳转到except print 'result:', r except ZeroDivisionError, e: print 'except:', e finally: # 若没有错误发生，except语句块不会被执行，但是finally如果有，则一定会被执行（可以没有finally语句）。#此外，如果没有错误发生，可以在except语句块后面加一个else，当没有错误发生时，会自动执行else语句： print 'finally...'print 'END' 错误类型都继承自BaseException，所以在使用except时需要注意的是，它不但捕获该类型的错误，还把其子类也“一网打尽”。比如ValueError是StandardError的子类，如果有except先捕获了StandardError，则第二个except就捕获不到ValueError。 记录错误 Python内置的logging模块可以非常容易地记录错误信息。logging.exception(e) 抛出错误如果要抛出错误，首先根据需要，可以定义一个错误的class，选择好继承关系，然后，用raise语句抛出一个错误的实例 12345678class FooError(StandardError): pass# 只有在必要的时候才定义我们自己的错误类型。如果可以选择Python已有的内置的错误类型（比如ValueError，TypeError），尽量使用Python内置的错误类型。def foo(s): n = int(s) if n==0: raise FooError('invalid value: %s' % s) return 10 / n 一种常见的抛出用法 12345678910def foo(s): n = int(s) return 10 / n def bar(s): try: return foo(s) * 2 except StandardError, e: #此处捕获只是为了记录错误，如果无法处理，可以上抛 print 'Error!' raise 调试 简单粗暴的print将可能出错的变量打印出来，print太多的话看着不爽 断言凡是用print来辅助查看的地方，都可以用断言（assert）来替代，assert n!=0,’n is zero’ ,如果断言失败，assert语句本身就会抛出AssertionError：n is zero运行时加参数-O可以关闭断言。 logging 12345678import logginglogging.basicConfig(level=logging.INFO) #它允许你指定记录信息的级别，有debug，info，warning，error等几个级别，#当我们指定level=INFO时，logging.debug就不起作用了。#同理，指定level=WARNING后，debug和info就不起作用了s = '0'n = int(s)logging.info('n = %d' % n)print 10 / n IDE 断点据说最好的IDE是pycharm，我用的是wing IDE，有个debug probe窗口，可以程序断点暂停后进行python命令交互，print之类的。编辑器推荐sublime text。 单元测试“测试驱动开发”（TDD：Test-Driven Development）；编写单元测试时，我们需要编写一个测试类，从unittest.TestCase继承。以test开头的方法就是测试方法，不以test开头的方法不被认为是测试方法，测试的时候不会被执行。 对每一类测试都需要编写一个test_xxx()方法。 由于unittest.TestCase提供了很多内置的条件判断，我们只需要调用这些方法就可以断言输出是否是我们所期望的。最常用的断言就是assertEquals()： 另一种重要的断言assertRaises()就是期待抛出指定类型的Error，比如通过d[&#39;empty&#39;]访问不存在的key时，断言会抛出KeyError：运行测试单元if __name__ == &#39;__main__&#39;: unittest.main()可以在单元测试中编写两个特殊的setUp()和tearDown()方法。这两个方法会分别在每调用一个测试方法的前后分别被执行 文档测试Python内置的“文档测试”（doctest）模块可以直接提取注释中的代码并执行测试。 IO 文件读写 123456789try: f = open('/path/to/file', 'r') print f.read()finally: if f: f.close()# 或者 使用with，Python会自动调用close方法with open('/path/to/file', 'r') as f: print f.read() 调用read()会一次性读取文件的全部内容，如果文件有10G，内存就爆了，所以，要保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容。另外，调用readline()可以每次读取一行内容，调用readlines()一次读取所有内容并按行返回list。因此，要根据需要决定怎么调用。 如果文件很小，read()一次性读取最方便；如果不能确定文件大小，反复调用read(size)比较保险；如果是配置文件，调用readlines()最方便 1234for line in f.readlines(): print line.strip() #strip()删除字符串末尾的回车等字符。os.mknod("new.txt")#创建空白新文件 fp=open('a.txt','w')#打开一个文件，如果不存在则创建文件 文件操作 fp.read([size]) #size为读取的长度，以byte为单位 fp.readline([size]) #读一行，如果定义了size，有可能返回的只是一行的一部分 fp.readlines([size]) #把文件每一行作为一个list的一个成员，并返回这个list。其实它的内部是通过循环调用readline()来实现的。如果提供size参数，size是表示读取内容的总长，也就是说可能只读到文件的一部分。 fp.write(str) #把str写到文件中，write()并不会在str后加上一个换行符 fp.writelines(seq) #把seq的内容全部写到文件中(多行一次性写入)。这个函数也只是忠实地写入，不会在每行后面加上任何东西。 fp.close() #关闭文件。python会在一个文件不用后自动关闭文件，不过这一功能没有保证，最好还是养成自己关闭的习惯。 如果一个文件在关闭后还对其进行操作会产生ValueError fp.flush() #把缓冲区的内容写入硬盘 fp.fileno() #返回一个长整型的”文件标签“ fp.isatty() #文件是否是一个终端设备文件（unix系统中的） fp.tell() #返回文件操作标记的当前位置，以文件的开头为原点 fp.next() #返回下一行，并将文件操作标记位移到下一行。把一个file用于for … in file这样的语句时，就是调用next()函数来实现遍历的。 fp.seek(offset[,whence]) #将文件打操作标记移到offset的位置。这个offset一般是相对于文件的开头来计算的，一般为正数。但如果提供了whence参数就不一定了，whence可以为0表示从头开始计算，1表示以当前位置为原点计算。2表示以文件末尾为原点进行计算。需要注意，如果文件以a或a+的模式打开，每次进行写操作时，文件操作标记会自动返回到文件末尾。 fp.truncate([size]) #把文件裁成规定的大小，默认的是裁到当前文件操作标记的位置。如果size比文件的大小还要大，依据系统的不同可能是不改变文件，也可能是用0把文件补到相应的大小，也可能是以一些随机的内容加上去。 open模式 w 以写方式打开，a 以追加模式打开 (从 EOF 开始, 必要时创建新文件)r+ 以读写模式打开w+ 以读写模式打开 (参见 w )a+ 以读写模式打开 (参见 a )rb 以二进制读模式打开wb 以二进制写模式打开 (参见 w )ab 以二进制追加模式打开 (参见 a )rb+ 以二进制读写模式打开 (参见 r+ )wb+ 以二进制读写模式打开 (参见 w+ )ab+ 以二进制读写模式打开 (参见 a+ ) 目录操作 os.mkdir(“file”) 创建目录复制文件：shutil.copyfile(“oldfile”,”newfile”) oldfile和newfile都只能是文件shutil.copy(“oldfile”,”newfile”) oldfile只能是文件夹，newfile可以是文件，也可以是目标目录复制文件夹：shutil.copytree(“olddir”,”newdir”) olddir和newdir都只能是目录，且newdir必须不存在重命名文件（目录）os.rename(“oldname”,”newname”) 文件或目录都是使用这条命令移动文件（目录）shutil.move(“oldpos”,”newpos”) 删除文件os.remove(“file”)删除目录os.rmdir(“dir”)只能删除空目录shutil.rmtree(“dir”) 空目录、有内容的目录都可以删转换目录os.chdir(“path”) 换路径 文件或文件夹操作python中对文件、文件夹 （文件操作函数） 的操作需要涉及到os模块和shutil模块。 得到当前工作目录，即当前Python脚本工作的目录路径: os.getcwd() 返回指定目录下的所有文件和目录名:os.listdir() 函数用来删除一个文件:os.remove() 删除多个目录：os.removedirs（r“c：\python”） 检验给出的路径是否是一个文件：os.path.isfile() 检验给出的路径是否是一个目录：os.path.isdir() 判断是否是绝对路径：os.path.isabs() 检验给出的路径是否真地存:os.path.exists() 返回一个路径的目录名和文件名:os.path.split() eg os.path.split(‘/home/swaroop/byte/code/poem.txt’) 结果：(‘/home/swaroop/byte/code’, ‘poem.txt’) 分离扩展名：os.path.splitext() 获取路径名：os.path.dirname() 获取文件名：os.path.basename() 运行shell命令: os.system() 读取和设置环境变量:os.getenv() 与os.putenv() 给出当前平台使用的行终止符:os.linesep Windows使用’\r\n’，Linux使用’\n’而Mac使用’\r’ 指示你正在使用的平台：os.name 对于Windows，它是’nt’，而对于Linux/Unix用户，它是’posix’os.uname() 系统详细版本，Windows上无 重命名：os.rename（old， new） 创建多级目录：os.makedirs（r“c：\python\test”） 创建单个目录：os.mkdir（“test”） 获取文件属性：os.stat（file） 修改文件权限与时间戳：os.chmod（file） 终止当前进程：os.exit（） 获取文件大小：os.path.getsize（filename） 比如我们要列出当前目录下的所有目录，只需要一行代码： 12&gt;&gt;&gt; [x for x in os.listdir(&apos;.&apos;) if os.path.isdir(x)][&apos;.lein&apos;, &apos;.local&apos;, &apos;.m2&apos;, &apos;.npm&apos;, &apos;.ssh&apos;, &apos;.Trash&apos;, &apos;.vim&apos;, &apos;Adlm&apos;, &apos;Applications&apos;, &apos;Desktop&apos;, ...] 要列出所有的.py文件，也只需一行代码： 12&gt;&gt;&gt; [x for x in os.listdir(&apos;.&apos;) if os.path.isfile(x) and os.path.splitext(x)[1]==&apos;.py&apos;][&apos;apis.py&apos;, &apos;config.py&apos;, &apos;models.py&apos;, &apos;pymonitor.py&apos;, &apos;test_db.py&apos;, &apos;urls.py&apos;, &apos;wsgiapp.py&apos;] 序列化 我们把变量从内存中变成可存储或传输的过程称之为序列化，在Python中叫pickling，在其他语言中也被称之为serialization，marshalling，flattening等等。序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上。反过来，把变量内容从序列化的对象重新读到内存里称之为反序列化，即unpickling。 Python提供两个模块来实现序列化：cPickle和pickle。这两个模块功能是一样的，区别在于cPickle是C语言写的，速度快，pickle是纯Python写的，速度慢，跟cStringIO和StringIO一个道理。用的时候，先尝试导入cPickle，如果失败，再导入pickle： 123456789101112131415161718try: import cPickle as pickleexcept ImportError: import pickle&gt;&gt;&gt; d = dict(name=&apos;Bob&apos;, age=20, score=88)&gt;&gt;&gt; pickle.dumps(d) #序列化为str&quot;(dp0\nS&apos;age&apos;\np1\nI20\nsS&apos;score&apos;\np2\nI88\nsS&apos;name&apos;\np3\nS&apos;Bob&apos;\np4\ns.&quot;&gt;&gt;&gt; f = open(&apos;dump.txt&apos;, &apos;wb&apos;)&gt;&gt;&gt; pickle.dump(d, f) #pickle.dump()#写入文件&gt;&gt;&gt; f.close()#当我们要把对象从磁盘读到内存时，可以先把内容读到一个str，然后用pickle.loads()方法反序列化出对象，也可以直接用pickle.load()方法从一个file-like Object中直接反序列化出对象。&gt;&gt;&gt; f = open(&apos;dump.txt&apos;, &apos;rb&apos;)&gt;&gt;&gt; d = pickle.load(f)&gt;&gt;&gt; f.close()&gt;&gt;&gt; d&#123;&apos;age&apos;: 20, &apos;score&apos;: 88, &apos;name&apos;: &apos;Bob&apos;&#125; JSON 标准化对象序列格式Python内置的json模块提供了非常完善的Python对象到JSON格式的转换。我们先看看如何把Python对象变成一个JSON： 1234&gt;&gt;&gt; import json&gt;&gt;&gt; d = dict(name=&apos;Bob&apos;, age=20, score=88)&gt;&gt;&gt; json.dumps(d)&apos;&#123;&quot;age&quot;: 20, &quot;score&quot;: 88, &quot;name&quot;: &quot;Bob&quot;&#125;&apos; dumps()方法返回一个str，内容就是标准的JSON。类似的，dump()方法可以直接把JSON写入一个file-like Object。 要把JSON反序列化为Python对象，用loads()或者对应的load()方法，前者把JSON的字符串反序列化，后者从file-like Object中读取字符串并反序列化： 123&gt;&gt;&gt; json_str = &apos;&#123;&quot;age&quot;: 20, &quot;score&quot;: 88, &quot;name&quot;: &quot;Bob&quot;&#125;&apos;&gt;&gt;&gt; json.loads(json_str)&#123;u&apos;age&apos;: 20, u&apos;score&apos;: 88, u&apos;name&apos;: u&apos;Bob&apos;&#125; 有一点需要注意，就是反序列化得到的所有字符串对象默认都是unicode而不是str。 JSON进阶JSON序列化一个类对象，json.dumps(class_a,defaul=func_x) ,func_x函数，负责将对象变成可序列化的json对象。 1print(json.dumps(s, default=lambda obj: obj.__dict__)) JSON反序列化得到类对象：json.loads(json_str,object_hook=dict_2_student) 12345def dict2student(d): return Student(d['name'], d['age'], d['score'])json_str = '&#123;"age": 20, "score": 88, "name": "Bob"&#125;'print(json.loads(json_str, object_hook=dict2student)) 进程和线程windows下没有os.fork（）调用,multiprocessing模块就是跨平台版本的多进程模块。 process 1234567891011121314from multiprocessing import Processimport os# 子进程要执行的代码def run_proc(name): print 'Run child process %s (%s)...' % (name, os.getpid())if __name__=='__main__': print 'Parent process %s.' % os.getpid() p = Process(target=run_proc, args=('test',)) ###创建子进程时，只需要传入一个执行函数和函数的参数，创建一个Process实例，用start()方法启动，这样创建进程比fork()还要简单 print 'Process will start.' p.start() p.join() #join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。 print 'Process end.' pool 12345678910111213141516171819from multiprocessing import Pool #使用进程池创建大量子进程import os, time, randomdef long_time_task(name): print 'Run task %s (%s)...' % (name, os.getpid()) start = time.time() time.sleep(random.random() * 3) end = time.time() print 'Task %s runs %0.2f seconds.' % (name, (end - start))if __name__=='__main__': print 'Parent process %s.' % os.getpid() p = Pool() for i in range(5): p.apply_async(long_time_task, args=(i,)) print 'Waiting for all subprocesses done...' p.close() p.join() print 'All subprocesses done.' 进程间通信操作系统提供了很多机制来实现进程间的通信。Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。 多线程Python的标准库提供了两个模块：thread和threading，thread是低级模块，threading是高级模块，对thread进行了封装。绝大多数情况下，我们只需要使用threading这个高级模块。启动一个线程就是把一个函数传入并创建Thread实例，然后调用start()开始执行： 123456789101112131415161718import time, threading# 新线程执行的代码:def loop(): print 'thread %s is running...' % threading.current_thread().name n = 0 while n &lt; 5: n = n + 1 print 'thread %s &gt;&gt;&gt; %s' % (threading.current_thread().name, n) time.sleep(1) print 'thread %s ended.' % threading.current_thread().nameprint 'thread %s is running...' % threading.current_thread().namet = threading.Thread(target=loop, name='LoopThread')t.start()t.join()print 'thread %s ended.' % threading.current_thread().name##由于任何进程默认就会启动一个线程，我们把该线程称为主线程，主线程又可以启动新的线程，Python的threading模块有个current_thread()函数，它永远返回当前线程的实例。主线程实例的名字叫MainThread，子线程的名字在创建时指定，我们用LoopThread命名子线程。名字仅仅在打印时用来显示，完全没有其他意义，如果不起名字Python就自动给线程命名为Thread-1，Thread-2… Lock多线程访问修改同一变量，互斥操作，创建一个锁就是通过threading.Lock()来实现。注意死锁问题。 12345678910111213balance = 0lock = threading.Lock()def run_thread(n): for i in range(100000): # 先要获取锁: lock.acquire() try: # 放心地改吧: change_it(n) finally: # 改完了一定要释放锁: lock.release() Python解释器由于设计时有GIL全局锁，导致了多线程无法利用多核。多线程的并发在Python中就是一个美丽的梦。 Threadlocal每个线程都有自己的局部变量，threading.local()相当于创建了一个全局的dict，每个属性都是线程的局部变量，多线程读写不会相互干扰。ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。 123456789101112131415161718import threading# 创建全局ThreadLocal对象:local_school = threading.local()def process_student(): print 'Hello, %s (in %s)' % (local_school.student, threading.current_thread().name)def process_thread(name): # 绑定ThreadLocal的student: local_school.student = name process_student()t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')t1.start()t2.start()t1.join()t2.join() 进程vs线程 多任务的一般模式master-worker。多进程模式最大的优点就是稳定性高，缺点是创建进程的代价大；多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。异步IO，对于Python语言，单进程的异步编程模型称为协程，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。 分布式进程Python的multiprocessing模块不但支持多进程，其中managers子模块还支持把多进程分布到多台机器上。一个服务进程可以作为调度者，将任务分布到其他多个进程中，依靠网络通信。由于managers模块封装很好，不必了解网络通信的细节，就可以很容易地编写分布式多进程程序。]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python学习笔记-1]]></title>
    <url>%2F2016%2F07%2F02%2F%E6%8A%80%E6%9C%AF%2FPython-study%2F</url>
    <content type="text"><![CDATA[基础语法数据结构list len() 求长度 a[i] list a 中第i个元素， a[2:9] 第2到9个元素，a[-1] 倒数第一个元素。 a.append(elem) list尾部追加一个元素 a.insert(i,elem) list第i个位置插入一个元素 a.pop(i) list 删除第i个元素，不指定i则默认删除最后一个 list的元素可以类型不同，也可以是list tupletuple不可变的元素集合，只有一个元素是的定义 a=(1,) 注意,是为了避免数学运算()的歧义 dict dict：key-value对，查询dict[key]可以取出对应的value。添加新键值对或修改值 dict[key]=newvalue。判断key是否存在 key in dict 或 dict.get(key,int-flag) 如果key不存在则返回指定的数值，不指定则返回none，none在交互式命令中不显示。删除一个key-value，用dict.pop(key) dict 插入查找速度快，占用内存多，list查找、插入与元素数量有关，占用内存空间少 set set： 也是一组key的集合，但是没有value set 初始化传入参数由一个list提供，s=set([1,1,2,2,3,4,5]),输出结果s为set([1,2,3,4,5])，其中的[]表示集合，重复元素被剔除，而不是list。 添加元素s.add(key),删除元素 s.remove(key) s1 &amp; s2 求交集；s1 | s2 ,求并集。 判断和循环 if 123456if x : # x非0非None即True xxxelif y: # 可以多个if嵌套使用 oooelse: xxoo for 123# xxxx为可迭代对象，list，dict，set和任何实现__next_item__方法的对象for x in xxxx: print x while 12345678# 当条件为真，执行循环while a&gt;0: a += 1 if a == 100: continue # a为100时跳过本次，进入下一层循环 if a &gt; 1000: # a为1000时跳过本次，跳出循环 break print a 函数 help(func) 查看函数fanc的帮助信息；dir(func)查看函数的内置方法；isinstance（x，（int,float））,类型检查； 定义函数 def myfunc(para1,para2): pass ;pass占位符，不知道写啥时可以先用它占位。 return x 返回x，没有return也会返回none，return可以返回多个值，但其本质是返回一个tuple。 默认参数放到后面，def power(x,n=2): pass;调用函数时默认参数如果不按顺序赋值，则需指定参数名。默认参数的值要设为不可变的变量类型，而不能是list。 可变参数，即输入的可以是0或多个参数不固定。定义可变参数仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple，因此调用该函数时，可以传入任意个参数，包括0个参数。如果变量已经保存为list或tuple，则可以用 *list来传递参数，而不用list[0],list[1] … 那么麻烦； 1234def func(*numbers): for num in numbers : pass #numbers是一个tuple pass 关键字参数：允许传入0或多个带参数名的参数，在函数内部作为一个dict, 使用**para 表示关键字参数.调用函数时也可将dict转换为关键字参数传递进去，func（**dict） 12def student(name,age,**p_other): print name,age,p_other 组合参数：参数定义的顺序必须是：必选参数、默认参数、可变参数和关键字参数。在函数调用的时候，Python解释器自动按照参数位置和参数名把对应的参数传进去，因此，对于任意函数，都可以通过类似func(args, *kw)的形式调用它，无论它的参数是如何定义的。 递归函数 注意栈溢出问题 Python高级特性切片切片 L[0:3] 或 L[:3] 取L的前三个元素,不包括3；L[-2:]取倒数后2个元素；L[:10:2] 前10个元素，每2个取一个；tuple或字符串也可以切片操作。 迭代迭代 for … in 实现遍历list或tuple或其他可迭代对象。默认情况下，dict迭代的是key，for key in d : pass。如果要迭代value，可以用for value in d.itervalues()，如果要同时迭代key和value，可以用for k, v in d.iteritems()。字符串也可以迭代，for ch in ‘ABC’: print ch。 for循环中同时迭代索引和元素本身 12for i, value in enumerate(['A', 'B', 'C']): print i, value 列表生成式快速创建list，简单强大。 12345678range(1,11) ;[x * x for x in range(1,11)] =[1,4,9,...,100] ;[x * x for x in range(1,11) if x%2==0] = [4,16,36,64,100] ; # 两层循环 [x + y for x in 'ABC' for y in 'ZXD' ]; # 列出当前目录下的文件和目录：import os[d d in os.listdir('.')] 生成器像不生成完整的list，而采用一边循环一边计算的机制；创建方法1： 将列表生成式的[]改为() g=(x * x for x in range(10)) 如果要一个一个打印出来g的元素，可以通过generator的next()方法，但是通常用for迭代来遍历。 for n in g: print g 方法2：通过函数实现生成器 123456def fib(max): n, a, b = 0, 0, 1 while n &lt; max: yield b # generator在执行过程中，遇到yield就中断，下次又继续执行。 a, b = b, a + b n = n + 1 要理解generator的工作原理，它是在for循环的过程中不断计算出下一个元素，并在适当的条件结束for循环。对于函数改成的generator来说，遇到return语句或者执行到函数体最后一行语句，就是结束generator的指令，for循环随之结束。 函数式编程高阶函数允许函数作为参数传入: 12def add(x, y, f): return f(x) + f(y) map/reduce map()函数接收两个参数，一个是函数，一个是序列，map将传入的函数依次作用到序列的每个元素，并把结果作为新的list返回。 123456def f(x): return x**2map(f, [1,2,3,4,5,6])# 输出 [1,4,9,16,25,36]map(str, [1, 2, 3, 4, 5, 6, 7, 8, 9])#输出 ['1', '2', '3', '4', '5', '6', '7', '8', '9'] reduce()把一个函数作用在一个序列[x1, x2, x3…]上，这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算,例如，实现‘1 3 5 7 9’序列变为整数13579 1234def fn(x, y): return x*10 + yreduce(fn, [1, 3, 5, 7, 9])# 输出 13579 filter filter()也接收一个函数和一个序列。filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。 123def is_odd(n): return n/2==1filter(is_odd,[1,2,3,4,5,6]) #求奇数 sorted Python内置的sorted()函数就可以对list进行排序。sorted()函数也是一个高阶函数，它还可以接收一个比较函数来实现自定义的排序。比如实现倒序排序reversed_cmp函数 1234567891011sorted([36, 5, 12, 9, 21])# 输出 [5, 9, 12, 21, 36]def reversed_cmp(x, y): if x &gt; y: return -1 if x &lt; y: return 1 return 0 sorted([36, 5, 12, 9, 21], reversed_cmp)# 输出 [36, 21, 12, 9, 5] 返回函数匿名函数lambda当高阶函数的参数是传入函数时，可以不显示地定义函数，直接传入匿名函数： 12map(lambda x: x * x, [1, 2, 3, 4, 5, 6, 7, 8, 9])# 输出 [1, 4, 9, 16, 25, 36, 49, 64, 81] 关键字lambda表示匿名函数，冒号前面的x表示函数参数。 匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数. 装饰器假设我们要增强now()函数的功能，比如，在函数调用前后自动打印日志，但又不希望修改now()函数的定义，这种在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator）。 123456789def log(func): def wrapper(*args, **kw): print 'call %s():' % func.__name__ return func(*args, **kw) return wrapper #定义如上，使用如下： @logdef now(): print '2013-12-25' 把@log放到now()函数的定义处，相当于执行了语句 now=log(now) 参考文章-python装饰器 偏函数functools模块的一个功能， 1int2 = functools.partial(int, base=2) int2函数就是int（n，base=2）导出的新函数，int()函数的默认base=10，但是int2也可以接收参数base=10；functools.partial的作用就是，把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。 模块package &gt; module &gt; func package:按目录结构来管理模块，每一个包目录下面都会有一个__init__.py的文件，这个文件是必须存在的，否则，Python就把这个目录当成普通目录，而不是一个包。__init__.py可以是空文件，也可以有Python代码，因为__init__.py本身就是一个模块，而它的模块名就是mycompany。 编写模块 1234567891011121314151617181920#!/usr/bin/env python# -*- coding: utf-8 -*-' a test module ' #任何模块代码的第一个字符串都被视为模块的文档注释；__author__ = 'Michael Liao'import sysdef test(): args = sys.argv #用list存储了命令行的所有参数。argv至少有一个元素，因为第一个参数永远是该.py文件的名称，运行python hello.py Michael获得的sys.argv就是['hello.py', 'Michael]。 if len(args)==1: print 'Hello, world!' elif len(args)==2: print 'Hello, %s!' % args[1] else: print 'Too many arguments!'if __name__=='__main__': test() 导入模块 123456789try: import cStringIO as StringIO #使用别名except ImportError: # 导入失败会捕获到ImportError import StringIO# 常见用法try: import json # python &gt;= 2.6except ImportError: import simplejson as json # python &lt;= 2.5 模块中__xx__这样的变量或函数是有特殊用途的，比如__doc__,一般自己的不要这样定义。 模块中_XX或__xx是私有函数或变量，不能直接引用。外部不需要引用的函数全部定义成private，只有外部需要引用的函数才定义为public。 安装第三方模块 pip install module-namepip install wheel Scrapy pymongo requests celery -i http://pypi.douban.com/simple --trusted-host pypi.douban.com-i 指定源，—-trusted-host 添加域名信任 导入模块时，默认情况下，Python解释器会搜索当前目录、所有已安装的内置模块和第三方模块，搜索路径存放在sys模块的path变量中 123import syssys.path# 输出 ['', '/Library/Python/2.7/site-packages/pycrypto-2.6.1-py2.7-macosx-10.9-intel.egg', '/Library/Python/2.7/site-packages/PIL-1.1.7-py2.7-macosx-10.9-intel.egg', ...] 如果我们要添加自己的搜索目录，有两种方法：一是运行时修改sys.path，添加要搜索的目录：sys.path.append(‘/user/module/path’) ，运行结束后失效。 第二种在系统中设置环境变量“PYTHONPATH” 面向对象编程类和实例面向对象最重要的概念就是类（Class）和实例（Instance），必须牢记类是抽象的模板，比如Student类，而实例是根据类创建出来的一个个具体的“对象”，每个对象都拥有相同的方法，但各自的数据可能不同,和静态语言不同，Python允许对实例变量绑定任何数据，也就是说，对于两个实例变量，虽然它们都是同一个类的不同实例，但拥有的变量名称都可能不同。 1234567class Student(object): def __init__(self, name, score): self.__name = name self.__score = score def print_score(self): print '%s: %s' % (self.__name, self.__score) (object)，表示该类是从哪个类继承下来的，通常，如果没有合适的继承类，就使用object类，这是所有类最终都会继承的类。 类的初始化方法init,传进的第一个参数是self，表示实例自身。创建实例时必须传入与init一致的变量，self除外。 属性方法和访问限制class内的属性前加上__就会变成私有变量，外部无法访问,获取或修改私有变量可以创建方法get set等，在方法中可以对参数进行检查。 类的属性仅对当前类起作用，对继承的子类是不起作用的,除非在子类中也定义__slots__，这样，子类允许定义的属性就是自身的__slots__加上父类的__slots__。 12345678910111213141516171819202122232425class Student(object): passs=Student()s.name='abc' #为一个实例添加属性，对其他实例无效 def set_age(self,age): self.age=agefrom types import MethodTypes.set_age = MethodType(set_age, s, Student) # 给实例绑定一个方法s.set_age(25)print s.age #为对象绑定一个方法def set_score(self,score): self.score=scoreStudent.set_score=MethodType(set_score,None,Student)# 如果我们想要限制class的属性怎么办？比如，只允许对Student实例添加name和age属性。# 为了达到限制的目的，Python允许在定义class的时候，定义一个特殊的__slots__变量，来限制该class能添加的属性：class Student(object): __slots__ = ('name', 'age') # 用tuple定义允许绑定的属性名称#__slots__定义的属性仅对当前类起作用，对继承的子类是不起作用的,除非在子类中也定义__slots__，这样，子类允许定义的属性就是自身的__slots__加上父类的__slots__。 有没有既能检查参数，又可以用类似属性这样简单的方式来访问类的变量呢?Python内置的@property装饰器就是负责把一个方法变成属性调用的. 12345678910111213class Student(object): @property def score(self): return self._score @score.setter def score(self, value): if not isinstance(value, int): raise ValueError('score must be an integer!') if value &lt; 0 or value &gt; 100: raise ValueError('score must between 0 ~ 100!') self._score = value 继承和多态继承可以把父类的所有功能都直接拿过来，这样就不必重零做起，子类只需要新增自己特有的方法，也可以把父类不适合的方法覆盖重写； 多态真正的威力：调用方只管调用，不管细节，而当我们新增一种Animal类的子类时，只要确保run()方法编写正确，不用管原来的代码是如何调用的。这就是著名的“开闭”原则：对扩展开放：允许新增Animal子类；对修改封闭：不需要修改依赖Animal类型的run_twice()等函数。 123def run_twice(animal): #animal是Animal类对象的一个实例 animal.run() animal.run() 获取对象信息获取对象类型用函数type(),模块types里保存了所有的type类型常量。 123import typesprint type('abc') == types.StringType# output: True 使用isinstance(x,y)判断的是x对象是否是y类型本身，或者位于y类型的父继承链上。 dir() 获取一个对象的所有方法和属性，返回一个list。 getattr()、setattr()访问设置对象属性，hasattr() 可以测试对象的属性是否存在。 1234def readImage(fp): if hasattr(fp, 'read'): return readData(fp) return None 多重继承class dog(Mammal, Runnable): pass ,使用多继承可以避免复杂庞大的继承链。 定制类__xxx__的变量或者函数名在Python中是有特殊用途的,__slots__是为了限制类的属性，__len__()方法是为了能让class作用于len()函数。__str__()方法，打印实例；如果一个类想被用于for … in循环，类似list或tuple那样，就必须实现一个__iter__()方法，该方法返回一个迭代对象，然后，Python的for循环就会不断调用该迭代对象的next()方法拿到循环的下一个值，直到遇到StopIteration错误时退出循环。要表现得像list那样按照下标取出元素，需要实现__getitem__()方法；__getattr__()方法，动态返回一个属性，如果找不到引用的属性，则用该方法动态返回 更多可定制属性参考python官方文档 元类参考博客]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python读写XLS和CSV]]></title>
    <url>%2F2016%2F07%2F01%2F%E6%8A%80%E6%9C%AF%2FPython%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[python读写CSV1. 写入并生成csv文件 代码： 123456789101112131415# coding: utf-8import csvcsvfile = file('csv_test.csv', 'wb')writer = csv.writer(csvfile)writer.writerow(['姓名', '年龄', '电话'])data = [ ('小河', '25', '1234567'), ('小芳', '18', '789456')]writer.writerows(data)csvfile.close() wb中的w表示写入模式，b是文件模式写入一行用writerow多行用writerows 2. 读取csv文件 代码： 123456789# coding: utf-8import csvcsvfile = file('csv_test.csv', 'rb')reader = csv.reader(csvfile)for line in reader: print linecsvfile.close() python读写Excel 1、导入模块 import xlrd 2、打开Excel文件读取数据 data = xlrd.open_workbook(&#39;excelFile.xls&#39;) 3、使用技巧 123456789101112131415161718192021222324252627282930313233343536# 获取一个工作表table = data.sheets()[0] #通过索引顺序获取table = data.sheet_by_index(0) #通过索引顺序获取table = data.sheet_by_name(u'Sheet1')#通过名称获取# 获取整行和整列的值（数组）table.row_values(i)table.col_values(i)# 获取行数和列数nrows = table.nrowsncols = table.ncols# 循环行列表数据for i in range(nrows ): print table.row_values(i)# 单元格cell_A1 = table.cell(0,0).valuecell_C4 = table.cell(2,3).value# 使用行列索引cell_A1 = table.row(0)[0].valuecell_A2 = table.col(1)[0].value#简单的写入row = 0col = 0# 类型 0 empty,1 string, 2 number, 3 date, 4 boolean, 5 errorctype = 1 value = '单元格的值' xf = 0 # 扩展的格式化table.put_cell(row, col, ctype, value, xf) table.cell(0,0) #查看单元格的值table.cell(0,0).value #单元格的值]]></content>
      <categories>
        <category>技术</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github问题汇总]]></title>
    <url>%2F2016%2F05%2F18%2F%E6%8A%80%E6%9C%AF%2FGithub%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[https 转换为 ssh 查看当前地址版本 git remote -v 123$ git remote -vorigin git@github.com:shuaiyy/shuaiyy.github.io.git (fetch)origin git@github.com:shuaiyy/shuaiyy.github.io.git (push) 设置为ssh地址 git remote set-url origin git@github:USERNAME/OTHERREPOSITROY.git Git冲突：commit your changes or stash them before you can merge. 当本地修改未提交，使用git pull更新时，会报错 解决方法： stash通常遇到这个问题，你可以直接commit你的修改；但我这次不想这样。看看git stash是如何做的。git stashgit pullgit stash pop接下来diff一下此文件看看自动合并的情况，并作出相应修改。git stash: 备份当前的工作区的内容，从最近的一次提交中读取相关内容，让工作区保证和上次提交的内容一致。同时，将当前的工作区内容保存到Git栈中。git stash pop: 从Git栈中读取最近一次保存的内容，恢复工作区的相关内容。由于可能存在多个Stash的内容，所以用栈来管理，pop会从最近的一个stash中读取内容并恢复。git stash list: 显示Git栈内的所有备份，可以利用这个列表来决定从那个地方恢复。git stash clear: 清空Git栈。此时使用gitg等图形化工具会发现，原来stash的哪些节点都消失了。 放弃本地修改，直接覆盖之 git reset –hardgit pull​]]></content>
      <categories>
        <category>技术</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从二次型最优化问题中理解矩阵特征值的意义]]></title>
    <url>%2F2015%2F09%2F12%2F%E7%A7%91%E7%A0%94%2F2015-09-12-Intuition-of-Eigen-Value%2F</url>
    <content type="text"><![CDATA[惯例开场故事在某次从实验室去往食堂的路上，曾发生这样一段对话： 『大师兄，为什么你对算法的理解总是那么透彻呢？为什么我很难看出它背后的思想？』 『因为你去理解一个算法的时候，不能只是看懂它的形，还要去思考它的神啊~』 这就是我天分不够当不了科学家的佐证吧T。T 从二次型最优化来理解最小化二次型目标函数，其中A为已知的实对称二阶矩阵，，.这个问题的求解很简单，这里以此为例来说明该问题与矩阵特征值的关系。 首先，可以得到目标函数的网格图与等高线图如下。 对矩阵A进行特征分解可以得到其特征向量为[-0.7071, 0.7071], [0.7071, 0.7071]，对应的特征值分别是0.5, 1.5. 观察函数的等高线图可以知道，等高线最密集的地方，函数值变化最快，而这个函数值变化最快的方向归一化后就是[0.7071, 0.7071]，这恰好是矩阵的一个特征向量。同样地，可以观察，等高线最稀疏的地方，函数值变化最慢，变化方向则是矩阵的另一个特征向量。可以看出，矩阵特征值的大小与函数值的变化快慢有关，较大特征值所对应的特征向量方向上函数值的变化较快，较小特征值所对应的特征向量方向上函数值的变化较慢。 进一步，对于实对称矩阵，我们总是可以对其进行相似变化，得到一个以该矩阵特征值为对角线元素的对角阵。，其中，P为正交矩阵，有性质P的逆等于P的转置。把目标函数改写为，其中. 相似变换的作用可以理解为将等高线图进行旋转，于是得到下面经过旋转后的等高线图。 在这张图上说明矩阵特征值的意义。当函数值取1时所对应的椭圆等高线的长轴长度为， 即由矩阵特征值0.5决定。同理，该椭圆短轴长度为，由矩阵特征值1.5决定。 二阶矩阵的理解较为直观。高阶矩阵的道理是一样的。 资料【1】如何理解矩阵特征值]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Math</tag>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[牛顿法与拟牛顿法（DFP BFGS LBFGS VLBFGS）]]></title>
    <url>%2F2015%2F03%2F23%2F%E7%A7%91%E7%A0%94%2F2015-03-23-Newton-QuasiNewton-Method%2F</url>
    <content type="text"><![CDATA[最近做LBFGS的并行，顺便把牛顿法、拟牛顿法顺理一下。 拟牛顿法是求解非线性优化问题最有效的方法之一。考虑无约束的极小化问题，假设为凸函数，且二阶连续可导。 原始牛顿法基本思想：在现有极小点估计值的附近对f(x)进行二阶泰勒展开，进而找到下一个极小点的估计值 牛顿法具有二次收敛性，但当目标函数非二次型时，牛顿法不能保证函数稳定地下降（缺点）。 阻尼牛顿法每次迭代前需要沿迭代方向做线搜索，寻求最优的步长因子，即 拟牛顿法基本思想：不使用二阶偏导数而构造出可以近似Hession或Hession的逆的正定对称阵，在“拟牛顿”的条件下优化目标函数。 先推导拟牛顿条件：在附近对做泰勒展开，取二阶近似项 推出 取，推出 引入记号 ， 推出 (拟牛顿条件) 它迭代过程中的hession矩阵做约束，因此，对hession对近似的，以及对hession的逆做近似的，可以将 或 作为指导。 DFP算法（Davidon–Fletcher–Powell formula）核心：通过迭代的方法，对hession的逆做近似。迭代格式为 （通常） 猜想待定为（具有对称性） 括号中是数值，将其分别简单赋值为1，-1，即 其中向量u,v仍有待确定，由上面 （要此式成立，不妨直接取） 至此，校正矩阵就已经构造出来了 BFGS算法（Broyden–Fletcher–Goldfarb–Shanno algorithm）核心公式的推导过程与DFP完全类似，只是互换了其中s{k}和y{k}的位置。BFGS直接逼近Hession矩阵B_k。(公式敲起来太累了，请自行推导) LBFGS算法(limited-memory BFGS)不再存储完整的D_k，而是存储计算过程中的向量序列{s}，{y}。当需要矩阵D_k时，利用向量序列的计算来代替。并且，向量序列也不是全部存储，而是固定存最新的m个。 若要实现并行，需要同时在x与梯度（影响y的计算）那儿求一致平均。 资料【1】DFP算法 【2】BFGS算法 【3】LBFGS算法 【4】Large-scale L-BFGS using MapReduce]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Math</tag>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据机器学习初探---南大李武军]]></title>
    <url>%2F2015%2F02%2F04%2F%E7%A7%91%E7%A0%94%2F2015-02-04-Group-Meeting%2F</url>
    <content type="text"><![CDATA[每周的组会大概会持续2小时。如果是主讲，就需要花更多的时间去准备报告内容。之前，组会开完我就不管了，缺乏总结思考。而这样子的话实质上意义就不大了，没有内化为自己的知识，也没有什么critical thinking。从现在开始，记录每一次组会的思考。 常言道：亡羊补牢，为时未晚。T.T Outline Learning to Hash Distributed Learning Stochastic Learning 有一个形象的比喻是这样说的，大数据是金矿，云计算是采矿技术，大数据机器学习是冶金技术。 大数据机器学习面临的挑战，一是存储，而是计算速度，三是网络。 哈希学习，在内存、硬盘、cpu、通信上有优势；分布式学习在内存、硬盘、cpu上有优势，但会增加通信成本；随机学习在内存、硬盘、cpu方面有优势。 Learning to Hash主讲人：大师兄 最近邻搜索在大数据背景下，会出现维数灾难，存储成本也高，查询速度也慢。解决方法之一是保相似性哈希，可以降低维数并减少存储成本。通常用海明距离（hamming distance）来表征哈希值之间的差异。哈希方案也具有较快的查询速度，通常具有常数或者次线性的搜索时间复杂度；即使是穷举搜索也可以被接受，因为海明距离计算起来是很快的。 哈希函数学习的两个阶段： Projection Stage（dimension reduction） Quantization Stage 贡献： Isotropic Hash 思想：学习一个正交阵（幻灯片21页），其目的是让大于某一阈值的feature的重要程度是一样的。 Supervised Hashing with Latent Factor Models Supervised Multimodal Hashing with SCM Multiple-Bit Quantization Distributed Learning主讲人：我 主要内容： 文章：Coupled Group Lasso for Web-Scale CTR Prediction 文章：Distributed Power-Law Graph Computing 文章1为了解决在线广告的CTR（click through rate）预测，即当某广告展示给某用户时，它被该用户点击的概率，通常的方法是LR（logistic regression），即逻辑回归。但LR的一个短板是，因其是线性的，所以无法将用户与广告之间某些微妙的非线性关系纳入。注意LR中，正则项若为2范数平方，称为标准逻辑回归；正则项若为1范数，问题通常被叫做Lasso。所以需要一种新的方法。 这里的贡献是： CGL的似然定义中，可以纳入用户与广告之间的某些非线性关系的考量。 正则项改为参数的2-1范数，目的是是用户特征向量参数W、广告特征向量参数V中更多的行为0，行为0说明该行对应的feature没作用，即达到删除冗余feature的作用。 分布式实现。这个算法具有较好的扩展性，一个master，若干slave，类似于并行计算，从而实现分布式。 文章2GP（graph partitioning）图分割的方法有两种：边分割；点分割。点分割在分布式计算中的通信成本会比图分割小，原因在于在不同的machine上，点分割只需保留点的copy，而边分割需要同时保留点与边的copy。 切割degree大的点，即邻居多的点可以降低通信成本。 Stochastic Learning主讲人：浩锋 思想：在需要用到所有节点上的信息时，通信代价往往很大，这时可以随机的选取某一个节点上的信息（比如梯度）作为替代品。 资料【1】幻灯片 【2】Coupled Group Lasso forWeb-Scale CTR Prediction in Display Advertising 【3】Distributed Power-law Graph Computing:Theoretical and Empirical Analysis]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Math</tag>
        <tag>Optimization</tag>
        <tag>MachineLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常用命令速查表]]></title>
    <url>%2F2015%2F01%2F30%2F%E6%8A%80%E6%9C%AF%2FGit-Resources%2F</url>
    <content type="text"><![CDATA[master: 默认开发分支 origin: 默认远程版本库 Head: 默认开发分支 Head^: Head的父提交 创建版本库12$ git clone &lt;url&gt; #克隆远程版本库$ git init #初始化本地版本库 修改和提交123456789$ git status #查看状态$ git diff #查看变更内容$ git add . #跟踪所有改动过的文件$ git add &lt;file&gt; #跟踪指定的文件$ git mv &lt;old&gt;&lt;new&gt; #文件改名$ git rm&lt;file&gt; #删除文件$ git rm --cached&lt;file&gt; #停止跟踪文件但不删除$ git commit -m "commit messages" #提交所有更新过的文件$ git commit --amend #修改最后一次改动 查看提交历史123$ git log #查看提交历史$ git log -p &lt;file&gt; #查看指定文件的提交历史$ git blame &lt;file&gt; #以列表方式查看指定文件的提交历史 撤销1234$ git reset --hard HEAD #撤销工作目录中所有未提交文件的修改内容$ git checkout HEAD &lt;file&gt; #撤销指定的未提交文件的修改内容$ git revert &lt;commit&gt; #撤销指定的提交$ git log --before="1 days" #退回到之前1天的版本 分支与标签1234567$ git branch #显示所有本地分支$ git checkout &lt;branch/tag&gt; #切换到指定分支和标签$ git branch &lt;new-branch&gt; #创建新分支$ git branch -d &lt;branch&gt; #删除本地分支$ git tag #列出所有本地标签$ git tag &lt;tagname&gt; #基于最新提交创建标签$ git tag -d &lt;tagname&gt; #删除标签 合并与衍合12$ git merge &lt;branch&gt; #合并指定分支到当前分支$ git rebase &lt;branch&gt; #衍合指定分支到当前分支 远程操作12345678$ git remote -v #查看远程版本库信息$ git remote show &lt;remote&gt; #查看指定远程版本库信息$ git remote add &lt;remote&gt; &lt;url&gt; #添加远程版本库$ git fetch &lt;remote&gt; #从远程库获取代码$ git pull &lt;remote&gt; &lt;branch&gt; #下载代码及快速合并$ git push &lt;remote&gt; &lt;branch&gt; #上传代码及快速合并$ git push &lt;remote&gt; :&lt;branch/tag-name&gt; #删除远程分支或标签$ git push --tags #上传所有标签 资料链接 Try Git]]></content>
      <categories>
        <category>技术</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Mac上用LaTeX写漂亮的简历]]></title>
    <url>%2F2014%2F12%2F06%2F%E6%8A%80%E6%9C%AF%2FLaTeX-Make-resume%2F</url>
    <content type="text"><![CDATA[你会搜索查看到这篇文章，相信就不需要我解释为什么要用LaTeX写Resume了：） 今晚报名Facebook China Tech Talk，最后一步需要上传简历。看着已经2年没有更新过的简历，好捉急。那时真是年轻，不舍得做减法，恨不能一张A4纸写尽一生。于是索性重新制作一份简历。 需要准备 安装好的LaTeX，如果没有安装请参考在Mac上通过Sublime、Skim编辑LaTeX 互联网 资料 Using the LaTeX Resume Templates LaTeX Templates 步骤 在上述资料中寻找自己喜欢的模板 下载模板对应的tex文件 用LaTeX打开对应文件，编辑，编译 这个时候，如果你使用的是Mac系统，非常不幸，大多数情况下都将编译失败。因为网上多数模板需要使用windows环境下的Tex应用程序，而Mac环境下MacTex应用程序会缺少部分文件。没关系，我们有办法解决。 解决方案一：moderncv 进入http://www.ctan.org/pkg/moderncv 下载moderncv package 解压，找到模板文件template.tex 用已经安装好的LaTeX打开模板文件，编辑，编译，成功 但是呢，我个人觉得moderncv模板并不够好，虽然其结构清新简洁，但布局过于稀疏。没关系，我们仍然有办法。感谢一个我无意中发现的网站：ShareLaTeX.com 解决方案二：ShareLaTeX.com也许你在上面的资料中找到了你最喜欢的模板，却苦于在Mac OS X系统下无法编译成功。这时可以求助于ShareLaTeX，这是一个在线LaTeX编辑网站，并且提供Resume,Cover Letter,Journal Article,Presentation,Thesis,Bibliographies等不同分类的多种模板。最重要的一点事，只需要确定Latex语法无误，再也不需担心什么编译环境、文件缺失等乱七八糟的问题。 进入ShareLaTeX，注册账号 点击New Project，选择CV or Resume，挑选你喜欢的简历模板 根据自己的情况编辑，自动或手动编译，保存PDF 后记既然写到这里了，还想讲讲自己对于简历的体会。但我真的是困得不行了。。。。北京第一次不归夜。。。改天再来补全。。。。]]></content>
      <categories>
        <category>技术</category>
        <category>latex</category>
      </categories>
      <tags>
        <tag>LaTeX</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的报告 Decentralized Privacy-Preserving Low-Rank Matrix Completion]]></title>
    <url>%2F2014%2F11%2F26%2F%E7%A7%91%E7%A0%94%2F2014-11-26-Presentation-at-Chinese-Academy-of-Science%2F</url>
    <content type="text"><![CDATA[转载 我的报告Section 0: Introduce MyselfPage 1 Good afternoon everyone! My name is Anya Lin. I’m a second-year master candidate from University of Science and Technology of China. It’s my great pleasure to introduce to you the Decentralized Privacy-Preserving Low-Rank Matrix Completion. It’s a joint work with my supervisor, Prof. Ling from USTC. Before I start, I want to express my thanks to Prof. Ling for his patient instructions and help over the last a few months. Page 2 Here’s the outline of my presentation. First is the introduction. And then the centralized matrix completion problem. We develop a decentralized algorithm in section 3, and our algorithm is derived from a centralized algorithm as I will talk about in section 2. Next, I will introduce the main result of the topology-dependent privacy preservation. At last, it’s the conclusion. Section 1: IntroductionPage 3 OK， let’s go into the introduction. Page 4 I’d like to begin with the concept of matrix completion. So what is matrix completion? As we can see in this picture, we have an incomplete matrix, whose entries are known only for a subset of the whole matrix. And the rank of the matrix is very small compared with the size of the matrix. The goal of the matrix completion is to recover all these unknown entries of of the matrix, as the right-side picture shows. Here, Z is the recovery of W. Page 5 There’s many applications of such a problem. Like image processing, recommendation system and so on. Here are 2 examples. The first one is a problem of image processing. The left picture has a lot of noises, or say, only a part of the original picture is known. By using the fact that the original picture is usually low-rank, we can matrix completion to denoise the picture and get a clear version of high quality as the right picture shows. The second example is more close to our lives. It’s related to a recommendation system. As you can see, it’s a webpage of Douban Movie. A user sees a movie, such as Interstella, and then scores it on the website. Here we can imagine a huge matrix with rows representing users and columns the movies. This matrix is incomplete and it’s low-rank. Once this matrix is completed, the website can recommend new movies to users. Page 6 Now, here comes a privacy concern. First what is privacy? Privacy is the values one considers private. In the example we mentioned just now, the users’ scores of the movies are privacy, because one may not want others to know what movies he has seen or likes. Also, the entries of the matrix could be medical records of patients, or selling data of merchants. These data are considered as privacy. Obviously, no one wants the leakage of his privacy. However, in reality there may exist a malicious agent, a bad guy. For some reasons you have to give your private data to it, but you don’t know wether you can trust it or not. In this situation, we need privacy-preservation. Privacy-preservation is the ability to prevent a malicious agent from obtaining or reconstructing the private data. Section 2: Centralized Matrix Completion ProblemPage 7 Now let’s go into the centralized matrix completion problem. Page 8 When we are faced with a low-rank matrix completion problem, the intuitive thought would be to minimize the rank of the matrix, but this is a nonconvex problem. Therefore, we insteadly minimize the nuclear-norm the the matrix, since nuclear-norm is the approximation of the rank and it’s convex. Another approach is if the rank of matrix is known to be r as a prior theoreticallyor empirically, we can get the matrix factorization formulation. This approach is advantageous over the nuclear-norm approach since the latter one needs sigular value decomposition, which is computationally expensive and even intractable in decentralized computing. A centralized algorithm called LMaFit to solve this is as the following steps shows. We have to keep in mind that our algorithm is derived from LMaFit. Section 3: Decentralized Matrix Completion ProblemPage 9 After the centralized problem, let’s go into the decentralized one. Page 10 In decentralized computing, we have a network composed of L agents. There is an undirected edge between two agents if they can communicate with each other through one hop. The goal of all the agents in such a network is to collaboratively complete a low-rank matrix in a decentralized fashion. Page 11 To be specific, we segment the whole data matrix W into groups of columns. And do the same to Y and Z. Each agent i in the network holds the corresponding Zi, Yi and entries of Wi. However, X cannot be segmented and distributed to agents because the update of X contains the summation of ZiYi’ over all agents. So we let each agent i holds a local copy X(i) of X. After doing this, we get a naive decentralized implementation of LMaFit. At iteration k, each agent i does the following steps respectively. Notice that the update of X requires information aggregation of all agents. So here is the challenge: informationaggregationofallagentsisimpossible in real decentralized network unless every agent is connected to all the other agents. How to deal with this challenge? Page 12 The answer is dynamic average consensus. Recall that each agent i holds a local copy X(i) of X. If we can make sure that X(i) equals to X for all i, the challenge is solved. To do this, we choose c to be 1/L and the update of X becomes the average consensus problem, as we can see in equation (8), X(i) is the average of all the ZiYi’. At iteration k,we formulate the average consensus problem as equation (9). The constraint means that instead of letting all the X(i) to be identical we choose to let each X(i) equals to it neighboring X(j). A key observation is that exact average consensus at every iteration is not necessary. We use EXTRA to do inexact dynamic average consensus, which saves the computational cost. Page 13 Our decentralized algorithm called D-LMaFit is developed as below. Step 1 is the initialization. Step 2, use EXTRA to do the inexact average consensus problem. Step 3, update Y and X respectively. Page 14 The performance of D-LMaFit is shown in these two pictures. (Explain what these pictures indicate to the audience) Section 4: Topology-Dependent Privacy PreservationPage 15 Now let’s go into the section of the topology-dependent privacy preservation. Page 16 First compare decentralized algorithm with centralized one. Centralized algorithm needs a fusion center to collect global data. What if the fusion center is a malicious agent? Oops TT, you’ll lose all your privacy. How about the decentralzied algorithm? One important advantage of decentralized algortihm over a centralized is there’s no global data collection, each agent observes part of the raw data and communicates with its neighboring agent(s). It seems safer. But things aren’t so lucky in reality. Because the communication of X(i) among the network may lead to information leakage. Page 17 How does this happen? Suppose in a network as this picture shows, we have a malicious agent M, and M attempts to recover the local data matrices of some other agents through information exchange. M is interested in recovering the local data Wi, or equivalently Yi or Zi of a set of agents i∈I. When the iteration k is large enough, X(i) will be identical. So if a malicious agent M somehow knows other agents’ Yi, it can recover the data Zi of agent i by doing X(M)Yi. So our concern is, is there any possibility that the malicious agent M can somehow obtain Yi of agent i, and thus get Zi, which is private. Page 18 Before going to details, consider two simple topologies. (Explain the two topologies) Under what conditions can not a malicious agent M reconstruct the sensitive information of P and Q ? Page 19 Recall the update of X. If you could just take a look at the equation, you can find that if the topology is as in the left picture, M can reconstruct ZiYi’ and it may be able to solve Yi so that gets the privacy of P and Q. But if the topology is as shown in the right picture. M cannot get the private data of P and Q. Why? (Explain with the equation) M can solve a series of linear inverse problems and calculate the values of ZiYi’, as what we have said just now. Page 20 Now we get a naive conclusion. Page 21 So the privacy-preserving problem boils down to the linear inverse problem. First we define some variables as this. And further we define A and B. Using these definition,the update of X can be represented by (14). Page 22 Rewrite this as a linear time-invariant systems we get (15). In this system, QI selects those row blocks in Q belonging to the agents in I, and BI selects the corresponding columns in B. QIC and BIC selects the other corresponding row blocks and columns which do not belong to the agents in I. Our analysis uses the concept of z-transfer matrix of (15). The concept is from modern control theory. Obviously, rank(T)=rank(TI TIC), since the latter matrix is just a column rearrangement of the former one. Now we are ready to develop our theorem. Page 23 Check the proof of the suffienciency of our theorem, it’s rather straightforward. If this condition is satisfired, then M has full knowledge of all the X(i). So M can solve a series of linear inverse problems. Page 24 The proof of necessity is a little bit complicated. Here’s the only the simplified version of the proof. First we show that to determine a unique sequence of Q􏰇 from V􏰇 , we must have (18). Suppose (18) doesn’t hold, then there exists at least one column of TI that is linearly dependent on the other columns of T. Then there exists a Q with that column nonzero, and satisfies TQ=0. This corresponds to a nonzero input in I, but the output V is zero for all time. Thus this nonzero input cannot be recovered. This contradicts with the hypothesis. So (18) must hold. (Explain these items) Page 25 (Explain these items) Section 5: ConclusionPage 26 I’d like to quickly go over the main point of today’s topic. Page 27 First, we propose a decentralized privacy-preserving algorithm, D-LMaFit, to solve the matrix completion problem. We solve dynamic average consensus subproblem inexactly. We prove the topology-dependent privacy-preserving theorem. It provides a guideline of designing a privacy-preserving network. Page 28 Still we’ve got work to do in the future. (Read items) Page 29 I guess that’s it. Thank you all very much for listening. Now if you have any question, please feel free to ask me. 故事这学期我在中科院数学与系统科学研究院(AMSS)访问。第一次参与这边的讨论班时，我就被惊到了：学生做报告也全程英文，不愧是袁亚湘老师的学生。于是，11月25日，我也在这儿完成了自己第一次的英文学术报告。 报告前3天，我问盛镇醴师兄他们报告前会不会排练，师兄说：“肯定要啊！上次去葡萄牙开会，马士谦师兄已经讲得那么好了，都还又自己私下练习了5、6遍。师兄真的可以做到每句话精确到几秒钟！”太荔枝了有木有TT。 于是我也练习了。果然只有努力了内心才会踏实。在当天的报告中，我不仅不紧张，还在瞅到台下一堆人的专注神情时，心里突然弹幕全开：“哇，这感觉好爽。” 在记录报告之前，插播一段回忆：大三暑假，我参加中国大学生物联网创新创业大赛，正式比赛前一天系里组织答辩练习，我们组讲得一塌糊涂。那一晚，我和向国菲师兄在实验室通宵改幻灯片，准备发言稿，然后一句一句地练习。中途师兄压力太大又累得不行溜出去躲着抽了根烟，回来被我发现了教育了一顿，嗅觉就是这么灵敏没办法。直到凌晨4点，终于觉得还算满意了，两人躺椅子上睡了会儿，当然我被蚊子咬安逸了。早晨7点，寝室开门，两人各自回去洗澡调整状态。9点，开始比赛。不知道为什么突然想起这个，太，美好了。尽管当时觉得真苦逼。 资料【1】有哪些高级的英语表达技巧，让人一听就很地道？]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Math</tag>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[凸优化的一些基础算法]]></title>
    <url>%2F2014%2F11%2F10%2F%E7%A7%91%E7%A0%94%2F2014-11-10-Basic-Algorithms-of-Convex-Opt%2F</url>
    <content type="text"><![CDATA[本文假设读者对凸优化有基本了解，主要归纳一些基础算法，以便查阅。 其中，f，g，h都是凸函数，g是光滑项，h是非光滑项。 Gradient Descent ###Proximal Gradient Conjugate Gradient是介于最速下降法和牛顿法之间的一个方法，它仅需要利用一阶导数信息，但克服了最速下降法收敛慢的缺点，又避免了牛顿法需要存储和计算Hession并求逆的缺点。它是解决大型线性方程组最有用的方法之一，也是解决大型非线性最优化最有效的算法之一。 Newton见牛顿法与拟牛顿法（DFP BFGS LBFGS VLBFGS） Quasi Newton见牛顿法与拟牛顿法（DFP BFGS LBFGS VLBFGS）]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是 P, NP, NP-complete, NP-hard]]></title>
    <url>%2F2014%2F11%2F09%2F%E7%A7%91%E7%A0%94%2F2014-11-09-What-is-NP-Hard%2F</url>
    <content type="text"><![CDATA[相关概念NP-hard（non-deterministic polynomial-time hard） P：能在多项式时间内解决 NP：不能在多项式时间内解决或不确定能不能在多项式时间内解决，但一旦你找到一个解，只需要多项式时间去验证这个解是正确的 NP-hard：如果一个问题是NP-hard，意味着可以将任意NP问题化约到这个问题。如果可以解这个问题，那么可以轻松地解任意NP问题。 NPC：NP完全问题，所有NP问题在多项式时间内都能化约（Reducibility）到某一NP问题，这一NP问题就是NPC问题，即解决了此NPC问题，所有NP问题也都解决了。 资料原文These refer to how long it takes a program to run. Problems in class P can be solved with algorithms that run in polynomial time. Say you have an algorithm that finds the smallest integer in an array. One way to do this is by iterating over all the integers of the array and keeping track of the smallest number you’ve seen up to that point. Every time you look at an element, you compare it to the current minimum, and if it’s smaller, you update the minimum. How long does this take? Let’s say there are n elements in the array. For every element the algorithm has to perform a constant number of operations. Therefore we can say that the algorithm runs in O(n) time, or that the runtime is a linear function of how many elements are in the array. So this algorithm runs in linear time. You can also have algorithms that run in quadratic time (O(n^2)), exponential time (O(2^n)), or even logarithmic time (O(log n)). Binary search (on a balanced tree) runs in logarithmic time because the height of the binary search tree is a logarithmic function of the number of elements in the tree. If the running time is some polynomial function of the size of the input, for instance if the algorithm runs in linear time or quadratic time or cubic time, then we say the algorithm runs in polynomial time and the problem it solves is in class P. NPNow there are a lot of programs that don’t (necessarily) run in polynomial time on a regular computer, but do run in polynomial time on a nondeterministic Turing machine. These programs solve problems in NP, which stands for nondeterministic polynomial time. A nondeterministic Turing machine can do everything a regular computer can and more. This means all problems in P are also in NP. An equivalent way to define NP is by pointing to the problems that can be verified in polynomial time. This means there is not necessarily a polynomial-time way to find a solution, but once you have a solution it only takes polynomial time to verify that it is correct. Some people think P = NP, which means any problem that can be verified in polynomial time can also be solved in polynomial time and vice versa. If they could prove this, it would revolutionize computer science because people would be able to construct faster algorithms for a lot of important problems. NP-hardWhat does NP-hard mean? A lot of times you can solve a problem by reducing it to a different problem. I can reduce Problem B to Problem A if, given a solution to Problem A, I can easily construct a solution to Problem B. (In this case, “easily” means “in polynomial time.”) If a problem is NP-hard, this means I can reduce any problem in NP to that problem. This means if I can solve that problem, I can easily solve any problem in NP. If we could solve an NP-hard problem in polynomial time, this would prove P = NP. NP-completeA problem is NP-complete if the problem is both NP-hard, and in NP. 参考资料【1】What are P, NP, NP-complete, and NP-hard?]]></content>
      <categories>
        <category>学习</category>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown输入LaTeX数学公式]]></title>
    <url>%2F2014%2F09%2F16%2F%E6%8A%80%E6%9C%AF%2FMarkdown-Math%2F</url>
    <content type="text"><![CDATA[Markdown是读写性都非常好的轻量文本编辑语言，这个博客以及世界上许多博客的文章都是用其书写的。但是，在写“科研”博客时，难免会需要频繁地输入数学公式，而Markdown本身并不支持数学公式的输入。但是支持插入LaTex公式。 本文默认我们是会使用LaTeX编辑数学公式的。 解决办法： 将数学公式以图片形式保存，再在Markdown中将其插入。 或者，使用LaTeX在线编辑器，输入数学公式，获得html代码，将其插入Markdown。 步骤： 进入CodeCogs 在盒子里书写公式 在页面下方复制html代码 将复制的html代码拷贝到Markdown里 缺点：Markdown文件的易读性却因此下降了很多。 高级解决方式： 直接使用LaTeX公式，在两个$ 或 $$ 中间的LaTeX数学代码会直接渲染成数学公式，比如n^2 的数学符号样式为 $n^2$ 常用的LaTeX数学公式：$X$ $x$ $\tilde{x}$ $x_{ij}$ $x_0$ $x_1$ $x_2$ $x_3$ $x_4$ $y$ $\tilde{y}$ $f$ $g$ $\tilde{z}$ $i$ $i+1$ $j$ $n$ $n/2$ $fi$ $f{n/2}$ $g_n$ $g_4$ $R{n \times m}$ $U{n \times k}$ $V{k \times m} $ $R{n\times m}\approx U{n\times k} \cdot V{k \times m}$ $u_i \cdot vj$ $r{ij}$ $$ ${ x,\tilde{x}, y, \tilde{y}}$ $T$ $U$ $V$ $R$ $\tilde{U}$ $\tilde{V}$ $\tilde{U} \cdot \tilde{V}$ $L$ $l_0$ $l_1$ $l_2$ $l_3$ $l_4$ $l_c$ $L_{loss}$ $L{sdae} = \frac{1}{n}\sum\limits{i=1}^{n}\left ( x_i - \tilde{xi}\right )^2 + \lambda \cdot \frac{1}{n}\sum\limits{i=1}^{n}\left ( y_i - \tilde{y_i}\right )^2$ $\lambda$ $\lambda_1$ $\lambda_2$ $\alpha_1$ $\alpha = 0.1$ $\lambda_u$ $\lambda_v$ $f_e^{(2)}(X,\omega^+ )$ $\omega^+$ $ T = f_e^{(2)}(X,\omega^+ ) $ $$\omega_0^+ = { (W_i, b_i) | i \in {1,2,3,4}}$$ $$\omega_0^+$$ $$\omega^+$$ $L_{cfm}$ $L{cfm} = \sum\limits{i=1}^{N}\sum\limits{j=1}^{M}(R{ij}-U_i^TV_j)^2 + \lambda_1\left | U_i \right |^2 + \lambda_2\left | V_j \right |^2$ $$\frac{\partial^2 L(U,V)}{\partial U^2} &gt; 0$$ $$\frac{1}{2} \cdot \frac{\partial L(U,V)}{\partial U} = (V_j^2 + \lambda_1E)Ui -R{ij}V_j$$ $$\frac{1}{2} \cdot \frac{\partial L(U,V)}{\partial V} = (U_i^2 + \lambda_2E)Vj -R{ij}U_i$$ $$ \frac{\partial V(w,b)}{\partial w} = T$$ $$ \frac{1}{2}\cdot\frac{\partial L(w,b)}{\partial w} = \frac{1}{2} \frac{\partial L}{\partial V} \cdot \frac{\partial V}{\partial w} $$ $$(U_i^2+\lambda2E) (wT+b)T - R{ij}U_iT$$ $$\frac{\partial V(w,b)}{\partial b} = 1$$ $V = w \cdot T + b $ $R{ij}=0, \varepsilon{ij}=0 $ $u_i, vj, x{ij}$ $r_{ij}$ $r_{ij} \approx u_i v_j = u_i (\omega * fe^{(2)}(x{ij},\omega^+) + \varepsilon )$ $\frac{20000236}{138493 \times 27278} \approx 0.05294$ $1- 20000236/(138493 \times 27278) \approx 0.99471$ $\frac{465564}{138493 \times 27278} \approx 0.00012$ $\left { 2, 3, 4, 6 \right }$ $$x_{ij}=\begin{bmatrix} 0 1 1 1 0 1 0 0 0 0 0 0 \ldots\ldots 0 0\end{bmatrix}$$ $R = \left { r_1, r_2, \ldots, r_n \right }$$P = \left { p_1, p_2, \ldots, pn \right }$$MSE = \frac{1}{n} * \sum{i=1}^{n}(r_i - p_i)^2$ $k$ $f_e^{(n-1)}$ $f_e^{(1)}$ $f_e^{(2)}$ $f_e^{(3)}$ $f_e^{(4)}$ 超参数： $n(l_0)$ $n(l_1)$ $n(l_2)$ $n(l_3)$ $n(l_4)$ $n(l_c)$ $n(l_0)$ $n(l_0)$ $n(l_0)$ $35173 \times 1$ $K\text{-}precision = \frac{1}{n}\sum\limits_{i=1}^{n} \frac{\left | Predict(k \small{|} u_i;J) \bigcap Real(k,| u_i;J)\right |}{\left | Predict(k \small{|} u_i;J) \right |}$ $Real(k \small{|} u;J)$ $\lambda_1=0.1,\lambda_2=0.1$ $$ y = f_{\theta}(x) = s(Wx+b)$$ $$ y = f_{\theta’}(x) = s(Wx+b)$$ $$\tilde{x} = g_{\theta’}(y) = s(W’y + b’)$$ $$\theta = { W, b }$$ $\theta’$ $$x’$$ $$L = ||x-\tilde{x}||^2 + ||y-\tilde{y}||^2$$ $\xi = e^{-9}$ $\xi$ $\Delta U{ik} = \alpha \cdot \frac{\partial L}{\partial U{ik}}$ $\Delta w{jk} = \alpha \cdot \frac{\partial L(w,b)}{\partial w{jk}}$ $\Delta b{jk} = \alpha \cdot \frac{\partial L(w,b)}{\partial b{jk}}$ $\Delta U &lt; \xi $$ \Delta w &lt; \xi $$ \Delta b &lt; \xi $ $U{ik}^{t+1} := U{ik}^t - \alpha \cdot \frac{\partial L(U,V)}{\partial U_{ik}^t}$ $w{jk}^{t+1} := w{jk}^t - \alpha \cdot \frac{\partial L(w,b)}{\partial w_{jk}^t}$ $b{jk}^{t+1} := b{jk}^t - \alpha \cdot \frac{\partial L(w,b)}{\partial b_{jk}^t}$]]></content>
      <categories>
        <category>技术</category>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>LaTeX</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 0：实际问题]]></title>
    <url>%2F2014%2F09%2F12%2F%E6%8A%80%E6%9C%AF%2FLinux-Problems%2F</url>
    <content type="text"><![CDATA[《鸟哥的Linux私房菜——基础学习篇》 《鸟哥的Linux私房菜——服务器架设篇》 本系列文章分为两部分： 系统学习上面两本书的笔记。 实际中遇到的问题及解决方案，即本文内容。 实际问题1. 建立网络映射 Mac：Finder-&gt;前往-&gt;连接服务器-&gt;输入smb://IPaddress/samba-&gt;连接 Linux：位置-&gt;连接服务器-&gt;“服务类型”选择自定义位置-&gt;输入smb://IPaddress/samba-&gt;连接 2. ssh登陆失败以root身份远程登陆服务器，密码正确，却显示如下警告： 12345678910111213@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the RSA key sent by the remote host is3a:17:4b:6e:62:e6:94:df:09:78:99:90:51:68:18:62.Please contact your system administrator.Add correct host key in /Users/AnyaLin/.ssh/known_hosts to get rid of this message.Offending RSA key in /Users/AnyaLin/.ssh/known_hosts:4RSA host key for 222.195.93.129 has changed and you have requested strict checking.Host key verification failed. 解决方法： 12345vi ~/.ssh/known_hosts #选中最后一条登陆记录，双击`d`删除，按“：”进入末行编辑模式，输入“x”，回车ssh root@222.195.93.129 #再次登陆The authenticity of host '222.195.93.129 (222.195.93.129)' can't be established.RSA key fingerprint is 3a:17:4b:6e:62:e6:94:df:09:78:99:90:51:68:18:62.Are you sure you want to continue connecting (yes/no)? #输入yes 3. tar.gz 文件解压 打开终端 进入需要解压的xxxx.tar.gz文件所在目录 $ tar xvfz xxxx.tar.gz -C /指定的目录 压缩并打包目录 123tar -czf small.tar.gz small(目录名)tar zcvf backup.tar.gz site/* --exclude=site/attach --exclude=site/images注意 --exclude后面的排除目录后不能带/ ，否则不起作用 ​ 4. 新建文件命令1touch a.txt =======]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matlab科研小贴士]]></title>
    <url>%2F2014%2F09%2F11%2F%E7%A7%91%E7%A0%94%2F2014-09-11-Matlab-tips%2F</url>
    <content type="text"><![CDATA[使用MATLAB运行算法程序时，可能遇到各种各样的报错。比如，为了保护隐私数据，我在分布式矩阵补全算法中加入随机矩阵之后，某项变量在运行几百步之后会出现NaN报错。我只根据算法顺序去分析问题出现的可能原因，并修改程序。感觉并没有很好地利用MATLAB的强大功能去锁定症结所在。幸运的是，施伟大师兄当时和我在一起，他非常热心地帮我分析问题，教我以后遇到类似状况应该怎么去分析与思考。和大师兄讨论了半小时，感觉自己收获不少。 这篇文章会陆续记录下自己使用MATLAB的体会，以及解决问题的一些技巧。 Clear运行一段代码前通常需要将工作空间里的已有数据清除掉。只需要在编辑有实际意义的代码之前写下如下代码： 1clc; clear; close all; Random Seed为了保证程序在相同环境下运行以便测试某一个或几个改变对于算法的影响，在使用各种random命令时，需要设定固定种子。这样就不会因为每次随机产生的序列不同而影响程序运行结果。设置随机种子的代码如下： 12345678910%% random seed%seed=round(5000*rand); % use this line if you set a random seedseed=3302; % use this line if you set a fixed seed. 3302 can be replaced by other numbers.fprintf('Seed = %d\n',seed); % print the current seed if exist('RandStream','file') RandStream.setGlobalStream(RandStream('mt19937ar','seed',seed));else rand('state',seed); randn('state',seed^2);end NaNNaN是Not a Number的缩写。当某变量显示NaN时，表示该变量是不明确的数值结果。比如0/0、inf/inf等运算会出现NaN报错。遇到这种情况，首先判断NaN出现在哪一步： 123if isnan(norres) %括号里是变量名。判断norres是否为NaN，若是，则在该步暂停程序。 keyboard;end 再在命令窗里单独查看与该变量有关的其他变量，从而排除正常变量，获知究竟是哪个或哪几个变量出了问题，变为无穷大或无穷小。再检查与这些变量有关的算法。 SaveAs若需要比较各参数对算法性能的影响，通常是在程序中修改参数运行，得到算法收敛精度与迭代次数的曲线图。再根据曲线图反向思考修改哪些参数有效。这个过程需要保存产生的大量图片。可以使用hold on命令将所有虚线画在同一张图上，也可以使用saveas将所有图片自动保存。 123456789%% plotfigure(1)semilogy(1:iter,y_axis(1:iter),'b-'); %b：蓝色。－：线段形状set(gca,'fontsize',12);grid on;xlabel('\fontsize&#123;12&#125;\it Iteration'); ylabel('\fontsize&#123;12&#125;\it Normalized residual');legend('\fontsize&#123;12&#125;\it text'); %text：这条蓝色代表什么hold onsaveas(gcf,'filename','fig') %filename：将图片保存为这个名字。fig：保存为fig格式 保存变量数据的命令： 12save(&apos;filename&apos;)save(&apos;filename&apos;,&apos;variables&apos;) 注意，在使用hold on命令时，应该保留上次程序运行后产生的各种数据。即不能在程序中写类似与clear all之类的清除语句，否则上次曲线图也将被删除。 矩阵规范化已知满秩矩阵A，进行下面操作使其所有奇异值均为1。 12[u s v]=svd(A);A=u*v'; 安装CVX 将cvx压缩包解压 将cvx文件夹拷贝至如D:\MATLAB Programs\Compressed Sensing目录下 在Current Folder窗口中打开cvx文件夹 在Command Window中输入cvx_setup 在MATLAB的File菜单下的set path把此路径加上。 把路径加进去后在file→Preferences→General的Toolbox Path Caching里点击update Toolbox Path Cache更新一下 完成 %%分段运行程序 选中%%分段 右键选择evaluate current section]]></content>
      <categories>
        <category>学习</category>
        <category>Matlab</category>
      </categories>
      <tags>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态一致平均问题算法-EXTRA和DAC]]></title>
    <url>%2F2014%2F08%2F31%2F%E7%A7%91%E7%A0%94%2F2014-08-31-Papers-about-average-consensus%2F</url>
    <content type="text"><![CDATA[EXTRA DAC 优缺点比较其中，DAC最大的缺点在于第一次迭代时对于r(-1)时刻的依赖，在实际仿真中，如果需要对动态输入求一致平均，往往并不能获取输入在-1时刻的值。导致在矩阵补全问题中，DAC做不精确的动态一致平均的子问题效果并不好。 而EXTRA却有很好的效果。]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于一致平均问题的理解]]></title>
    <url>%2F2014%2F08%2F22%2F%E7%A7%91%E7%A0%94%2F2014-08-22-Average-Consensus%2F</url>
    <content type="text"><![CDATA[最近几个月在研究分布式低秩矩阵补全的问题，参考文章《低秩矩阵补全》。 低秩矩阵补全问题的各类算法中，很关键的一个子问题叫做一致平均问题(Average Consensus)，而上一篇文章并没有对这个问题进行说明。那么，什么叫做“一致平均”呢？ 问题阐释：考虑一个有个节点的网络，每个节点上存储一个关于自己的数值信息，叫做初值。一致平均问题就是使所有节点在算法停止的时候收敛到个初值的平均。 在分布式算法中，通常会存在这样一个变量，它作为公有信息在网络中传递，每个节点储存自己的。在总算法的每一次迭代中，每个节点接收自己邻居节点传递过来的公有信息，然后与自己的私有信息共同计算出新的公有信息，并传给自己的邻居。我们需要保证每个节点上的公有信息，使分布的算法以某种方式交流合作，以便获得最优解。这就是分布式算法中的一致平均问题。 问题分类：根据节点上的数值信息是否随时间变化，又把一致平均问题分为： 静态一致平均 (Static average consensus) 动态一致平均 (Dynamic average consensus) 顾名思义，静态一致平均指节点上的初值不会发生变化，只需要保证最后每个节点都收敛到个初值的平均值即可；而动态一致平均则是，节点上的数值不断发生变化，即在时刻的值并不一定与0时刻的值（初值）相同，我们使用不断变化的公有信息（因为公有信息不断在被更新），仍需要保证最后每个节点都收敛到个初值的平均。相比于静态一致平均，动态一致平均问题更为棘手。 求解方法分类：在文章《低秩矩阵补全》的最后，提供一种求解方法的分类概念，将方法分为： 精确一致平均 (Exact average consensus) 不精确一致平均 (Inexact average consensus) 这又是什么意思呢？ 在解决分布式低秩矩阵补全问题的时候，我们将算法分解两个子问题不断求解，一是交替极小化(Alternating minimization)得到每个节点的新的,；二是在网络中对个节点的求一致平均。对于第二个子问题，在每一次算法总的迭代中，都去求解精确的一致平均显然能够解决问题，但是因为一致平均也需要一定次数的迭代才能被解除，如果在总算法的每一次迭代中都去求精确的一致平均，则相当耗费计算资源，增加了算法的时间复杂度。 很自然地，我们会想到，既然一致平均只是矩阵补全的一个子问题，我们是不是可以通过某种松弛，来降低算法的时间复杂度并节省计算资源，同时仍旧保证总算法的收敛呢。这样，就提出了不精确的一致平均。 不精确一致平均，就是在每一次求解一致平均子问题时，只迭代一次或者若干次，而不是迭代所有次（可以很大），使每个节点近似的达到它们初值的均值。 精确一致平均与不精确一致平均优缺点比较: 精确(Exact)求解：理论上容易证明，但计算代价通常比inexact方法高 不精确(Inexact)求解：理论分析上不好证明，除此之外具有exact不具有的所有优点，比如算法时间复杂度低，节省计算资源等等。]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Mac上通过Sublime、Skim编辑LaTeX]]></title>
    <url>%2F2014%2F08%2F10%2F%E6%8A%80%E6%9C%AF%2FLaTeX-use-with-Sublime-and-Skim-for-Mac%2F</url>
    <content type="text"><![CDATA[Sublime Text是一款非常优秀的编辑器，速度快，界面简洁，插件众多。并且能跨平台使用，在Mac和Windows上都能完美使用。虽然是一款付费软件，但作者很厚道地给了无限期的试用期限。这一切正如其官网广告词说的那样：The text editor you’ll fall in love with. Skim是一款免费轻量的PDF阅读、标注工具，布局贴心友好，与OS X自带的Previewer相比，Skim能更好的注释PDF文件。 LaTeX是一款权威的科技论文排版软件，不仅可以写论文，也可以处理日常的各种文档工作，甚至是做幻灯片。相比于Word，LaTeX最大的优势是对于复杂公式的编辑与排版非常漂亮。并且用简单的命令就可以生成脚注、索引、目录和参考文献等复杂的结构。这一切优点都使得世界上众多的“科学家”们不再需要身兼作者与排版工两职，从而将更多的精力集中于文章内容本身。 本文的目的是将上述三种软件综合部署在Mac上。完成之后，你将可以在Sublime Text里面进行LaTeX代码编辑，用Skim预览生成的PDF文件。更重要的是，让你觉得，写论文也可以是一件很优美的事。 准备工作： Mac上至少4GB的空余空间 高速的互联网连接 第一步：安装MacTeX 进入MacTeX官网下载MacTeX.pkg文件。文件大约2GB，需要一段时间才能完成下载，趁现在去喝杯咖啡吧。 下载完成之后，双击MacTeX.pkg进行安装。 安装完成之后，会看到许多与TeX有关的程序图标，暂时忽略它们。 第二步：安装Sublime Text 进入Sublime Text官网下载最新版本的Sublime Text。这里我下载的是Sublime Text 3. 下载完成之后，将文件拖入应用程序文件夹安装。 第三步：在Sublime Text中安装Package Control我们需要在Sublime Text中下载插件以便能够很好地操作与LaTeX有关的文件。而插件是通过Package Control下载的。 进入Package Control官网复制灰色区块的代码。 打开Sublime Text。 使用快捷键“control+~”（~就在Esc键的下方）打开控制面板Console。你会在Sublime Text的底部看到弹出一个白色窗口。 将刚才复制的代码粘贴到控制面板。 按下“Enter”回车键。然后退出并重启Sublime Text。 第四步：安装LaTeX Tools Sublime Text重启后，按下“Command+Shift+P”打开命令托盘Command pallet，这一步也可以通过Tools下拉菜单完成。 在命令托盘里输入“Install Package”，按下Enter回车建。 完成之后，输入“LaTeX Tools”，找到这一项并回车安装。 退出并重启Sublime Text。 第五步：安装Skim 进Skim下载Skim并安装 打开Skim，在菜单栏中Skim &gt; Preference(选项) &gt; Sync(同步) 在预设菜单中选择Sublime Text 关闭上面这个窗口。 全部完成，✌️现在，我们已经做完了所有的步骤，可以打开Sublime Text，Command+N新建文件并在里面编写LaTeX代码了，完成编辑之后，Command+S保存文件，Command+B编译并运行，这时就可以在Skim里面看到PDF预览了。]]></content>
      <categories>
        <category>技术</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>LaTeX</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各类范数]]></title>
    <url>%2F2014%2F07%2F27%2F%E7%A7%91%E7%A0%94%2F2014-07-27-norms-of-vector-and-matrix%2F</url>
    <content type="text"><![CDATA[转载 向量范数 矩阵范数 矩阵乘积的迹 特殊范数 矩阵W的L2-1范数： TV范数||L(x)||_1。 其中L是差分算子，x是某种数字信号，在一维情况下，如下所示： ||L(x)||_1 = |x2-x1| + |x3-x2| + |x4-x3| + …… 加TV范数的目的是为了使求得的去噪信号仍然具有分段连续的性质。因为差值的1范数说明差值稀疏，从而说明求得的信号分段连续。]]></content>
      <categories>
        <category>学习</category>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[低秩矩阵补全]]></title>
    <url>%2F2014%2F07%2F25%2F%E7%A7%91%E7%A0%94%2F2014-07-25-matrix-completion%2F</url>
    <content type="text"><![CDATA[转载 问题描述:如果有这样一个矩阵 矩阵中有部分元素缺失 矩阵的秩相较于矩阵维数来说很小，并作为先验已知 我们希望恢复那些缺失的元素，这个问题就是低秩矩阵补全问题。 思考过程: 需要恢复一个低秩矩阵 直接想法是极小化矩阵的秩但是的优化问题非凸，不好求解核范数是秩的凸近似，所以想到 极小化核范数的集中式算法:求解的集中式算法有很多，比如： singular value thresholding algorithm fixed-point shrinkage algorithm proximal gradient algorithm ADMM 但如果矩阵规模和秩增大，以上算法的计算代价也增大，因为它们都需要求解奇异值分解(SVD)。SVD中求伪逆的步骤运算量大，很耗费资源。因此需要想更好的方法，避免极小化核范数。 极小化分解矩阵之积的集中式方法:将问题写为，其中是对的估计，在元素没有缺失的位置上和的元素相同，,是对的乘法分解。介绍两种求解该问题的方法： nonlinear Gauss-Seidel method nonlinear SOR(Successive Over-Relaxation)-like scheme:LMaFit 其中SOR方法是GS方法的拓展，区别仅在于SOR方法中对于X的更新加了权重，并对权值进行更新。 去中心式算法:当矩阵规模大到一定程度时，集中式算法在计算能力上要求过高，普通计算机也许无法计算。这时，我们需要在由许多普通计算机作为节点组成的网络中运算，这需要实现去中心式计算。去中心式计算式很容易实现的，将,,分别切块放在每个节点上，将作为公共信息在网络各个邻居节点间交换，优化问题形式不变，但需要加上的约束。而这样一个约束就引出了另一个子问题：一致平均(average consensus)问题。 关于一致平均问题的介绍请看： 《对于一致平均问题的理解》 《动态一致平均问题的4篇论文》]]></content>
      <categories>
        <category>学习</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
      </tags>
  </entry>
</search>
